| zfs
| полезняшки

еще раз хочу показат полезняшку

анализируем датасет с рекордсайз 4К


так запускаем бенчмарк
# export BLOCK_KB=4; fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/boot-pool/ds2-"$BLOCK_KB"K/fio.dat  --bs=$(( $BLOCK_KB  *1024 )) --iodepth=1  --runtime=8  --readwrite=randread --numjobs=1  --group_reporting




так можно увидеть удобно какой средний размер иопса с диска
# iostat -d  ada1  1

            ada1 
 KB/t  tps  MB/s 
  4.0   91   0.4 
  4.0   89   0.3 
  4.0   95   0.4 
  4.0   91   0.4 
  4.0   93   0.4 
  4.0   95   0.4 
  4.0   96   0.4 
  4.0   91   0.4 
  4.0   18   0.1 


видно что блокФС лежит на диске единым непрерывным куском 4К по размеру



так можно увидеть сколько запросов нужно зфс сделать чтобы скачать 1 блокФС

# arcstat 1
    time  read  miss  miss%  dmis  dm%  pmis  pm%  mmis  mm%  size     c  avail
16:31:46     7     0      0     0    0     0    0     0    0  457M  681M   500M
16:31:47   196    65     33    65   33     0    0     0    0  459M  681M   489M
16:31:48   265    89     33    89   33     0    0     0    0  459M  681M   489M
16:31:49   273    91     33    91   33     0    0     0    0  459M  681M   489M
16:31:50   274    94     34    94   34     0    0     0    0  459M  681M   489M
16:31:51   291    96     32    96   32     0    0     0    0  460M  681M   489M
16:31:52   284    97     34    97   34     0    0     0    0  459M  681M   489M
16:31:53   276    94     34    94   34     0    0     0    0  460M  681M   489M
16:31:54   280    94     33    94   33     0    0     0    0  460M  681M   489M
16:31:55   145    47     32    47   32     0    0     0    0  458M  681M   490M
16:31:56     7     0      0     0    0     0    0     0    0  457M  681M   491M
16:31:57     4     0      0     0    0     0    0     0    0  457M  681M   493M

проаалиизируем одну строку
    time  read  miss  miss%  dmis  dm%  pmis  pm%  mmis  mm%  size     c  avail
16:31:55   145    47     32    47   32     0    0     0    0  458M  681M   490M


145 это сколько блоковФС и блоковМетаданных в секунду зфс считало либо с диска
либо из АРК\Л2АРК в целом.
47 это сколько запросов небыло в АРК\Л2АРК
32 это процент 47\145
47 показвывает сколько запросов из 145 были запросы именно данных полезных юзеру
тоесть 47 это 47 блоковФС
из чего следует что 145-47 это число запросов к метаданным.
pmis и %pm это число запросов связанных с префетчем.
mmis и mm% это число запросов которых не было в АРК\Л2АРК. так как это 0
то это значит что все метаданные уже были в АРК\л2АРК.
то есть 145-47 были считаны из арка а не с диска.
значит 47 блоков ФС было считано с диска. 

эта таблица нам дает понимание лежат ли метаданные в кешах или они читаются с дисков.
таке оно дает пнимание что на считываение для нас одного блокаФС зфс нужно еще считать 2 блока
метаданных. и хорошо если оги лежат в кеще. тоесть еще раз 
    зфс читает 2 блока метаданных и потом 1 блокФС
если метаданные лежат в кешах то с диска читаются только полезные нам данные



# zpool iostat  1
              capacity     operations     bandwidth 
pool        alloc   free   read  write   read  write
----------  -----  -----  -----  -----  -----  -----
boot-pool   92.0G   836G      0      0      0      0
boot-pool   92.0G   836G     22      0  91.7K      0
boot-pool   92.0G   836G     89      0   359K      0
boot-pool   92.0G   836G     89      0   359K      0
boot-pool   92.0G   836G     92      0   371K      0
boot-pool   92.0G   836G     91      0   366K      0
boot-pool   92.0G   836G     95      0   382K      0
boot-pool   92.0G   836G     95      0   383K      0
boot-pool   92.0G   836G     91      0   368K      0
boot-pool   92.0G   836G     89      0   359K      0
boot-pool   92.0G   836G      0      0      0      0


насколько я понимаю эта команда показывает именно статистику работы дисков.
тоесть здесь zpool показывает нам туже самую стаститику что gstat 
ни об какиах обращениях в АРК тут речи нет. это чисто дисковая статистика.
это аналог gstat или iostat только в своей реализации.
просто показано число иопосов ридов и вратов на диски. толкьо разбивка идет не по дискам
отделным  а по всем дискам сразу суммарно.
правда я незнаю если у нас в пуле есть Л2АРК или SLOG он тоже ихние иопсы сюда сует.
нужно уточнять





а вот приер когда я читаю с 16К рекордсет датасета запросами по 16К
и при этом я вижу вот это 


  # iostat ....

KB/t  tps  MB/s 
 15.8   73   1.1 
 15.0   63   0.9 



что средний азмер запроса меньше чем 16К. 
возникает вопрос почему?

 # arcstat ...


    time  read  miss  miss%  dmis  dm%  pmis  pm%  mmis  mm%  size     c  avail
16:58:56   176    68     38    68   38     0    0     3    2  544M  681M   673M
16:58:57   189    75     39    75   39     0    0     3    2  546M  681M   672M
16:58:58   154    64     41    64   41     0    0     6    6  547M  681M   671M
16:58:59   176    66     37    66   37     0    0     4    3  521M  681M   670M
16:59:00   165    61     36    61   36     0    0     2    1  523M  681M   669M
16:59:01   168    63     37    63   37     0    0     3    2  526M  681M   668M



а вот и ответ видно что    mmis  mm%   ненулеввые. это значит что метаданнных небыло в
АРК\Л2АРК и зфс читал с диска нетолько полезные нам данные но и метаданные.
они по 4К каждый. поэтому  у нас помимо чтения с диска кусков по 16К за ипос с блоками ФС
еще нужно было читать несколько иопс по 4К чтобы считать метааданные. (собсвтено метаданные
читаются чтобы узнать где искать сами данные).  поэтому то у нас средений запрос на чтение
становится меньше чем 16К
возьмем эту строчку

    time  read  miss  miss%  dmis  dm%  pmis  pm%  mmis  mm%  size     c  avail
16:58:56   176    68     38    68   38     0    0     3    2  544M  681M   673M


с диска было считано  dmis=68 блоков данных по 16К и mmis=3 блока метаданых по 4К
поэтому иопсов было 71 а средний размер чтения был (68иопс*16К+3иопс*4К)\(68иопс+3К)=15.5К

