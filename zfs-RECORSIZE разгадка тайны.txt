| zfs
| recordsize

значит коротко.

как работает recordsize.

мы создаем пул. это просто куча блоков. едиснвтенное что мы указываем ashift
то есть типа размер физ блока. тоесть пул это типа куча блоков кажый из которых имеет
размер ashift.(ашифт после создания пула менять никак нельзя)


   # dd if=/dev/urandom of=./file1  bs=1M count=100 status=progress
   # zpool create -o ashift=13  testpool   ./file1

потом на пуле мы создаем датасет.

   # zfs create testpool/ds1


для датасета задется параметр recordsize по дефолту он 128к. и его можно менять в любой момент.


# zfs get recordsize testpool/ds1
NAME          PROPERTY    VALUE    SOURCE
testpool/ds1  recordsize  16K      local

# zfs get recordsize testpool/ds2-128k
NAME               PROPERTY    VALUE    SOURCE
testpool/ds2-128k  recordsize  128K     local


при создании датасета его автмоатом зфс монтиуерует в папку. например датасет testpool/ds1
будет авматомтатом сонтирован в ппку testpool/ds1

так величайшая тайна что дает и что делает и на что влиеет рекордсайз.

значит датасет это уже файловая система. она состоит из блоков файловой системы.
эти блокиФС они в свою очредь состояи из блоков пула тоесть физ блоков уже на дисках.
так вот каждый блокФС он не сам по себе болтается а он принадлжеить файлу.
также в одном блокеФС может лежать толко тело одного файла. тела от двух файлов не моугтут
лежать в одном блокеФС. файл минимально состоит из одного блокаФС. или из многих.
когда мы создаем файл на фС. то зфс под него создает блокиФС на фс.

одна из важных свойств блокаФС в том что он имеет контроьну сумму. (более того после создания
блокаФС ряд других блоков будет иметь обновление контрьльных сумм из за этой контронойо сумммы
чтоттот типа кругогвой поруки или блокчейна.но щас все аткие не об этом)

предположим мы содздаем в начале маленткйи файл с крошечным телом. 
файл с телом 2K.


   # dd if=/dev/urandom bs=2K count=1 of=/testpool/ds1/t10-2k.dat


так вот если запрос на запись меньше чем рекордсайз , тоесть у нас в данном случае
мы просим создать файл и записать на диск 2К данных а рекордсайз на этом датасете равен 16К
ТО зфс создает блокФС равный размеру рквеста на запись то есть зфс созадаст блокФС размером 2К.
как я уже сказал этот блокФС будет иметь контроьну сумму. а это сразу значит то что 
если мы хотим пото считать из этого блокаФС 500байт то зфс по факту прочтет с диска все 2К
потому что ей надо сверить контроьную сумму. но щас не об этом.
итак у нас запрос на запись был 2К а рекордсет 16К и пофатку на диске создася блоакФС 
размером 2К. вроде как пока влияение роекрдсета нулевое.

щас я покажу как узнать сколько блоковФС занимет тело файла и какого они размера

узнаем номер иноды файала

root@:~ # ls -i /testpool/ds1/t10-2k.dat 
13 /testpool/ds1/t10-2k.dat


подтавяем 13

root@:~ # zdb -ddddd testpool/ds1  13
WARNING: ignoring tunable zfs_arc_max (using 88293120 instead)
Dataset testpool/ds1 [ZPL], ID 83, cr_txg 190, 1.51M, 18 objects, rootbp DVA[0]=<0:23bc000:1000> DVA[1]=<0:1410000:1000> [L0 DMU objset] fletcher4 uncompressed unencrypted LE contiguous unique double size=1000L/1000P birth=6980L/6980P fill=18 cksum=0000000f93f567d3:00002b2a7a50fe39:003fc01665b78744:425895997a2152c5

    Object  lvl   iblk   dblk  dsize  dnsize  lsize   %full  type
        13    1   128K     2K     4K     512     2K  100.00  ZFS plain file
                                               168   bonus  System attributes
	dnode flags: USED_BYTES USERUSED_ACCOUNTED USEROBJUSED_ACCOUNTED 
	dnode maxblkid: 0
	path	/t10-2k.dat
	uid     0
	gid     0
	atime	Tue Dec  2 23:02:40 2025
	mtime	Tue Dec  2 23:02:40 2025
	ctime	Tue Dec  2 23:02:40 2025
	crtime	Tue Dec  2 23:02:40 2025
	gen	6980
	mode	100644
	size	2048
	parent	34
	links	1
	pflags	40800000004
Indirect blocks:
               0 L0 0:23b2000:1000 800L/800P F=1 B=6980/6980 cksum=000000f352eca504:0000f4e06e164e31:00a3e91347150fe1:52b1059e6cc79dd1

		segment [0000000000000000, 0000000000000800) size    2K

root@:~ # 


нас интерсует вот это 


               0 L0 0:23b2000:1000 800L/800P F=1 B=6980/6980 cksum=000000f352eca504:0000f4e06e164e31:00a3e91347150fe1:52b1059e6cc79dd1


это зачит что тело файла занимает  1 блокФС
и его размер 800L/800P  , 800 это хекс и это 2048 байт или 2K а  L\P рзамер сжатый и несжатый
так как я откюлчит сжатие на датасете то они совпдаают.

итак мы получили то что блокФС раеально равен 2К



дальше я допиывааю в хвост файла кусок еще на 10K


# dd if=/dev/urandom bs=2k count=5 conv=notrunc of=/testpool/ds1/t10-2k.dat  seek=1

root@:~ # sync
root@:~ # 
root@:~ # 
root@:~ # zdb -ddddd testpool/ds1  13
WARNING: ignoring tunable zfs_arc_max (using 88293120 instead)
Dataset testpool/ds1 [ZPL], ID 83, cr_txg 190, 1.52M, 18 objects, rootbp DVA[0]=<0:23d0000:1000> DVA[1]=<0:1421000:1000> [L0 DMU objset] fletcher4 uncompressed unencrypted LE contiguous unique double size=1000L/1000P birth=7017L/7017P fill=18 cksum=0000000fa1a1b7e0:00002b5cc043ae2d:00401cb9bff7c15f:42ca829d0b9a1467

    Object  lvl   iblk   dblk  dsize  dnsize  lsize   %full  type
        13    1   128K    12K    12K     512    12K  100.00  ZFS plain file
                                               168   bonus  System attributes
	dnode flags: USED_BYTES USERUSED_ACCOUNTED USEROBJUSED_ACCOUNTED 
	dnode maxblkid: 0
	path	/t10-2k.dat
	uid     0
	gid     0
	atime	Tue Dec  2 23:02:40 2025
	mtime	Tue Dec  2 23:05:44 2025
	ctime	Tue Dec  2 23:05:44 2025
	crtime	Tue Dec  2 23:02:40 2025
	gen	6980
	mode	100644
	size	12288
	parent	34
	links	1
	pflags	40800000004
Indirect blocks:
               0 L0 0:23c6000:3000 3000L/3000P F=1 B=7017/7017 cksum=0000060474fadf40:0023fc75d71b86fb:8f5affb5d24496c6:32a797a34a0874db

		segment [0000000000000000, 0000000000003000) size   12K

root@:~ # 


смотрим вот сдюда


               0 L0 0:23c6000:3000 3000L/3000P F=1 B=7017/7017 cksum=0000060474fadf40:0023fc75d71b86fb:8f5affb5d24496c6:32a797a34a0874db



у нас по прежнему 1 блокФС и его размер 3000 тоесть 12288 байт или 12К
пока что как видим рекордсет вообще нихуя не влияет.
еще можно замтетить что  изменился физ адрес этотго блокаФС 0:23c6000:3000
это потому что зфс каждый раз когда ей нужно модифициоровать блокФС она его немодицифирует 
там где он лежит она его читает (с диска либо в кеше держит) модифицрует в памяти и 
пишет в асолютно новое место на диске. (тот самйы COW).
тоесть блок фм у нас перместился. и он подрос в размере. 
теперь я добавлю к хвосту файала еще 8КБ


root@:~ # dd if=/dev/urandom bs=2k count=4 conv=notrunc of=/testpool/ds1/t10-2k.dat  seek=6
4+0 records in
4+0 records out
8192 bytes transferred in 0.000466 secs (17588344 bytes/sec)
root@:~ # 
root@:~ # sync
root@:~ # sync
root@:~ # 
root@:~ # 
root@:~ # zdb -ddddd testpool/ds1  13
WARNING: ignoring tunable zfs_arc_max (using 88293120 instead)
Dataset testpool/ds1 [ZPL], ID 83, cr_txg 190, 1.55M, 18 objects, rootbp DVA[0]=<0:23e2000:1000> DVA[1]=<0:1433000:1000> [L0 DMU objset] fletcher4 uncompressed unencrypted LE contiguous unique double size=1000L/1000P birth=7074L/7074P fill=18 cksum=0000000f047de299:000029038003b913:003b9e4e205b3cf3:3d0e4313cf6deaa3

    Object  lvl   iblk   dblk  dsize  dnsize  lsize   %full  type
        13    2   128K    16K    40K     512    32K  100.00  ZFS plain file
                                               168   bonus  System attributes
	dnode flags: USED_BYTES USERUSED_ACCOUNTED USEROBJUSED_ACCOUNTED 
	dnode maxblkid: 1
	path	/t10-2k.dat
	uid     0
	gid     0
	atime	Tue Dec  2 23:02:40 2025
	mtime	Tue Dec  2 23:10:30 2025
	ctime	Tue Dec  2 23:10:30 2025
	crtime	Tue Dec  2 23:02:40 2025
	gen	6980
	mode	100644
	size	20480
	parent	34
	links	1
	pflags	40800000004
Indirect blocks:
               0 L1  0:23da000:1000 20000L/1000P F=2 B=7074/7074 cksum=0000008bb9bd8221:0001ff73246872b9:03aadfe08b479c16:80740a4dbc9597aa
               0  L0 0:2388000:4000 4000L/4000P F=1 B=7074/7074 cksum=000008010dd8a54e:00401098b5898283:54e0236f49217909:9971fcb0feb2596d
            4000  L0 0:238c000:4000 4000L/4000P F=1 B=7074/7074 cksum=000001fc23bf5543:001bbf807b4b7312:c3568e70535d4bbf:2fb7e023ba479c16

		segment [0000000000000000, 0000000000008000) size   32K

root@:~ # 


и вот что мы имеем.


вот этот блок

               0 L1  0:23da000:1000 20000L/1000P F=2 B=7074/7074 cksum=0000008bb9bd8221:0001ff73246872b9:03aadfe08b479c16:80740a4dbc9597aa


это блок метаданных. он тело файла несодержит.



а вот это два блока уже с телом файла

               0  L0 0:2388000:4000 4000L/4000P F=1 B=7074/7074 cksum=000008010dd8a54e:00401098b5898283:54e0236f49217909:9971fcb0feb2596d

            4000  L0 0:238c000:4000 4000L/4000P F=1 B=7074/7074 cksum=000001fc23bf5543:001bbf807b4b7312:c3568e70535d4bbf:2fb7e023ba479c16



так вот ревлюционно важно тут заметить вот что. размер этих двух блоков  4000L/4000P
это 16384б или 16КБ. ТОЕСТЬ здесь наконец поялкется РЕКОРДСАЙЗ.
зфс вот что делает. оно расширяет наш первый блокФС но кактолько его рзмер ставновится
равен рекордсайз то зфс создает +1 блокФС  И!!! что еще очень важно что несмря на то что
у нас оставлся хвстик размером всего 4КБ записать зфс созает блокФС строогого размером
как рекордсайз. тоесть елси она нам раздешелаал страдат хуйней в плане размера блокаФС
пока наш файл был всего один блокФС то рарешалось его иметь меньше чем рекодрсайз
но как только файл стал занимать два блока больше такой хуйни она не потерпить.
теперт кждый новй блокФС будет сразу занмиать рекодсайз в данномл случае 16КБ.
есди мы и адьше прдолжим расширять файл то зфс будет набивать до отказа второй блокФС 
кактолько он закнчится то добавить трейтий блокФС итак далее.

это нам дает то что если файл на датасете занмиает 2 и болше блокаФС то он ханится на 
датасете СТРОГО В ВИДЕ мноества блоковФС КАЖДЫЙ ИЗ КОТОРЫХ РАВЕН РЕКОРДсАЙЗ.!!!

отсюда проситуеааю очень много посделедствий.
щас раскажу.

а пока еще вот что замечу.
положим что мы изменили размер рекоордсета. и дальше прододжвает расширять хвост файла нашего
. возникает вопрос. какого размера будут новые блокиФС для этого файла. причем тутже хитро.
мы можем заменят контент файла в тех болкахфс которые уже есть. а можем расширсять размер
файла. в люобом случае как мы помним у нас зфс новые версии этих блоков будет писать в новое
место. так вот вопрос - какогор размера будут этиблоки фс в связи с новым рекорд сайзтом.
ТАК ВОТ Я ПРОЕРИЛ   - походу зфс когда она создает файл он а там гдето запиывает какой бы
на тот момент рекдрдсет. и дальше внезаисимости от того как меняется рекордс сет на
датасете для данного файла нихуя ничего неменяется. тоесть если я будут писать новый
контент в офссеты файла под котоыре уже выделены блокифс то зфс будет их писать в новом
месте но размер их будет поп режнему 16К. и если я будут рашиять хвост файла тоесть 
зфс будет увелчивать число блоковФС для этого файла то они оже будут разером 16К.
( влсучае замены контенат файла в болкахФС котоыре уже есть. грубо говоря порядковый номер
блока не меняется. да он пишеся в новое место на диске с новым контенотом но его пордковый
номер неменяется. и его размер тоже неменяется. еси я расширяю хвост файла то создается 
новый по порядку блок и конечно в новом месте и у неготоже будет размер 16к).поэому
меняей неменяй рекордсайз  этоникак не вляет на закон о том в каких блокафс какого размера
будет хранится его тело. оно будет харнится строгого кусками того рекордсайза который был
когда его создвавали. новый рекдрайз влияет тлкольк на новые с нуля создваемвые при нем
файлы!



а теперь последствия этого пзидеца.


что дает рекордсайз. 
так как блокФС имеет контрольуную сумум. тоесли нам нужно прочиать кусоочк из блокаФС
то по факту с диска будет считан весь блок. чтообы сверить контрльную.сумму.
тоесть зфс небудет читать  часть блока ради нас. она будет читать всесь блок целиком!


если нам нужно заменит кусочек в блокФС то его нужно считать в памят. модфиицовать 
и обтртано записать.


если мы говоирим про шпиндели то у нас при записи новой версии того же блока
из за COW зфс пишет его в новое место на диске. поэтому у нас файл на диске 
чем болше мы в него пишем то он все болше разбросан по диску кусками рвынми рекордсайз!!
потму если мы хотим его прочитать линейно скажем то чем длинее рекордсайз тем болше 
данных мы можем считать линейно за один присест (это критчино если диски шпиндельные
которые хуево работают на рандомнюу нагрузку).
тоесть оцени. если файл разброасн по диску кусками 4К то нам придется его собирать по 
диску укскми по 4к.и насколько веселее если файл разбросан по диску кусками по 128К или
даже 1М кускамми. тоестьвот на это влияет рекодрсаайз тоже осбенно это важно на шпиндеьных
дисказжъ.



вот у нас на диске есть файл который харнится на нем кусками по 128К.
мы хотим считать из файла кускочки по 4К. каждый такой кусочек входит в состав одного
или двух блоковФС и так как зфс должен сверить контрльную сумму то он считает с диска
либо 128к либо 2х128к. тоесть вместо 4К ядро считчает 128К или 256К тоесть рид амплифи
кешен будет либо x16 либо x32
и прблема здесь вот в чем. так как блоки входящие в блокФС физичеки лежат рядом друг с 
другом тодаже со шпиндельногого диска нетакая большая разница проитать 4К блоков лежащих
дярядом илли 128К но! у нас при этом забивается срупут канала по котрому поключен диск.
условного говоря. канал 600МБ. значит по нему можно прочитать кусочков 153600 штук по 4К
но по этому же каналу можно прчотать кусочков размером 128К всего 4800
чустуешь разницу!?!?!?!? тоесть нам нужны куски по 4К и если бы они были записаны 
релаьно кускаи по 4к мы бы полуили 153 600 ипосов. но так как у нас 4к куски запиааны
на фм как куски по 128К то мы сможем прочиатьт и поулчит всего 4800 ипосов. тоест это
охуеть как меньше. чисто изза рид ампилфииукейшн.



тоже самое про врайт амплиивфкейшн.
если у нас файл лежит кускми по 128К а мы хотим поменять тот там то здес кусочки по 4К
то для этго зфс должен счиатть с диска кусок 128к ам ожет даже два куска по 128К
модцифирвать их и записать обратно этот один или два куска по 128К
тоестьтту мы имеем во первых соврещенно ненужный рид да еще огромный. а потом еше
огромнй врайт амплификейшн! это все охует как убьет иопсы.


в чем прикл если звять и просто поставить рекодрсаайз 4К.
ну тогда зфс пртдтся обрабывать уже херову тучу этих блоков в плане контрльных сумм
и так далее ( это как двигать по сет стеку ядра 10 пакетов или миллион).
во вторых у нас файлы будут хранится на диске рабросанными микрокусочкаами. 
с точки зреня рандомной напгзруки нам как бы похуй. а вот линейная сокрость чтения 
охеть как просядет на шпинделных дисках. 
лин скорость записи кстаи недолжна просесть. потому что чиаттать нам неао чтобы записааьть.
мы можем сразу писать. и пишутся новые блоки рядышком друг с дуругом линейно на диск
на свободное место.


если у нас есть два дватасета. и мы копируем файл с одного на другой то у нас
зфс должен будет нептсто скопировать блокиФс с одного места на другое а дрлжен будет
переразбить исходный поток на новый поток блоковФС друогого размера. что тоже вобщето ебала.

в принципе бы этот ркекрорд сайз так бы сильно не влияел если бы не COW.

нужнобы давбит больше zdb дампов но нет времени.

вот такое громаожное занчение имеет рекордсайз!!!!




