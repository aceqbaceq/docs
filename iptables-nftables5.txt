| iptables
| nftables


# Логирование ICMP в таблице filter
ebtables -A INPUT   -t filter -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES FILTER INPUT: "
ebtables -A OUTPUT  -t filter -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES FILTER OUTPUT: "
ebtables -A FORWARD -t filter -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES FILTER FORWARD: "

# Логирование ICMP в таблице nat
ebtables -A PREROUTING  -t nat -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES NAT PREROUTING: "
ebtables -A POSTROUTING -t nat -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES NAT POSTROUTING: "
ebtables -A OUTPUT      -t nat -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES NAT OUTPUT: "

# Логирование ICMP в таблице broute
ebtables -A BROUTING -t broute -p ipv4 --ip-proto icmp -j LOG --log-prefix "EBTABLES BROUTING: "

====================================================

на счет LOCAL PROCESS картинки на картинке iptables. 
что это значит. это значит сокет сетевой приложения.


картина такая.


у нас на хосте есть куча L3 сет карточек. в том числе и LO. это неважно каточка
физ и вирт.


       внешний мир

   eth0   eth1    lo   br0
     |      |      |    | 

           ИПТЕЙБЛС


из внешенго мира через эти карты в иптейблс поступюат пакеты
так вот к этим картом изунитри памяти линукса могу быт подвязаны процессы своими сокетами.
например если IP адрес карты eth=192.168.10.10  то процесс1 может привязаться к этой сет карте
указав в коде IP =192.168.10.10 и порт1, тогда я дро создает сокет который подвяазан к этой карте
через порт1




закончил на том то пытассю понять чрез пинг н адвух вириуаокаха про работу иптебйлс и 
свича



   eth0   eth1    lo   br0
   / |      |      |    | 
  / 
 /       ИПТЕЙБЛС
+
+
+

сокет1(порт1)



так вот если пакет прилетел из eth0 и в нем указан dest_port=порт1  
то ипттейблс сканиурет сокеты которые подвязаны к этой карте и находит что сокет имеет 
такой же порт. тогда ип тейблс понимает что этот пакет далее нужно пихнуть не в остащиеся
карты а его нужно пихнуть в сокет1
пээтому пакет в елетев ядро через порт eth0 и попав в иптейлс суется им в сокет1 и там
этот пакет заканчывает свой путь. это накатнке показана как то что пакет заканывате свой
путь на "Local procss"
как пцросс првзется к карте. через

  socket()
  bind(192.168.10.10. port=1234)
  listen()


теперь переходим к свичу


=============================
iatbeks тлоько интерфсы 3 уровня. 
работает с пакетами поэтмоу по мак нету фильтра




лок приоложе -DNAT-....--> inet
             \|/        /\
              |        |
              |        |
              |        |
              \/       |
              br0      |
              |        |
              |        |
              redsocks |



ТУДА

	сокет --- таблица маршутиацзии --- [NAT-OUTPUT(DNAT)] ---[FILTER-OUTPUT] --- 
	         --- таблица маршутиацзии ---[NAT-POSTROUTING(SNAT)] --- сет карта




в NAT-OUTPUT я делаю DNAT 127.0.0.1:3838 или REDIRECT 3838
в [FILTER-OUTPUT]  я делаю -p tcp -to-port 127.0.0.1 3838 ACCEPT


атаблица что я дал раньше  и реальная отичаются!

важно еще то что кодга мы юзаем DNAT, SNAT REDIRECT то это заменяет s_IP d_IP и для 
обратног трафика автоматом идет обратная замена


============================
значит я понял то что иптейблс и нфтейблс это 
набор модулей (код ядра) и юзер спейс уитилиты которые 
суют правила в ядро. 
так вот  я понял то что иптейблс и нфттейблс по своей сути
в итоге работают плюс минус с одними и теми ХУКАМИ в ядре.
в в итоге это значит то что если я задам часть правил 
через иптейблс а другую часть чрез нфтейблс то в итоге
по факту обе гурппы правил попадут в одни и теже хуки.
и в итоге возможен просто напросто конфликт.

а вот как это выглядит на практике.


# iptables-legacy-save
*filter
:INPUT ACCEPT [11031:858636]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [5541:446400]
-A INPUT -p icmp -j LOG --log-prefix "legacy icmp"
COMMIT


# iptables-nft-save
*filter
:INPUT ACCEPT [13036:1010980]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [6643:567260]
-A INPUT -p icmp -j NFLOG --nflog-prefix "NFLOG icmp"
COMMIT


а вот кстати доказтельство о том что iptables-nft имееет
на бекенде своем правила на самом деле засунутые в nftables


# nft list table ip filter
table ip filter {
	chain INPUT {
		type filter hook input priority filter; policy accept;
		meta l4proto icmp counter packets 8 bytes 672 log prefix "NFLOG icmp" group 0
	}

	chain FORWARD {
		type filter hook forward priority filter; policy accept;
	}

	chain OUTPUT {
		type filter hook output priority filter; policy accept;
	}
}

отсюда видно что правила iptales-nft

-A INPUT -p icmp -j NFLOG --nflog-prefix "NFLOG icmp"

конвертруктся в 

		meta l4proto icmp counter packets 8 bytes 672 log prefix "NFLOG icmp" group 0

причем видно что оно ксати конвертруеися в группу 0



итак мы имеем

# iptables-legacy-save
*filter
:INPUT ACCEPT [11031:858636]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [5541:446400]
-A INPUT -p icmp -j LOG --log-prefix "legacy icmp"
COMMIT


# iptables-nft-save
*filter
:INPUT ACCEPT [13036:1010980]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [6643:567260]
-A INPUT -p icmp -j NFLOG --nflog-prefix "NFLOG icmp"
COMMIT


# nft list table ip filter
table ip filter {
	chain INPUT {
		type filter hook input priority filter; policy accept;
		meta l4proto icmp counter packets 8 bytes 672 log prefix "NFLOG icmp" group 0
	}
...


а теперь я запускаю пинг
# ping -4 -c1 localhost -q


и я увижу логи как  в кернел логе
[Fri Feb 14 08:46:45 2025] legacy icmpIN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 DST=127.0.0.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=43619 DF PROTO=ICMP TYPE=8 CODE=0 ID=27347 SEQ=1 
[Fri Feb 14 08:46:46 2025] legacy icmpIN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 DST=127.0.0.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=43620 PROTO=ICMP TYPE=0 CODE=0 ID=27347 SEQ=1 

так и в логе ulogd
Feb 14 08:46:45 debian12-c3 NFLOG icmp IN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 DST=127.0.0.1 LEN=84 TOS=00 PREC=0x00 TTL=64 ID=43619 DF PROTO=ICMP TYPE=8 CODE=0 ID=27347 SEQ=1 MARK=0x0 
Feb 14 08:46:45 debian12-c3 NFLOG icmp IN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 
DST=127.0.0.1 LEN=84 TOS=00 PREC=0x00 TTL=64 ID=43620 PROTO=ICMP TYPE=0 CODE=0 ID=27347 SEQ=1 MARK=0x0 

тоесть это показывает доказывает ту мысль что пакет 
в итоге был обработан и праивилами старого иптейблс
и правилами нфтейблс . почему. потому что как я сказал 
правила от обоих систем в итоге пишутся в одни и теже хуки.


 
==================
пытаюсь понять как работает nftables

для начал
вспомним как устроен iptables.
первая важная штука это ПРАВИЛО. правило характеризуется
условием и действием. пакет прогоняется через правило
если пакет удовлетворяет правилу то к нему применяется действие.
мы еще вернемся к правилам. 

следующая важная вещь это ХУКИ.
в ядре были сделаны ХУКИ.
внутри ядра поток(как автобус) прогонялся по тракту как
по дороге. на этом тракте есть остановки - хуки. на этих
хуках собраны правила. пакет обрабатывается по этим правилам.
когда мы пишем правило то  в конечном итоге оно добавляется
в тот или иной хук. как я понимаю в иптейблс модули ядра
создавали в нем вот такие хуки - PREROUTING, INPUT, FORWARD,
OUTPUT, POSTROUTING
итак еще раз внури ядра пакет прогоняется по хукам. 
внутри хуков размещаются правила. пакет прогонятся через 
эти правила и далее либо он передается в следующий хук
либо уничтожается. 
внутри хуков правила сгруппированы по цепочкам. 
цепочки как бы это ни было забавно имеют такие же имена как
и хуки. тоесть вот имена цепочек - PREROUTING, INPUT, FORWARD,
OUTPUT, POSTROUTING
эти цепочки предефайнд. тоесть они автоматом создаются
системой. 
итак если я хочу чтобы мое правило попало  в определенный хук
то  я должен просто правило засунуть в цепочку с таким же
именем. наприме если я хочу чтобы мое правило попало в хук
postrouting то мне нужно заснуть правило в цепочку postrouting.
мы не можем никак влиять на хуки. их число строго задано.
что касается цепочек  - мы можем создавать свои кастомные цепочки и совать их в хуки. как оьяснить иптейблс в какой хук
сунуть мою кастомную цепочку я скажу позже.
итак мы взяли создали правило, засунули его в предефайнд
цепочку и оно автоматом попало внутрь хука. 
но правила группируются нетолько по цепочкам. 
цепочка определяет в какой хук будет засунуто правило.
но правила сидящие внутри какогото хука различаются по тем
действиям какие эти правила делают. 
для примера возьмем хук OUTPUT.
внутри этого хука находится куча правил которые в него 
попали потому что наши правила мы сунули в цепочку OUPTUT,
из за этого ядро сунули наши правила в хук OUTPUT.

итак мы имеемм


        ХУК OUTPUT
  --------------------
  |  rule1            |
  |  rule2            |  
  |  rule3            |  
  |  rule4            |  
  |  rule5            |  
   --------------------


так вот привила внутри хука делятся по типу действий 
которые они делают.
есть четыре типа действий котоыре правило может делать

  raw
  mangle
  nat
  filter

если мы хотим фильтровать трафик (действие accept \drop)
то это правило относится к типа filter
а если мы хотим делать nat для пакета (действие dnat)
то правило относится к типу nat.
тип действий задается через таблицы. тоесть разные таблицы
в себя могут принять правила котоыре делают только определенные
действия.

таким образом если я хочу создать правило то мне нужно 
для себя ответить на два вопроса:
      в какой хук я хочу засунуть мое правило?
      какой тип действий мое правило будет делать?


если я знаю нужный мне хук - то я знаю в какую цепочку сунуть
правило.
если я знаю какой тип дейсвтий я хочу делать - то я знаю в 
какую таблицу пихать мое правило.

таким образом - что нужно чтобы создать правило:

   нужно задать условие
   нужно задать действие
   нужно задать цепочку
   нужно задать таблицу


толлько задава эти четыре параметры мы можем создать правило.
пример правила:

   iptables -t nat  -A OUTPUT  условие1  -j действие1  


это строка создает правило которое пихается в цепочку output
что в свою  очередь пихает в ядре это правило в хук output.
также у этого правила есть условие1 и действие1
и это правило пихается в таблицу nat это задает тот тип 
дейсвтия которое это правило может делать.


таким образом в иптбейлс такие сущности как

  условие
  действие
  правилами
  хук
  цепочка
  таблица


цепочка в себе содержит правило и действие.
правило суется в ядре в хук. хук это такая точка где ядро
обрабатывает пакеты на основе правил кооторые лежат в этом хуке.
юзер никак не влияет на число хуков и не влияет на то по каким
хукам прогонядтся пакеты. это все жестко закрплено.
все что может делать юзер это пихать праваила в предефайнд 
хуки. как обьяснить ядру в какой хук сунуть правило - для этого
нужно правило сунуть в цепочку которая имеет тоже самое имя
что и хук. внутри хука правила разделяются по тем дествиям
которые правила делают. тоесть внути хука праивла раздедяются
по типу дейсвтий. есть 4 типа дейвтий - raw, mangle, nat , filter. 
есть предейфайнд дейсвтия котоыре разделяются по этим  4 группам. более того приавло относящееся к одному типу которое
всунуто в заданный хук может применять только часть от действий
этого типа. напрмиер правило имеющее тип nat  сидящее внутри  
хука output может только делать DNAT.
а правило тип nat сдящее внутри хука postrouting может делать
только действие SNAT
тоесть действия snat и dnat  относятся к одному типу nat
но внутри каждого хука нельзя применять все действия 
одного типа. а можно применять только субгруппу действий этого
типа.  так вот если у меня правило имеет заданное действие
то я обязан поместить это правло в заданную таблицу. 
таблица обьединяет правила  одного типа действий. 

таким образом я пытался обьяснить в чем смысл таблиц 
в иптбейлс. и в чем смысл цепочек.

еще раз. то в какую цепочку мы сунем правило задает в какой
хук у нас правило в итоге будет записано.
то в какую таблицу мы сунем правило задает тот тип действий
которое правило может в себе содержать.

в конечном итоге ядро берет все таблицы. из них выбирает
правила сидящие в одной цепочке и сует эти правила внутрь 
хука. внутри хука сидят только правила принадлежащие одной
цепочке. все правилла внутри хука принадлежать одной цепочке.
в рамках одной цепочки правила разбрасываются по таблицам
в зависимости от того типа действия которое делает правило



        ХУК OUTPUT
  =======================
  |  _____________      |
  |  |chain OUTPUT|     |
  |  |table raw   |     | 
  |  |rule1       |     |
  |  |rule2       |     |
  |  --------------     |
  |  _____________      |
  |  |chain OUTPUT|     |
  |  |table mangle|     | 
  |  |rule1       |     |
  |  |rule2       |     |
  |  --------------     |
  |                     |
  |  _____________      |
  |  |chain OUTPUT|     |
  |  |table nat   |     |
  |  |rule1       |     |
  |  |rule2       |     |
  |  --------------     | 
  |                     |
  |  ______________     |
  |  |chain OUTPUT |    |
  |  |table filter |    |
  |  |rule1        |    |
  |  |rule2        |    |
  |  ---------------    |
  =======================
  

у нас есть предоерплеленные цепочки но можно создать и свои
цепочки. тогда возникает вопрс - как ядру понять в какой 
хук совать эти цепочки. ответ вот какой - мы обязаные из 
предефайнд цепочки сделать JUMP на  нашу кастомную. тогда
ядро понимает в какой хук сунуть нашу кастмную цепочку.

при созлании приавила нам надо для себя опредеить цеопочку
и таблицу. с точки зрения ядра преже всего нужно опреедить
цпочку потому что это задает хук. а потом уже таблицу.
цепчка зависит от хука в окторый мы суем правиало. 
когда мы с хуком(цепокой) опреедлиись то мы должны понять какое
дейсвтие мы хотим делать и это вляет на таблицу. наприме
мы хоитим добавить правило в хук OUTPUT значит

  -A OUTPUT

мы хотим дейлть дейтсвие -j DROP значит по типу это таблицы FILTER. значит

  -t filter  -A OUTPUT ..... -j DROP

а если мы хотим обавить -j DROP дейсвтие в хук OUTPUT 
в кастомуню цеопчку то нужно пойти в таблицу filter 
там создать правло в цепочке OUTPUT на касмную цепочку

  *filter (таблица)
   -A OUTPUT -j VASYA
   ...
   -A VASYA .... -j DROP



выше  я описал как раотае шарманка для потока котырый влетел
в ядро из L3 порта. и тут важно прояснить вот что :
в пакете иптейблс есть четыре утилиты iptabes, ip6tables, arptables, ebtables которые задают четырые группы отдеьных
правил. 
в чем разница этих правил. 
. если пакет влетел в ядро из L2 порта он отправлется на обработку в ebtables правила и нам это все. если пакет влетел в ядро из L3 порта то далее ядро смотрит если протокол ARP то оно его пихает в arptables а если там протокол ipv4 то в iptables правила а если протокол ipv6 то в ip6tables правила.
таким оюразом как я понимаю artabels проверка идет только если
пакет влетел из L3 порта. если из L2 то нет. то идет нарпавление
в ebtables. тоесть iptables\ip6tables\arptables это для трафика
из L3 порта. а ebtales для трафика из L2 порта.
также насколко я понимаю правила из  iptabes\ip6tables\arptables\ebtables
в итоге суются в свои отдельные хуки в ядре. 

когда мы хотим посмтреть правила то софт показыает правила
в итоге срупирование прежде всего по таблицам. а уже 
потом по цепочкам. а считаю что это дебилизм надо было делать
наоброт - групироть их по цеопочкам тоесть хукам. а уже
внтри хука показываьт деление по таблицам.



итак при создании правила в iptales нужно определиться с какого порта влетает трафик в ядро (L2\L3) если это L2 то утилита будет ebtables если это L3 то нужно спросить себя какой проткол , если ARP то утиита arptables если это ipv4 то утилита iptables если это ipv6 то утилита ip6tables

когда мы опрделелились с утилитой пусть это будет iptables 
то теперь надо определиться с  хуком . это задаст цепочку.
далее нужно опрееделится с дейсвтием. это задаст таблицу. тогда все готооово для длбавлеия праивла

iptables -t filter -A forward .... -j DROP

 




ТЕПЕРЬ что стало с этой шарманкой в NFTABLES

здесь при создании правила утилита одна nft для всех
типов портов и трафика. 
далее нужно опреедлится с хуком. хук как раз таки зависит 
от того с какого порта (L2\L3) влетел трафик и какой у трафика
протокол. коггда мы определились с хуком то он напрямую 
укзвыается в правиле. далее нам нужно определится с действием. 
точнее с типом действия. дело в том что разные хуки 
разрешаю только определыенный тип действий. это нам задаст
тип цепочки. имя цепочки может быть произвольное. а вот 
тип цепочки это предефайнд вещь. таким образом в отлиии от 
иптейблс где имя цепочки задавала хук в который помещается
правило то здесь в нфт имя цепочки типа неважно чему равно
зато важно какой тип у цепочки. и задает тип цепочки не 
хук куда будет засунуто правило а  тип дейсвтия которым
правло может в себе содержать ( то что в иптбейлс задвалось 
через имя таблицы). а тип таблицы в котрорую мы помещаем
правило задает не тип действия как это было у иптейлс а заадает
тип порта L2\L3 через который трафик влетел в ядро
или тип порта+протокол.


в иптбейлс в имени цепочки был зашифрован хук.
в имени таблицы был зашифрован тип действий.

в нфтейблс имя цепочки вобще неважно. зато при создании
цеопчки мы укываем хук в который нужно правила пихать из 
этой цепочки. и также при созании цеопчки мы укызваем тип 
дейвтий которые эта цпочка дает делать. а тип таблицы где
лежит цеопчка задает условно протокол трафика. 

то что в ипбтейблс задавлось через разные утилиты в нфттйейблс
задается чрез разные типы таблиц.
то что в иптейблс задавлось через таблицы в нфттейблс
задается через тип цепочки. 
то что в иптбейлс задавлось черз имя цепочки в нфтейблс
задается через свойства цепочки (прямоу указаие хука)



смотрю вот эти правила

--
add table ip nat
add chain ip nat PREROUTING { type nat hook prerouting priority -100; policy accept; }
add chain ip nat INPUT { type nat hook input priority 100; policy accept; }
--
add table ip filter
add chain ip filter INPUT { type filter hook input priority 0; policy drop; }
add chain ip filter FORWARD { type filter hook forward priority 0; policy drop; }


насколко я понимаю все начинается с ПРАВИЛА. это минимальна
единица nftables. 
правило состоит из УСЛОВИЯ и ДЕЙСТВИЯ. 
правило должно входить в ЦЕПОЧКУ. самих цепочек может быть
миллион, но есть всего три типа цепочек :
  
  filter
  route
  nat

если мы суем правило в цепочке такого то типа то это задает
какие ДЕЙСТВИЯ можно делать в этом правиле. например действие
dnat или snat можно применять толко в цепочке которая 
принадлежит цепочке типа nat.


таким образом цепочка это группа правил. если цепочка имеет
такой то тип то это ограничивает какие действия можно в этих
цепочках применять. если я хочу делать действие snat\dnat
я дожлен правило сунуть в цепочку типа nat. если я хочу
делать действие DROP то я должен правило сунуть в цепочку 
типа  filter. 

таким образом цепочки позволяют правла разгруппировать по 
типу действий которые правила делают


каждая цепочка привязываются к ХУКУ. хук это штука которая
жестко задана в ядре. нетфильтер протаскивает пакеты внутри
ядра через хуки. мы на хуки влиять не можем. они жестко
заданы в ядре. так вот цепочка привязывается к хуку. 

на данный ммент в ядре есть вот такие хуки - ingress 	prerouting 	forward 	input 	output 	postrouting 	egress 

далее важно то что внутрь хука нельзя привязать любой тип 
цепочки. нет. в хук output можно привязать цепочки всех 
трех типов nat, filter, route а в хук forward можно привязать
тольк цепочку типа filter

хуки это как бутто остановки на маршруте автобуса. автобус
едет по маршруту и останавивыается на хуках. внутри хуков
записаны цепочки. внутри цепочки есть кучка правил сгруппированых
по типу действий которое делает правило. 


тоесть 
  
        ХУК INPUT
  --------------------
  |  _____________   |
  |  |chain1(nat)|   | 
  |  |rule1      |   |
  |  |rule2      |   |
  |  -------------   |  
  |                  |
  |  _____________   |
  |  |chain1(filter) | 
  |  |rule1      |   |
  |  |rule2      |   |
  |  -------------   |  
  |                  |  
  --------------------




пытаюсь понять то что я вижу.
я вижу четыре правила которые сгруппированы в две таблицы.
таблица это всего навсего споособ разбить правила на разные
кучки. обе таблицы имеют тип ip поэтому в них можно пихать
правила только по обработке ipv4 трафика.
насклко я понимаю в ядре установлена цепочка так назаываемых 
ХУКОВ как показано на этой картинке. так вот как я понимаю
в конечно итоге каждое правило суется в тот или иной хук
на этой картинке. например вот это правило

add chain ip nat PREROUTING { type nat hook prerouting priority -100; policy accept; }

оно сует это правило в хук prerouting. тоесть еще раз - 
в ядре кажое праивло в итоге суется в хук. имена хуков и 
порядок проходждения пакетов через хуки жестко задан заранее.
мы сами создавать хуки не можем. мы можем лишь совать праивла
в эти хуки. если мы засунули неклько правил в один хук
то порядоке прогона пакетов по этим правилам задается 
чрез priority 
тоесть в правиле 

add chain ip nat PREROUTING { type nat hook prerouting priority -100; policy accept; }

задан priotity=-100

наколко  понимаю чем меньше число тем более приоритетеное 
правило внутри хука

============
,  , ,  


NFPROTO_UNSPEC =  0,
	NFPROTO_INET   =  1,    inet,
	NFPROTO_IPV4   =  2,    ip
	NFPROTO_ARP    =  3,    arp,
	NFPROTO_NETDEV =  5,    netdev
	NFPROTO_BRIDGE =  7,   bridge
	NFPROTO_IPV6   = 10,   ip6
	NFPROTO_DECNET = 12,
	NFPROTO_NUMPROTO,

==================
$ cat /proc/net/netfilter/nf_log
...
 2 nfnetlink_log (nf_log_ipv4,nfnetlink_log)

nf_log_ipv4 = что это за модуль?

$ sudo modinfo nf_log_ipv4
filename:       /lib/modules/6.11.11-1-MANJARO/kernel/net/netfilter/nf_log_syslog.ko.zst
alias:          nf-logger-10-0
alias:          nf-logger-5-0
alias:          nf-logger-3-0
alias:          nf-logger-2-0
alias:          nf-logger-7-0
alias:          nf_log_netdev
alias:          nf_log_ipv6
alias:          nf_log_ipv4      ****
alias:          nf_log_bridge
alias:          nf_log_arp

видим алиасы!

и оказывается !
nf_log_ipv4 = nf_log_syslog.ko  ***


 $ lsmod | grep nf_log
nf_log_syslog          24576  26


имеем правила

~$ sudo iptables-save
# Generated by iptables-save v1.8.9 (nf_tables) on Mon Feb 10 20:52:04 2025
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -p icmp -j LOG --log-prefix "[FILTER-INPUT icmp] "
COMMIT
# Completed on Mon Feb 10 20:52:04 2025


запускаю пинг

$ ping -c1 localhost
PING localhost(localhost (::1)) 56 data bytes
64 bytes from localhost (::1): icmp_seq=1 ttl=64 time=0.083 ms

--- localhost ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.083/0.083/0.083/0.000 ms
noroot@debian12-c3:~$ ping -4 -c1 localhost
PING  (127.0.0.1) 56(84) bytes of data.
64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=17.3 ms

---  ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 17.297/17.297/17.297/0.000 ms

но логи dmesg пустые!
потому что иптебйсл приавла для ipv4! а мой пинг для ipv6!



sysctl net.netfilter.nf_log_all_netns=1



# ip netns add mynet

# ip netns  exec mynet ip   link set lo up

# ip netns  exec mynet ip  -c  a sh
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever


# ip netns  exec mynet  iptables -A INPUT -p icmp -j LOG --log-prefix "mynet[FILTER-INPUT icmp] "

# ip netns  exec mynet  iptables-save
# Generated by iptables-save v1.8.9 (nf_tables) on Mon Feb 10 21:02:30 2025
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -p icmp -j LOG --log-prefix "mynet[FILTER-INPUT icmp] "
COMMIT


# sysctl net.netfilter.nf_log_all_netns=1
net.netfilter.nf_log_all_netns = 1


# ip netns  exec mynet  ping -c1 -4 localhost
PING  (127.0.0.1) 56(84) bytes of data.
64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.076 ms
---  ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.076/0.076/0.076/0.000 ms



[Mon Feb 10 21:03:24 2025] mynet[FILTER-INPUT icmp] IN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 DST=127.0.0.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=57780 DF PROTO=ICMP TYPE=8 CODE=0 ID=30049 SEQ=1 
[Mon Feb 10 21:03:24 2025] mynet[FILTER-INPUT icmp] IN=lo OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:08:00 SRC=127.0.0.1 DST=127.0.0.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=57781 PROTO=ICMP TYPE=0 CODE=0 ID=30049 SEQ=1 



# sysctl net.netfilter.nf_log_all_netns=0
net.netfilter.nf_log_all_netns = 0



apt-get install -y ulogd2


	# ip netns  exec mynet  iptables -A INPUT  -p icmp   -j NFLOG --nflog-group 0  --nflog-prefix "NFLOG gr0 icmp"

# ip netns  exec mynet  iptables-save

# Generated by iptables-save v1.8.9 (nf_tables) on Mon Feb 10 21:13:16 2025
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -p icmp -j LOG --log-prefix "mynet[FILTER-INPUT icmp] "
-A INPUT -p icmp -j NFLOG --nflog-prefix "NFLOG gr0 icmp"
COMMIT
# Completed on Mon Feb 10 21:13:16 2025


вмместо ulod можнр заюзать tcpdump -i nflog:0 
ulogd выгоден тем что лог сохранется не в ринге ядра с потерей (хотя системд
это логирует уже гвсегда на диске)


оказалось что нужно ulogd запускат в том сет неймсейсе где  я хочу получат из 
ядра логи иптблейс. потмоу что ulgd связан с ядром ерчерез нетлинк а он 
привязан к сет нейсмейсу!!

вот жта херня
$ cat /proc/net/netfilter/nf_log
 0 NONE (nfnetlink_log)
 1 NONE (nfnetlink_log)
 2 nfnetlink_log (nf_log_ipv4,nfnetlink_log)

 ога вобще никаой роли не играет если я логирую чере з -j NFLOG --group 0
 тоесть через указание группы

получается ulog ужно запускать внутри кажого докер контейнера!



отписаться в интете на счет вопроса "netfilter logs another network namespace"
ибо там нихуя нет

======
полчается что картинка (png) это тракт если модуль загружен.
если он не загржуен то в L2 слое убирается все зеленые таблички (и стрелочки тоже меняются)

по идее одпгрущка модуля дат что что когда пакет идет внути свича то для него 
насильно вызыаются коды иптбейлс как бутто пакет летит внутри ядра а не внутри свича.

поэтому надо чтетко разивачать еси мы видим зеленую табличку в логах - мы щас где 
в ядре или внути свича.


вопрс почему пинг схоста витулки имет однаковый вид с моделем и без. надо понять.
я считаю что катинка неаиавьаная. и то что br0 инетрефйес это как бы два инфтрейса рядом.
один это L3 а за ним идет L2 такой же. br0(l3)-br0(l2) - tap0(l2)

надо для начала понять каковы картнкски схемы для ebtables без br_netfulet. тоест 
схма чистго свича потоа обоаработктич через ebtabels

путь когда у нас tap0 и tap1 и мы без модуля и мы делаем персылку между вм

туда
[EBTABLES BROU BROU ICMP]  IN=tap1 OUT= MAC source = ba:ec:24:5c:80:3b MAC dest = ba:ec:24:5c:80:3a proto = 0x0800
[EBTABLES NAT PREROU ICMP]  IN=tap1 OUT= MAC source = ba:ec:24:5c:80:3b MAC dest = ba:ec:24:5c:80:3a proto = 0x0800
[EBTABLES FILTER FORW ICMP]  IN=tap1 OUT=tap0 MAC source = ba:ec:24:5c:80:3b MAC dest = ba:ec:24:5c:80:3a proto = 0x0800
[EBTABLES NAT POSTR ICMP]  IN= OUT=tap0 MAC source = ba:ec:24:5c:80:3b MAC dest = ba:ec:24:5c:80:3a proto = 0x0800


  пакет влетел в ядро
  через свич порт
  и попал в код свича
  тоест в код
  ebtables

           порт 
   ядро -> tap1 -> 

(код свича код ebtables  [brout brout] - [nat preroute] - (switch deciscion) - [filter forw] - [nat postr] ) 

      порт
   -> tap0 -  ядро

тоеть еще раз

ядро - порт свича -- код ebtables - порт свича - ядро

где код ebtables 

	[brout brout] - [nat preroute] - (switch deciscion) - [filter forw] - [nat postr] 



[свич  ][  l3       ]
tap0 -- br0 -- сокет



                                  filter input 
                                     |
[brout brout] - [nat preroute] - (switch deciscion) - filter forward


если фрейм влетев  в свич должен покинуть его (тоесть вылтеелть через свич порт) то 
такой пакет илет на  filter forward 
а еесли нет то пакет формально остается внутри свича! и он идет на filter input  тоесть
пакет который невылпевыается из свича через свич порт считаетс что он поглощается некоторой
магмческой сущностью внутри свича! 

тоесть как бы схема

 пакет
 
 -----> [tap0    исчазает ]  ---xxxx--- > 
                                из свича ничего не выходит через его свич порты!


пакеты в ходятв в свич но ничего из свича не выхоит! 
такие пакеты идут в filter input

из filter input пакет передается на br0 (l3) для свича это аналог процесса который поглолщает
пакет. вот такой прикол. 


тесть

                                    br0(l3)   
                                     |
                                  [filter input] 
                                     |
[brout brout] - [nat preroute] - (switch deciscion) - filter forward



тоесть для свича порт br0 так как он не свичечый то это аноалог local process ! прикол!
порт br0 не яялется с точки зрения свича свичевым портом. это большой прикол.
как толкьк пак влетает в br0 то он уже поадает в iptables и там все как в оычном ипттейблс

поэтому вот тут внутри свича

(                                        ebtables свич                          )
tap0 -[brout brout] - [nat preroute] - (switch deciscion) - [filter input] - br0


а дальге внутри роутера iptables

(                                        iptables     роутер                     )
br0 - [raw prerouting] - [nat prerouting] - (route decision)
                                                  |
                                            [filter input]
                                                  |
                                            [nat input]
                                                  |
                                              local process
                                              или ядро


если у нас принимаюей стороной яявлсят ядро то ему ненужено чтобы поток входил из lo
а вот если примающей сторнй явлется юзер прога то для нее поток должен войти только из lo

так как у нас принмиетядро то пэтому для него пакет влетвеший в иптбейлс из br0 ненужно 
дполениетльно прогонять через lo можно сразу в ядро

[RAW PREROUTING icmp] IN=br0 OUT= MAC=f6:72:b2:f6:dd:ce:ba:ec:24:5c:80:3a:08:00 SRC=172.16.10.11 DST=192.168.62.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=4658 DF PROTO=ICMP TYPE=8 CODE=0 ID=45311 SEQ=1 
[NAT-PREROUTING icmp] IN=br0 OUT= MAC=f6:72:b2:f6:dd:ce:ba:ec:24:5c:80:3a:08:00 SRC=172.16.10.11 DST=192.168.62.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=4658 DF PROTO=ICMP TYPE=8 CODE=0 ID=45311 SEQ=1 
[FILTER-INPUT icmp] IN=br0 OUT= MAC=f6:72:b2:f6:dd:ce:ba:ec:24:5c:80:3a:08:00 SRC=172.16.10.11 DST=192.168.62.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=4658 DF PROTO=ICMP TYPE=8 CODE=0 ID=45311 SEQ=1 
[NAT-INPUT icmp] IN=br0 OUT= MAC=f6:72:b2:f6:dd:ce:ba:ec:24:5c:80:3a:08:00 SRC=172.16.10.11 DST=192.168.62.1 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=4658 DF PROTO=ICMP TYPE=8 CODE=0 ID=45311 SEQ=1 

поэтмоу у нас OUT=пусто везде

забавно как у нас вутри свича проходит поток по свичу если свич получил пакеты не через l2 порт
а из local process ( имеется ввиду из br0(l3))


          br0  -  [FILTER OUTP] - [NAT OUTPUT ] - [ NAT POSTR ] - tap0



рисую полуную схему внутри свича



                                            br0(l3) - [filter outp] - [nat output ] -   
                                              |                                     |
                                        [filter input]                              |
                                              |                                     |
tapX -[brout brout] - [nat preroute] - (switch deciscion) - [filter forward] - [nat postr]  - tapN


tapX и tapN это два L2 порта свича. br0 это аналог local process это l3 порт. с точки зрения
свича пакеты котоыре летят туда это пакеты не покидающие свича! пакеты которые поступают 
оттуда это пакеты влетающие в свич изнутри свича!(а не из внешнего мира)

теперь наконец когда стало понятно что внутри свича иде а что снаружи. и куда относистя br0 порт
остается вопрос - акуратно понять какие цепочки иптейблс добавляютсв внутри свича при активаации
модуля br_netfilter


посмотрим на тракт для форвард свич  трафика

 tap1 --- свич -- tap2

тоесть у нас было


tapX -[brout brout] - [nat preroute] - (switch deciscion) - [filter forward] - [nat postr]  - tapN


а станет




тепрь посморим как поменятая прохот трафика который вытекает из br0 внутрь свича
оказыается никак не поменяется
поэтому в итоге мы имеем внутри свича будет во такое



                                                                                  br0(l3) - [filter outp] - [nat output ] -----------------   
                                                                                    |                                                     |
                                                                             [filter input]                                               |
                                                                                    |                                                     |
tapX -[brout brout] - [nat preroute] - [RAW PREROUTING ]-[NAT-PREROUTING] - (switch deciscion) -[filter forward] - [FILTER-FORWARD ] -[nat postr] - (если трафик прилетел не из br0 то [NAT-POSTROUTING ]) - tapN



ЕЩЕ ВАЖНО! ОЧЕНЬ ВАЖНО! в этоих цеопках еще есть шаг conntrack.
это дает то что если в таблцие коннтрак уже есть запись то тогда все iptables nat цепочки тут
же аннулируются на тракте и он их не проходит! поэтому в этимх случая внутри свича цеопчки
[NAT-PREROUTING] и [NAT-POSTROUTING ] будут исчезать из тракта 


например если пакет влететл в свич из br0  то он по картинке пойдет направо и вниз и в tapN
тоесть он на этом пути зайдет во все цеопчки. 
а потом когда виртуалка пошлет ответный трафик(обратый) то у нас пакет из этого потока но 
обратный и обьявляется слева на кратинке в tapX и идет слева направо по направлению к br0
и на этом пути шаг [NAT-PREROUTING] исчезнет. 
ксатти отличие цеопчк иптбейлс в отличеи от цепочек ebtaves в том что обратый трафк (запись 
о кттором есть в коннтрак) шаги в таблицах NAT исчезают а в таблциах ebbbtables там нет 
нкиакого контрака поэтмоу траиф и туда и оборатно течет строго повсем цеопчкам ebtables. ничего
не исчезает.

вроде бы шаг коннтрак находится перед [mangle-prerouting] а он в свою очередь перед [nat-prerouting]
тоесть

 conntrack - [mangle-prerouting] - [nat-prerouting]

либо 

 conntrack - [mangle-output] - [nat-output]

но так как я таблицу мангл вообще не использую в трейсах то схематиачно тогда 


 conntrack - [nat-prerouting]


 conntrack - [nat-output]


тогда верхняя схема 



                                                                                  br0(l3) - [filter outp] - [nat output ] -----------------   
                                                                                    |                                                     |
                                                                             [filter input]                                               |
                                                                                    |                                                     |
tapX -[brout brout] - [nat preroute] - [RAW PREROUTING ]-conntrack-[NAT-PREROUTING] - (switch deciscion) -[filter forward] - [FILTER-FORWARD ] -[nat postr] - (если трафик прилетел не из br0 то [NAT-POSTROUTING ]) - tapN




именно из за шага conntrack когда летит обратный пакет из вм (из tap0) в br0 то
шаг  [NAT-PREROUTING] пропадает 

шаг [RAW PREROUTING ] меня мало интерсует ибо в этой таблице я на практкие ничего не меняю
но поскольку шаг коннтрак не отображается в логах а из за него исчезает  шаг [NAT-PREROUTING]
либо [NAT-OUTPUT] исчезает то чтобы точно знать что мы проходим это шаг я оставляю шаг 
[NAT-PREROUTING]




помотрим на iptables таблциы теперь


                           _________ LOCAL PROCESS ______
                          |                              |
                          |                          (routing decision)
                          |                              |
                          |                           [output]
                       [input]                           |
                          |                              |
  [prerouting] -> (routing decision) -> [forward] -> [postrouting]
    /|\                                                  |
     |                                                  \|/
    eth0                                                eth1



=================
 ip  link add link DEVICE name NAME type vlan [ protocol VLAN_PROTO ] id VLANID [ reorder_hdr { on | off } ] [ gvrp { on |
              off } ] [ mvrp { on | off } ] [ loose_binding { on | off } ] [ bridge_binding { on | off } ] [ ingress-qos-map QOS-MAP  ]
              [ egress-qos-map QOS-MAP ]



ip link add link vethN1  name vethN1.2  type vlan id 2 

ip  addr add  172.16.100.1/24   scope link dev vethN1.2

ip netns exec ns02  ip link add link vethN2  name vethN2.2  type vlan id 2

# ip netns exec ns02    ip  addr add  172.16.100.2/24   scope link dev vethN2.2



=============

         иптейблс
сокет>|ядро ----- bondV2.2(L3)

                                            [ebtables]
       [  невидимая хня                 ]   [ бридж  ]
bondV2.2 ---- bondV2(L3) --- veth3-1(L3) --- veth3-2 --- tap14



источники пакетов в ядро

 
 socket>| ядро
 L3 port>|ядро
 L2 port>|ядро

тоесть ядро получает пакет нетолько из порта
но и из сокета


ping 172.16.10.11


забвано что на свичах вилан порт это l2 порт 
а вдиуксе порт вилан это L3 порт

socket>|ядро  (L3 правила) --|-> br0

===========
 авот трек когда я с локального серуиса стуу на локлаьнй сервис


  прога-А ---SYN--> прога-Б

[FILTER-OUTPUT REDSOCKS:rule]IN= OUT=lo SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 SYN 

[FILTER-INPUT REDSOCKS:rule]IN=lo OUT= SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 SYN


  прога-А <--SYN-- прога-Б

[FILTER-OUTPUT REDSOCKS:rule]IN= OUT=lo SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 ACK

[FILTER-INPUT REDSOCKS:rule]IN=lo OUT= SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 ACK 


обычно судя по идагармме преед пердоачей пакетв FILETER таблицу ядро смотрит в табл 
маррутиз и прнимает решение окоанчательно чрез ккую сет карту оно бдует в коенчно итоге выплелывать пакет 
в сеть. либо ядро будет выплыетьвы паккет в сокет. да это будет далеко. но уже до входа
в фильтреталицу ядро это решает. поэтому если мы смотрим пакет в этой тбцелице то мы уже 
тчоно видим в гарфе OUT= на кку карту он выстрет пакет. если там пусто это значит что 
пакет будет высран в сокет а не вкарту. 

из этих картинко видно то что. 

[FILTER-OUTPUT REDSOCKS:rule]IN= OUT=lo SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 SYN 


когда прцес-А высрал пакет то в FULTER-OUTPUT видно что 
исходной карты нет. там пусто значит мы вылели из сокета. есть только сорс адрес как ни странно.
зато четко видно что OUT=lo это значит что если наш пакет направлен на локальный сервис то 
он не будет засунут в сокет! входящи в иптебйлс поток от приложения может не имет 
сорс сет карту но он обязательно будует всунуть в сет карту lo  а не в сокет. тоесть такого
не получится чтобы у нас высрать пакет из сокета и засунуть его сразу в сокет!
если мы авсрали пает из сокета то он обязательно удет зансуть в сет карту даже если он 
предазнчен для лоального процеса!
получатся у нас пцроесс высрал пакет  в сокет. он влететл в иптбейлс. и ипбейблс его в итге
сует в lo сет карту. тоесьт как бы в сеть!
значит так как у нас таой тарифик в иготоге суетсвя в карту тто даже если эта карта lo
то полный трафик выгдядт вот так

	сокет -- [NAT OUTPUT] --- [FILTER OUTPUT] --- [NAT POSTROUTING] - сет крата lo

фрмально пакет был высран в сеть.
теперь кода пакет ушел в сеть. то по факту наше яжоро как утто приняо из сет карты lo 
пакетиз сети. и мы начинаем его обрабывать заново в иптбейлс.

значт по идее полны йтрафик для пакета когда он оратно поплал в ядрл из lo бует 
вот такой


надо это все будет провреить
в итоге мы видим


[FILTER-INPUT REDSOCKS:rule]IN=lo OUT= SRC=127.0.0.1 DST=127.0.0.1 PROTO=TCP SPT=52664 DPT=3838 SYN

подвеждене о том что влетел пакет из сет карты lo
и что он будет заснууть в сокет а не в карту  потму что пустой OUT=  


таким образом в приницпе вот он тракст для пакета от лок прложения к лок проожению
ТУДА

	сокет --------- [NAT OUTPUT] ------ [FILTER OUTPUT] --- [NAT POSTROUTING] - сет крата lo
    сет карта lo -- [NAT PREROUTING] -- [FILTER INPUT] ---- [NAT INPUT] -------- сокет

тоесть вот это вот туда оно будет состоять из двух частей
а щее будет тракт ОБРАТНО.
мне кажется он будет выглядеть вот так

	сокет --------- [FILTER OUTPUT] --- сет крата lo
    сет карта lo -- [FILTER INPUT] ----  сокет


самое интеерсно что в коннтракт таблцие удет всего одна запист
а не две

tcp      6 84 TIME_WAIT src=127.0.0.1 dst=127.0.0.1 sport=33318 dport=3838 src=127.0.0.1 dst=127.0.0.1 sport=3838 dport=33318 [ASSURED] mark=0 use=1

хотя в принципе понятно. пакет до того как он уетел в lo имеет паамтерры

src=127.0.0.1 dst=127.0.0.1 sport=33318 dport=3838

и после того как он влетлв в ядрообратно он будет иметь жее самые парамтеры

src=127.0.0.1 dst=127.0.0.1 sport=33318 dport=3838

поэтому запись будет одна






=================
обррватны трфик можно легко разеррешить через conntrack 
иначе нужно кадое обратное равило разершать рукками.
а сам пос ебеобрный трафик разрешене не будет!




путь по таблице NAT для исходящего трафика от локального прилоежения


придлоение ---> OUTPUT ----- POSTROUTING



на первом можно менять только DNAT, на втором можно менять только SNAT




     eth0     wlp2s0
      |          |
    ________________________
    |iptables  и его пакеты |   ---  lo
    -------------------------
      |          |       |
     eth1      br0       |
                         |
                         сокет локального сервиса 




    в иптейбл простарнствао памти пакет может попасть либо из сет карты
либо из сокета в памяти от процесса.  тоесть не всегда за пакетом стоит src сетевая
карта

и получетвот акаой прикол. если за обычной картой стоит сеть. то за картами lo , br0 
стоит софт ядра. поэтому когда в lo или br0 из нащего же ядра влетает пакет
то это выглдяит так как бутто с внешнего мира в наше ядро через карты lo , br0 ктото 
прислал пакет. поэтмоу мы через iptables сует туда пакеыт. и тут же эти пакеты 
начиают заново обраываться через iptabels.  только скажем вот как это выглядт


  iptbales                       iptables
 postrouting  ---> lo   ----->   preroting


   iptbales                       iptables
 postrouting  ---> br0   ----->   preroting


конечный этап рабооты iptables. он сует пакет либо в сет карту. либо в сокет в памяти 
от докального процесса!


каждая цепочка POSTROTUNG , REROTUTING, OUTPUT , INOUT  обрабывает толко одну полвину
трафика тоесть либо строго входящий либо исходящий.  слвоо входящлий исходящий  с точки 
зрени кода иптбейлс. если пакет влетуает вунтрб иптейблс то это входящий а если 
ипбетйбс из себя исторает пакет в сет карту или в сокет приожения то это исходящий.
так вот 

POSTROTING - исходящий
INPUT - исходящий

PREROTING - входящий
OUTPUT - входящий


(поэтмоу навзания ряда цепочек дебилно путащий)

так вот  во исходящрй хцепоках можно менять тлько SRC_IP чрез SNAT
в входящий цеопокчказ можно менять тьтолько DST_IP через DNAT либо REDIRECT

итого

POSTROTING - исходящий  | SNAT
INPUT - исходящий       | SNAT

PREROTING - входящий    | DNAT, REDIRECT
OUTPUT - входящий       | DNAT , REDIRECT


вот  у меня приложение. я хочу у трафика который он из себя высирает поменять dst_ip
тоесть DNAT, REDIERCT. тоесть это входящий трафик.
нао тока понять ОТКУДА он  входит в итейблс  - входит он из локлаьно срвиса. пооэтому 
надо идт и в OUTPUT. 

вот такой прикол для входяещего ттрафика мы ищем ОТКУДА он входит
для исхоядешгго трафика мы ищем ОТКУДА он исходит 

итого

POSTROTING - исходящий трафик НЕ в локальный сервис  | SNAT
INPUT - исходящий трафик в локальный сервис          | SNAT

тоесть (исходящий трафик в локальный сервис) означает что  у данного пакета на данынй
момент dst карточка = пусто. потому что пакет летит прямо в сокета
тоесть (исходящий трафик НЕ в локальный сервис) означает что  у данного пакета на данынй
момент dst карточка = НЕпусто. потому пакет летит из  иптейлс в сет карту


PREROTING - входящий трафик не отлокального сервиса   | DNAT, REDIRECT
OUTPUT - входящий   трафик от локального сервиса      | DNAT , REDIRECT


тоесть (входящий   трафик от локального сервиса) означает что  у данного пакета на данынй
момент src карточка = пусто. потому что пакет влетел в иптейблс прямо из сокета а не из карточки
тоесть (входящий трафик не отлокального сервиса) означает что  у данного пакета на данынй
момент src карточка = НЕпусто. потому пакет влетел в   иптейлс из сет карты


вот тракт сет пакета если он летит из лок сервиса  в инет


	сокет -- OUTPUT --- POSTROUTING - сет карта

а если он летит обратно в ответ то его тракт по идее выглядит как

	сет карта - PREROUTING - INPUT - сокет


это я щас говорил только про цепочки NAT таблицы. а если еще доабвить цпочки FITER 
таблицы то это выдядит вот так

туда		сокет -- [NAT OUTPUT] --- [FILTER OUTPUT] --- [NAT POSTROUTING] - сет карта

обратно 	сет карта - [NAT PREROUTING] --- [FILTER INPUT] --- [NAT INPUT] - сокет


но оказалось это не совсем так. дело в том что все наши таблицы и цеопчки служат для того
чтобы либо пакет отфилтовать либо измнить. так вот для обратного пакета менять его IP 
параетры уже запрещено. он должен быть такой какой он есть. поэтому ВНМИАНИ для обратного 
пакета ядро не прогоняет пакет чреез NAT таблицу вообще! однако оставляет прогон через FILTER
таблцупоэтому обратный путь вылядит вот так


обратно 	сет карта - [FILTER INPUT] - сокет


итого суммарно

туда		сокет -- [NAT OUTPUT] --- [FILTER OUTPUT] --- [NAT POSTROUTING] - сет карта
обратно 	сет карта - [FILTER INPUT] - сокет


я вставил вот такие правиал логирования
таблица nat
*nat
-A INPUT -p icmp  -j LOG --log-prefix "[NAT-INPUT icmp] "
-A OUTPUT -p icmp  -j LOG --log-prefix "[NAT-OUTPUT icmp] "
-A PREROUTING -p icmp  -j LOG --log-prefix "[NAT-PREROUTING icmp] "
-A POSTROUTING -p icmp  -j LOG --log-prefix "[NAT-POSTROUTING icmp] "

талица filter
*filter
-A INPUT   -p icmp --icmp-type 0 -i wlp2s0   -j LOG --log-prefix " [FILTER-INPUT icmp] "
-A OUTPUT  -p icmp  --icmp-type 8 -o wlp2s0  -j LOG --log-prefix " [FILTER-OUTPUT icmp] "


далее я пустил пинг  и вот что я увидел в логах

[NAT-OUTPUT icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8 PROTO=ICMP TYPE=8 
[FILTER-OUTPUT icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8  PROTO=ICMP TYPE=8 
[NAT-POSTROUTING icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8 PROTO=ICMP TYPE=8 
[FILTER-INPUT icmp] IN=wlp2s0 OUT= MAC=80:30:49:b2:85:cf:06:7f:c6:b9:18:cd:08:00 SRC=8.8.8.8 DST=192.168.21.1 PROTO=ICMP TYPE=0

тоесть четко видно что пакет внутри иптейблс туда летел по траектории 
	[NAT-OUTPUT icmp] - [FILTER-OUTPUT icmp] - [NAT-POSTROUTING icmp]

обратно он летел внутри иптейблс по траектории
	[FILTER-INPUT icmp]

вот такой прикол.
что касается обратного пакета то  я разрешил его пролет через во ттакое правило

	-A INPUT   -i wlp2s0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT

это правиало разрешает прием пакетов если пакет принадлежит потоку пакетов о котором уже 
есть запись в таблице conntrack котоаря является таблицей конектов. 
ращберем эту строку у нас после слова INPUT идет набор условий которые провряеются в
пакете. так вот у нас кое что с пакетами в плане анализа может делать сам модуль iptables
модуль ядра вроде бы назвыется ip_tables так вот он может многое но у есть другие модули
ядра которые расияряют умения иптейблс. например -m conntrack или -m tcp это все модули 
с точки зрения иптейблс которые являются некотоыримм модулями ядра но  сдругими именами
вроде бы модуль ядра  xt_tcpudp как раз отвечает за -m tcp с точки зрения иптейблс.
(там уже ногу можно сломать). с точки зрения иптбейлс он свои модуль -m N называется расширения
и об них можно прочиать вот тут 

	$ man iptables-extensions


так вот если у нас в строке не указано нкикого модуля -m N то это значит что строку обрабатывает
базовый код иптейблс. 
прикольно то что если мы укызваем протокол 

  -p name

наример 

  -p tcp 

то иптейблс если нужно автоматом загрузит одноминный модуль сам. НО! это нужно не всегда
например если я напишу

  -p tcp 

то итейблс загрузит модуль -m tcp
а если я еапишу 

 -p icmp

то сам базовый код итейлс обработует эту строку. потому что если я все таки сам напшу

  -m icmp -p icmp 

то меня тут же иптейлс пошлет нахуй потому что если я все таки указал модуль то этот конкретно
модуль требует указать с каким типом icmp я соиараюсь работаь.

также - если я указал модуль это не значит что мне тереперь ненужно укзывать протколк. нужно
еще как

  -m tcp -p tcp 

если я не укзывают модуль то эт знак для иптебйлс что строку нужно орабвыать через баозовй
код иптейблс. а если указал модуль то строку нжно орабывать через мкод мопддуля . в любом
случе нужно укзывать проткол!

так вот в нашем случае

		-m conntrack --ctstate RELATED,ESTABLISHED		

мы юзаем опдуль коннтрак. и укзваем его опцию  ctstate
она обоазнчает статус коннекта. 

 # conntrack -L |  head -n1
tcp      6 431706 ESTABLISHED src=172.16.10.1 dst=172.16.10.11 sport=46896 dport=2080 src=172.16.10.11 dst=172.16.10.1 sport=2080 dport=46896 [ASSURED] mark=0 use=1

вот мы видим  ESTABLISHED 
это свойство конкта! а не отделного пакета. 
пакеты которые имеют 

src=172.16.10.1 dst=172.16.10.11 sport=46896 dport=2080

либо

src=172.16.10.11 dst=172.16.10.1 sport=2080 dport=46896

отностя к днному конекту или потоку. поэтому когда я пишу


	-A INPUT   -i wlp2s0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT


это значит что мы щас раобтаем с пакетом который оказался в цпочке INPUT эта цепочка
после которой пакет суется или неуется в сокет прогармы
мы должны решить пропускать его или нет. 
это сулосвие  -i wlp2s0 требует чтобы пакет прилеет с интерфейса wlp2s0
а это условие -m conntrack --ctstate RELATED,ESTABLISHED  оно третует чтобы 
пакет принадлежал потоку запись о котором есть в тадлцеи коннтрак и чтобы статус
этого потока была либо  ESTABLISHED либо  RELATED
я оставлю вс тороне  RELATED 
я скау жу при ккоаком уловии поток имет атстутстс  ESTABLISHED
иедем в man iptables-extensions

 ESTABLISHED
              The packet is associated with a connection which has seen packets in both directions.

что значит что конект увидел пакет туда и обатно. имется ввиду что ядро увидело пакет
котоырй улетел туда и сответсвущий пакет приелет в ядро обратно.

тоесть наша прога послла туда пакет SYN ядро его высрало в сеть.
оттуа в ядро приелет пакет ACK+SYN ядро его получило и щас оно топчется в INPUT очереди.
приложение его еще не получило. его получило ядро. статус конекта меняется когда пакет 
долетает до ядра! так вот ядро братно получет пакет SYN+ACK при этом сттус конктета ядр
мянетяе на ESTABLISHED  и на оснвое этого даный пакет будет пропущен внутрт приложения!

ест еще флаг ctstatus
это я так понимаю некая субифномацаци я о потоке . более тонкая. поток нужно предлевесе
всего анаизиртвать на оснвое --ctstate а уж потом добавлять если нужно анализ 
на освное --ctstatus


таким оразом вотэта хрень

	-A INPUT   -i wlp2s0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT


вот о чем. у нас ядро получило пакет и снуло его в INUT цепочку. 
он там сидит.  иптейблс егододно либо принять и двигать далге по тракту тоесть ав данном
слулчае в сокет приложения. либо ответргунуть. 
по своей сти INUOT это цпяка для входщено трафика в сторну локального сервиса.
мы его пропстим если пакет прилетел в ипттейлсл из карты wlp2s0 и ели этот пакет 
прианделжит конекту из коннтак таблицы и если статус у это йтаблицы ESTAFBLISHED 
тоесть это если пакет который прилетел в ответ на наш прежде этого посланнйы пакет.
если это tcp то это должен быть ответный SYN, ответный SYN+ACK . на сосом деле это должен 
быть люому tcp пакет ответный на нащ. 

что касется icmp то у него статус в таблице нет нихуя

icmp     1 22 src=192.168.21.1 dst=8.8.8.8 type=8 code=0 id=21 src=8.8.8.8 dst=192.168.21.1 type=0 code=0 id=21 mark=0 use=1

но почум то это првало все равно рабовтает.
как сказа ИИ. если мы полуили ответный пинг в ядро то якобы стту конкетт равен ESTABLISEGEHDD

таким оразом вот ккой сымысла этой сторки в коннтарраркт. именно она разершит влет ответного
пинга на наш комп.


так вот что в итоге тракт туда и обртано с тчоки зрения иптейлс


туда		сокет -- [NAT OUTPUT] --- [FILTER OUTPUT] --- [NAT POSTROUTING] - сет карта
обратно 	сет карта - [FILTER INPUT] - сокет


и вот это в логах

[NAT-OUTPUT icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8 PROTO=ICMP TYPE=8 
[FILTER-OUTPUT icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8  PROTO=ICMP TYPE=8 
[NAT-POSTROUTING icmp] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=8.8.8.8 PROTO=ICMP TYPE=8 
[FILTER-INPUT icmp] IN=wlp2s0 OUT= MAC=80:30:49:b2:85:cf:06:7f:c6:b9:18:cd:08:00 SRC=8.8.8.8 DST=192.168.21.1 PROTO=ICMP TYPE=0










!!!!!<<<<<< оставноился тут 
теперь надо проверить а какой сет тракт есл 
если он летит от одного лок сериса до другого то вот так

	сокет -- OUTPUT --- lo - PRERORUTING -INPUT - cокет  (проверить!!! что именно эти цеопочки)

что инетесно если иптейблс собирается выпюунут пакет в сет карту илил сокет то таблицы идут вот
так 
   FILTER - NAT

а если пакет влетает в иптебйлс то таблицы идут во так 

  NAT-FILTER


проработать проветь цепочки для
 nc --- redsocks --- br0\tap0




приколтаня тема
 [NAT-OUTPUT 443:port] IN= OUT=wlp2s0 SRC=192.168.21.1 DST=74.125.131.102 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=7296 DF PROTO=TCP SPT=46140 DPT=443 WINDOW=64240 RES=0x00 SYN URGP=0 

NAT OUTPUT. траики влетел в иптебйлс из срвиса.
при этмо у нас есть SRC_IP но у нас нет src сетевой картчоки!


===========
чере таблицу nat идет тлько первый пакет из потока. 
также - iptabes он работает на чтобы приять из сет картчоки и всууть в карточку.
если пакет предназнячен для локалногоп приожения то после входа в lo картчоку 
у нас опять будет идти побрабтка через iptales




прога-А ---> сет карта ---> iptabes ---> сет карта

это значит что 

прога-А ---> сет карта ---> iptabes ---> lo  -->  iptabes ---> прога-Б


что еще . запись про сет карту меняется не на стадии изменеия ip адреса  атолько
на стадии загядываения в rotunf тейбл поэтому могут быть типа нелогичные стоки
в логе 

IN= OUT=wlp2s0 SRC=192.168.21.1 DST=127.0.0.1 

тоесть destpi 127.0.0.1 а выходная карта wlp2s0 потому что мы еще не дошли до стадии
принятия решения на счет выходнйо карты


еще момент логирование надо делать до реальных действий

-A REDSOCKS -d 240.0.0.0/4 -j RETURN
-A REDSOCKS  -p tcp --dport 443 -j LOG --log-prefix "[NAT REDSOCKS 443]"
-A REDSOCKS -p tcp -j REDIRECT --to-ports 3838

как только у анс REDIREСЕ то даны пакет сразу покинет эут ттаблцу и этот цопчку поэтому
вот далее вставлять логируююще прваиало


-A REDSOCKS -d 240.0.0.0/4 -j RETURN
-A REDSOCKS  -p tcp --dport 443 -j LOG --log-prefix "[NAT REDSOCKS 443]"
-A REDSOCKS -p tcp -j REDIRECT --to-ports 3838
-A REDSOCKS  -p tcp --dport 3838 -j LOG --log-prefix "[NAT REDSOCKS 3838]" <== **
  

потому что до этого rule уже пакет никогда не попдает. поэтому мы можем уивдтеь как
пакет выгляди до экешена а кк он выгляди после экшена мы уже в этой талице не уидвиим


как экспортиовать правила из nft

% echo "flush ruleset" > backup.nft
% nft list ruleset >> backup.nft
(https://wiki.nftables.org/wiki-nftables/index.php/Operations_at_ruleset_level)




===================
links:

https://wiki.nftables.org/wiki-nftables/index.php/Nftables_families
https://superuser.com/questions/764986/howto-setup-a-veth-virtual-network#
https://serverfault.com/questions/704700/how-can-i-move-an-interface-out-of-a-network-namespace
https://wiki.libvirt.org/Net.bridge.bridge-nf-call_and_sysctl.conf.html
https://unix.stackexchange.com/questions/720105/what-is-the-net-bridge-bridge-nf-call-iptables-kernel-parameter
https://reintech.io/blog/configuring-network-interfaces-debian-12
https://www.snel.com/support/how-to-configure-802-1q-vlan-tagging-on-debian-9/
https://unix.stackexchange.com/questions/381990/network-interface-vlan-static-addressing
https://wiki.nftables.org/wiki-nftables/index.php/Netfilter_hooks
https://datahacker.blog/industry/technology-menu/networking/routes-and-rules/special-routing-use-cases-iproute2
https://datahacker.blog/industry/technology-menu/networking/routes-and-rules
https://wiki.linuxfoundation.org/networking/iproute2
https://lartc.org/howto/lartc.iproute2.arp.html
https://unix.stackexchange.com/questions/579087/whats-the-meaning-of-linkdown-and-onlink-in-linux-route
https://unix.stackexchange.com/questions/87990/linux-as-router-with-multiple-internet-providers
https://unix.stackexchange.com/questions/768760/meaning-of-prefix-length-with-ip-addr-add-noprefixroute
https://unix.stackexchange.com/questions/123084/what-is-the-interface-scope-global-vs-link-used-for/611945#611945
https://serverfault.com/questions/63014/ip-address-scope-parameter
https://unix.stackexchange.com/questions/123084/what-is-the-interface-scope-global-vs-link-used-for
https://www.dilnetpc.com/ebtables-cmd-overview.pdf
https://info.support.huawei.com/info-finder/encyclopedia/en/LACP.html
https://docs.bisdn.de/network_configuration/link_aggregation.html
https://www.uni-koeln.de/~pbogusze/posts/LACP_configuration_using_iproute2.html
https://wiki.archlinux.org/title/Nftables
https://forums.unraid.net/topic/122247-iptables-with-conntrack-does-not-work-correctly-inside-docker-container/
https://bookstack.swigg.net/books/linux/page/netfilteriptable-logging
https://unix.stackexchange.com/questions/704511/linux-packet-mark-across-network-namespaces
https://serverfault.com/questions/1109818/i-cant-enable-ip-tables-logging
https://home.regit.org/2014/02/nftables-and-netfilter-logging-framework/
https://git.netfilter.org/ulogd2/tree/README
https://wiki.nftables.org/wiki-nftables/index.php/Moving_from_iptables_to_nftables
https://wiki.nftables.org/wiki-nftables/index.php/Main_Page#Upgrading_from_xtables_to_nftables
https://www.netfilter.org/documentation/index.html
https://www.mybluelinux.com/how-nftables-log-to-external-file/
https://www.mybluelinux.com/how-nftables-log-to-external-file/
https://git.netfilter.org/ulogd2/tree/ulogd.conf.in
https://workshop.netfilter.org/2013/wiki/images/8/8b/Eric_Leblond_ulogd2.pdf
https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html
https://home.regit.org/2014/02/nftables-and-netfilter-logging-framework/
https://wiki.nftables.org/wiki-nftables/index.php/Main_Page
https://serverfault.com/questions/1109818/i-cant-enable-ip-tables-logging#
https://ebtables.netfilter.org/br_fw_ia/br_fw_ia.html
https://serverfault.com/questions/162366/iptables-bridge-and-forward-chain
https://en.wikipedia.org/wiki/Iptables#/media/File:Netfilter-packet-flow.svg
https://www.systutorials.com/docs/linux/man/8-ebtables/
https://unix.stackexchange.com/questions/108169/what-is-the-difference-between-m-conntrack-ctstate-and-m-state-state
https://superuser.com/questions/1071656/whats-the-difference-between-iptables-state-and-ctstate
https://thermalcircle.de/doku.php?id=blog:linux:connection_tracking_3_state_and_examples#fnt__2
https://stackoverflow.com/questions/242772/using-iptables-to-change-a-destination-port
https://gist.github.com/tomasinouk/eec152019311b09905cd
https://stuffphilwrites.com/wp-content/uploads/2024/05/FW-IDS-iptables-Flowchart-v2024-05-22.png
https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/7/html/networking_guide/sec-configure_802_1q_vlan_tagging_using_the_command_line_tool_nmcli#sec-Configure_802_1Q_VLAN_Tagging_Using_the_Command_Line_Tool_nmcli
https://unix.stackexchange.com/questions/769448/how-to-create-a-linux-vlan-aware-bridge-with-ingress-packets-untagged-and-egress
https://serverfault.com/questions/1110088/why-we-need-different-types-of-base-chain-in-nftables
https://wiki.archlinux.org/title/Nftables

https://wiki.nftables.org/wiki-nftables/index.php/Configuring_chains#Base_chain_types
https://wiki.nftables.org/wiki-nftables/index.php/Quick_reference-nftables_in_10_minutes#Statements
https://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/
https://kb.gtkc.net/iptables-with-ulogd-quick-howto
https://unix.stackexchange.com/questions/704511/linux-packet-mark-across-network-namespaces
https://bookstack.swigg.net/books/linux/page/netfilteriptable-logging

https://devops-insider.mygraphql.com/zh-cn/latest/kernel/network/conntrack/conntrack-troubleshooting/iptables-troubleshooting.html
https://www.linkedin.com/pulse/how-take-iptables-trace-inside-container-syed-miftahur-rahman/
https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?id=2851940ffee313e0ff12540a8e11a8c54dea9c65
https://serverfault.com/questions/691730/iptables-log-rule-inside-a-network-namespace
https://ebtables.netfilter.org/br_fw_ia/br_fw_ia.html
