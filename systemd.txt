systemd
systemctl


проясним вывод команды

$ sudo systemctl list-units 
  UNIT                                                                              LOAD   ACTIVE SUB       DESCRIPTION
  sys-kernel-debug.mount                                                            loaded active mounted   Debug File System
  gssproxy.service                                                                  loaded active running   GSSAPI Proxy Daemon
● kdump.service                                                                     loaded failed failed    Crash recovery kernel 
  kmod-static-nodes.service                                                         loaded active exited    Create list of ...


проясним смысл полей.
во первых колонка LOAD которое равно "loaded".
я скажу так что это поле оно никогда небывает каким то другим. поэтому в целом это поле 
можно 100% игнорировать. это поле мусорное . никакой полезной инфо не несет.
"loaded" означает что systemd прочитала с диска содержимое файла в котором указан конфиг юнита. 
невозможно получить статус отличный от loaded. каждый раз когда мы хотим получить инфо о юните системд читает 
его конфиг в память. поэтому это поле всегда равно loaded. и поэтому это поле можно всегда прлсто игнорировать
оно ненесет никакой абсолютно полезной смысловой нагрузки. еще раз смысла слова "loaded" означает что системд 
прочитала с диска конфиг этого юнита.


далее. колонка ACTIVE и  в ней значения "active" или "failed".
колонка ACTIVE как написано в man systemctl означает состояние юнита в главном генерализованном смысле без деталей.
забегая вперед колонка SUB показывает состояние юнита уже в более конкретном детальном смысле  с подробностями.
если "active" это значит что юнит запущен и щас выполняется в памяти, крутится на цпу. условно говоря если юнит это nginx
то он сидит в памяти и крутится на цпу. 

пример:
$ sudo systemctl list-units | grep -E  "LOAD|nginx"
  UNIT                                                                                LOAD   ACTIVE SUB       DESCRIPTION
  nginx.service                                                                       loaded active running   The nginx 

если колонка равна "failed" это значит что система хотела запустить юнит но чтото помещало и несрослось. юнит сейчас
не выполняется из за ошибки. а вообще то он должен был бы работать. 

из верхнего примера примером такого юнита является kdump

$ sudo systemctl list-units 
  UNIT                                                                              LOAD   ACTIVE SUB       DESCRIPTION
● kdump.service                                                                     loaded failed failed    Crash recovery kernel

итак если колонка ACTIVE = active это знчит что юнит (сервис) щас успешно сидит в системе и выполняется на цпу.сервис
активен и работает.
если колонка ACTIVe = failed это значит что сервис должен был бы работать но чтото пошло нетак и возникла ошибка и сервис
щас из за какойто ошибки неработает.

далее. если колонка ACTIVE в целом показывает нам работает сервис или нет. то колонка SUB дает нам более развернутые 
детали о том что значит сервис раобтает либо что значит он неработает. 

так вот возвращаяесь к команде $ sudo systemctl list-units  = эта команда в итоге нам показывает все юниты(сервисы)
которые щас работают крутятся на системе плюс все сервисы которые должны были бы работать но они неработают потому
что при их запуске произошла ошибка. вот что нам показывает ключ list-units.
это очень важно осознать.



так вот двигаясь дальге у systemctl есть ключ --all.
что он дает. 

$ sudo systemctl list-units --all |  grep -vE " active | failed "
  UNIT                                                                                LOAD      ACTIVE   SUB       DESCRIPTION
  proc-fs-nfsd.mount                                                                  loaded    inactive dead      NFSD 
  proc-sys-fs-binfmt_misc.mount                                                       loaded    inactive dead      Arbitrary 
  sys-fs-fuse-connections.mount                                                       loaded    inactive dead      FUSE Control 

этот ключ --all дает то что помимо юнитов со статусом "active","failed" нам будут показаны юниты со статусом "inactive".
а что значит "inactive"? это юниты которые сейчас незапущены некрутятся на системе! но в отличие от юнитов со статусом "failed"(которые щас неработают внешататно из за какойто ошибки аварии при их запуске)
юниты со статусом "inactive" неработают щас на системе по совершенно легитимной штатной причине - потому что запуск этих юнитов неактивирован, невключен, неуказан, незадан. запуск этих юнитов неактивирован админом этого хоста. 
как так могло получиться - либо данный юнит был остановлен руками сисадмином в какойто момент после старта хоста. 
либо старт данного юнита непрописан при boot системы. итак либо данный юнит остановили руками. либо его старт не прописан 
при загузке системы. но опять же - это незначит что данный юнит никогда незапускается в системе. нет! вот пример:


$ sudo systemctl list-units --all | grep -E "LOAD|certbot"
  UNIT                                                                                LOAD      ACTIVE   SUB       DESCRIPTION
  certbot-renew.service                                                               loaded    inactive dead      This service 
  certbot-renew.timer                                                                 loaded    active   waiting   This is the 

есть юнит certbot-renew.service со статусом "inactive" это значит что прям щас он неработает в системе. он застоплен.
он неактивен. он не исполняется. почему он неисполняется? я скажу - потому что его старт непрописан при загрузке системы.
и есть юнит certbot-renew.timer со статусом "active" он на даннйы момент исполняется на системе. так вот этот таймер 
он периодически срабатывает , и когда он срабатывает то он запускает юнит certbot-renew.service !!! гоча!
поэтому если юнит находится в состоянии "inavctive" это значит что прям щас он застоплен но это незначит что все время как
наш хост работает этот юнит не выполняется. нет. может быть какойто другой юнит который этот юнит регулярно дергает и стартует!
таким образом юнит "inactive" неработает прям щас. именно прям щас. но в какойото другой момент его может запускать другой
юнит!

таким образом когда мы вводим systrmctl с опцией list-units 
то мы просим систему показать нам юниты которые щас работают на системе(active) либо должны работать но нерабоботают из 
за ошибки (failed).

$ sudo systemctl list-units

если мы добавляем опцию --all то мы просим систему нам дополнительно показать те юниты которые прям щас в системе неработают.
неработают они потому что либо их до этого остановили руками, либо изначально их запуск непрописан при boot системы. 
и важно отметить что если эти юниты прям щас неработают это незначит что они никогда неработают на этом хосте. их могут 
в какието моменты времени запускать и стопить другие юниты. это надо исследовать отдельно.

$ sudo systemctl list-units --all


примером такйо связи явлется пара сервисов certbot. сам сервис в системе отключен при старте. но его братец timer
заупущен на хосте. и он периодически запускает своего братца.


$ sudo systemctl list-units --all | grep -E "LOAD|certbot"
  UNIT                                                                                LOAD      ACTIVE   SUB       DESCRIPTION
  certbot-renew.service                                                               loaded    inactive dead      This service
  certbot-renew.timer                                                                 loaded    active   waiting   This is the 


итак если мы хотим увиеть юниты со статусом "inactve" мы должны дбавить ключ --all.
какой вывод мы делаем для себя когда видим юнит со статусом "inavctve" - мы делаем вывод что прям щас сию минуту
этот юнит остановлен. но также мы понимаем что в какйото другой момент этот юнит может запускаться каким то другим
юнитом. и этот вопрос надо исследовать отдельно!

а как исследовать? а я щас покажу.
если мы хотим узнать а когда то на компе вообще стартовал запускался наш юнит то для этого надо просто
попросить journalctl показать логи этого юнита!

$ sudo  journalctl -u certbot-renew.service
-- Logs begin at Вс 2022-10-23 10:11:45 UTC, end at Вт 2022-10-25 19:53:15 UTC. --
окт 23 15:10:34 kvs10-test.8.8.8.8 systemd[1]: Starting This service automatically renews any certbot certificates found...
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: Saving debug log to /var/log/letsencrypt/letsencrypt.log
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: Processing /etc/letsencrypt/renewal/paidsupport.example.kz.conf
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: Cert not yet due for renewal
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
окт 23 15:10:35 kvs10-test.8.8.8.8 certbot[2293]: Processing /etc/letsencrypt/renewal/paidsupport2.example.kz.conf


тоесть мы просто берем тот юнит который нас интересует. и просим journalctl показать логи запуска этого юнита!
и сразу видим что да. данный юнит стартует на системе в какието моменты! amazing!

что интересно - логи самого таймера выглядят очень скромно:
$ sudo  journalctl -u certbot-renew.timer
-- Logs begin at Вс 2022-10-23 10:11:45 UTC, end at Вт 2022-10-25 19:55:05 UTC. --
окт 23 10:48:39 kvs10-test.8.8.8.8 systemd[1]: Started This is the timer to set the schedule for automated renewals.



так. ну еще чуть я добавлю.
$ sudo systemctl list-units --all
  UNIT                                                                             LOAD      ACTIVE   SUB       DESCRIPTION
● sysroot.mount                                                                    not-found inactive dead      sysroot.mount
● tmp.mount                                                                        masked    inactive dead      tmp.mount

порой колонка LOAD бывает равна не "active" а "not-found","masked".
но это скорее внештатные ситуации. "not-found" - означает что системд несмогла прочитать юнит. а masked 
означает что мы руками пометили юнит на запрет запуска.



===========================
как делать маунтинг с помощью systemd когда нужно монтироватьточки  в опреденном порядке
смотри этот вопрос в fstab.txt 
=======

как сделать так чтобы systemd автоматом перезагружал сервис если он упал.
по дефолту и в  этом полный прикол что systemd сука  если сервис упал то он с ним ничего неделает.
чтобы сервис был автоматом загружен если он упал надо делать изменения на systemd.

полузуюсь этой стстьей

https://serverfault.com/questions/840996/modify-systemd-unit-file-without-altering-upstream-unit-file

оказатесячто ест неколькол способов редактивровать systemd юниты.
первый лоховской эьто редактировать их в папках /lib/,,, или /usr/... но 
это плохо потому что обноавление пакета перетрует наши кастомные настройки

более правилный способ это скопироват юнит файл из /lib/ или /usr/.. в /etc/systmd/system и такм редактировать.
тогда обнолвание пакетов неперетрет наши настйорки.

но есть еще более крутой споособ редактирования юнит файлов через drop-ins

создаем drop-in файл:
/etc/systemd/system/[name-goes-here].service.d/config_name.conf

имя файла знаения неимеет имеет значение только имя папки. например для mariadb делаем вот так

/etc/systemd/system/mariadb.service.d/restart.conf

и в него суем конент
[Service]
Restart=always


тоесть

# cat /etc/systemd/system/mariadb.service.d/restart.conf 
[Service]
Restart=always


эти дропины позвяляют менять кусочек в основном файле.

далее надо перезашрущить сам демон systemd

# systemctl daemon-reload

наличие дроп-ин файла можно найти в свойствах сервиса

# systemctl status mariadb
● mariadb.service - MariaDB 10.6.12 database server
     Loaded: loaded (/lib/systemd/system/mariadb.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/mariadb.service.d
             └─restart.conf
     Active: active (running) since Tue 2023-05-02 23:34:44 +06; 35min ago
       Docs: man:mariadbd(8)
             https://mariadb.com/kb/en/library/systemd/
   Main PID: 3248 (mariadbd)
     Status: "Taking your SQL requests now..."
      Tasks: 8 (limit: 4915)
     Memory: 57.2M
     CGroup: /system.slice/mariadb.service
             └─3248 /usr/sbin/mariadbd


замечем строчку

    Drop-In: /etc/systemd/system/mariadb.service.d
             └─restart.conf


очень удобно.


ну а смысл конкртено это го допина в том чтобы заставить системд сразу же перезапускать maeiadb 
если он упал ( в том числе если его убил OOM killer)


я проерил - работает.

кстати из того же статуса вижно как давно процесс был стартанут. тоже очень удобно.


=



===
memcache
memcached


как его запустить на компе чтобы было несколько инстансов.


останаливаем и дизейблим исходный memcahced

# systemctl disable memcached

создаем новый unit файло для systemd

# cat /etc/systemd/system/memcached@.service


[Unit]
Description=memcached daemon for %i
After=network.target
Documentation=man:memcached(1)

[Service]
ExecStart=/usr/share/memcached/scripts/systemd-memcached-wrapper /etc/memcached_%i.conf
PrivateTmp=true
ProtectSystem=full
NoNewPrivileges=true
PrivateDevices=true
CapabilityBoundingSet=CAP_SETGID CAP_SETUID CAP_SYS_RESOURCE
RestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX
MemoryDenyWriteExecute=true
ProtectKernelModules=true
ProtectKernelTunables=true
ProtectControlGroups=true
RestrictRealtime=true
RestrictNamespaces=true
PIDFile=/var/run/memcached/memcached_%i.pid
Restart=always

[Install]
WantedBy=multi-user.target


его собственно можно созать из юнит файла исходного мемкэш.
главное заменить строки:

Description=memcached daemon for %i
ExecStart=/usr/share/memcached/scripts/systemd-memcached-wrapper /etc/memcached_%i.conf
PIDFile=/var/run/memcached/memcached_%i.pid




далее создаем конфиг файлы  для инстаносв мемкэша


# cat /etc/memcached_api-test.conf | grep -v '#'

-d
logfile /var/log/memcached_2.log
-m 64
-p 11311
-u memcache
-l 127.0.0.1
-P /var/run/memcached/memcached_api-test.pid



# cat /etc/memcached_api-prod.conf | grep -v '#'

-d
logfile /var/log/memcached_1.log
-m 64
-p 11211
-u memcache
-l 127.0.0.1
-P /var/run/memcached/memcached_api-prod.pid


эти два файоа отличаются только индивдуальным портом 
-p 11311
и индивидуальным pid файлом
-P /var/run/memcached/memcached_api-prod.pid


порты понятное дело можно выбиать какие угодно.
а вот с пид файлами и с именами конфигом мемкеша есть тонкость (memcached_api-test.conf, memcached_api-prod.conf)


дело в том что в systemd юните мы указали:

ExecStart=/usr/share/memcached/scripts/systemd-memcached-wrapper /etc/memcached_%i.conf
PIDFile=/var/run/memcached/memcached_%i.pid

что такое %i ?  это имя инстансов.  щас покажу. кога мы создали юнит файл.
и создали конфиги под инстансы мемекеша. можно приступать к их запуску

# systemctl daemon-reload

#systemctl  enable  memcached@api-prod
#systemctl  start  memcached@api-prod
# systemctl status  memcached@api-prod



#systemctl  enable  memcached@api-test
#systemctl  start  memcached@api-test
# systemctl status  memcached@api-test

так вот api-test и api-prod это имена инстаносов с точки зрения systemd.
мы их прдидумываем заранее. и в соотвестии с их именами 
мы и создали 
memcached_api-test.conf, 
memcached_api-prod.conf 
и  также в них указали путь к pid файл как 
-P /var/run/memcached/memcached_api-prod.pid
-P /var/run/memcached/memcached_api-test.pid



таким образом плучим два инстарса. каждый из них слушает свой порт

# systemctl status  memcached@api-prod
● memcached@api-prod.service - memcached daemon for api-prod
     Loaded: loaded (/etc/systemd/system/memcached@.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2023-05-29 20:27:40 MSK; 4s ago
       Docs: man:memcached(1)
   Main PID: 1749678 (memcached)
      Tasks: 10 (limit: 19067)
     Memory: 1.7M
        CPU: 39ms
     CGroup: /system.slice/system-memcached.slice/memcached@api-prod.service
             └─1749678 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -P /var/run/memcached/memcached_api-prod.pid



# systemctl status  memcached@api-test
● memcached@api-test.service - memcached daemon for api-test
     Loaded: loaded (/etc/systemd/system/memcached@.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2023-05-29 20:27:37 MSK; 11s ago
       Docs: man:memcached(1)
   Main PID: 1749664 (memcached)
      Tasks: 10 (limit: 19067)
     Memory: 1.7M
        CPU: 39ms
     CGroup: /system.slice/system-memcached.slice/memcached@api-test.service
             └─1749664 /usr/bin/memcached -m 64 -p 11311 -u memcache -l 127.0.0.1 -P /var/run/memcached/memcached_api-test.pid




===

