kubernetes
глобальная сетевая проблема

положим у нас есть дата хост куба.
этот хост имеет IP1=192.168.1.1 . тот через который кубелет связываться с контрол плейном. пока все впорядке все отлично.

далее мы на кубе публикуем под и над ним публикуем сервис. и мы пробрасываем этот сервис наружу на внешний порт port1 хоста. пока по прежнему все впорядке все отлично. мы теперь можем обратиться из вне на Ip1:port1 и нас добросит до пода внутри. все хорошо.

далее у нас есть в сети комп2 Ip2=10.0.0.100 и мы если мы будем обращаться к сервису куба на IP1 то мы это можем сделать только через гейтвей а это жопа. мы так нехотим. мы хотим связываться с кубом без гейтвея.
что мы делаем. мы на хосте дата ноды куба  добавляем Ip3=10.0.0.1
теперь комп2 может достучаться до пода через Ip3:port1 и самое главное без участия гейтвея а напрямую. пока все просто замечательно.

а далее вылезает проблема.предположим зачем то мы с компа2 Ip2=10.0.0.100 постучимся на
IP1=192.168.1.1 например по ssh. 
что произойдет. эти ip сидят в разных ip сетях поэтому пакет туда уйдет 
через гейтвей. когда хост куба начнет отправлять обратный пакет то он 
пойдет по таблице маршрутизации и обнаружит что у него есть карточка которая смотрит напрямую в сеть 10.0.0.0 Ip3=10.0.0.1 и хост куба обратный пакет выплюнет не через исходную сетевую карту и не на гейтвей а 
через карту Ip3=10.0.0.1 получается что хост куба принял пакет через одну сетевую карту а обратно отправил через другую сетевую карту. 
  С точки зрения компа отправителя наскольк я понимаю жопа состоит в том что  когда он отпраляет пакет то он отправляет его с указанием DST_MAC = мак гейтвея а обратный фрейм он получает в котором указан src_MAC=мак куб хоста и как бы это очень плохо потому что комп ожидает что если он отправил пакет с фреймом src_MAC dst_MAС то обратный фрейм придет с точно такими же мак полями только поменянными местами. с точки зрения L2 потока запрос был направлен на один комп а ответ прилетел от другого компа.
  
получается на хосте куба вылезает задача как заставить его обратный поток 
отправлять ровно через туже сетевую карту что и входящий поток.
 причина такого поведения в том что решение куда пихать пакеты линукс принимает на основе табдицы маршрутизации.фишка этой таблицы в том что в ней указаны только dst IP. поэтому решение принимает только на основе dst ip пакета. нам же надо чтобы дополниельно учитыался и src_ip пакета.
 в общем чтобы ихсодящий поток отправлять ровно из тойже карты в которую он влетел надо:
	для каждого ip  на хосте куба создать свою отдельную таблицу маршрутизации. например на кубе имеем
	
	Ip2=10.0.0.100
	
	создаем таблицу маршрутизации под этот ip либо сразу под эту сеть
		
	# echo 200 T1 >> /etc/iproute2/rt_tables
	имя T1 абсолютно неважно. 
	можно другое заюзать

	далее мы говорим линуксу чтобы он для пакетов у которых src ip = 192.168.1.56 использовал необщую таблицу маршрутиацщии а эту T1
	
	# ip rule add from 192.168.1.56 table T1


    и далее в эту таблицу добавляем маршруты 

	ip route add 192.168.1.0/24 dev ens160 src 192.168.1.56 table T1
	ip route add default via 192.168.1.1 dev ens160 src 192.168.1.56 table T1
	
	таблица T1 в итоге будет выглядеть так :
	
	# ip route show table T1
		192.168.1.0/24 dev ens160  scope link
		default via 192.168.1.1 dev ens160

    а правило туда ее загоняющее будет выглядеть так:
		# ip rule
		0:      from all lookup local
		32764:  from 192.168.1.0/24 lookup T1
		32766:  from all lookup main
		32767:  from all lookup default

	
    после перезагрузки хоста сама таблица T1 но пустая сохраняется тоесть ее пересоздаваь ненужно. но так как она будет пустая то ее нужно заполнять заново. и линуксу говорить чтобы он ей пользовался тоже нужно заново поэтому поледние три команды после перезагрузки нужно вводить заново. как это делат решать тебе. например можно это вписать в /etc/network/interfaces  например как описано здесь (см. "interfaces сетевой конфиг дата ноды.txt"  )

    и вот такую кастомную таблицу маршрутизации и весь этот мудеж надо делать для каждого нового IP который мы добавляем на дата ноду куба.
	например если дата нода куба имеет три IP
	
	192.168.1.100
	192.168.0.100
	10.0.0.100
	
	то чтобы входящий в них поток вылетал из той же карты нужно будет 
	создать три кастомные таблицы маршрутизации и в кажду вбить вот все те команды что выше.
	
но это еще неконец.
остается еще одна проблема. дело в том что у нас внутри дата ноды куба
будут крутится поды. и они все сидят в своей сети вида 10.254.0.0\16 условно говоря. и понятно что эта сеть совершенно отличается от первоначальной сети дата ноды куба когда на нем только один внешний IP1=192.168.1.1

значит кастомная таблица для этго IP1 у нас сейчас выглядит как 

	# ip route show table T1
		192.168.1.0/24 dev ens160  scope link
		default via 192.168.1.1 dev ens160

получается что если под внутри хоста направит пакет к 192.168.1.1
и потом пойдет обратный пакет от 192.168.1.1  к IP пода 10.254.x.y 
то этот пакет попадет в таблицу маршрутизации T1 и на основе
нее он будет направлен (внимание жопа) на внешний гейтвей. приплыли.
чтобы это исправить чтобы этого небыло в эту таблицу и во все такие кастомные таблицы нужно добавить строки отвественные за работу с оверлейными сетями подов 


10.254.0.0/24 via 10.254.0.0 dev flannel.1 onlink
10.254.1.0/24 via 10.254.1.0 dev flannel.1 onlink
10.254.2.0/24 via 10.254.2.0 dev flannel.1 onlink
10.254.3.0/24 via 10.254.3.0 dev flannel.1 onlink
10.254.4.0/24 via 10.254.4.0 dev flannel.1 onlink
10.254.5.0/24 via 10.254.5.0 dev flannel.1 onlink
10.254.6.0/24 via 10.254.6.0 dev flannel.1 onlink
10.254.7.0/24 via 10.254.7.0 dev flannel.1 onlink
10.254.8.0/24 via 10.254.8.0 dev flannel.1 onlink
10.254.9.0/24 dev cni0  proto kernel  scope link  src 10.254.9.1

потому что эти строки они в дефолтовой таблице маршрутизации сидят ибо созданы там автоматом системой а в нашей таблице этого нет туда это нужно добавить руками. эти строки надо добавит во все наши кастомные таблицы маршрутизации.

как это делать. ведь после презагрузки это надо делать заново.
я предочел это делать через systemd самописный сервис. дело в том что это надо сделать не только при загрузке хоста но и регулярно проверять что оно там все на месте и если в кубе добавляется новый куб дата хост то система будет доблавять новый такие маршруты и их тоже надо следить и добавлять.
	(см. "systemd сервис для iproute cni0.txt" )	

вот теперь вроде как мы исправили все проблемы на дата ноде куба после того как мы на нее добавиили +1 IP адрес.

--
