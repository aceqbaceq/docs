| freenas
| fio
| iops


общая плезная инфо
в fio есть разные "движки"

root@truenas-0-233[~]# fio  --enghelp
Available IO engines:
  cpuio
  mmap
  sync
  psync
  vsync
  pvsync
  null
  net
  ftruncate
  filecreate
  filestat
  filedelete
  exec
  posixaio
  rdma


они отличаются тем что 


psync   O_DIRECT  

sync    O_SYNC  

vsync  O_SYNC 

pvsync   O_DIRECT + O_SYNC 


| smartctl
| sata
| 6 Gb/s
| 3 Gb/s
| 12 Gb/s

как узнатьна лиукске на каком порту 3\6\12 Gb\s сидит наш диск

# smartctl -x /dev/disk/by-partuuid/f642d05c-527c-4bb8-b7f7-38bfe07efe0a | grep SATA
SATA Version is:  SATA 3.0, 6.0 Gb/s (current: 6.0 Gb/s)



| offset


# ./fio-3-28-115 --rw=read --bs=1m --direct=1 --ioengine=libaio --size=10G\
  --group_reporting --filename=/dev/tank/bucket --name=job1 --offset=0G\
  --name=job2 --offset=10G --name=job3 --offset=20G --name=job4 --offset=30G\
  --name=job5 --offset=40G --name=job6 --offset=50G --name=job7 --offset=60G\
  --name=job8 --offset=70G
  (...)
    read: IOPS=4174, BW=4175MiB/s (4378MB/s)(80.0GiB/19622msec)


| zfs

полезные комнады для fio

 #  zfs create  -o compression=off -o  primarycache=metadata  -o secondarycache=metadata -o recordsize=4KiB  POOL-02/ds2-4K
 
 (кстати вот так можно создать недатасет а zvol 
   # zfs create -V 10G  -o compression=off -o  primarycache=metadata  -o secondarycache=metadata -o volblocksize=128KiB  POOL-01/zvol-01-128K)

 # zfs get recordsize POOL-02/ds2-4K

 # dd if=/dev/urandom bs=1M count=$(( 10 * 1024 )) of=/POOL-03-MIRROR-SSD/ds2-128K/fio.dat status=progress


# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-04/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=1  --size=10G  --readwrite=randwrite --numjobs=1  --group_reporting --loops=5

# gstat 
# arcstat 1



|

| zfs
| SEAGATE ST2000NM0023 0003
| HGST HUS724020ALA640


сравнеие двух дисков 


1: SEAGATE ST2000NM0023 0003
2: HGST HUS724020ALA640

тест делаю на файле fio.dat 10G которыйлежит на 
zfs dataset 128K 
fio.dat  сильно фрагментрован


1:
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-1-DISK/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=1  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting

test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=89.9MiB/s][r=719 IOPS][eta 00m:00s]




2:
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=1  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][7.1%][r=39.4MiB/s][r=314 IOPS][eta 04m:33s] 
test: (groupid=0, jobs=1): err= 0: pid=9633: Fri Dec  5 23:18:28 2025
  read: IOPS=292, BW=36.6MiB/s (38.4MB/s)(736MiB/20111msec)


разница офигеть

1:
-5[/]# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-1-DISK/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=2  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting

test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=101MiB/s][r=810 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=59054: Fri Dec  5 12:24:02 2025
  read: IOPS=755, BW=94.5MiB/s (99.1MB/s)(1896MiB/20066msec)


2:
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=2  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][6.2%][r=34.6MiB/s][r=276 IOPS][eta 05m:16s]  
test: (groupid=0, jobs=1): err= 0: pid=9643: Fri Dec  5 23:19:24 2025
  read: IOPS=254, BW=31.8MiB/s (33.3MB/s)(640MiB/20131msec)

  разница офигеть


1:
# 
root@freenas-5[/]# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-1-DISK/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=4  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting

test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=4
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=105MiB/s][r=842 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=59064: Fri Dec  5 12:25:02 2025
  read: IOPS=810, BW=101MiB/s (106MB/s)(2032MiB/20045msec)


2:
]# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=4  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=4
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=38.6MiB/s][r=308 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=9655: Fri Dec  5 23:20:23 2025
  read: IOPS=283, BW=35.4MiB/s (37.1MB/s)(712MiB/20110msec)





1:
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-1-DISK/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=32  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting

test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=32
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=127MiB/s][r=1017 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=59068: Fri Dec  5 12:25:59 2025
  read: IOPS=979, BW=122MiB/s (128MB/s)(2456MiB/20049msec)


2:
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=$((128 *1024)) --ioengine=posixaio     --iodepth=32  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=32
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][9.0%][r=50.8MiB/s][r=406 IOPS][eta 03m:32s] 
test: (groupid=0, jobs=1): err= 0: pid=9665: Fri Dec  5 23:21:25 2025
  read: IOPS=367, BW=45.9MiB/s (48.1MB/s)(928MiB/20218msec)



вывод SEAGATE ST2000NM0023 0003 это диск просто УРАГАН
вывод2: есть диски которые небоятся глубокого iodepth и на нем прям выстреливают. а есть которые почти никак
        неумеют  соптимизироать поиск запрсов из извесной очереди. тупо видимо ищут поооччереди.




| общая часть


root@2hst1 .../temp/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=32000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.25
Starting 1 process
test: Laying out IO file (1 file / 32000MiB)
Jobs: 1 (f=1): [r(1)][100.0%][r=108MiB/s][r=27.7k IOPS][eta 00m:00s]  
test: (groupid=0, jobs=1): err= 0: pid=2385796: Tue Sep 16 18:09:13 2025
  read: IOPS=20.3k, BW=79.4MiB/s (83.3MB/s)(31.2GiB/402962msec)
   bw (  KiB/s): min= 1320, max=110880, per=99.99%, avg=81307.40, stdev=33287.90, samples=805
   iops        : min=  330, max=27720, avg=20326.84, stdev=8321.97, samples=805
  cpu          : usr=2.96%, sys=14.59%, ctx=2791262, majf=0, minf=5723
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=8192000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=79.4MiB/s (83.3MB/s), 79.4MiB/s-79.4MiB/s (83.3MB/s-83.3MB/s), io=31.2GiB (33.6GB), run=402962-402962msec
root@2hst1 .../temp/fio# 
root@2hst1 .../temp/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=32000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.25
Starting 1 process
^Cbs: 1 (f=1): [w(1)][7.6%][w=3260KiB/s][w=815 IOPS][eta 02h:08m:56s] 
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=2430390: Tue Sep 16 18:35:16 2025
  write: IOPS=978, BW=3912KiB/s (4006kB/s)(2437MiB/637716msec); 0 zone resets
   bw (  KiB/s): min=  192, max= 9160, per=100.00%, avg=3913.46, stdev=1616.22, samples=1275
   iops        : min=   48, max= 2290, avg=978.36, stdev=404.06, samples=1275
  cpu          : usr=0.19%, sys=0.76%, ctx=349138, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,623763,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=3912KiB/s (4006kB/s), 3912KiB/s-3912KiB/s (4006kB/s-4006kB/s), io=2437MiB (2555MB), run=637716-637716msec
root@2hst1 .../temp/fio# 


| nfs-ext (на 2hst1)
| fio
| iops


root@2hst1 .../nfs-ext/temp# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=32000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.25
Starting 1 process
test: Laying out IO file (1 file / 32000MiB)
^Cbs: 1 (f=1): [r(1)][9.4%][r=5789KiB/s][r=1447 IOPS][eta 01h:24m:20s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=2468782: Tue Sep 16 18:52:28 2025
  read: IOPS=1465, BW=5864KiB/s (6005kB/s)(3019MiB/527267msec)
   bw (  KiB/s): min= 4448, max= 6552, per=100.00%, avg=5865.15, stdev=229.89, samples=1054
   iops        : min= 1112, max= 1638, avg=1466.24, stdev=57.50, samples=1054
  cpu          : usr=0.34%, sys=1.30%, ctx=648177, majf=0, minf=99
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=772966,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=5864KiB/s (6005kB/s), 5864KiB/s-5864KiB/s (6005kB/s-6005kB/s), io=3019MiB (3166MB), run=527267-527267msec
root@2hst1 .../nfs-ext/temp# 
root@2hst1 .../nfs-ext/temp# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=32000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.25
Starting 1 process
^Cbs: 1 (f=1): [w(1)][0.1%][w=1492KiB/s][w=373 IOPS][eta 06h:01m:18s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=2486918: Tue Sep 16 18:53:00 2025
  write: IOPS=380, BW=1523KiB/s (1559kB/s)(33.7MiB/22664msec); 0 zone resets
   bw (  KiB/s): min=  848, max= 1760, per=99.94%, avg=1522.84, stdev=177.84, samples=45
   iops        : min=  212, max=  440, avg=380.71, stdev=44.46, samples=45
  cpu          : usr=0.00%, sys=0.36%, ctx=3998, majf=0, minf=5
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.2%, 32=0.4%, >=64=99.3%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,8629,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=1523KiB/s (1559kB/s), 1523KiB/s-1523KiB/s (1559kB/s-1559kB/s), io=33.7MiB (35.3MB), run=22664-22664msec

  

| sas3008
| lsi
| raid 10 x 4 SSD 960GB
| iops
| fio

[root@acs-master fio]# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.19
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
^Cbs: 1 (f=1): [r(1)][0.5%][r=1594KiB/s][r=398 IOPS][eta 02h:01m:41s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=295504: Tue Sep 16 19:45:58 2025
  read: IOPS=348, BW=1392KiB/s (1426kB/s)(50.0MiB/37487msec)
   bw (  KiB/s): min=  976, max= 1744, per=100.00%, avg=1396.49, stdev=170.57, samples=74
   iops        : min=  244, max=  436, avg=349.11, stdev=42.63, samples=74
  cpu          : usr=0.33%, sys=1.41%, ctx=13022, majf=0, minf=73
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.2%, >=64=99.5%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=13048,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=1392KiB/s (1426kB/s), 1392KiB/s-1392KiB/s (1426kB/s-1426kB/s), io=50.0MiB (53.4MB), run=37487-37487msec

Disk stats (read/write):
    dm-0: ios=13325/483, merge=0/0, ticks=2499055/105897, in_queue=2604952, util=99.38%, aggrios=13325/462, aggrmerge=0/20, aggrticks=2500173/53376, aggrin_queue=2553550, aggrutil=99.41%
  sda: ios=13325/462, merge=0/20, ticks=2500173/53376, in_queue=2553550, util=99.41%
[root@acs-master fio]# 
[root@acs-master fio]# 
[root@acs-master fio]# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.19
Starting 1 process
^Cbs: 1 (f=1): [w(1)][0.2%][w=918KiB/s][w=229 IOPS][eta 02h:15m:28s] 
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=296029: Tue Sep 16 19:46:22 2025
  write: IOPS=314, BW=1259KiB/s (1289kB/s)(21.0MiB/17871msec); 0 zone resets
   bw (  KiB/s): min=  496, max= 2056, per=99.80%, avg=1256.51, stdev=420.98, samples=35
   iops        : min=  124, max=  514, avg=314.06, stdev=105.32, samples=35
  cpu          : usr=0.41%, sys=1.12%, ctx=4653, majf=0, minf=6
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.3%, 32=0.6%, >=64=98.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,5625,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=1259KiB/s (1289kB/s), 1259KiB/s-1259KiB/s (1289kB/s-1289kB/s), io=21.0MiB (23.0MB), run=17871-17871msec

Disk stats (read/write):
    dm-0: ios=14/5783, merge=0/0, ticks=1324/1178475, in_queue=1179799, util=89.85%, aggrios=14/5782, aggrmerge=0/3, aggrticks=1323/1179962, aggrin_queue=1181285, aggrutil=90.00%
  sda: ios=14/5782, merge=0/3, ticks=1323/1179962, in_queue=1181285, util=90.00%




===========================================================


ГОЛЫЕ AHCI SATA порты


| micron 5300 PRO 480GB 6Gbit/s


порт SATA AHCI 3Gbit/s


root@test:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
^Cbs: 1 (f=1): [r(1)][50.9%][r=193MiB/s][r=49.4k IOPS][eta 00m:26s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=684: Wed Sep 17 07:50:57 2025
  read: IOPS=49.3k, BW=193MiB/s (202MB/s)(5087MiB/26424msec)
   bw (  KiB/s): min=196656, max=197528, per=100.00%, avg=197208.62, stdev=236.24, samples=52
   iops        : min=49164, max=49382, avg=49302.15, stdev=59.06, samples=52
  cpu          : usr=13.12%, sys=29.00%, ctx=1293942, majf=0, minf=72
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=1302184,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=193MiB/s (202MB/s), 193MiB/s-193MiB/s (202MB/s-202MB/s), io=5087MiB (5334MB), run=26424-26424msec

Disk stats (read/write):
  sdc: ios=1289849/4, merge=48/4, ticks=1666221/8, in_queue=1666232, util=68.75%

root@test:/mnt/sdc/1/fio# 
root@test:/mnt/sdc/1/fio# 
root@test:/mnt/sdc/1/fio# dd if=/dev/sdc of=/dev/null bs=4MiB count=100
100+0 records in
100+0 records out
419430400 bytes (419 MB, 400 MiB) copied, 1.46834 s, 286 MB/s
root@test:/mnt/sdc/1/fio# dd if=/dev/sdc of=/dev/null bs=4MiB count=1000
1000+0 records in
1000+0 records out
4194304000 bytes (4.2 GB, 3.9 GiB) copied, 13.2697 s, 316 MB/s




PORT 6Gb\s

RAND READ

root@test:/mnt/sda/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=335MiB/s][r=85.8k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=589: Wed Sep 17 07:57:32 2025
  read: IOPS=85.8k, BW=335MiB/s (352MB/s)(9.77GiB/29822msec)
   bw (  KiB/s): min=340096, max=347320, per=100.00%, avg=343650.44, stdev=1400.44, samples=59
   iops        : min=85024, max=86830, avg=85912.75, stdev=350.10, samples=59
  cpu          : usr=17.89%, sys=48.35%, ctx=2101910, majf=0, minf=72
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=335MiB/s (352MB/s), 335MiB/s-335MiB/s (352MB/s-352MB/s), io=9.77GiB (10.5GB), run=29822-29822msec

Disk stats (read/write):
  sda: ios=2543725/0, merge=1611/0, ticks=1865656/0, in_queue=1865656, util=76.70%
root@test:/mnt/sda/1/fio# 




RAND WRITE

root@test:/mnt/sda/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=342MiB/s][w=87.6k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=682: Wed Sep 17 08:03:11 2025
  write: IOPS=86.2k, BW=337MiB/s (353MB/s)(9.77GiB/29692msec); 0 zone resets
   bw (  KiB/s): min=325640, max=354560, per=100.00%, avg=344899.12, stdev=6809.60, samples=59
   iops        : min=81410, max=88640, avg=86224.85, stdev=1702.35, samples=59
  cpu          : usr=19.37%, sys=51.88%, ctx=1784190, majf=0, minf=6
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=337MiB/s (353MB/s), 337MiB/s-337MiB/s (353MB/s-353MB/s), io=9.77GiB (10.5GB), run=29692-29692msec

Disk stats (read/write):
  sda: ios=0/2552727, merge=0/2713, ticks=0/1862992, in_queue=1862993, util=84.35%





LINEAR READ

root@test:/mnt/sda/1/fio# dd if=/dev/sda of=/dev/null bs=4MiB count=1000
1000+0 records in
1000+0 records out
4194304000 bytes (4.2 GB, 3.9 GiB) copied, 7.83174 s, 536 MB/s








INTEL DCS3110 256GB


PORT SATA AHCI 6Gb/s


RAND READ

root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=298MiB/s][r=76.4k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=661: Wed Sep 17 08:00:24 2025
  read: IOPS=76.1k, BW=297MiB/s (312MB/s)(9.77GiB/33627msec)
   bw (  KiB/s): min=302424, max=310440, per=99.98%, avg=304454.09, stdev=1185.86, samples=67
   iops        : min=75606, max=77610, avg=76113.46, stdev=296.43, samples=67
  cpu          : usr=12.70%, sys=42.85%, ctx=2249194, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=297MiB/s (312MB/s), 297MiB/s-297MiB/s (312MB/s-312MB/s), io=9.77GiB (10.5GB), run=33627-33627msec

Disk stats (read/write):
  sdb: ios=2539156/0, merge=1363/0, ticks=2098909/0, in_queue=2098909, util=85.64%





RAND WRITE


root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=261MiB/s][w=66.9k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=668: Wed Sep 17 08:02:09 2025
  write: IOPS=72.7k, BW=284MiB/s (298MB/s)(9.77GiB/35231msec); 0 zone resets
   bw (  KiB/s): min=245328, max=356624, per=100.00%, avg=290814.51, stdev=30699.63, samples=70
   iops        : min=61332, max=89156, avg=72703.66, stdev=7674.90, samples=70
  cpu          : usr=16.06%, sys=42.82%, ctx=1732438, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=284MiB/s (298MB/s), 284MiB/s-284MiB/s (298MB/s-298MB/s), io=9.77GiB (10.5GB), run=35231-35231msec

Disk stats (read/write):
  sdb: ios=0/2551609, merge=0/2402, ticks=0/2197811, in_queue=2197865, util=85.32%





====================


контроллер 3ware 700-3260-10D
JBOD режим скорость порта на 3ware контролерер 3 Gbit/s
диск micron 5300 PRO 480GB (макс скорость порта диска самого 6Gbit/s )


root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [r(1)][31.1%][r=55.8MiB/s][r=14.3k IOPS][eta 02m:04s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=608: Wed Sep 17 08:19:02 2025
  read: IOPS=14.2k, BW=55.6MiB/s (58.3MB/s)(3146MiB/56561msec)
   bw (  KiB/s): min=55096, max=57736, per=100.00%, avg=57003.04, stdev=367.11, samples=113
   iops        : min=13774, max=14434, avg=14250.76, stdev=91.79, samples=113
  cpu          : usr=10.96%, sys=29.62%, ctx=679751, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=805280,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=55.6MiB/s (58.3MB/s), 55.6MiB/s-55.6MiB/s (58.3MB/s-58.3MB/s), io=3146MiB (3298MB), run=56561-56561msec

Disk stats (read/write):
  sdb: ios=802835/1, merge=0/0, ticks=3592781/5, in_queue=3592785, util=77.33%
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [w(1)][6.7%][w=27.9MiB/s][w=7142 IOPS][eta 05m:34s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=615: Wed Sep 17 08:19:32 2025
  write: IOPS=7166, BW=28.0MiB/s (29.4MB/s)(683MiB/24412msec); 0 zone resets
   bw (  KiB/s): min=28480, max=28936, per=100.00%, avg=28696.00, stdev=121.89, samples=48
   iops        : min= 7120, max= 7234, avg=7174.00, stdev=30.47, samples=48
  cpu          : usr=6.36%, sys=18.62%, ctx=174896, majf=0, minf=10
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,174938,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=28.0MiB/s (29.4MB/s), 28.0MiB/s-28.0MiB/s (29.4MB/s-29.4MB/s), io=683MiB (717MB), run=24412-24412msec

Disk stats (read/write):
  sdb: ios=0/174833, merge=0/0, ticks=0/1555190, in_queue=1555190, util=77.20%
root@test:/mnt/sdb/1/fio# 







контроллер 3ware 700-3260-10D
JBOD режим скорость порта на 3ware контролерер 3 Gbit/s
диск INTEL DCS3110 256GB
 (макс скорость порта диска самого 6Gbit/s )



root@test:/mnt/sdc/1/fio# 
root@test:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [r(1)][22.8%][r=54.6MiB/s][r=14.0k IOPS][eta 02m:22s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=633: Wed Sep 17 08:23:05 2025
  read: IOPS=13.9k, BW=54.5MiB/s (57.1MB/s)(2283MiB/41915msec)
   bw (  KiB/s): min=54872, max=56416, per=100.00%, avg=55829.01, stdev=414.91, samples=83
   iops        : min=13718, max=14104, avg=13957.28, stdev=103.72, samples=83
  cpu          : usr=10.93%, sys=29.90%, ctx=518319, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=584417,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=54.5MiB/s (57.1MB/s), 54.5MiB/s-54.5MiB/s (57.1MB/s-57.1MB/s), io=2283MiB (2394MB), run=41915-41915msec

Disk stats (read/write):
  sdc: ios=584136/1, merge=0/0, ticks=2669961/6, in_queue=2669968, util=78.10%
root@test:/mnt/sdc/1/fio# 
root@test:/mnt/sdc/1/fio# 
root@test:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [w(1)][2.4%][w=12.7MiB/s][w=3252 IOPS][eta 13m:42s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=640: Wed Sep 17 08:23:32 2025
  write: IOPS=3058, BW=11.9MiB/s (12.5MB/s)(245MiB/20508msec); 0 zone resets
   bw (  KiB/s): min= 4432, max=13096, per=99.94%, avg=12228.80, stdev=2003.69, samples=40
   iops        : min= 1108, max= 3274, avg=3057.20, stdev=500.92, samples=40
  cpu          : usr=3.57%, sys=10.53%, ctx=62739, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,62730,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=11.9MiB/s (12.5MB/s), 11.9MiB/s-11.9MiB/s (12.5MB/s-12.5MB/s), io=245MiB (257MB), run=20508-20508msec

Disk stats (read/write):
  sdc: ios=0/62370, merge=0/0, ticks=0/1301541, in_queue=1301542, util=85.15%
root@test:/mnt/sdc/1/fio# 







контроллер 3ware 700-3260-10D
RAID0 режим  скорость порта на 3ware контролерер 3 Gbit/s
диски intel+micron


root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
^Cbs: 1 (f=1): [r(1)][11.8%][r=62.3MiB/s][r=15.9k IOPS][eta 02m:22s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=651: Wed Sep 17 08:31:37 2025
  read: IOPS=16.0k, BW=62.3MiB/s (65.4MB/s)(1178MiB/18897msec)
   bw (  KiB/s): min=63488, max=64464, per=100.00%, avg=63904.22, stdev=271.00, samples=37
   iops        : min=15872, max=16116, avg=15976.05, stdev=67.75, samples=37
  cpu          : usr=11.19%, sys=31.20%, ctx=202968, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=301565,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=62.3MiB/s (65.4MB/s), 62.3MiB/s-62.3MiB/s (65.4MB/s-65.4MB/s), io=1178MiB (1235MB), run=18897-18897msec

Disk stats (read/write):
  sdb: ios=300534/0, merge=0/0, ticks=1197801/0, in_queue=1197802, util=78.15%

root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [w(1)][3.3%][w=25.7MiB/s][w=6577 IOPS][eta 07m:54s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=658: Wed Sep 17 08:31:59 2025
  write: IOPS=5321, BW=20.8MiB/s (21.8MB/s)(325MiB/15636msec); 0 zone resets
   bw (  KiB/s): min= 8480, max=26560, per=99.96%, avg=21278.97, stdev=7309.18, samples=31
   iops        : min= 2120, max= 6640, avg=5319.81, stdev=1827.32, samples=31
  cpu          : usr=5.08%, sys=15.03%, ctx=70638, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,83208,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=20.8MiB/s (21.8MB/s), 20.8MiB/s-20.8MiB/s (21.8MB/s-21.8MB/s), io=325MiB (341MB), run=15636-15636msec

Disk stats (read/write):
  sdb: ios=0/81737, merge=0/0, ticks=0/981357, in_queue=981357, util=83.70%
root@test:/mnt/sdb/1/fio# 

==


LSI MegaRAID SAS 2108

Product Name = ServeRAID M5015 SAS/SATA Controller
Serial Number = SV21106943
SAS Address =  500605b004872b90
PCI Address = 00:01:00:00
System Time = 09/18/2025 08:07:13
Mfg. Date = 03/12/12
Controller Time = 09/18/2025 12:07:12
FW Package Build = 12.12.0-0047
FW Version = 2.120.53-1235
BIOS Version = 3.22.00_4.11.05.00_0x05020000
Driver Name = megaraid_sas
Driver Version = 07.719.03.00-rc1
Vendor Id = 0x1000
Device Id = 0x79
SubVendor Id = 0x1014
SubDevice Id = 0x3B2
Host Interface = PCI-E
Device Interface = SAS-6G


--------------------------------------------------------------
DG/VD TYPE   State Access Consist Cache Cac sCC     Size Name 
--------------------------------------------------------------
0/0   RAID10 Optl  RW     No      NRWTD -   ON  1.744 TB      
--------------------------------------------------------------


root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=305MiB/s][r=78.0k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=920: Thu Sep 18 08:03:48 2025
  read: IOPS=76.5k, BW=299MiB/s (313MB/s)(9.77GiB/33473msec)
   bw (  KiB/s): min=297160, max=313856, per=100.00%, avg=306095.27, stdev=4463.30, samples=66
   iops        : min=74290, max=78464, avg=76523.79, stdev=1115.79, samples=66
  cpu          : usr=22.88%, sys=52.82%, ctx=100108, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=299MiB/s (313MB/s), 299MiB/s-299MiB/s (313MB/s-313MB/s), io=9.77GiB (10.5GB), run=33473-33473msec

Disk stats (read/write):
  sdb: ios=2554208/1, merge=0/0, ticks=1843885/1, in_queue=1843886, util=52.75%
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=200MiB/s][w=51.1k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=927: Thu Sep 18 08:04:57 2025
  write: IOPS=50.3k, BW=197MiB/s (206MB/s)(9.77GiB/50847msec); 0 zone resets
   bw (  KiB/s): min=197048, max=205232, per=100.00%, avg=201547.01, stdev=2289.84, samples=101
   iops        : min=49262, max=51308, avg=50386.81, stdev=572.47, samples=101
  cpu          : usr=16.85%, sys=38.16%, ctx=87377, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=197MiB/s (206MB/s), 197MiB/s-197MiB/s (206MB/s-206MB/s), io=9.77GiB (10.5GB), run=50847-50847msec

Disk stats (read/write):
  sdb: ios=0/2549855, merge=0/0, ticks=0/2677049, in_queue=2677050, util=54.22%





=====


LSI MegaRAID SAS 2108

Product Name = ServeRAID M5015 SAS/SATA Controller
Serial Number = SV21106943
SAS Address =  500605b004872b90
PCI Address = 00:01:00:00
System Time = 09/18/2025 08:07:13
Mfg. Date = 03/12/12
Controller Time = 09/18/2025 12:07:12
FW Package Build = 12.12.0-0047
FW Version = 2.120.53-1235
BIOS Version = 3.22.00_4.11.05.00_0x05020000
Driver Name = megaraid_sas
Driver Version = 07.719.03.00-rc1
Vendor Id = 0x1000
Device Id = 0x79
SubVendor Id = 0x1014
SubDevice Id = 0x3B2
Host Interface = PCI-E
Device Interface = SAS-6G




RAID0 
INTEL SSDSC2KB960G7



root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
Jobs: 1 (f=1): [r(1)][14.3%][r=246MiB/s][r=63.1k IOPS][eta 00m:36s]
^Cbs: 1 (f=1): [r(1)][53.7%][r=247MiB/s][r=63.2k IOPS][eta 00m:19s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=995: Thu Sep 18 08:12:14 2025
  read: IOPS=63.0k, BW=246MiB/s (258MB/s)(5199MiB/21134msec)
   bw (  KiB/s): min=248280, max=253344, per=100.00%, avg=252162.10, stdev=814.25, samples=42
   iops        : min=62070, max=63336, avg=63040.52, stdev=203.54, samples=42
  cpu          : usr=21.17%, sys=48.66%, ctx=154537, majf=0, minf=73
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=1330975,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=246MiB/s (258MB/s), 246MiB/s-246MiB/s (258MB/s-258MB/s), io=5199MiB (5452MB), run=21134-21134msec

Disk stats (read/write):
  sdb: ios=1318618/0, merge=0/0, ticks=1277415/0, in_queue=1277415, util=47.29%
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# 
root@test:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [w(1)][37.2%][w=230MiB/s][w=58.9k IOPS][eta 00m:27s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=1002: Thu Sep 18 08:12:34 2025
  write: IOPS=58.9k, BW=230MiB/s (241MB/s)(3693MiB/16062msec); 0 zone resets
   bw (  KiB/s): min=232040, max=236984, per=100.00%, avg=235610.00, stdev=965.50, samples=32
   iops        : min=58010, max=59246, avg=58902.50, stdev=241.38, samples=32
  cpu          : usr=17.38%, sys=37.41%, ctx=152214, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,945452,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=230MiB/s (241MB/s), 230MiB/s-230MiB/s (241MB/s-241MB/s), io=3693MiB (3873MB), run=16062-16062msec

Disk stats (read/write):
  sdb: ios=0/935784, merge=0/4, ticks=0/975429, in_queue=975429, util=48.09%
root@test:/mnt/sdb/1/fio# 


=====

LSI MegaRAID SAS 2108

Product Name = ServeRAID M5015 SAS/SATA Controller
Serial Number = SV21106943
SAS Address =  500605b004872b90
PCI Address = 00:01:00:00
System Time = 09/18/2025 08:07:13
Mfg. Date = 03/12/12
Controller Time = 09/18/2025 12:07:12
FW Package Build = 12.12.0-0047
FW Version = 2.120.53-1235
BIOS Version = 3.22.00_4.11.05.00_0x05020000
Driver Name = megaraid_sas
Driver Version = 07.719.03.00-rc1
Vendor Id = 0x1000
Device Id = 0x79
SubVendor Id = 0x1014
SubDevice Id = 0x3B2
Host Interface = PCI-E
Device Interface = SAS-6G







1 диск
RAID0 
INTEL SSDSC2KB960G7



root@debian:/mnt/sda/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=201MiB/s][r=51.5k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1814: Thu Sep 18 11:15:02 2025
  read: IOPS=50.1k, BW=196MiB/s (205MB/s)(9.77GiB/51140msec)
   bw (  KiB/s): min=182824, max=206456, per=100.00%, avg=200362.20, stdev=8635.42, samples=102
   iops        : min=45706, max=51614, avg=50090.53, stdev=2158.85, samples=102
  cpu          : usr=14.52%, sys=57.54%, ctx=388748, majf=0, minf=187
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=196MiB/s (205MB/s), 196MiB/s-196MiB/s (205MB/s-205MB/s), io=9.77GiB (10.5GB), run=51140-51140msec

Disk stats (read/write):
  sda: ios=2559902/2, merge=0/0, ticks=3158090/2, in_queue=3158091, util=51.00%
root@debian:/mnt/sda/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=159MiB/s][w=40.7k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1953: Thu Sep 18 11:16:23 2025
  write: IOPS=40.7k, BW=159MiB/s (167MB/s)(9.77GiB/62916msec); 0 zone resets
   bw (  KiB/s): min=156632, max=163160, per=100.00%, avg=162856.45, stdev=691.91, samples=125
   iops        : min=39158, max=40790, avg=40714.14, stdev=172.99, samples=125
  cpu          : usr=14.18%, sys=52.51%, ctx=889890, majf=0, minf=124
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=159MiB/s (167MB/s), 159MiB/s-159MiB/s (167MB/s-167MB/s), io=9.77GiB (10.5GB), run=62916-62916msec

Disk stats (read/write):
  sda: ios=0/2558699, merge=0/0, ticks=0/3938846, in_queue=3938846, util=55.70%





===



LSI MegaRAID SAS 2108

Product Name = ServeRAID M5015 SAS/SATA Controller
Serial Number = SV21106943
SAS Address =  500605b004872b90
PCI Address = 00:01:00:00
System Time = 09/18/2025 08:07:13
Mfg. Date = 03/12/12
Controller Time = 09/18/2025 12:07:12
FW Package Build = 12.12.0-0047
FW Version = 2.120.53-1235
BIOS Version = 3.22.00_4.11.05.00_0x05020000
Driver Name = megaraid_sas
Driver Version = 07.719.03.00-rc1
Vendor Id = 0x1000
Device Id = 0x79
SubVendor Id = 0x1014
SubDevice Id = 0x3B2
Host Interface = PCI-E
Device Interface = SAS-6G







4 диска
RAID10 

---------------------------------------------------------------------------------------
EID:Slt DID State DG       Size Intf Med SED PI SeSz Model                     Sp Type 
---------------------------------------------------------------------------------------
34:0     21 Onln   0 893.137 GB SATA SSD N   N  512B Micron_5300_MTFDDAK960TDS U  -    
34:1     22 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
34:2     39 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
34:3     40 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
---------------------------------------------------------------------------------------




root@debian:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=275MiB/s][r=70.5k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2119: Thu Sep 18 11:23:10 2025
  read: IOPS=71.3k, BW=278MiB/s (292MB/s)(9.77GiB/35929msec)
   bw (  KiB/s): min=277536, max=309976, per=100.00%, avg=285214.42, stdev=7099.08, samples=71
   iops        : min=69384, max=77494, avg=71303.61, stdev=1774.77, samples=71
  cpu          : usr=17.00%, sys=79.84%, ctx=20282, majf=0, minf=191
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=278MiB/s (292MB/s), 278MiB/s-278MiB/s (292MB/s-292MB/s), io=9.77GiB (10.5GB), run=35929-35929msec

Disk stats (read/write):
  sdc: ios=2557039/1, merge=0/0, ticks=1632510/1, in_queue=1632510, util=33.25%





root@debian:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randrwrite --rwmixread=75
        valid values: read       Sequential read
                    : write      Sequential write
                    : trim       Sequential trim
                    : randread   Random read
                    : randwrite  Random write
                    : randtrim   Random trim
                    : rw         Sequential read and write mix
                    : readwrite  Sequential read and write mix
                    : randrw     Random read and write mix
                    : trimwrite  Trim and write mix, trims preceding writes
                    : randtrimwrite Randomly trim and write mix, trims preceding writes

fio: failed parsing readwrite=randrwrite
root@debian:/mnt/sdc/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=193MiB/s][w=49.5k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2192: Thu Sep 18 11:24:16 2025
  write: IOPS=49.4k, BW=193MiB/s (202MB/s)(9.77GiB/51820msec); 0 zone resets
   bw (  KiB/s): min=189696, max=200832, per=100.00%, avg=197733.13, stdev=1181.14, samples=103
   iops        : min=47424, max=50208, avg=49433.28, stdev=295.28, samples=103
  cpu          : usr=15.25%, sys=52.89%, ctx=148382, majf=0, minf=124
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=193MiB/s (202MB/s), 193MiB/s-193MiB/s (202MB/s-202MB/s), io=9.77GiB (10.5GB), run=51820-51820msec

Disk stats (read/write):
  sdc: ios=0/2550976, merge=0/0, ticks=0/2606447, in_queue=2606448, util=40.51%




# history | grep -i megaraid
    5  /opt/MegaRAID/storcli/storcli64 /c0 /v0 delete force
    6  /opt/MegaRAID/storcli/storcli64 /c0 add vd type=raid10 drives=252:0,252:1,252:2,252:3 pdperarray=2
    7  /opt/MegaRAID/storcli/storcli64 /c0 show
    8  /opt/MegaRAID/storcli/storcli64 /c0 add vd type=raid10 drives=34:0,34:1,34:2,34:3 pdperarray=2
    9  /opt/MegaRAID/storcli/storcli64 /c0/v0 set iopolicy=direct
   10  /opt/MegaRAID/storcli/storcli64 /c0 /v0 set iopolicy=direct
   11  /opt/MegaRAID/storcli/storcli64 /c0 /v0 set wrcache=wt
   12  /opt/MegaRAID/storcli/storcli64 /c0 show
   43  history | grep -i megaraid



==========================



root@ocsamsh1:/mnt/01/fio# storcli64 /c0 show
Generating detailed summary of the adapter, it may take a while to complete.

CLI Version = 007.3405.0000.0000 May 15, 2025
Operating system = Linux 6.14.8-2-pve
Controller = 0
Status = Success
Description = None

Product Name = ServeRAID M5015 SAS/SATA Controller
Serial Number = SV21106943
SAS Address =  500605b004872b90
PCI Address = 00:04:00:00
System Time = 09/19/2025 18:48:02
Mfg. Date = 03/12/12
Controller Time = 09/19/2025 15:48:02
FW Package Build = 12.12.0-0047
FW Version = 2.120.53-1235
BIOS Version = 3.22.00_4.11.05.00_0x05020000
Driver Name = megaraid_sas
Driver Version = 07.727.03.00-rc1
Vendor Id = 0x1000
Device Id = 0x79
SubVendor Id = 0x1014
SubDevice Id = 0x3B2
Host Interface = PCI-E
Device Interface = SAS-6G
Bus Number = 4
Device Number = 0
Function Number = 0
Domain ID = 0
Security Protocol = None
Drive Groups = 2

TOPOLOGY :
========

------------------------------------------------------------------------------
DG Arr Row EID:Slot DID Type   State BT       Size PDC  PI SED DS3  FSpace TR 
------------------------------------------------------------------------------
 0 -   -   -        -   RAID10 Optl  N    1.744 TB dsbl N  N   dflt N      N  
 0 0   -   -        -   RAID1  Optl  N  893.137 GB dsbl N  N   dflt N      N  
 0 0   0   34:0     21  DRIVE  Onln  N  893.137 GB dsbl N  N   dflt -      N  
 0 0   1   34:1     22  DRIVE  Onln  N  893.137 GB dsbl N  N   dflt -      N  
 0 1   -   -        -   RAID1  Optl  N  893.137 GB dsbl N  N   dflt N      N  
 0 1   0   34:2     39  DRIVE  Onln  N  893.137 GB dsbl N  N   dflt -      N  
 0 1   1   34:3     40  DRIVE  Onln  N  893.137 GB dsbl N  N   dflt -      N  
 1 -   -   -        -   RAID1  Optl  N  278.464 GB dflt N  N   dflt N      N  
 1 0   -   -        -   RAID1  Optl  N  278.464 GB dflt N  N   dflt N      N  
 1 0   0   34:12    32  DRIVE  Onln  N  278.464 GB dflt N  N   dflt -      N  
 1 0   1   34:13    33  DRIVE  Onln  N  278.464 GB dflt N  N   dflt -      N  
------------------------------------------------------------------------------

DG=Disk Group Index|Arr=Array Index|Row=Row Index|EID=Enclosure Device ID
DID=Device ID|Type=Drive or RAID Type|Onln=Online|Rbld=Rebuild|Optl=Optimal
Dgrd=Degraded|Pdgd=Partially degraded|Offln=Offline|BT=Background Task Active
PDC=PD Cache|PI=Protection Info|SED=Self Encrypting Drive|Frgn=Foreign
DS3=Dimmer Switch 3|dflt=Default|Msng=Missing|FSpace=Free Space Present
TR=Transport Ready

Virtual Drives = 2

VD LIST :
=======

----------------------------------------------------------------
DG/VD TYPE   State Access Consist Cache Cac sCC       Size Name 
----------------------------------------------------------------
0/0   RAID10 Optl  RW     No      NRWTD -   ON    1.744 TB      
1/1   RAID1  Optl  RW     No      NRWBD -   ON  278.464 GB      
----------------------------------------------------------------

VD=Virtual Drive| DG=Drive Group|Rec=Recovery
Cac=CacheCade|OfLn=OffLine|Pdgd=Partially Degraded|Dgrd=Degraded
Optl=Optimal|dflt=Default|RO=Read Only|RW=Read Write|HD=Hidden|TRANS=TransportReady
B=Blocked|Consist=Consistent|R=Read Ahead Always|NR=No Read Ahead|WB=WriteBack
AWB=Always WriteBack|WT=WriteThrough|C=Cached IO|D=Direct IO|sCC=Scheduled
Check Consistency

Physical Drives = 6

PD LIST :
=======

---------------------------------------------------------------------------------------
EID:Slt DID State DG       Size Intf Med SED PI SeSz Model                     Sp Type 
---------------------------------------------------------------------------------------
34:0     21 Onln   0 893.137 GB SATA SSD N   N  512B Micron_5300_MTFDDAK960TDS U  -    
34:1     22 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
34:2     39 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
34:3     40 Onln   0 893.137 GB SATA SSD N   N  512B INTEL SSDSC2KB960G7       U  -    
34:12    32 Onln   1 278.464 GB SAS  HDD N   N  512B ST300MM0006               U  -    
34:13    33 Onln   1 278.464 GB SAS  HDD N   N  512B ST300MM0006               U  -    
---------------------------------------------------------------------------------------

EID=Enclosure Device ID|Slt=Slot No|DID=Device ID|DG=DriveGroup
DHS=Dedicated Hot Spare|UGood=Unconfigured Good|GHS=Global Hotspare
UBad=Unconfigured Bad|Sntze=Sanitize|Onln=Online|Offln=Offline|Intf=Interface
Med=Media Type|SED=Self Encryptive Drive|PI=PI Eligible
SeSz=Sector Size|Sp=Spun|U=Up|D=Down|T=Transition|F=Foreign
UGUnsp=UGood Unsupported|UGShld=UGood shielded|HSPShld=Hotspare shielded
CFShld=Configured shielded|Cpybck=CopyBack|CBShld=Copyback Shielded
UBUnsp=UBad Unsupported|Rbld=Rebuild

Enclosures = 2

Enclosure LIST :
==============

--------------------------------------------------------------------------------------------
EID State Slots PD PS Fans TSs Alms SIM Port#                      ProdID    VendorSpecific 
--------------------------------------------------------------------------------------------
 34 OK       15  6  0    0   0    0   0 Port 0 - 3 & Port 4 - 7 x8  Expander                
252 OK        8  0  0    0   0    0   1 -                          SGPIO                    
--------------------------------------------------------------------------------------------

EID=Enclosure Device ID | PD=Physical drive count | PS=Power Supply count
TSs=Temperature sensor count | Alms=Alarm count | SIM=SIM Count | ProdID=Product ID


BBU_Info :
========

-----------------------------------------------------------------------
Model  State   RetentionTime Temp Mode MfgDate    Next Learn           
-----------------------------------------------------------------------
iBBU08 Optimal 48 hours +    28C  5    2012/01/16 2025/10/17  17:14:30 
-----------------------------------------------------------------------



RAND READ

/mnt/01/fio
root@ocsamsh1:/mnt/01/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
^Cbs: 1 (f=1): [r(1)][47.1%][r=293MiB/s][r=75.1k IOPS][eta 00m:18s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=9032: Fri Sep 19 18:46:02 2025
  read: IOPS=75.7k, BW=296MiB/s (310MB/s)(4930MiB/16671msec)
   bw (  KiB/s): min=288288, max=320424, per=100.00%, avg=303056.00, stdev=5805.60, samples=33
   iops        : min=72072, max=80106, avg=75764.00, stdev=1451.40, samples=33
  cpu          : usr=15.67%, sys=53.11%, ctx=54722, majf=0, minf=82
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=1262203,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=296MiB/s (310MB/s), 296MiB/s-296MiB/s (310MB/s-310MB/s), io=4930MiB (5170MB), run=16671-16671msec

Disk stats (read/write):
    dm-5: ios=1256861/0, sectors=10054888/0, merge=0/0, ticks=991957/0, in_queue=991957, util=99.44%, aggrios=1262211/0, aggsectors=10099672/0, aggrmerge=0/0, aggrticks=941186/0, aggrin_queue=941186, aggrutil=55.43%
  sda: ios=1262211/0, sectors=10099672/0, merge=0/0, ticks=941186/0, in_queue=941186, util=55.43%
root@ocsamsh1:/mnt/01/fio# 
root@ocsamsh1:/mnt/01/fio# 







RAND WRITE

root@ocsamsh1:/mnt/01/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite --rwmixread=75
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
^Cbs: 1 (f=1): [w(1)][48.1%][w=191MiB/s][w=48.8k IOPS][eta 00m:27s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=9140: Fri Sep 19 18:46:32 2025
  write: IOPS=49.3k, BW=193MiB/s (202MB/s)(4831MiB/25079msec); 0 zone resets
   bw (  KiB/s): min=179104, max=202344, per=100.00%, avg=197379.04, stdev=3554.30, samples=50
   iops        : min=44776, max=50586, avg=49344.76, stdev=888.58, samples=50
  cpu          : usr=11.27%, sys=40.07%, ctx=41887, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,1236806,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=193MiB/s (202MB/s), 193MiB/s-193MiB/s (202MB/s-202MB/s), io=4831MiB (5066MB), run=25079-25079msec

Disk stats (read/write):
    dm-5: ios=0/1227279, sectors=0/9818220, merge=0/0, ticks=0/1272004, in_queue=1272004, util=99.47%, aggrios=12/1236810, aggsectors=3072/9894468, aggrmerge=0/0, aggrticks=29/1310411, aggrin_queue=1310440, aggrutil=50.68%
  sda: ios=12/1236810, sectors=3072/9894468, merge=0/0, ticks=29/1310411, in_queue=1310440, util=50.68%





SEQUENTIAL WRITE


root@ocsamsh1:/mnt/01/fio# dd if=/dev/zero of=./test bs=4MiB count=2000
2000+0 records in
2000+0 records out
8388608000 bytes (8.4 GB, 7.8 GiB) copied, 13.2475 s, 633 MB/s



============

585g7

Model name:            AMD Opteron(TM) Processor 6276
BIOS Model name:     AMD Opteron(TM) Processor 6276                    CPU @ 2.3GHz




Smart Array P410i in Slot 0 (Embedded)
   Bus Interface: PCI
   Slot: 0
   Serial Number: 5001438023EC2230
   Cache Serial Number: PACCQID12480X2X
   Controller Status: OK
   Hardware Revision: C
   Firmware Version: 5.76
   Rebuild Priority: Low
   Expand Priority: Medium
   Surface Scan Delay: 15 secs
   Surface Scan Mode: Idle
   Parallel Surface Scan Supported: No
   Queue Depth: Automatic
   Monitor and Performance Delay: 60  min
   Elevator Sort: Enabled
   Degraded Performance Optimization: Disabled
   Inconsistency Repair Policy: Disabled
   Wait for Cache Room: Disabled
   Surface Analysis Inconsistency Notification: Disabled
   Post Prompt Timeout: 0 secs
   Cache Board Present: True
   Cache Status: OK
   Cache Ratio: 100% Read / 0% Write
   Drive Write Cache: Enabled
   Total Cache Size: 256 MB
   Total Cache Memory Available: 144 MB
   No-Battery Write Cache: Disabled
   Battery/Capacitor Count: 0
   SATA NCQ Supported: True
   Number of Ports: 2 Internal only
   Driver Name: hpsa
   Driver Version: 3.4.20
   Driver Supports HPE SSD Smart Path: True
   PCI Address (Domain:Bus:Device.Function): 0000:03:00.0
   Host Serial Number: CZ33109AJ9
   Sanitize Erase Supported: False
   Primary Boot Volume: logicaldrive 1 (600508B1001CFBAB2623FB21A81DBB09)
   Secondary Boot Volume: None


raid0

      physicaldrive 1I:1:2
         Port: 1I
         Box: 1
         Bay: 2
         Status: Predictive Failure
         Drive Type: Data Drive
         Interface Type: Solid State SATA
         Size: 179.2 GB
         Drive exposed to OS: False
         Native Block Size: 512
         Firmware Revision: LHF002D
         Serial Number: BTLA9466085G256CGN
         Model: ATA     INTEL SSDSC2KI25
         SATA NCQ Capable: True
         SATA NCQ Enabled: True
         Current Temperature (C): 39
         Maximum Temperature (C): 40
         SSD Smart Trip Wearout: Not Supported
         PHY Count: 1
         PHY Transfer Rate: 3.0Gbps
         Sanitize Erase Supported: False




root@p565h1:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=130MiB/s][r=33.4k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=272279: Wed Sep 24 21:59:20 2025
  read: IOPS=33.9k, BW=132MiB/s (139MB/s)(9.77GiB/75541msec)
   bw (  KiB/s): min=129592, max=136976, per=100.00%, avg=135631.30, stdev=1283.92, samples=150
   iops        : min=32398, max=34244, avg=33907.43, stdev=320.93, samples=150
  cpu          : usr=13.33%, sys=67.32%, ctx=301929, majf=0, minf=91
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=132MiB/s (139MB/s), 132MiB/s-132MiB/s (139MB/s-139MB/s), io=9.77GiB (10.5GB), run=75541-75541msec

Disk stats (read/write):
  sdb: ios=2554900/0, merge=0/0, ticks=4407348/0, in_queue=4407348, util=100.00%
root@p565h1:/mnt/sdb/1/fio# 









root@p565h1:/mnt/sdb/1/fio# 
root@p565h1:/mnt/sdb/1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=105MiB/s][w=26.9k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=272741: Wed Sep 24 22:02:17 2025
  write: IOPS=26.7k, BW=104MiB/s (109MB/s)(9.77GiB/95808msec); 0 zone resets
   bw (  KiB/s): min=37716, max=113384, per=100.00%, avg=106944.64, stdev=9403.84, samples=191
   iops        : min= 9429, max=28346, avg=26735.85, stdev=2350.94, samples=191
  cpu          : usr=12.54%, sys=60.37%, ctx=341206, majf=0, minf=28
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=104MiB/s (109MB/s), 104MiB/s-104MiB/s (109MB/s-109MB/s), io=9.77GiB (10.5GB), run=95808-95808msec

Disk stats (read/write):
  sdb: ios=0/2555454, merge=0/0, ticks=0/5800922, in_queue=5800922, util=100.00%
root@p565h1:/mnt/sdb/1/fio# 






=================

585G7  сервер
smart array p410i  контрроллер

ceph из 3-х дисков  (три OSD)           INTEL SSDSC2KI25


выдает 17 000-18 000 IOPS на тесте
 fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/fio/1/test --bs=4k --iodepth=64 --size=10000M --readwrite=randread


если убавить osd до двух то чтение падает до 12 000 IOPS тоесть  один диск (oSD ) дает 5000-6000 IOPS


сам контроллер с этого диска на RAID0 может снять на этом тесте 26 000 IOPS.
а если этот диск сунуть в AHCI порт то на этом тесте с этого диска можно снять 86 000 IOPS

однозначно я упираюсь в скорость ядра!
Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
sdb           4356.00  17424.00     0.00   0.00    0.19     4.00    2.00     12.00     1.00  33.33    0.50     6.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.84  54.50

потому что видно что диск занят по busytime на 54%
(остальные иопсы читаются по сети от других нод)



на текущем этапе как я понимаю упираемся в скорость 1-го ядра цпу.
также если запустить две виртуалки или два контейнера то скорость делится между 
ними. тоесть 18000 IOPS делится между контейнерами

сеть 10Gb при этом загружена на 22 МБ/с в обе стороны


====================

ceph 
performance

8 хостов
на каждом хосте стоит по 3 OSD. (итого 24 OSD)
каждый OSD состоит из 
       1 HDD 2.5'' 900GB SAS 10000 RPM шпиндель диска 
          плюс 
        SSD диск INTEL SSDSC2KG48 под журнал

сеть 10Gb 


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread --rwmixread=75
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
^Cbs: 1 (f=1): [r(1)][9.8%][r=9024KiB/s][r=2256 IOPS][eta 15m:08s] 
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=17845: Fri Sep 26 18:48:32 2025
  read: IOPS=2542, BW=9.93MiB/s (10.4MB/s)(985MiB/99189msec)
   bw (  KiB/s): min= 5984, max=12984, per=100.00%, avg=10192.67, stdev=1340.03, samples=198
   iops        : min= 1496, max= 3246, avg=2547.99, stdev=335.03, samples=198
  cpu          : usr=1.09%, sys=8.09%, ctx=212931, majf=0, minf=89
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=252154,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=9.93MiB/s (10.4MB/s), 9.93MiB/s-9.93MiB/s (10.4MB/s-10.4MB/s), io=985MiB (1033MB), run=99189-99189msec

Disk stats (read/write):
  rbd1: ios=252129/22, merge=0/0, ticks=6314288/497, in_queue=6314785, util=100.00%


ИТОГО random read 2256 IOPS (пиздец как медленно)



# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
 bs: 1 (f=1): [w(1)][9.2%][w=7235KiB/s][w=1808 IOPS][eta 17m:46s]
fio: terminating on signal 2
Jobs: 1 (f=0): [f(1)][100.0%][w=4316KiB/s][w=1079 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=17852: Fri Sep 26 18:50:36 2025
  write: IOPS=2174, BW=8698KiB/s (8907kB/s)(916MiB/107817msec); 0 zone resets
   bw (  KiB/s): min= 3711, max=15014, per=100.00%, avg=8720.94, stdev=2247.92, samples=215
   iops        : min=  927, max= 3753, avg=2180.09, stdev=562.01, samples=215
  cpu          : usr=0.99%, sys=7.10%, ctx=180594, majf=0, minf=14
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,234453,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=8698KiB/s (8907kB/s), 8698KiB/s-8698KiB/s (8907kB/s-8907kB/s), io=916MiB (960MB), run=107817-107817msec

Disk stats (read/write):
  rbd1: ios=0/234330, merge=0/0, ticks=0/6850661, in_queue=6850660, util=99.98%




ИТОГО random write 1808 IOPS (пиздец как медленно)


======================


ZFS 
pool вот такой

  pool: strip-2mirror
 state: ONLINE
  scan: scrub repaired 0B in 08:46:21 with 0 errors on Sun Sep 14 08:46:24 2025
config:

  NAME                                            STATE     READ WRITE CKSUM
  strip-2mirror                                   ONLINE       0     0     0
    mirror-0                                      ONLINE       0     0     0
      gptid/04b6cc93-dca8-11ea-af22-782bcb09ac2d  ONLINE       0     0     0
      gptid/04becd1b-dca8-11ea-af22-782bcb09ac2d  ONLINE       0     0     0
    mirror-1                                      ONLINE       0     0     0
      gptid/04c381f9-dca8-11ea-af22-782bcb09ac2d  ONLINE       0     0     0
      gptid/04df1d47-dca8-11ea-af22-782bcb09ac2d  ONLINE       0     0     0
    mirror-2                                      ONLINE       0     0     0
      gptid/04fa174a-dca8-11ea-af22-782bcb09ac2d  ONLINE       0     0     0
      gptid/b4ed60c8-7b3c-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
    mirror-3                                      ONLINE       0     0     0
      gptid/aa2e44c8-7b3b-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
      gptid/aa3c7586-7b3b-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
    mirror-4                                      ONLINE       0     0     0
      gptid/0714e2bd-7b3c-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
      gptid/0725ae55-7b3c-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
    mirror-5                                      ONLINE       0     0     0
      gptid/69564a87-a431-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
      gptid/6991aa26-a431-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
    mirror-6                                      ONLINE       0     0     0
      gptid/4d34f1b1-9c8b-11ed-9ab1-782bcb09ac2d  ONLINE       0     0     0
      gptid/4d5598d8-9c8b-11ed-9ab1-782bcb09ac2d  ONLINE       0     0     0
    mirror-7                                      ONLINE       0     0     0
      gptid/8b53c1e9-b6dc-11ee-9b3c-782bcb09ac2d  ONLINE       0     0     0
      gptid/8b80fc53-b6dc-11ee-9b3c-782bcb09ac2d  ONLINE       0     0     0
    mirror-8                                      ONLINE       0     0     0
      gptid/67481144-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
      gptid/6764fb75-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
    mirror-9                                      ONLINE       0     0     0
      gptid/95bedf1a-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
      gptid/95aa8d1a-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
    mirror-10                                     ONLINE       0     0     0
      gptid/a9b90f50-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
      gptid/a9c2aecc-2df8-11ef-9b3c-782bcb09ac2d  ONLINE       0     0     0
    mirror-11                                     ONLINE       0     0     0
      gptid/60fdf86b-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
      gptid/6109c0d5-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-12                                     ONLINE       0     0     0
      gptid/7258d993-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
      gptid/726281c0-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-13                                     ONLINE       0     0     0
      gptid/85fc24bc-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
      gptid/85f1da7e-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-14                                     ONLINE       0     0     0
      gptid/b4f96ce9-7b3c-11eb-8ac6-782bcb09ac2d  ONLINE       0     0     0
      gptid/90d7907b-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-15                                     ONLINE       0     0     0
      gptid/9c46ff52-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
      gptid/9c948a9a-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-16                                     ONLINE       0     0     0
      gptid/ab56f791-5d07-11f0-9585-782bcb09ac2d  ONLINE       0     0     0
      gptid/a89a9348-0963-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
    mirror-17                                     ONLINE       0     0     0
      gptid/e7a009d4-5bed-11f0-ae79-782bcb09ac2d  ONLINE       0     0     0
      mfid24                                      ONLINE       0     0     0
  spares
    gptid/ab4cba0d-5d07-11f0-9585-782bcb09ac2d    AVAIL   
    gptid/bcdadc57-713d-11f0-9585-782bcb09ac2d    AVAIL   


по факту это все 2ТБ шпидель диски

и он расшарен по NFS


тестирую скорость


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=./test --filename=test --bs=4k --iodepth=64 --size=32000M --readwrite=randread 
./test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.25
Starting 1 process
^Cbs: 1 (f=1): [r(1)][0.6%][r=2506KiB/s][r=626 IOPS][eta 02h:00m:18s] 
fio: terminating on signal 2
Jobs: 1 (f=1): [r(1)][0.7%][r=1469KiB/s][r=367 IOPS][eta 02h:02m:00s]
./test: (groupid=0, jobs=1): err= 0: pid=3033789: Fri Sep 26 22:42:53 2025
  read: IOPS=1112, BW=4451KiB/s (4558kB/s)(209MiB/48010msec)
   bw (  KiB/s): min=  848, max=65640, per=100.00%, avg=4493.00, stdev=7958.88, samples=95
   iops        : min=  212, max=16410, avg=1123.24, stdev=1989.71, samples=95
  cpu          : usr=0.68%, sys=2.76%, ctx=37579, majf=0, minf=388
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=53428,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=4451KiB/s (4558kB/s), 4451KiB/s-4451KiB/s (4558kB/s-4558kB/s), io=209MiB (219MB), run=48010-48010msec



ИТОГО: какой то пиздец  RAND READ 626 IOPS


======================

nvme диск

$ nvme list
Model                                    Namespace  Usage                      Format             
--------------------- --------------------- -------------------- -----------------------------
WDC PC SN520 SDAPMUW-512G-1101           0x1        512.11  GB / 512.11  GB      4 KiB +  0 B   


 N 㸒  $ fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=431MiB/s][r=110k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=153276: Sat Sep 27 19:16:59 2025
  read: IOPS=113k, BW=440MiB/s (461MB/s)(9.77GiB/22727msec)
   bw (  KiB/s): min=419896, max=470736, per=100.00%, avg=450731.38, stdev=8717.04, samples=45
   iops        : min=104974, max=117684, avg=112682.84, stdev=2179.26, samples=45
  cpu          : usr=18.01%, sys=59.32%, ctx=2322, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=440MiB/s (461MB/s), 440MiB/s-440MiB/s (461MB/s-461MB/s), io=9.77GiB (10.5GB), run=22727-22727msec

Disk stats (read/write):
    dm-0: ios=2548971/43, sectors=20391768/1544, merge=0/0, ticks=781053/14, in_queue=781067, util=99.62%, aggrios=2560000/43, aggsectors=20480000/1544, aggrmerge=0/0, aggrticks=739692/14, aggrin_queue=739714, aggrutil=86.34%
  nvme0n1: ios=2560000/43, sectors=20480000/1544, merge=0/0, ticks=739692/14, in_queue=739714, 
  util=86.34%


итого рандом рид 110 000 IOPS


а вот еще
 N 舔  $ sudo dd if=/dev/nvme0n1   of=/dev/null bs=8MiB status=progress
3531603968 bytes (3,5 GB, 3,3 GiB) copied, 5 s, 703 MB/s^C
439+0 records in
438+0 records out
3674210304 bytes (3,7 GB, 3,4 GiB) copied, 5,60163 s, 656 MB/s

ну както маловато. согласно спеку
    https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/pc-sn520-ssd/data-sheet-pc-sn520-compute.pdf

он должен на секвеншиал рид выжимать 1700 MB/s



=========================

AHCI порт 6Gb/s
cpu Intel(R) Core(TM) i3-4130 CPU @ 3.40GHz
диск  INTEL SSDSC2KI256G8

linear read
 dd if=/dev/sda2 of=/dev/null bs=8MiB status=progress
24754782208 bytes (25 GB, 23 GiB) copied, 44 s, 563 MB/s


random read  76 000 IOPS

o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=301MiB/s][r=76.9k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1113: Tue Sep 30 07:54:43 2025
  read: IOPS=76.6k, BW=299MiB/s (314MB/s)(9.77GiB/33406msec)
   bw (  KiB/s): min=304360, max=308032, per=99.96%, avg=306399.88, stdev=737.70, samples=66
   iops        : min=76090, max=77008, avg=76599.97, stdev=184.41, samples=66
  cpu          : usr=18.48%, sys=29.29%, ctx=2401403, majf=0, minf=71
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=299MiB/s (314MB/s), 299MiB/s-299MiB/s (314MB/s-314MB/s), io=9.77GiB (10.5GB), run=33406-33406msec

Disk stats (read/write):
  sda: ios=2555449/0, merge=3482/0, ticks=2121214/0, in_queue=2121214, util=79.07%


random write 68 800 IOPS

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=269MiB/s][w=68.8k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1120: Tue Sep 30 07:56:09 2025
  write: IOPS=72.9k, BW=285MiB/s (298MB/s)(9.77GiB/35136msec); 0 zone resets
   bw (  KiB/s): min=256696, max=358720, per=100.00%, avg=291689.83, stdev=31415.96, samples=70
   iops        : min=64174, max=89680, avg=72922.49, stdev=7853.97, samples=70
  cpu          : usr=19.87%, sys=40.21%, ctx=1419012, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=285MiB/s (298MB/s), 285MiB/s-285MiB/s (298MB/s-298MB/s), io=9.77GiB (10.5GB), run=35136-35136msec

Disk stats (read/write):
  sda: ios=0/2542649, merge=0/1107, ticks=0/2146857, in_queue=2146895, util=83.84%




диск  Micron_5300_MTFDDAK480TDS


LINEAR READ
# dd if=/dev/sdc2 of=/dev/null bs=8MiB status=progress
23882366976 bytes (24 GB, 22 GiB) copied, 45 s, 531 MB/s




RANDOM READ  83.6k IOPS


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=327MiB/s][r=83.6k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1184: Tue Sep 30 08:04:44 2025
  read: IOPS=84.0k, BW=328MiB/s (344MB/s)(9.77GiB/30463msec)
   bw (  KiB/s): min=330336, max=341280, per=100.00%, avg=336455.60, stdev=2010.31, samples=60
   iops        : min=82584, max=85320, avg=84113.87, stdev=502.54, samples=60
  cpu          : usr=22.57%, sys=43.84%, ctx=2204234, majf=0, minf=72
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=328MiB/s (344MB/s), 328MiB/s-328MiB/s (344MB/s-344MB/s), io=9.77GiB (10.5GB), run=30463-30463msec

Disk stats (read/write):
  sdc: ios=2552055/0, merge=2546/0, ticks=1925696/0, in_queue=1925696, util=72.27%




RANDOM WRITE   87.2k IOPS


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=340MiB/s][w=87.2k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1191: Tue Sep 30 08:05:44 2025
  write: IOPS=86.4k, BW=338MiB/s (354MB/s)(9.77GiB/29622msec); 0 zone resets
   bw (  KiB/s): min=329488, max=350888, per=100.00%, avg=345828.75, stdev=6021.10, samples=59
   iops        : min=82372, max=87722, avg=86457.15, stdev=1505.16, samples=59
  cpu          : usr=20.06%, sys=39.11%, ctx=2116614, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=338MiB/s (354MB/s), 338MiB/s-338MiB/s (354MB/s-354MB/s), io=9.77GiB (10.5GB), run=29622-29622msec

Disk stats (read/write):
  sdc: ios=0/2539291, merge=0/1424, ticks=0/1853982, in_queue=1853983, util=83.09%

==================================================================


HBA контроллер LSI 9217-8i  , 6Gb/s  (чипсет 2308)
  ( не путать с другим чипсетом 2308_2 и картой SAS9207-8i !! ) 




диск  INTEL SSDSC2KI256G8


LINEAR READ 483 MB/s




RANDOM READ  49.8k IOPS


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=195MiB/s][r=49.8k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1243: Tue Sep 30 08:16:06 2025
  read: IOPS=49.4k, BW=193MiB/s (202MB/s)(9.77GiB/51801msec)
   bw (  KiB/s): min=192672, max=203568, per=100.00%, avg=197688.85, stdev=981.26, samples=103
   iops        : min=48168, max=50892, avg=49422.25, stdev=245.31, samples=103
  cpu          : usr=14.05%, sys=42.12%, ctx=1574887, majf=0, minf=79
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=193MiB/s (202MB/s), 193MiB/s-193MiB/s (202MB/s-202MB/s), io=9.77GiB (10.5GB), run=51801-51801msec

Disk stats (read/write):
  sda: ios=2548663/0, merge=2044/0, ticks=3274666/0, in_queue=3274666, util=78.01%





RANDOM WRITE 40.8k IOPS

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=159MiB/s][w=40.8k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1536: Tue Sep 30 08:25:57 2025
  write: IOPS=40.8k, BW=159MiB/s (167MB/s)(9.77GiB/62740msec); 0 zone resets
   bw (  KiB/s): min=150656, max=169928, per=100.00%, avg=163220.74, stdev=3468.80, samples=125
   iops        : min=37664, max=42482, avg=40805.17, stdev=867.20, samples=125
  cpu          : usr=14.31%, sys=41.35%, ctx=1880876, majf=0, minf=19
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=159MiB/s (167MB/s), 159MiB/s-159MiB/s (167MB/s-167MB/s), io=9.77GiB (10.5GB), run=62740-62740msec

Disk stats (read/write):
  sda: ios=0/2552193, merge=0/2547, ticks=0/3947846, in_queue=3947893, util=84.92%




диск  Micron_5300_MTFDDAK480TDS


LINEAR READ 460 MB/s



RANDOM READ  41.6k IOPS


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=162MiB/s][r=41.6k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1305: Tue Sep 30 08:19:47 2025
  read: IOPS=37.8k, BW=148MiB/s (155MB/s)(9.77GiB/67770msec)
   bw (  KiB/s): min=135832, max=177560, per=100.00%, avg=151160.65, stdev=11261.55, samples=135
   iops        : min=33958, max=44390, avg=37790.19, stdev=2815.37, samples=135
  cpu          : usr=12.62%, sys=35.15%, ctx=1710786, majf=0, minf=79
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=148MiB/s (155MB/s), 148MiB/s-148MiB/s (155MB/s-155MB/s), io=9.77GiB (10.5GB), run=67770-67770msec

Disk stats (read/write):
  sdd: ios=2552457/2, merge=2639/0, ticks=4277346/4, in_queue=4277352, util=77.48%



RANDOM WRITE 40.1k IOPS


# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [w(1)][100.0%][w=157MiB/s][w=40.1k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=1588: Tue Sep 30 08:26:11 2025
  write: IOPS=40.2k, BW=157MiB/s (165MB/s)(9.77GiB/63721msec); 0 zone resets
   bw (  KiB/s): min=159072, max=164736, per=100.00%, avg=160714.08, stdev=750.45, samples=127
   iops        : min=39768, max=41184, avg=40178.54, stdev=187.62, samples=127
  cpu          : usr=16.15%, sys=45.16%, ctx=1997986, majf=0, minf=17
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560000,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=157MiB/s (165MB/s), 157MiB/s-157MiB/s (165MB/s-165MB/s), io=9.77GiB (10.5GB), run=63721-63721msec

Disk stats (read/write):
  sdd: ios=0/2553514, merge=0/2881, ticks=0/3982685, in_queue=3982689, util=84.14%



ОБЩИЙ ВЫВОД : видно что карта  LSI 9217-8i (на чипе 2308) в режиме HBA 
дает в 2 раза скорость меньше чем обычный AHCI порт на простом компе !!


итак мы выяснили что данный хба контррллер режет теряет скорость в 1.5-2 раза
по сравннеию какая скорость у диска вобщето может быть.

причем я проверил что нет разницы какая прошивка у контроллера IR или IT
тоесть если у вас контррлллер  на прошивке IR (рейдовая) то особого смысла
перешивать ее в IT смысла нет.

еще раз скажу что этот контрроллер работате на чипе 2308

====================================

AHCI
диск Samsung SSD 860 EVO 1TB



o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=384MiB/s][r=98.4k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=803: Thu Oct  2 10:25:05 2025
  read: IOPS=98.1k, BW=383MiB/s (402MB/s)(9.77GiB/26101msec)
   bw (  KiB/s): min=387288, max=396072, per=100.00%, avg=392423.69, stdev=892.87, samples=52
   iops        : min=96822, max=99018, avg=98106.00, stdev=223.22, samples=52
  cpu          : usr=25.85%, sys=39.00%, ctx=2415048, majf=0, minf=74
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=383MiB/s (402MB/s), 383MiB/s-383MiB/s (402MB/s-402MB/s), io=9.77GiB (10.5GB), run=26101-26101msec

Disk stats (read/write):
  sdb: ios=2538005/1, merge=1336/0, ticks=1640310/1, in_queue=1640311, util=71.87%

===========================

| LSI
| SAS3008


КАРТА:
root@debian:/opt/SAS3IRCU# ./sas3ircu list
Avago Technologies SAS3 IR Configuration Utility.
Version 17.00.00.00 (2018.04.02) 
Copyright (c) 2009-2018 Avago Technologies. All rights reserved. 


         Adapter      Vendor  Device                       SubSys  SubSys 
 Index    Type          ID      ID    Pci Address          Ven ID  Dev ID 
 -----  ------------  ------  ------  -----------------    ------  ------ 
   0     SAS3008       1000h   97h    00h:01h:00h:00h      1000h   3090h 
SAS3IRCU: Utility Completed Successfully.
root@debian:/opt/SAS3IRCU# 
root@debian:/opt/SAS3FLASH# chmod +x sas3flash 
root@debian:/opt/SAS3FLASH# ./sas3flash -list
Avago Technologies SAS3 Flash Utility
Version 16.00.00.00 (2017.05.02) 
Copyright 2008-2017 Avago Technologies. All rights reserved.

  Adapter Selected is a Avago SAS: SAS3008(C0)

  Controller Number              : 0
  Controller                     : SAS3008(C0)
  PCI Address                    : 00:01:00:00
  SAS Address                    : 5d494e8-0-f1b2-8000
  NVDATA Version (Default)       : 02.06.00.02
  NVDATA Version (Persistent)    : 02.06.00.02
  Firmware Product ID            : 0x2721 (IR)
  Firmware Version               : 02.00.00.00
  NVDATA Vendor                  : LSI
  NVDATA Product ID              : SAS3008
  BIOS Version                   : 08.05.00.00
  UEFI BSD Version               : 02.00.00.00
  FCODE Version                  : N/A
  Board Name                     : SAS3008
  Board Assembly                 : N/A
  Board Tracer Number            : N/A

  Finished Processing Commands Successfully.
  Exiting SAS3Flash.




диск: Samsung SSD 860 EVO 1TB

CPU :  Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz


RANDOM READ 57.6k IOPS 
 
root@debian:/mnt/sdb1/fio# dd if=/dev/zero of=/dev/sdd bs=1M count=100^C
root@debian:/mnt/sdb1/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
test: Laying out IO file (1 file / 10000MiB)
Jobs: 1 (f=1): [r(1)][100.0%][r=225MiB/s][r=57.6k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=16218: Thu Oct  2 12:38:55 2025
  read: IOPS=57.5k, BW=225MiB/s (236MB/s)(9.77GiB/44519msec)
   bw (  KiB/s): min=181664, max=240440, per=100.00%, avg=230088.54, stdev=7168.94, samples=89
   iops        : min=45416, max=60110, avg=57522.16, stdev=1792.25, samples=89
  cpu          : usr=12.20%, sys=43.54%, ctx=1359624, majf=0, minf=85
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=225MiB/s (236MB/s), 225MiB/s-225MiB/s (236MB/s-236MB/s), io=9.77GiB (10.5GB), run=44519-44519msec

Disk stats (read/write):
  sdb: ios=2547957/4, merge=1982/4, ticks=2817383/731, in_queue=2818296, util=88.13%


вывод: результат отстой. из за медленного контролллера



запустил тест сразу на двух дисках.
резулттат один и тот же. 
тоесть диски друг другу немешают.  с каждого читается RANDOM READ плюс минус 
со скоростью 57.6k IOPS


а вот тест RANDOM WRITE  r=59.3k IOPS

o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=232MiB/s][r=59.3k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=16491: Thu Oct  2 12:45:39 2025
  read: IOPS=59.3k, BW=232MiB/s (243MB/s)(9.77GiB/43139msec)
   bw (  KiB/s): min=235976, max=239776, per=100.00%, avg=237420.47, stdev=377.66, samples=86
   iops        : min=58994, max=59944, avg=59355.12, stdev=94.42, samples=86
  cpu          : usr=13.23%, sys=42.01%, ctx=1703688, majf=0, minf=84
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=232MiB/s (243MB/s), 232MiB/s-232MiB/s (243MB/s-243MB/s), io=9.77GiB (10.5GB), run=43139-43139msec

Disk stats (read/write):
  sdc: ios=2555925/0, merge=3818/0, ticks=2734927/0, in_queue=2734928, util=83.69%


вывод: контрроллер медленный . диски свою скорость не раскрывают.


ДАЛЕЕ:
я перешил контролллер на прошивку IT результатт тот же самый! RAND READ 59.9k IOPS !!
тоесть пршивка невлияет IR или IT!


===========

ОБЩИЙ ВЫВОД НА ДАННЫЙ МОМЕНТ на счет контроллеров:

 лучше всего выжимает голый AHCI порт. скажем 98 kIOPS (samsung 860) тоесть 100% от 
   возможностей диска
 потом с потерей в 2 раза 50-60 KIOPS выжимает LSI 2308\3008 
 потом еще хуже smart array P410. он выжимает всего 26 kIOPS. (тоесть еще в 2 раза хуже)


===========================

lsi 9300 (sas 3008)
диск Model Family:     Hitachi/HGST Ultrastar 7K4000
Device Model:     HGST HUS724020ALA640


лин чтение 150-170 МБ/с
лин запись 150-170 МБ/с

ранд рид 33 ИОПС
ранд врайт 33 ИОПС



пул из 8 таких дисков на zfs
лин запись 460 МБ/с
лин чтение 650 МБ/с
ранд рид всего 150 ИОПС (почему то кадый диск выдает всего 18-30 иопс)
ранд врайт  150 ИОПС (при этом видно что идут паразитные чтения перед записью
нейронка говорит это норм. это он читает метаданные. типа без этого никак)



==============================

| lsi
| sas2008
| SAS9207-8i
| Samsung SSD 860 EVO 1TB
| INTEL SSDSC2KB480GZ


вот такой чип

root@pve:/opt/LSI# ./sas2ircu  list
LSI Corporation SAS2 IR Configuration Utility.
Version 20.00.00.00 (2014.09.18) 
Copyright (c) 2008-2014 LSI Corporation. All rights reserved. 


         Adapter      Vendor  Device                       SubSys  SubSys 
 Index    Type          ID      ID    Pci Address          Ven ID  Dev ID 
 -----  ------------  ------  ------  -----------------    ------  ------ 
   0     SAS2308_2     1000h    87h   00h:02h:00h:00h      1028h   1f38h 
SAS2IRCU: Utility Completed Successfully.



вот такая карта

root@pve:/opt/LSI# ./sas2flash -list
LSI Corporation SAS2 Flash Utility
Version 20.00.00.00 (2014.09.18) 
Copyright (c) 2008-2014 LSI Corporation. All rights reserved 

  Adapter Selected is a LSI SAS: SAS2308_2(D1) 

  Controller Number              : 0
  Controller                     : SAS2308_2(D1) 
  PCI Address                    : 00:02:00:00
  SAS Address                    : 500605b-1-2345-6777
  NVDATA Version (Default)       : 14.01.00.06
  NVDATA Version (Persistent)    : 14.01.00.06
  Firmware Product ID            : 0x2214 (IT)
  Firmware Version               : 20.00.07.00
  NVDATA Vendor                  : LSI
  NVDATA Product ID              : SAS9207-8i
  BIOS Version                   : 07.39.02.00
  UEFI BSD Version               : 07.27.01.01
  FCODE Version                  : N/A
  Board Name                     : SAS9207-8i
  Board Assembly                 : N/A
  Board Tracer Number            : N/A

  Finished Processing Commands Successfully.
  Exiting SAS2Flash.



диск INTEL SSDSC2KB480GZ



RAND READ [70.0k] IOPS

root@pve:/opt/LSI# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdc --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=276MiB/s][r=70.6k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=5018: Tue Oct 14 18:51:18 2025
  read: IOPS=54.5k, BW=213MiB/s (223MB/s)(9.77GiB/46962msec)
   bw (  KiB/s): min=159360, max=283448, per=99.79%, avg=217582.19, stdev=45479.13, samples=93
   iops        : min=39840, max=70862, avg=54395.59, stdev=11369.74, samples=93
  cpu          : usr=20.75%, sys=66.76%, ctx=311765, majf=0, minf=83
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=213MiB/s (223MB/s), 213MiB/s-213MiB/s (223MB/s-223MB/s), io=9.77GiB (10.5GB), run=46962-46962msec

Disk stats (read/write):
  sdc: ios=2550859/0, sectors=20427744/0, merge=2619/0, ticks=1441791/0, in_queue=1441791, util=99.84%


для сраврния этот же диск на  такомже тесте на AHCI 6Gb порту выдает [76.9k] IOPS


этот же контррллер этот же тест
но диск 

   Samsung SSD 860 EVO 1TB


root@pve:/opt/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=./test  --bs=4k --iodepth=64 --size=10000M --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=211MiB/s][r=54.1k IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=5367: Tue Oct 14 18:53:18 2025
  read: IOPS=58.3k, BW=228MiB/s (239MB/s)(9.77GiB/43942msec)
   bw (  KiB/s): min=121048, max=271056, per=99.87%, avg=232725.15, stdev=55396.98, samples=87
   iops        : min=30262, max=67764, avg=58181.31, stdev=13849.20, samples=87
  cpu          : usr=17.25%, sys=67.31%, ctx=140265, majf=0, minf=73
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=2560000,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=228MiB/s (239MB/s), 228MiB/s-228MiB/s (239MB/s-239MB/s), io=9.77GiB (10.5GB), run=43942-43942msec

Disk stats (read/write):
    dm-1: ios=2556265/17, sectors=20450120/562, merge=0/0, ticks=2001246/35, in_queue=2001281, util=99.82%, aggrios=2556019/16, aggsectors=20484096/562, aggrmerge=3997/1, aggrticks=2005842/29, aggrin_queue=2005872, aggrutil=72.56%
  sda: ios=2556019/16, sectors=20484096/562, merge=3997/1, ticks=2005842/29, in_queue=2005872, util=72.56%



для сраранеия этот же диск на AHCI порту выдает [98.4k] IOPS
а на 3008 чипе выдает [57.6k] IOPS


этотже контролер проверим лин чтение.
диск INTEL SSDSC2KB480GZ  

o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdc  --bs=1M --iodepth=1 --size=10000M --readwrite=read
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=libaio, iodepth=1
fio-3.39
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=398MiB/s][r=398 IOPS][eta 00m:00s]
( на AHCI этот диск выдает 361 MB/s)



проверим лин чтение для     Samsung SSD 860 EVO 1TB

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=./test  --bs=1M --iodepth=1 --size=10000M --readwrite=read
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=libaio, iodepth=1
fio-3.39
Starting 1 process
Jobs: 1 (f=0): [f(1)][100.0%][r=450MiB/s][r=450 IOPS][eta 00m:00s]
( на AHCI этот диск выдает 482 MB/s)




итого на вот этом контролере
 sas2008
 SAS9207-8i

из вот этого диска 
диск INTEL SSDSC2KB480GZ  

он выжимает 
RAND READ [70.0k] IOPS   из максимально возможных  [76.9k] IOPS
LIN READ r=398MiB/s  из такой же максимально возможной


из вот этого диска 
диск    Samsung SSD 860 EVO 1TB

он выжимает 
RAND READ [54.1k] IOPS   из максимально возможных  [98.4k] IOPS
LIN READ r=450MiB/s      из максимально возможной  482 MB/s



еще раз тестирую


диск INTEL SSDSC2KB480GZ  
  RAND READ 
    fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=./test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
        AHCI(linux):                    [84.9k] IOPS
        sas2008(SAS9207-8i)(linux)      [69.9k] IOPS
        sas2008(SAS9207-8i)(solaris)    [15.7K] IOPS   ***солярис полный провал!!***


  LIN READ
    fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdc  --bs=1M --iodepth=1 --size=10000M --readwrite=read
      AHCI(linux):                      403MiB/s
      sas2008(SAS9207-8i)(linux)        401MiB/s
      sas2008(SAS9207-8i)(solaris)      322.0MiB/s   ***солярис провал***




диск Samsung SSD 860 EVO 1TB
  RAND READ 
    fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=./test --bs=4k --iodepth=64 --size=10000M --readwrite=randread
      AHCI(linux)                     [98.9k] IOPS
      sas2008(SAS9207-8i)(linux)      [57.2k] IOPS
      sas2008(SAS9207-8i)(solaris)    [16.8K] IOPS   ***солярис полный провал!!***



  LIN READ
    fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdc  --bs=1M --iodepth=1 --size=10000M --readwrite=read
      AHCI(linux):                    502MB/s
      sas2008(SAS9207-8i)(linux)      484MB/s
      sas2008(SAS9207-8i)(solaris)    449MiB/s   





==============================================================================


связка двух компов

host1
    dell r720 
      Intel(R) Xeon(R) CPU E5-2643 v2 @ 3.50GHz   x 24 ядра
      RAM 192 GB
    proxmox 9
    NIC 10GiB Intel Corporation 82599ES  1xport  9000 mtu


host2
    dell r720 
      Intel(R) Xeon(R) CPU E5-2643 v2 @ 3.50GHz x 24 ядра
      RAM 256 GB
    truenas 25.10.0.1 - Goldeye 
    NIC 10GiB  Intel Corporation 82599ES  1xport  9000 mtu

    диски :
      6 Х HDD HGST_HUS724020ALA640    2TB   (содеиненны в страйп из мирроров)
      1 X SSD INTEL_SSDSC2KB480GZ  480 GB    (исползуется как SLOG)



на хост с прокскскс маунтится NFS шара от трунаса.
в папке зпускается fio  3.39-1 

файл для тестирования размером 3.8 ТБ



LIN READ   1049MiB/s
 
root@pve:/mnt/pve/NFS-2/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test   --filename=/mnt/pve/NFS-2/fio/fio.dat        --bs=4M --iodepth=64 --size=47000M  --readwrite=read
test: (g=0): rw=read, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=1049MiB/s][r=262 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=52913: Mon Nov 24 23:42:01 2025
  read: IOPS=286, BW=1147MiB/s (1203MB/s)(45.9GiB/40972msec)
   bw (  MiB/s): min=  768, max= 1192, per=99.93%, avg=1146.29, stdev=51.45, samples=82
   iops        : min=  192, max=  298, avg=286.56, stdev=12.88, samples=82
  cpu          : usr=0.47%, sys=22.51%, ctx=11391, majf=0, minf=196650
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.3%, >=64=99.5%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=11750,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=1147MiB/s (1203MB/s), 1147MiB/s-1147MiB/s (1203MB/s-1203MB/s), io=45.9GiB (49.3GB), run=40972-40972msec





LIN WRITE   440MiB/s
 

root@pve:/mnt/pve/NFS-2/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test   --filename=/mnt/pve/NFS-2/fio/fio.dat        --bs=4M --iodepth=64 --size=47000M  --readwrite=write
test: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
^Cbs: 1 (f=1): [W(1)][20.0%][w=440MiB/s][w=110 IOPS][eta 01m:32s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=53497: Mon Nov 24 23:44:48 2025
  write: IOPS=104, BW=417MiB/s (437MB/s)(9700MiB/23270msec); 0 zone resets
   bw (  KiB/s): min=163840, max=614400, per=98.54%, avg=420625.39, stdev=87241.13, samples=46
   iops        : min=   40, max=  150, avg=102.67, stdev=21.31, samples=46
  cpu          : usr=2.88%, sys=12.05%, ctx=1603, majf=0, minf=213253
  IO depths    : 1=0.1%, 2=0.1%, 4=0.2%, 8=0.3%, 16=0.7%, 32=1.3%, >=64=97.4%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2425,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=417MiB/s (437MB/s), 417MiB/s-417MiB/s (437MB/s-437MB/s), io=9700MiB (10.2GB), run=23270-23270msec





RAND READ    24.7k IOPS

root@pve:/mnt/pve/NFS-2/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test   --filename=/mnt/pve/NFS-2/fio/fio.dat        --bs=4k --iodepth=64 --size=47000M  --readwrite=randread
test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
^Cbs: 1 (f=1): [r(1)][2.3%][r=96.4MiB/s][r=24.7k IOPS][eta 07m:54s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=53711: Mon Nov 24 23:45:43 2025
  read: IOPS=25.0k, BW=97.8MiB/s (103MB/s)(1141MiB/11664msec)
   bw (  KiB/s): min=96808, max=104096, per=100.00%, avg=100322.43, stdev=2150.38, samples=23
   iops        : min=24202, max=26024, avg=25080.61, stdev=537.60, samples=23
  cpu          : usr=12.83%, sys=35.93%, ctx=99131, majf=0, minf=176
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=292141,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=97.8MiB/s (103MB/s), 97.8MiB/s-97.8MiB/s (103MB/s-103MB/s), io=1141MiB (1197MB), run=11664-11664msec
root@pve:/mnt/pve/NFS-2/fio# 




RAND WRITE   2804 IOPS

root@pve:/mnt/pve/NFS-2/fio# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test   --filename=/mnt/pve/NFS-2/fio/fio.dat        --bs=4k --iodepth=64 --size=47000M  --readwrite=randwrite
test: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.39
Starting 1 process
^Cbs: 1 (f=1): [w(1)][0.9%][w=11.0MiB/s][w=2804 IOPS][eta 36m:56s]
fio: terminating on signal 2

test: (groupid=0, jobs=1): err= 0: pid=53867: Mon Nov 24 23:46:35 2025
  write: IOPS=5354, BW=20.9MiB/s (21.9MB/s)(450MiB/21523msec); 0 zone resets
   bw (  KiB/s): min= 7432, max=84128, per=100.00%, avg=21429.95, stdev=16149.43, samples=43
   iops        : min= 1858, max=21032, avg=5357.49, stdev=4037.36, samples=43
  cpu          : usr=5.45%, sys=14.22%, ctx=82054, majf=0, minf=15
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=99.9%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,115249,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=20.9MiB/s (21.9MB/s), 20.9MiB/s-20.9MiB/s (21.9MB/s-21.9MB/s), io=450MiB (472MB), run=21523-21523msec
root@pve:/mnt/pve/NFS-2/fio# 


=====================================================================

сервер huawei v2 RAM 256GB
HBA карта 
  Controller                     : SAS2308_2(D1) 
  Firmware Product ID            : 0x2214 (IT)
  NVDATA Vendor                  : LSI
  NVDATA Product ID              : SAS9207-8i
  Board Name                     : LSISAS2308



ПУЛ:
record set 128KB
8xHDD(2TB) mirror (по два диска)



ТЕСТ:
LINEAR WRITE (1 поток)
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda  --bs=4M --iodepth=1  --size=2G  --readwrite=write

  TRUENAS 25 LINUX   [46.7MiB/s]
  FREENAS 13 FREEBSD [35.0MiB/s]

тут победил линукс


LINEAR WRITE (64 поток)
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda  --bs=4M --iodepth=64  --size=2G  --readwrite=write

  TRUENAS 25 LINUX   [83.6MiB/s]
  FREENAS 13 FREEBSD [22.4MiB/s]

тут победил линукс


LINEAR READ (1 поток)
по сути это тест чтения из ARC
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda  --bs=4M --iodepth=1  --size=20G  --readwrite=read

  TRUENAS 25 LINUX   [547MiB/s]
  FREENAS 13 FREEBSD [354MiB/s]

тут победил линукс



LINEAR READ (64 поток)
по сути это тест чтения из ARC
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda  --bs=4M --iodepth=64  --size=20G  --readwrite=read

  TRUENAS 25 LINUX   [1161MiB/s]
  FREENAS 13 FREEBSD [1176MiB/s]

тут победил фрибсд



RANDOM READ (1 поток)
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=1G --iodepth=1 --readwrite=randread

  TRUENAS 25 LINUX   [IOPS=3856]
  FREENAS 13 FREEBSD [IOPS=6204]

тут победил фрибсд



RANDOM READ (64 поток)
-gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=10G --iodepth=64 --readwrite=randread

  TRUENAS 25 LINUX   [IOPS=25.1k]
  FREENAS 13 FREEBSD [IOPS=81.2k]

тут победил фрибсд




RANDOM WRITE (1 поток)
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=20M --iodepth=1 --readwrite=randwrite

  TRUENAS 25 LINUX   [IOPS=93]
  FREENAS 13 FREEBSD [IOPS=48]

тут победил линукс



RANDOM WRITE (64 поток)
 fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=400M --iodepth=64 --readwrite=randwrite

  TRUENAS 25 LINUX   [IOPS=1192]
  FREENAS 13 FREEBSD [IOPS=654]

тут победил линукс



RANDOM RW (64 потока)
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=600M --iodepth=64  --readwrite=randrw --rwmixread=75

  TRUENAS 25 LINUX   [read IOPS=2503, write=833]
  FREENAS 13 FREEBSD [read IOPS=1575, write=524]

тут победил линукс



СУММАРНО: я все отдаю победу фрибсд













Добавляю SLOG
ПУЛ:
record set 128KB
8xHDD(2TB) mirror (по два диска)
+SLOG 480GB INTEL SSDSC2KB480GZ  (mirror из двух штук)



LINEAR WRITE (64 поток)
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda  --bs=4M --iodepth=64  --size=20G  --readwrite=write

  TRUENAS 25 LINUX   [359MiB/s]  (для сравнения без SLOG было [83.6MiB/s])
  FREENAS 13 FREEBSD [273MiB/s]  (для сравнения без SLOG было [22.4MiB/s])

видим что добавлка slog дает прибавку в скорости в x5-x10раз

тут победил линукс



RANDOM WRITE (64 поток)
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sda --bs=4k --size=5G --iodepth=64 --readwrite=randwrite

  TRUENAS 25 LINUX   [IOPS=3551] (для сравнения без SLOG было [IOPS=1192])
  FREENAS 13 FREEBSD [IOPS=5537] (для сравнения без SLOG было [IOPS=654])

видим что добавление slog дает прибавку в х3-х10раз

тут победил фрибсд






ТЕСТ:
LINEAR WRITE [383MiB\s]  
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4M --iodepth=64  --size=10G  --readwrite=write
test: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=0): [f(1)][100.0%][w=384MiB/s][w=96 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=884: Sun Nov 30 13:24:33 2025
  write: IOPS=95, BW=383MiB/s (402MB/s)(10.0GiB/26706msec); 0 zone resets
   bw (  KiB/s): min=40960, max=434176, per=98.30%, avg=385951.40, stdev=50259.63, samples=53
   iops        : min=   10, max=  106, avg=94.23, stdev=12.27, samples=53
  cpu          : usr=0.89%, sys=0.37%, ctx=2712, majf=0, minf=7
  IO depths    : 1=0.1%, 2=0.1%, 4=0.2%, 8=0.3%, 16=0.6%, 32=1.2%, >=64=97.5%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=383MiB/s (402MB/s), 383MiB/s-383MiB/s (402MB/s-402MB/s), io=10.0GiB (10.7GB), run=26706-26706msec

Disk stats (read/write):
  sdb: ios=51/10150, merge=0/0, ticks=15/6483057, in_queue=6483073, util=99.10%



тоесть добавление SLOG уведиичисло лин скрость записи в x3раза



тотже тест но на трунас трукор который на фрибсд
ТЕСТ:
LINEAR WRITE [BW=320MiB/s]  
root@stor5:/home/er# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4M --iodepth=64  --size=10G  --readwrite=write
test: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [W(1)][100.0%][w=228MiB/s][w=57 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=574: Sun Nov 30 15:57:30 2025
  write: IOPS=80, BW=320MiB/s (336MB/s)(10.0GiB/31995msec); 0 zone resets
   bw (  KiB/s): min=40960, max=548864, per=99.07%, avg=324689.27, stdev=85934.82, samples=63
   iops        : min=   10, max=  134, avg=79.27, stdev=20.98, samples=63
  cpu          : usr=0.86%, sys=0.22%, ctx=665, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.2%, 8=0.3%, 16=0.6%, 32=1.2%, >=64=97.5%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=0,2560,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=320MiB/s (336MB/s), 320MiB/s-320MiB/s (336MB/s-336MB/s), io=10.0GiB (10.7GB), run=31995-31995msec

Disk stats (read/write):
  sdb: ios=51/10227, merge=0/0, ticks=7/7833665, in_queue=7833672, util=99.24%


далее я запустил вот такой тест
  # dd if=/dev/urandom  of=/dev/sdb bs=4M status=progress

на двух одинаковых абсолюнтно системах.(одинаковые сервера и одинаковые пулы)
но одна из них это трунас25 набазе линукс и сторадж примаунчен по NFS4.2
  12691963904 bytes (13 GB, 12 GiB) copied, 60 s, 211 MB/s
при это скорость скачет. то 211 то 214 то 220
а вторая трунас core13 на базе фрибсд и сторадж примаунчен по NFS3
и скорсть держится просто железная
  12691963904 bytes (13 GB, 12 GiB) copied, 60 s, 261 MB/s
и только через 10 минут он плавно упал до 259МБ/с , но поток держит очень стабильно
а потом  я подключился к этому фрибсд трунас кору через NFS V4 и он уже стал показвыат скорость
  12691963904 bytes (13 GB, 12 GiB) copied, 60 s, 301 MB/s   (!!)
причем стабильно без каких либо рывков
причем взомжно можно лить еще быстрее просто такак urandom то я уперся в скорость цпу одного ядра.



ТЕСТ:
RANDOM RW  [r=2529,w=847 IOPS]
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4k --iodepth=64   --readwrite=randrw --rwmixread=75 --runtime=120
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
Jobs: 1 (f=1): [m(1)][100.0%][r=5236KiB/s,w=1904KiB/s][r=1309,w=476 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=893: Sun Nov 30 13:29:00 2025
  read: IOPS=2529, BW=9.88MiB/s (10.4MB/s)(1187MiB/120126msec)
   bw (  KiB/s): min= 3984, max=33888, per=100.00%, avg=10126.03, stdev=8809.10, samples=240
   iops        : min=  996, max= 8472, avg=2531.50, stdev=2202.27, samples=240
  write: IOPS=847, BW=3390KiB/s (3471kB/s)(398MiB/120126msec); 0 zone resets
   bw (  KiB/s): min= 1248, max=11616, per=100.00%, avg=3392.60, stdev=2925.09, samples=240
   iops        : min=  312, max= 2904, avg=848.15, stdev=731.27, samples=240
  cpu          : usr=2.28%, sys=4.66%, ctx=271286, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=303830,101800,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=9.88MiB/s (10.4MB/s), 9.88MiB/s-9.88MiB/s (10.4MB/s-10.4MB/s), io=1187MiB (1244MB), run=120126-120126msec
  WRITE: bw=3390KiB/s (3471kB/s), 3390KiB/s-3390KiB/s (3471kB/s-3471kB/s), io=398MiB (417MB), run=120126-120126msec

Disk stats (read/write):
  sdb: ios=303696/101715, merge=0/0, ticks=4506113/3155963, in_queue=7662076, util=99.97%


почемуто увеличмлся read iops, а write iops увеличился в х2раза


тоже самое на трукор фрибсд
ТЕСТ:
RANDOM RW  [r=10.4k,w=3444 IOPS] (!!!!)
root@stor5:/home/er# 
root@stor5:/home/er# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4k --iodepth=64   --readwrite=randrw --rwmixread=75 --runtime=120
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [m(1)][21.7%][r=40.7MiB/s,w=13.5MiB/s][r=10.4k,w=3444 IOPS][eta 01m:34s]
fio: terminating on signal 2

просто рвет лиункс



добавляю L2ARC
ПУЛ:
8xHDD(2TB) mirror (по два диска)
+SLOG 480GB INTEL SSDSC2KB480GZ  (mirror из двух штук)
+L2ARC 480GB INTEL SSDSC2KB480GZ








ПУЛ:
8xHDD(2TB) mirror (по два диска)
+L2ARC 480GB INTEL SSDSC2KB480GZ 


ТЕСТ:
RANDOM RW  [r=2841,w=965 IOPS]
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4k --iodepth=64   --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [m(1)][4.2%][r=11.1MiB/s,w=3860KiB/s][r=2841,w=965 IOPS][eta 06h:27m:09s] 


ПУЛ:
8xHDD(2TB) mirror (по два диска)
+PHUSION VDEV 480GB INTEL SSDSC2KB480GZ 


ТЕСТ:
RANDOM RW  [r=1573,w=510 IOPS]
# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/dev/sdb  --bs=4k --iodepth=64   --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.33
Starting 1 process
^Cbs: 1 (f=1): [m(1)][2.8%][r=6292KiB/s,w=2040KiB/s][r=1573,w=510 IOPS][eta 11h:53m:35s]  


из чего я делаю вывод если выбор стоит добавить L2ARC или PHUSION 
лучше добаить L2ARC и будет прибавка в скорости чтения в х5раз и в записи как ни странно в х5раз

===============================
хороший тест диска  <INTEL SSDSC2KB480GZ 7CV10100  480ГБ 6Gb/s



контроллер
  AHCI  6Gb/s


диск
<INTEL SSDSC2KB480GZ 7CV10100  480ГБ 6Gb/s

тестируею просто как блочное устрйотвао ada2 (никкой фс пока еще нет)
врайет кеш на диске включен





LIN READ 1 pototok  330.0MiB/s
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=read





LIN READ 2 pototok  445.0MiB/s
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=read --numjobs=2  --offset=0   --offset_increment=200M   --group_reporting

LIN READ 3 pototok  276.0MiB/s

LIN READ 6 pototok  284.0MiB/s

LIN READ 6 pototok  300.0MiB/s  iodepth=64

странно что на этом диске не получается выжать 550МБ/с









LIN WRITE 1 potok  416 MiB/s
fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=write  --numjobs=1  --group_reporting


LIN WRITE 2 potok  455.0MiB/s
fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=write --numjobs=2  --offset=0   --offset_increment=200M   --group_reporting 

LIN WRITE 6 potok  431.0MiB/s







RAND READ 1 potok   21.6k IOPS
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4k --iodepth=1  --runtime=30  --readwrite=randread  --numjobs=1  --group_reporting --offset=0   --offset_increment=200M

RAND READ 2 potok   38.2k IOPS

RAND READ 8 potok   75.4k IOPS 

RAND READ 10 potok  95.4k IOPS  (373 MB/s)

RAND READ 12 potok 100.0k IOPS  (391 MB/s)

RAND READ 14 potok 102.0k IOPS  (397 MB/s)

RAND READ 16 potok 102.0k IOPS  (397 MB/s) потолок







RAND WRITE 1 potok   27.2k IOPS
 fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4k --iodepth=1  --runtime=30  --readwrite=randwrite  --numjobs=1  --group_reporting


RAND WRITE 14 potok  88.8k IOPS

RAND WRITE 18 potok  90.5k IOPS  потолок

голый диск закончили тестировать



==============================

контроллер:
  AHCI  6Gb/s

диск 
  Model Family:     Hitachi/HGST Ultrastar 7K4000
  Device Model:     HGST HUS724020ALA640



тестируею просто как блочное устрйотвао ada2 (никкой фс пока еще нет)



LIN READ 1 pototok  160.0MiB/s
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=read


LIN READ 2 pototok  100.0MiB/s
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=read --numjobs=2  --offset=0   --offset_increment=200M  

LIN READ 6 pototok  100.0MiB/s







LIN WRITE 1 potok  161.0MiB/s
fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=write  --numjobs=1  --group_reporting


LIN WRITE 2 potok  150.0MiB/s
fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4M --iodepth=1  --runtime=30  --readwrite=write --numjobs=2  --offset=0   --offset_increment=200M   --group_reporting 

LIN WRITE 6 potok  118.0MiB/s







RAND READ 1 potok   83 IOPS
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4k --iodepth=1  --runtime=30  --readwrite=randread  --numjobs=1  --group_reporting

RAND READ 6 potok   125 IOPS





RAND WRITE 1 potok   190 IOPS
 fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/dev/ada1  --bs=4k --iodepth=1  --runtime=30  --readwrite=randwrite  --numjobs=1  --group_reporting

RAND WRITE 6 potok   190 IOPS

голый диск закончили тестировать








пеереходим к ФС  и датасетам
(важно зфс не отключает на диске write cache buffer!)

создал 4 датасета( с рекордсайзами 4К 32К 128К 1024К)

POOL-01/ds2-1024K                                           10.0G  1.72T     10.0G  /POOL-01/ds2-1024K
POOL-01/ds2-128K                                            9.77G  1.72T     9.77G  /POOL-01/ds2-128K
POOL-01/ds2-32K                                             10.0G  1.72T     10.0G  /POOL-01/ds2-32K
POOL-01/ds2-4K                                              9.98G  1.72T     9.98G  /POOL-01/ds2-4K

на каждом из них файл 10ГБ




root@truenas-0-233[~]# gpart create -s gpt ada1
ada1 created
root@truenas-0-233[~]# gpart add -b 2048 -t freebsd-zfs -i 1 ada1
ada1p1 added
root@truenas-0-233[~]# gpart list ada1
Geom name: ada1
modified: false
state: OK
fwheads: 16
fwsectors: 63
last: 3907029127
first: 40
entries: 128
scheme: GPT
Providers:
1. Name: ada1p1
   Mediasize: 2000397864960 (1.8T)
   Sectorsize: 512
   Stripesize: 0
   Stripeoffset: 1048576
   Mode: r0w0e0
   efimedia: HD(1,GPT,e84959e0-d14b-11f0-8e60-14dae9dc008a,0x800,0xe8e08088)
   rawuuid: e84959e0-d14b-11f0-8e60-14dae9dc008a
   rawtype: 516e7cba-6ecf-11d6-8ff8-00022d09712b
   label: (null)
   length: 2000397864960
   offset: 1048576
   type: freebsd-zfs
   index: 1
   end: 3907029127
   start: 2048
Consumers:
1. Name: ada1
   Mediasize: 2000398934016 (1.8T)
   Sectorsize: 512
   Mode: r0w0e0

root@truenas-0-233[~]# zpool create -o ashift=12 POOL-01  /dev/gptid/e84959e0-d14b-11f0-8e60-14dae9dc008a 
root@truenas-0-233[~]# 
root@truenas-0-233[~]# 
root@truenas-0-233[~]# 
root@truenas-0-233[~]# zfs create  -o compression=off -o  primarycache=metadata  -o secondarycache=metadata -o recordsize=4KiB  POOL-01/ds2-4K
root@truenas-0-233[~]# zfs create  -o compression=off -o  primarycache=metadata  -o secondarycache=metadata -o recordsize=128KiB  POOL-01/ds2-128K
root@truenas-0-233[~]# 
root@truenas-0-233[~]# zfs get recordsize POOL-01/ds2-4K
NAME            PROPERTY    VALUE    SOURCE
POOL-01/ds2-4K  recordsize  4K       local
root@truenas-0-233[~]# zfs get recordsize POOL-01/ds2-128K
NAME              PROPERTY    VALUE    SOURCE
POOL-01/ds2-128K  recordsize  128K     local
root@truenas-0-233[~]# 





# dd if=/dev/urandom of=/POOL-01/ds2-128K/fio.dat bs=10M count=1000 status=progress
  10370416640 bytes (10 GB, 9890 MiB) transferred 62.015s, 167 MB/s 


# dd if=/dev/urandom of=/POOL-01/ds2-4K/fio.dat bs=10M count=1000 status=progress
  10443816960 bytes (10 GB, 9960 MiB) transferred 79.001s, 132 MB/s 


это мне показало что отключкение arc для данных отключает только то что он неисплзуется как кеш при чтении
данных однако это не выключает такую вещь что при записи на этот же датасет данные буферизуются
где то там в памяти.  тоесть 167 МБ/с это нескорст ьзаписи на диск. это скрость записи в буфер.
скорост записи на диск НИЖЕ!







(ВААЖННОО!!)
итутя нашел конкттный пиздец программы fio если я использую --bs=4k
то фио считет что 4096 байт
а если я пишу --bs=4KiB то этот дебил считает что  4000 байт!!!
И ЭТО ПИЗДЕЦ. птому что это своврешнно не правилно. скорее должно было наобротрот!
и полуается то что запрос идет оффсетами в 4000 байт которые никак не выровнены по границе ЗФС блока который 4096
байт. и част данных лежит в одном блокеФС А ЧАСТЬ во втором! поэому чтоы считать 4000байт для нас зфс нужно
считать ДВА БЛОКА ФС. тоесть мы имеем двукратную порею скросососости!!!! gstat будет покызвает что  с диска
читается в 2 раза болше иопсов и срупуату чем мы увидим в фио!  
вобщем это никга не использщуй!!!! 

вот как я это узнал 

# 
fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4k --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting    



test: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1


в выводе мы видим   4096B-4096B


а теперь второй вариант 

]#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4KiB --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting 

test: (g=0): rw=read, bs=(R) 4000B-4000B, (W) 4000B-4000B, (T) 4000B-4000B, ioengine=psync, iodepth=1
fio-3.28



уже видим 4000B-4000B 


это ПРОСТО ПЗДЕЦ






                      --bs=4KiB      <====******==== неиспользуя НИКОГДА!!


                      --bs=4k   === ПРАВИЛЬНЫЙ ВАРИТАНТ!!





ПРОДОЛЖАЕМ ТЕСТЫ
итак имеем датасеты


POOL-01/ds2-1024K                                           10.0G  1.72T     10.0G  /POOL-01/ds2-1024K
POOL-01/ds2-128K                                            9.77G  1.72T     9.77G  /POOL-01/ds2-128K
POOL-01/ds2-32K                                             10.0G  1.72T     10.0G  /POOL-01/ds2-32K
POOL-01/ds2-4K                                              9.98G  1.72T     9.98G  /POOL-01/ds2-4K


я создал там на каждом файл fio.dat 10GB
но далее я в каждый файл еше прогнал несклько рандом врайт записей для того чтобы зфс на основе COW
повыдирал блоки из фйалов и разбросал их рандомно по диску. потому что в реаьной жизни еще раз скажу что
при записи в диск зфм постоянно проирзводит запись блоков в новые места на диске. и файлы офигеть как
разрываются фрагментируются. поэтому я привел файлы к макс натуральному виду
поехали теперь делтаь тесты


вначале я для каждого датасета прогоню тест ранд чтения. который мне покжает что чтение с диска (gstat)
идет именно тем же числом иопсов что я вижу в fio


# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=$((4*1024)) --iodepth=1  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting     
итд. для каждого датасета. все подтвердилдось.




теперь уже пойдут полезные реальные тесты на скорость

LINEAR READ 

LIN READ 1 potok,  пул  ds2-4K   27.8MiB/s
# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=$((4 *1024 *1024)) --iodepth=1  --runtime=20  --readwrite=read  --numjobs=1  --group_reporting    

при этом я открыл что средний размер чтения с диска 32КБ. тоесть ощущение что зфс кладет 4К ФСблоки на новое место 
в группы по 8штук. нейронка сказала это так называемы gang blocks

LIN READ 1 potok,  пул  ds2-32K   27.8MiB/s
здесь как ни странно средний размер чтения сдиска 48К.
arcstat показывает что чтения метаданныех с диск нет. тоесь чтения идут только полезных данных

    time  read  miss  miss%  dmis  dm%  pmis  pm%  mmis  mm%  size     c  avail
16:56:12  1.9K   928     49   928   49     0    0     0    0  306M  1.1G   3.8G
16:56:13  2.1K  1.0K     49  1.0K   49     0    0     0    0  306M  1.1G   3.8G
16:56:14  2.5K  1.2K     49  1.2K   49     0    0     0    0  306M  1.1G   3.8G


LIN READ 1 potok,  пул  ds2-128K    47.4MiB/s
здесь уже все понятно тут средний размер чтения с диска 128К

LIN READ 1 potok,  пул  ds2-1024K    79.5MiB/s
здесь уже все понятно тут средний размер чтения с диска 1024К


ИТОГО 

LINEAR READ 1 potok

LIN READ 1 potok,  пул  ds2-4K     27.8MiB/s

LIN READ 1 potok,  пул  ds2-32K    27.8MiB/s

LIN READ 1 potok,  пул  ds2-128K   47.4MiB/s

LIN READ 1 potok,  пул  ds2-1024K  79.5MiB/s


из чего я делаю выводы - даже при громадном рекордсете 1МБ у нас лин скорсть чтения в 2 раза падает
по сравнению если мы читали бы с голого диска(160МБ/с для голого диска). это все за счет того что зфс файлы сильно фрагментирует. станадртный рекрордсет 128К приводит к тому что сокрсть в 3.4 раза падает по сравению со скоростю голого диска. (это все конечн верно только для ситуации когда у нас пул на базе шпиндельных дисков. с ссд другая ситуация будет). скорость падает еще в 2 раза для рекордсетов 16К и 4К. 
да уж... даже для громадного рекордсета 128К и то мы наблюдаем чудовщиное падение скорсти в 3.4 раза по сравнениею
с голым диском. 
тоесь с точки зрения лин чтения даже 1МБ кусок и то в  2 раза нам проседает скорость. 128К проседает  скорость 
в 3.4 раза. а нам же даже 128К это большой рекорсайз блок. потому что он в других операциях нам налажает в скорости.
с ссд таких проблем небудет потому что там нет механической головки которая медленно шарится между треками. это
имнно пробелма шпинделей.


далее я решил еще посмтрет на этой же задаче как работает МИРРОР в зфс. и какая будет сокрость.
я создал пул на базе двух дисков таких же в миррор.  и на нем датасет из 128к рекордсет.

далее запустил тест    

  
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=1  --runtime=60  --readwrite=read  --numjobs=1  --group_reporting 
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=79.9MiB/s][r=639 IOPS][eta 00m:00s]

важны момент iodepth=1 
так как у нас иодепф равен 1 то это значит что наш фио пуляет один запрос и потом ждет ответа и пока ответа 
нет он новые запросы не пуляет. так вот в gstat видно что оба диска имеюит бузи тайм 50% что логично.

dT: 1.010s  w: 1.000s
 L(q)  ops/s    r/s   kBps   ms/r    w/s   kBps   ms/w   %busy Name
    0    255    255  32703    2.0      0      0    0.0   51.2| ada1
    0      0      0      0    0.0      0      0    0.0    0.0| ada0
    0      0      0      0    0.0      0      0    0.0    0.0| ada2
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p1
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p2
    0      0      0      0    0.0      0      0    0.0    0.0| gptid/48ba50a5-d141-11f0-a759-14dae9dc008a
    0      0      0      0    0.0      0      0    0.0    0.0| ada0p1
    0    209    209  26745    2.0      0      0    0.0   41.4| ada3


тоесть что происходит. на зфс прилеает запрос. он его пихает на первый диск в мироре. в это время второй
отдыхает. и фио тоже ждет ответ не шлет ничего. потом зфс шлет обратно ответ. фио шлет новый заапрос 
зфс пиахает запрос на второй диск а первый отдыахет. поэтому 50% бузи тайм.
то есть за тестовый период полвина времени работает один диск и полвину другой. в итоге если смотреть 
в gstat то чтобы понять какой срупут приодит  в fio нужно сложить срупуты обоих дисков в мирроре.
в нашем случае это 32703+26745=60MB/s  выше я выделил [r=79.9MiB/s] . это не среднее значение это мгнвоенное.
хотя картинка gstat она тоже мгновенная. вобшем если один поток прилает на миррор то срупуты двух дисков
нужно склдыать чтобы получит пнятие о птотоке который приходит на фио. 
кстати неважно какой бизит показывают диски в мирроре. чтобы понять скокьо срупута уходит с миррора сумарно
на фио надо просто складывать срупуты двух дисков. вот так просто.

вот скажем картинка


dT: 1.005s  w: 1.000s
 L(q)  ops/s    r/s   kBps   ms/r    w/s   kBps   ms/w   %busy Name
    0      0      0      0    0.0      0      0    0.0    0.0| da0
    0      0      0      0    0.0      0      0    0.0    0.0| da1
    6    441    440  56268   14.5      0      0    0.0   90.2| da2
    6    416    415  53086   15.0      0      0    0.0   94.4| da3
   20    528    523  66962   26.0      4     16  177.2   99.8| da4
   14    522    519  66453   24.0      2      8  312.3  100.0| da5
    0    435    434  55505    9.2      0      0    0.0   79.8| da6
    5    426    423  54104    8.7      2      8  132.7   75.0| da7
    0    342    342  43793    5.6      0      0    0.0   50.5| da8
    0    386    386  49394    6.4      0      0    0.0   59.5| da9
    0      0      0      0    0.0      0      0    0.0    0.0| da10
    0      0      0      0    0.0      0      0    0.0    0.0| da11


эти 8 диск обединены в пары 4 зекрал которые обидение в 4 страйпа.
так вот сумарный срупут в фио это просто сумма со всех этихдисков

# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=16  --runtime=60  --readwrite=read --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=16
fio-3.28
Starting 1 process
^Cbs: 1 (f=1): [R(1)][24.1%][r=421MiB/s][r=420 IOPS][eta 00m:22s]
fio: terminating on signal 2


все логично. 
приходит мысль а что если сделать иодепф=2 тогда по идее фио шлет сразу два запроса и ждет оввета.
зфс по идее может один запрос сунуть на один диск а ворой запрос на второй диск. и они по идее должны
одоновременно найти овтет или почти . и увелчить срупут в x1.5-2 раза
движок  psync неопзволяет выставиьт иодепф больше 1. тогда я беру движок posixaio (о движках читай в самом верху)
выставояю iodepth=2 и смотрю что будет

бузи тайм у меня ставиновится 87.5% что логично
dT: 1.002s  w: 1.000s
 L(q)  ops/s    r/s   kBps   ms/r    w/s   kBps   ms/w   %busy Name
    1    289    289  37052    3.3      0      0    0.0   87.5| ada1
    0      0      0      0    0.0      0      0    0.0    0.0| ada0
    0      0      0      0    0.0      0      0    0.0    0.0| ada2
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p1
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p2
    0      0      0      0    0.0      0      0    0.0    0.0| gptid/48ba50a5-d141-11f0-a759-14dae9dc008a
    0      0      0      0    0.0      0      0    0.0    0.0| ada0p1
    1    233    233  29770    4.1      0      0    0.0   87.5| ada3



а вот что со срупутом
#  fio --randrepeat=1 --ioengine=posixaio --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=2  --runtime=60  --readwrite=read  --numjobs=1  --group_reporting 
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][43.0%][r=77.6MiB/s][r=620 IOPS][eta 01m:21s] 

важный моент iodepth=2 , для этого приходистя заменит ioengine на posixaio
он не стал больше нифига . а даже стал меньше. 


вот я еще провел два теста

здесь gstat показывает 54% бузи тайм
     BW=74.2MiB/s
# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((1024 *1024)) --iodepth=1  --runtime=120  --readwrite=read  --numjobs=1  --group_reporting 
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=68.5MiB/s][r=68 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=7258: Fri Dec  5 20:43:44 2025
  read: IOPS=74, BW=74.2MiB/s (77.8MB/s)(8958MiB/120700msec)



здесь gstat покзывает 94% busytime
     BW=73.3MiB/s
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio  --iodepth=2  --runtime=120  --readwrite=read  --numjobs=1  --group_reporting 
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=79.5MiB/s][r=79 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=7300: Fri Dec  5 20:46:48 2025
  read: IOPS=73, BW=73.3MiB/s (76.9MB/s)(8830MiB/120446msec)


сосвтвтенно видно что скорость не увеличисилоась нихрена ни в х1.5 ни в х2 раза. (это шпиндель. на ссд  все по другому)


дальше я увеличил очередь до 10
    BW=99.2MiB/s
# fio --randrepeat=1  --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio  --iodepth=10  --runtime=120  --readwrite=read  --numjobs=1  --group_reporting 
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=10
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=103MiB/s][r=103 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=7425: Fri Dec  5 20:57:32 2025
  read: IOPS=99, BW=99.2MiB/s (104MB/s)(10.0GiB/103227msec)


результат стал повыше. почему. потому что в очередь запросов диску запрсвыается сразу куча запросов.
и он уже сразу знает что ему надо найти. и старется по мере прокрутки головки пособирать ответы. тоесть когда
запросы прилетат по одному то он каждый раз заново ищет. а тут у него уже заренее известен план поиска
на 10 запросов вперед. 



дальше я провел ряд эскприментов и пиришел к выводу что зфс вот как рабтает с миррором на режиме четния.
он работает так что если в зфс прилетает запрос то он его сует по принципу револьвера роунод робин 
на очередной диск. по очереди пуляет. в итоге в приложение поступает поток СУММАРНЫЙ который выдают  оба 
диска. тоесть миррор на режиме чтения работает как страйп.




тоестт вот иодепф=1

root@truenas-0-233[~]# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-03-MIRROR-SSD/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=1  --runtime=20  --readwrite=read --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=142MiB/s][r=1136 IOPS][eta 00m:00s]


а вот иодейфпфпаф=2
(заметь важный момент я заменил энжин на posixaio потому что енжин psync он неумеет работаьт с iodepth>1)

root@truenas-0-233[~]# fio --randrepeat=1 --ioengine=posixaio --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-03-MIRROR-SSD/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=2  --runtime=20  --readwrite=read --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=274MiB/s][r=2188 IOPS][eta 00m:00s]


тоесть не смотря на тупуую логику загрузки реквестами дисков в мирроре - ссд контроллер рулит. и мы полчаем
охуенный профит.

более того дадим очередь =32 

]# fio --randrepeat=1 --ioengine=posixaio --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-03-MIRROR-SSD/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=32  --runtime=20  --readwrite=read --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=posixaio, iodepth=32
fio-3.28
Starting 1 process
^Cbs: 1 (f=1): [R(1)][33.3%][r=447MiB/s][r=3573 IOPS][eta 00m:14s]

вот такой аолгоритм рабоы с миррором  у зфс в режиме четния.
в режиме записи все понятно. все ркквесты одновренно пихабтся на оба диска потому что нам надо чтобы 
на них хранилось одно и тоже. тут вопросов нет

смешно то что при такой логике тогда нпнятно почему зфс непихает запрос на оба диска когда иодепф=1.
тут у них мозгов както хватило. 


еще вот что щас посмтрим. 
я буду менять не иодепф а число ворекеров. посмтрим будет ли профит на чтение когда иодепф=1 а воркеров=2
окзывается все тоже самое никаого профита! что логично. какая разница зфс прилетело к ней два запроса
от одного процесса или от двух

вот у нас эталон
# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=1  --runtime=20  --readwrite=read --numjobs=1  --group_reporting
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=93.5MiB/s][r=748 IOPS][eta 00m:00s]

а вот наш кейс

# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-02-MIRROR/ds2-128K/fio.dat  --bs=$((128 *1024)) --iodepth=1  --runtime=20  --readwrite=read --numjobs=2  --group_reporting --offset=0   --offset_increment=200M  
test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=psync, iodepth=1
...
fio-3.28
Starting 2 processes
^Cbs: 2 (f=2): [R(2)][76.2%][r=68.1MiB/s][r=544 IOPS][eta 00m:05s]
fio: terminating on signal 2

test: (groupid=0, jobs=2): err= 0: pid=6609: Fri Dec  5 19:38:48 2025
  read: IOPS=533, BW=66.6MiB/s (69.9MB/s)(1060MiB/15907msec)


dT: 1.001s  w: 1.000s
 L(q)  ops/s    r/s   kBps   ms/r    w/s   kBps   ms/w   %busy Name
    0    299    299  38234    3.2      0      0    0.0   95.3| ada1
    0      0      0      0    0.0      0      0    0.0    0.0| ada0
    0      0      0      0    0.0      0      0    0.0    0.0| ada2
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p1
    0      0      0      0    0.0      0      0    0.0    0.0| ada2p2
    0      0      0      0    0.0      0      0    0.0    0.0| gptid/48ba50a5-d141-11f0-a759-14dae9dc008a
    0      0      0      0    0.0      0      0    0.0    0.0| ada0p1
    0    299    299  38234    3.2      0      0    0.0   95.3| ada1p1
    1    247    247  31585    3.9      0      0    0.0   96.6| ada3


скорсь даже упала!
то зфс тупо кинул два запроса на оба диска. потом ждет ответы. а потом ждет когда же диски дркурруят свой
поиск который зфс уже ненужен. 
с ссд конечно такой потери скорости не будет. будет увеличение. но не зачсет зфс а за счет ссд контроллрера 
внутри диск.

так я думаю с миррором разобрлись. он не про скорость он про надежность.
считай что реаьно он работает точно на такой же скорости как ОДИН диск. зфс откзыается использовать два диска
на режиме чтения как страйп. она тупо все запросы дублирует на оба диска а там трава не расти!

итак говря коротко зфс воббще не юзает примущество двух дисков. и по скрости мимррор работает как 1 диск
в случае шпинделей!!! и работает как страйп в случае ссд(на операциях чтения)!!



правильная строчка для LINEAR READ на многотоке.
# fio --randrepeat=1 --ioengine=posixaio --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --iodepth=8  --runtime=120  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M





а вот неочень понятный резуьтат. тоже железо (ну диски такиеже шиндели только не hgst а SEAGATE ST2000NM0023 0003 
но качественно я должен бы бл получить тот же самый рещультат с миррором что мы только что обсудили 
но повчемуто тут несколкьо по другому.
итак есть пул из 4-ех зеркал обьдиненных в страйп


пуляю иодепф=1
это дает то что просто у нас запрос посывлается на олдно из зеркал а остаотльные зеркала просто тупо отдыхают.
ну а как мы помним запрос прилеетвший на зекрало работает со сокростью диска в зеркале.
итак получаем скорсть чтения файла с фс с одного диска.


root@freenas-5[~]# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=1  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=143MiB/s][r=143 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=57036: Fri Dec  5 09:58:19 2025
  read: IOPS=104, BW=104MiB/s (109MB/s)(6270MiB/60074msec)

тоесть BW=104MiB/s


теперь добавляем иодепф. это дает то что у нас два запроса одноврменно пихаются на два разых зеркала.
пэтому  у нас скорость должна вырасти в х1.5 - х2 раза

# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=2  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=2
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=232MiB/s][r=231 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=57054: Fri Dec  5 09:59:35 2025
  read: IOPS=164, BW=165MiB/s (173MB/s)(9918MiB/60168msec)


тоесть BW=165MiB/s
тоесть да. теория совплаа с праккиеой. но это пока теория касающаяся страйпа.


так как унас в страйпе 4 vdev то между iodeph=1 и iodepth=4 у нас долна скорсость расти линейно.


# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=3  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=3
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=262MiB/s][r=261 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=57064: Fri Dec  5 10:00:43 2025
  read: IOPS=223, BW=223MiB/s (234MB/s)(10.0GiB/45900msec)

тоесть BW=223MiB/s




# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=4  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=4
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][97.4%][r=343MiB/s][r=343 IOPS][eta 00m:01s]
test: (groupid=0, jobs=1): err= 0: pid=57085: Fri Dec  5 10:01:33 2025
  read: IOPS=264, BW=265MiB/s (278MB/s)(10.0GiB/38689msec)


тоесть  BW=265MiB/s


тоесть итого 
iodepth=1 BW=104MiB/s
iodepth=4 BW=265MiB/s

ну вобщем выросло и значаительно хотя хотелост бы больше.


а вот дальше я делаю  iodepht=8
это значит что на кажде зеркало прилает 2 запроса сразу. бизитайм дисков в зеркале ставнится 94%
но прироса перфомранса мы больше не должны увидеть ровно так как это было ранее наверху когда у нас 
миррор и я делаю иодпеф=2
смотрим



# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=8  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=8
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=450MiB/s][r=449 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=57097: Fri Dec  5 10:02:29 2025
  read: IOPS=370, BW=371MiB/s (389MB/s)(10.0GiB/27638msec)

и на удивление BW=371MiB/s резулатат вырос да еще как. почему непонятно



увеичиваю еще иодепфс до 16 
это значит на один мироро будет пулятся 4 запроса сразу.
опять же по идее не долэжно все круто улучшится

# fio --randrepeat=1 --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/POOL-01/ds2-128K/fio.dat  --bs=$((1024 *1024)) --ioengine=posixaio      --iodepth=16  --runtime=60  --readwrite=read --numjobs=1  --group_reporting --offset=0   --offset_increment=200M
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=posixaio, iodepth=16
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][95.8%][r=510MiB/s][r=510 IOPS][eta 00m:01s]
test: (groupid=0, jobs=1): err= 0: pid=57123: Fri Dec  5 10:05:20 2025
  read: IOPS=437, BW=438MiB/s (459MB/s)(10.0GiB/23393msec)


однако оно еще улучшилсь и зачиенльно BW=438MiB/s !

я полагаю что тестовый файл слишком линейно лежит на диске. 
щас я ппробую его разорвать на раскиданные части и повтортть эксприепнтмент.





$$$$$$$$$$$$$$$$





 
(размер блока чтения 4К  )   (точное совпадение иопсов 14.0k IOPS в gstat и fio !!)
(этот тест я делаю тлокьо чтобы проверить что иопсы совпадают что вырваниеваение меджду блоками 
офсетов файла и блокамиФС совпдадает)
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4k --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting  
test: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=54.7MiB/s][r=14.0k IOPS][eta 00m:00s]


# fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=$((1024*1024)) --iodepth=1  --runtime=40  --readwrite=read  --numjobs=1  --group_reporting    
test: (g=0): rw=read, bs=(R) 1024KiB-1024KiB, (W) 1024KiB-1024KiB, (T) 1024KiB-1024KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][12.0%][r=33.7MiB/s][r=33 IOPS][eta 05m:02s] 




(размер блока чтения 4M  )  [160 MB/s]
  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4M --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting 

test: (g=0): rw=read, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][51.6%][r=160MiB/s][r=40 IOPS][eta 00m:30s] 


при этом видно что gstat читает диск со средней размеро блока 44КБ 
тоесть зфс агрегирует запросынадиск в крупные куски




LIN READ 1 potok,  пул  ds2-128K
   [r=1280 IOPS] (точное совпдаение иопсов в фио и гстат !!)
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=128k --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting

test: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=160MiB/s][r=1280 IOPS][eta 00m:00s]


[r=160MiB/s]
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=4M --iodepth=1  --runtime=30  --readwrite=read  --numjobs=1  --group_reporting  

test: (g=0): rw=read, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [R(1)][49.2%][r=160MiB/s][r=39 IOPS][eta 00m:32s] 



из чего видно что наодноптомчном линейном чтеннии сокрсть с обоих рекордсайзов соврешенно одинаковая!


делаем тоже самое но на 6 потоков



LIN READ 6 potok,  пул  ds2-4K  
[r=90.7MiB/s]
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4M --iodepth=1  --runtime=30  --readwrite=read  --numjobs=6  --group_reporting    --offset=0   --offset_increment=200M 

test: (g=0): rw=read, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=psync, iodepth=1
...
fio-3.28
Starting 6 processes
Jobs: 3 (f=3): [R(1),_(2),R(2),_(1)][32.5%][r=90.7MiB/s][r=22 IOPS][eta 01m:21s]
test: (groupid=0, jobs=6): err= 0: pid=2716: Thu Dec  4 23:50:57 2025
  read: IOPS=24, BW=97.7MiB/s (102MB/s)(3792MiB/38829msec)


тут хитрая настройка 
--offset=0   --offset_increment=200M 
она засталяет фио наичнаять делать запрос не от нулевого офсета а каждый вркер стартует со совего!
а тополучетс дебилизм кждый воркер читает с одного офсета. в итоге  всем вокрерам с диска в одно и тоже
время нужен один итот же кусок! пэтому диск читает кусок. и каждый  получает что хотел. и мы видим охиренный 
срупут в фио. а это хуйня. это нето сколкьо на диске был срупут. поэтому нужно завтсивть фио каждому воркеру
выдать изнчально офссет в ражной части диска!


LIN READ 6 potok,  пул  ds2-128K
[r=104MiB/s]

тоесть тоже самое. тоесть никакой рзаницы между рекордсайзами нет пока что.









теперь рандом риды
RAND READ 1 potok,  пул  ds2-4K  
[IOPS=149] что в точнончости совпадает что покзывает gstat . полное совдаание!
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4k --iodepth=1  --runtime=30  --readwrite=randread  --numjobs=1  --group_reporting    

test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [r(1)][100.0%][r=630KiB/s][r=157 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2799: Thu Dec  4 23:57:22 2025
  read: IOPS=149, BW=596KiB/s (611kB/s)(17.5MiB/30032msec)



RAND READ 1 potok,  пул  ds2-128K  
[IOPS=133 IOPS]
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=4k --iodepth=1  --runtime=30  --readwrite=randread  --numjobs=1  --group_reporting    

test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
Jobs: 1 (f=1): [r(1)][0.2%][r=533KiB/s][r=133 IOPS][eta 05h:29m:04s]

при этом на гстат срупут 18МБ/с . оно и понятно с лиска кажлый раз считыется не 4К а 128К



тоесть число ипосввов одинаковое. тлоко датасет с рекордсайзом 128к при этом офигенно засирает срупут 
порта диска. тоесть вместо 630КБ/с у нас читается 18-20МБ/с


тоже самое но на 6 потоков. тут уже офсет еннужен для воркеров.





RAND READ 6 potok,  пул  ds2-4K     [255 IOPS]
RAND READ 6 potok,  пул  ds2-128K   [204 IOPS]

в целом никакной разница. толкьо разнциа в том что впервом случае с диска читается 1МБ/с а во втором 20МБ/с



вопрос что покзыает zpool iostat? статситику чего?
пока что я вижу что он  покзазывает сатистику сколкьо было считано с дисков реално тоесть то что 
показыает gstat  (пока это так совпдает. но уменя отключен arc . )




теперь ЗАПИСЬ


LIN WRITE 1 potok
#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-4K/fio.dat  --bs=4M --iodepth=1  --runtime=30  --readwrite=write  --numjobs=1  --group_reporting    

test: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
bs: 1 (f=1): [W(1)][35.5%][w=156MiB/s][w=38 IOPS][eta 00m:20s]


#  fio --randrepeat=1 --ioengine=psync --direct=1 --gtod_reduce=1 --name=test --filename=/POOL-01/ds2-128K/fio.dat  --bs=4M --iodepth=1  --runtime=30  --readwrite=write  --numjobs=1  --group_reporting    

test: (g=0): rw=write, bs=(R) 4096KiB-4096KiB, (W) 4096KiB-4096KiB, (T) 4096KiB-4096KiB, ioengine=psync, iodepth=1
fio-3.28
Starting 1 process
^Cbs: 1 (f=1): [W(1)][22.6%][w=152MiB/s][w=37 IOPS][eta 00m:24s]

вобщем разницы никакой


RAND WRITE

здест я пока опстаноился. непнятно то что рандо врайт в итоге зфс прврадащет на диске в
линеар врайт. это понятно непонятно то что на 4к датасете если я пишу блоками по 4к из фио то 
по мне должен содапвдат срупут на гстат  и фио а он несовпдатает!

и еще видно четко вот что - если пишем 4к блоками из фио на датасет где рекодрсайз 128К
то идет бещеное чтение с датасета. потому что чтобы запист 4к вблок128к на новое место 
его нужно счиать. мдфиицровать и толко потом писать!


исходя из тгого что вижу пока я невижу смысла брать датасет с реекордсайз 128к. когда точно также
и еще лучше работает датасет с рекдрсдаесайз 4К




























это про другое:

root@fr:~ # dd if=/dev/urandom bs=129K count=1 of=/POOL-01/ds1-128K/t1.dat
1+0 records in
1+0 records out
132096 bytes transferred in 0.223978 secs (589772 bytes/sec)
root@fr:~ # 
root@fr:~ # zdb POOL-01/ds1-128K -O t1.dat
^C
root@fr:~ # ls -i /POOL-01/ds1-128K/t1.dat 
128 /POOL-01/ds1-128K/t1.dat
root@fr:~ # zdb -ddddd POOL-01/ds1-128K  128
^C
root@fr:~ # 
root@fr:~ # zdb -ddddd POOL-01/ds1-128K  128
Dataset POOL-01/ds1-128K [ZPL], ID 82, cr_txg 18, 9.77G, 9 objects, rootbp DVA[0]=<0:20102000:1000> DVA[1]=<0:400c0000:1000> [L0 DMU objset] fletcher4 uncompressed unencrypted LE contiguous unique double size=1000L/1000P birth=792L/792P fill=9 cksum=000000127f1a41e7:0000310d4041d42b:00452baaeaf56abf:4505ac86c91e5b13

    Object  lvl   iblk   dblk  dsize  dnsize  lsize   %full  type
       128    2   128K   128K   264K     512   256K  100.00  ZFS plain file
                                               168   bonus  System attributes
  dnode flags: USED_BYTES USERUSED_ACCOUNTED USEROBJUSED_ACCOUNTED 
  dnode maxblkid: 1
  path  /t1.dat
  uid     0
  gid     0
  atime Wed Dec  3 21:44:51 2025
  mtime Wed Dec  3 21:44:51 2025
  ctime Wed Dec  3 21:44:51 2025
  crtime  Wed Dec  3 21:44:51 2025
  gen 792
  mode  100644
  size  132096
  parent  34
  links 1
  pflags  40800000004
Indirect blocks:
               0 L1  0:7e0d0b000:1000 20000L/1000P F=2 B=792/792 cksum=0000008a1055c177:0001f8e9783a42f0:039e04881bc455af:6f998cb7a9e6e034
               0  L0 0:200b8000:20000 20000L/20000P F=1 B=792/792 cksum=00003fe244f8f8d5:0fff1f0d050b8d04:7393811299ba483b:002826f1577fa6d3
           20000  L0 0:200d8000:20000 20000L/20000P F=1 B=792/792 cksum=00000083017f37d0:00413ecee08a7013:3f6dc51befcd721f:97564c0d7d9a0ebb

    segment [0000000000000000, 0000000000040000) size  256K

root@fr:~ # 
root@fr:~ # dd if=/dev/urandom bs=17K count=1 of=/POOL-01/ds1-16K/t2.dat
1+0 records in
1+0 records out
17408 bytes transferred in 0.000139 secs (125097912 bytes/sec)
root@fr:~ # 
root@fr:~ # ls -i /POOL-01/ds1-16K/t2.dat 
3 /POOL-01/ds1-16K/t2.dat
root@fr:~ # 
root@fr:~ # zdb -ddddd POOL-01/ds1-16K  3
Dataset POOL-01/ds1-16K [ZPL], ID 90, cr_txg 23, 9.82G, 9 objects, rootbp DVA[0]=<0:7e0d34000:1000> DVA[1]=<0:8008f000:1000> [L0 DMU objset] fletcher4 uncompressed unencrypted LE contiguous unique double size=1000L/1000P birth=830L/830P fill=9 cksum=0000001010bbfbcf:00002b96b8401d5c:003f06069ee60b2f:406c88b76c56e9a6

    Object  lvl   iblk   dblk  dsize  dnsize  lsize   %full  type
         3    2   128K    16K    40K     512    32K  100.00  ZFS plain file
                                               168   bonus  System attributes
  dnode flags: USED_BYTES USERUSED_ACCOUNTED USEROBJUSED_ACCOUNTED 
  dnode maxblkid: 1
  path  /t2.dat
  uid     0
  gid     0
  atime Wed Dec  3 21:49:32 2025
  mtime Wed Dec  3 21:49:32 2025
  ctime Wed Dec  3 21:49:32 2025
  crtime  Wed Dec  3 21:49:32 2025
  gen 830
  mode  100644
  size  17408
  parent  34
  links 1
  pflags  40800000004
Indirect blocks:
               0 L1  0:e2134b000:1000 20000L/1000P F=2 B=830/830 cksum=00000088011c83ca:0001f0ccf3b0b99c:038e02430fb013c5:5a7e4794462e127e
               0  L0 0:7e0cea000:4000 4000L/4000P F=1 B=830/830 cksum=000007f34c07b8f9:004052918a339357:58705b8f51f31591:45bc9fa6fff2aa6a
            4000  L0 0:7e0ce6000:4000 4000L/4000P F=1 B=830/830 cksum=000000803bafb030:0007c3d05cc320bc:3c383ca009ad19cc:88f03314d87278b8

    segment [0000000000000000, 0000000000008000) size   32K

root@fr:~ # 



полное подврждение ттогго как работает рекордсайз



как приавлно создать даатсет для тестов fio

 #  zfs create  -o compression=off -o  primarycache=metadata  -o secondarycache=metadata -o recordsize=4KiB  POOL-02/ds2-4K

 # dd if=/dev/urandom bs=1M count=$(( 10 * 1024 )) of=/POOL-03-MIRROR-SSD/ds2-128K/fio.dat status=progress


(!!!) на даный момент я оанражил поразительную вещь. если у нас есть датасет с рекордсайз=А
и я читаю линейно с такиже размером блока запроса с него то число иопс в фио совпадает с числом иопс в 
гстат. а если я читаю рандомно то число иопс в фио падает в 2 раза чем число иопс которое читается с диксска.
при том что среднее число блока запроса если поедлить срупут на число иопсов в гстат осатется все равно 
раным рекодрсайз! тоесть зфс при чтении каждого полезного блока данных читает еще и чтото паразиитное этого же 
размера! я поумал можетэто какоето вырываниение несовпдает. но я создал пул с ашифт=9. и создал его 
на базе просто диска без всяких партиций. и ситуация такаяже саамая. приче неважно какой рекодрсет хотьт 128к
хотьь 16к хоть 4к. ...пц ккойто непонятный. нейронка утведрлает что арк некещиуерует все мтаданные а только 
метаднынеуровня1. а их там может быть 6 уровней. и они считаютс с диска. и то что при рандомном чтении
зфс читает адрес где искать блок. непонятно пока где правада...



еще видно то что ели у нас диск шпндельный то ему побарабану 


вобще судя по тесту на линукс zfs такой потери иопсов нету! ее там вобще нету. 
яделаю рандом риды и точн такие иопсы я вижу в фио!


получсет что 

0)
   Debian GNU/Linux 12 (bookworm)
   ZFS: Loaded module v2.3.4-1, ZFS pool version 5000, ZFS filesystem version 5
# modinfo zfs | grep version
version:        2.3.4-1
srcversion:     CD55446054D9A6B35134F5A
vermagic:       6.12.33-production+truenas SMP preempt mod_unload modversions 
# zpool version
zfs-2.3.4-1
zfs-kmod-2.3.4-1
# zdb  -C zroot

MOS Configuration:
        version: 5000


1)
  на TrueNAS-13.0-U6.8
  на базе 13.1-RELEASE-p9
  где установлен zfs # dmesg | grep -i zfs 
                        ZFS filesystem version: 5
                        ZFS storage pool version: features support (5000)

2)
  12.0-RELEASE
  # dmesg | grep -i zfs 
    ZFS filesystem version: 5
    ZFS storage pool version: features support (5000)

3) omniOS 



