ceph


установка это поделки.
документация хуйня полная.


во первых придется взять ununtu попоследнее. 
потому что хотя и заявлено что они новые релизы выкладыавют для 
нескольких версий ubuntu это хуйня полная. поэтому если хотим
релиз ceph попоследнее то придется использовать убунт попоследнее.

я взял ubuntu 20.
это новая жирная тупорылая версия которую сразу надо допиливать
	надо убрать netplan -  https://disnetern.ru/disable-netplan-ubuntu/
		sudo vim /etc/default/grub
		GRUB_CMDLINE_LINUX="netcfg/do_not_use_netplan=true"
		update-grub
		apt install ifupdown
		заполняем /etc/network/interfaces
		rm -rf /etc/netplan/*.yml
		
	надо убрать модуль floppy - онзаебет его искать и тормозить систему
	с ошибками :
			$ sudo rmmod floppy
			$ echo "blacklist floppy" | sudo tee /etc/modprobe.d/blacklist-floppy.conf
			$ sudo dpkg-reconfigure initramfs-tools

продолжаем ставить ceph

$ sudo wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add -


$ sudo apt-add-repository 'deb https://download.ceph.com/debian-octopus/ focal main'

где focal это кодовое имя релиза ubuntu 20


проверяем какая версия ceph доступна

$ sudo apt-cache madison ceph
      ceph | 15.2.5-1focal | https://download.ceph.com/debian-octopus focal/main amd64 Packages


ставим ceph, для этого достаточно поставить только пакет ceph.
он остальное вытяент что нужно

~$ sudo apt-get -y install ceph=15.2.5-1focal





в процессе установки надо будет сгенерироваь UUID
для этого в убунте юзаем 

# uuidgen

получим чтото типа того 

badd757e-6ef9-4d70-8d8b-9f28eded1c08

когда мы потом это посдунем ceph 
он нас пошлет нафиг, и скажет что UUID неверный.

оказвыается это я ошибся! и пришлось прочитать что такое uuid
моя ошбка была в том что я скопировал uuid с экрана и потерял одну
цфиру.

так вот что такое UUID

по определению
uudi это число длинной 128 бит , если мы это число типа конвертрруем 
в буквоцифры то полуичм 32 символа. обычно принимается что в итоге 
мы дожны получить 36 символов. а у нас 32. значит надо вставить четыре
минуса. обычно по таком правиалу 8-4-4-4-12. 

по ходу установки могу рекомендовать вобще ни на  йоту не отходить
от варианту установки. например неменять назвыание кластера
на свое . пусть будет дефолтовое!!!! иначе вобще ничего незваедетсяэ!!!

в доке указано без sudo и оно так неработает и еще там мудацкое
описание а в доке от ред хат указана очень полезная опция  
-o /var/lib/ceph/mgr/ceph-test-ceph-01/keyring

так что команда в итоге будет такая

	~$ sudo ceph auth get-or-create mgr.test-ceph-01 mon 'allow profile mgr' osd 'allow *' mds 'allow *' -o /var/lib/ceph/mgr/ceph-test-ceph-01/keyring
	
		
		

sudo -u ceph mkdir /var/lib/ceph/mgr/ceph-test-ceph-01
		


тесты (бекенд один и тот же ssd диск)

локальный тест [r=6690,w=2280 IOPS]

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1000M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.16
Starting 1 process
test: Laying out IO file (1 file / 1000MiB)
Jobs: 1 (f=1): [m(1)][100.0%][r=26.1MiB/s,w=9121KiB/s][r=6690,w=2280 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2145: Thu Nov  5 14:09:17 2020
  read: IOPS=11.0k, BW=43.1MiB/s (45.2MB/s)(750MiB/17378msec)
   bw (  KiB/s): min=23896, max=94976, per=100.00%, avg=44445.88, stdev=23771.52, samples=34
   iops        : min= 5974, max=23744, avg=11111.47, stdev=5942.88, samples=34
  write: IOPS=3689, BW=14.4MiB/s (15.1MB/s)(250MiB/17378msec); 0 zone resets
   bw (  KiB/s): min= 8384, max=31608, per=100.00%, avg=14851.76, stdev=7864.41, samples=34
   iops        : min= 2096, max= 7902, avg=3712.94, stdev=1966.10, samples=34
  cpu          : usr=3.56%, sys=13.10%, ctx=60174, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=191887,64113,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=43.1MiB/s (45.2MB/s), 43.1MiB/s-43.1MiB/s (45.2MB/s-45.2MB/s), io=750MiB (786MB), run=17378-17378msec
  WRITE: bw=14.4MiB/s (15.1MB/s), 14.4MiB/s-14.4MiB/s (15.1MB/s-15.1MB/s), io=250MiB (263MB), run=17378-17378msec

Disk stats (read/write):
    dm-0: ios=190453/63911, merge=0/0, ticks=854328/220184, in_queue=1074512, util=85.00%, aggrios=191133/64159, aggrmerge=760/228, aggrticks=858349/221327, aggrin_queue=621576, aggrutil=84.71%
  sda: ios=191133/64159, merge=760/228, ticks=858349/221327, in_queue=621576, util=84.71%





ceph [r=1675,w=595 IOPS]

o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=3000M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.16
Starting 1 process
Jobs: 1 (f=1): [m(1)][100.0%][r=6702KiB/s,w=2382KiB/s][r=1675,w=595 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2174: Thu Nov  5 14:15:07 2020
  read: IOPS=2484, BW=9939KiB/s (10.2MB/s)(2248MiB/231581msec)
   bw (  KiB/s): min=   96, max=53104, per=100.00%, avg=9937.84, stdev=5869.77, samples=463
   iops        : min=   24, max=13276, avg=2484.43, stdev=1467.45, samples=463
  write: IOPS=831, BW=3327KiB/s (3407kB/s)(752MiB/231581msec); 0 zone resets
   bw (  KiB/s): min=  272, max=17856, per=100.00%, avg=3333.73, stdev=1929.94, samples=462
   iops        : min=   68, max= 4464, avg=833.41, stdev=482.49, samples=462
  cpu          : usr=1.88%, sys=6.29%, ctx=752776, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=575394,192606,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=9939KiB/s (10.2MB/s), 9939KiB/s-9939KiB/s (10.2MB/s-10.2MB/s), io=2248MiB (2357MB), run=231581-231581msec
  WRITE: bw=3327KiB/s (3407kB/s), 3327KiB/s-3327KiB/s (3407kB/s-3407kB/s), io=752MiB (789MB), run=231581-231581msec


gluster [2810/975/0 iops]
(клиент размещен на хосте где и бекенд диски)

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1500M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.2.10
Starting 1 process
Jobs: 1 (f=1): [m(1)] [100.0% done] [11240KB/3900KB/0KB /s] [2810/975/0 iops] [eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2712: Thu Nov  5 06:31:17 2020
  read : io=1124.5MB, bw=14888KB/s, iops=3722, runt= 77339msec
  write: io=384564KB, bw=4972.5KB/s, iops=1243, runt= 77339msec
  cpu          : usr=1.89%, sys=4.39%, ctx=158501, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=287859/w=96141/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=1124.5MB, aggrb=14888KB/s, minb=14888KB/s, maxb=14888KB/s, mint=77339msec, maxt=77339msec
  WRITE: io=384564KB, aggrb=4972KB/s, minb=4972KB/s, maxb=4972KB/s, mint=77339msec, maxt=77339msec




gluster [3733/1302/0 iops]
(клиент сидит ненахосте где бекенд диски)

1# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1500M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.2.10
Starting 1 process
Jobs: 1 (f=1): [m(1)] [100.0% done] [14932KB/5208KB/0KB /s] [3733/1302/0 iops] [eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2081: Thu Nov  5 06:47:54 2020
  read : io=1124.5MB, bw=16712KB/s, iops=4178, runt= 68898msec
  write: io=384564KB, bw=5581.7KB/s, iops=1395, runt= 68898msec
  cpu          : usr=2.26%, sys=3.55%, ctx=215041, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=287859/w=96141/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=1124.5MB, aggrb=16712KB/s, minb=16712KB/s, maxb=16712KB/s, mint=68898msec, maxt=68898msec
  WRITE: io=384564KB, aggrb=5581KB/s, minb=5581KB/s, maxb=5581KB/s, mint=68898msec, maxt=68898msec
root@test-gluster-03:/mnt/01#



----------
новый этап установки 

rados = reliable autonomous distributed object storage

как я понял радос это как OSI некая теоретическая модель на которую опираютс но 
котоаря в жизни в чистом виде несуществует.

OSD  = object storage device. включает в себя цпу, RAM,nic, hdd\ssd\raid.

RADOS состоит из кучи OSD и мониторов.
мониторы это это процессы. еще мониторы требут (как они пишут) немного локального дискового пространства

еще я понял что есть cluster map. в нем как то описана вся карта кластера.
это картой управляюи мониторы.

каждый раз когда OSD ломается то меняется cluster map. меняется это epoque.

данные распрееляются по Placement Groups (PG)

Чем больше рзмер кластера тем больлше число PG

данные суются в PG на основе типа имени обьекта. 

наколько я понял  в PG находятся данные которые являются типа квантом данных в том плане
что данные реплицируются целиком размером с PG

далее как то непнятно. они пишут что данные суются в конкретный PG исходя из имени обьекта.
сами PG рассовываются по OSD неким равномерно- раномным способом.

пищут что увеличение ил уменьшение кластера не приводит к тому чтобы эти PG начали 
перетасовываться по OSD


далее они еще раз пишут что данные релицируются не науровне OSD. а на уровне PG.
реплицируются именно пэгэшки. обычно на одном OSD хранится порядка 100 PG


далее. cluster map имеет в сеебе инфо о всех здоровых и нездоровых OSD 
а также их сетевые адреса

для каждого PG кластер мап знает на каких OSD он сидит. и какие из этих OSD
живы  а какие сдохли

если в кластер мап записано об OSD что он  жив и здооров ( состояние up) и запиано что на нем сидит конкретный
PG (состояние in) то он обслуживает реквест (io) об данных в этом PG.

OSD может быть (согласно кластер мап) быть в состоянии down+in это значит что OSD недоступен  а PG который 
на нем сидел еще система неусмела среплицировать на здоровыый OSD восстановив заданный уровень репликации


длаее мало понятно. но  ясно одно что OSD обмениваются друг с другом  мессагами сообщая друг другу
о -- и вот тут мало понятно что они друг другу собщают. то ли о том какие PG на них хранятся. то ли 
собщая полный  кластер мап. еще OSD обмениваются инфо с мониторами.


клиент пишет данные на OSD. а OSD потом реплицирует эти данные самостоятельно по кластеру

далее есть три варианта  репликации у цефа.
- primary-copy
- chain
- splay

primary-copy = клиент пишет на первичный OSD. он в паралель обновляет все копии на других OSD. 
и после этого возрвашает клиенту инфо что запись состоялась.
также вот этот первый OSD он обаратывает не только записи но и операции чтения

chain= как я понял клиент пищет на первичный OSD тот обновляет копии непаралеьно 
а одну за другой по очереди. после обновления последнего OSD идет возврат клиенту
инфо о том что запись прошла успешно.
 при этом операции ччтения первичный OSD не обслуживает.
обслуживает их тот OSD который самый последний в очереди на обновление

splain == как этот метод репликации я непонял


как уже говорил что OSD друг с другом а также с монитором обвенимются  мессагами (messages)
о правда не сомвсес понятно о чем. то ли от тех PG которые хрантся на том или ином OSD. 
то ли о полной карте кластера.  так вот еще OSD посылвает такие же мессаги клиенту.
и может быть и клиен посылает к OSD мессаги но эт неточно.
точно то что месаги имеют epoque поэому типа OSD всегда знает какая мессага относится к более раннему
неактуальному состояию кластера чем это записано в OSD либо прищедшая месага относистя к более новой 
эпохе тоесть отаражает более атуальное состсоение кластера.

насколько я понял из описания - то клиенты цефа они получают карту с PG и таким образом не кластер изначально 
принимает реквесты от клиента и рооутит их на нужный OSD а сам клиент цефа имея карту направляет запрос 
на нужный OSD для доступа к данным с опреденного PG.


вот у нас есть PG и он лежит на таком то колчестве OSD.  так вот среди этих OSD есть первичный osd.
тот который как я понял прежде всего и принимает на себя операции записи.

далее может так случиться что OSD на чтение будет доустпен части клиентов а части небудет.
ии будет доступен части других OSD а части небудет.  тогда част клиентов будет продолжать с него считвать
втовреся как это делать ненадо. 

они вроде решабт проблему так. если копиия на чтение  не получила от своих peer товарией хартбит 
значит она больше операции чтения не обслуживает. дефотовй интервал хартбита 2с.
непонятно как это решает проблему если чтото случилось впределах меньше 2с.

из того что я понял OSD знает PG которые на нем харняться. и он знает для каких PG он не primary PG.
тогда он отправляет для primary PG OSD сообщение о том что тот по его инфо является примари PG.
примари PG узнает что он примари PG.
и этот примари также узнает где лежит реплика PG.
в ответ примари PG шлет всем этим репликам какую важную инфо по этой PG.

насколько я понял процессом восстановление на другие реплики руководит примари PG.
детали неясны.

на монииорах хранисят мастер копия  от cluster map.
нужно чтобы был кворум среди мониторов. чтобы они могли договориться и понять о том какая в итоге мастер 
копия верна.

выбирается некий мастер монитор .далее он собирает вокруг себя кворум мониторов. им разрешаается
рассылть амктуальную версию кластер мапа к OSD и клиентам.

далее есть lease time. по деолфту 2с. через 2с мастер монитор должен своим пирам прислать новый месседж
о том что он жив. тогда они понимаю что мастер жив. если он не прислал значит он сдох и выбирает
нового лидера среди мастеров


к мониторам обрашение за картой кластера от OSD или клиентов приходят редко если все окей.
оно приходит только если клиент обратился к OSD а он мертый. тогда он звонит к монитору. 
или OSD обнаружил мертвого соседа. а так если все норм то всем хватает информации о кластер мапе 
от соседей. клиент получает от OSD а OSD друг от друга. если поломоалась сразу куча OSD а на них лежала куча PG
то на монитор прилетит куча обращений.  чтобы этого небыло OSD  каждый полуслучаный интервал времени пигуют только я непонял
что . может соседей? и это как то охраняет монитор от шквала запрососв в случае обвала  кучи OSD,







до этого моменты мы рассматривали RADOS. это чисто сферический конь в вакуууме на котоором строится
ceph. но по факту цеф состоит из нескоько других компонертов.

ceph состоит из:
мониторы
OSD демоны
менеджеры
метадата серверы


мониторы содержат мастер копию кластер мапа. клиенты получают кластер мап от монитора. это странно
потому что в радосе написано что клтиенты получают кластер мап от OSD. 

OSD демон проверяет свое состояние и состтоние других OSD юнитов и докалдывает об этом мониторам.
это тоже странно. в радосе этого компоненты нет. OSD сами себя тестируеют и тестируют соседей. 
и если што докладывают мониторам.

A Ceph Manager acts as an endpoint for monitoring, orchestration, and plug-in modules. = это вобще
непоняно что значит. но вот еще нашел
A Ceph Manager daemon ( ceph-mgr ) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization, current performance metrics, and system load.
Тоесть походу это прсто типа мониторинговая хрень ни на что не влияющая.
хотя вот еще нашел = Since the 12.x (luminous) Ceph release, the ceph-mgr daemon is required for normal operations. The ceph-mgr daemon is an optional component in the 11.x (kraken) Ceph release. тоесть в 12 версии вроде бы он уже обязательно 
нужен . бардак какойто

метадата сервер хранить метадату файлов когда к цеф конектятся как  к файловой системе. получается если 
мы конектится к цеф как к блочному устроуству то метадата сервер нам нахер ненужен.

получется металата сервер нахен не встрался, менеждер тоже нахер невстрался, осатаются рельно важные компоенты
это мониторы и OSD демоны.

OSD = object based storage deice

в статеть они пишут что фишка OSD в том что они  содержат инфо не о блоках как на жестких дисках ибо этих блоков просто 
дохера а всего навсего об обьектах. обьектов мало по сравнению с блоками. тоесть блоки это некий лоу-левело инфо 
которая явлется внутрненней для OSD и для внешних чувачков она не предоставляется. наружу проеоставляется инфо 
об обьектах котораых хранстя на OSD и это типа компактная информация. поэтому типа реплиация блочных дисков это 
типа жопа. незнаю в ккаком смсыле. а репликация обьектов это типа очень компактно

далее они пишут вот о чем - что есть фундаметальная проблема сторадж у которого дохрена дисков или OSD без разницы.
проблема в том что если мы добавлем новые диски то они будут либо пустые. либо на них будут только новые даныные.
и прблема тут  в том что диски в системе будут загружены не равномерно. либо будут пахать толдько диски старые
со старыми данными либо только новые диски с новыми данными. а нам надо чтобы пахали все диски равномерно.
тогда приходит идея что если мы добавили новые диски то надо на них скопировать рандомные куски со старых дисков
тогда типа все дисики будут загружены равноемерно.

и вот  они пишут что они разработали алгоритм CRUSH (Controlled replication Under scalable hashing)
алгоритм береь обьект либо идетиификатор обьекта и применяя функцию рассчитывает список девайсов (видимо список OSD)
на которые надо засунуть этот обьект

фишка CRUSH в том что цефу ненужно иметь никакой элемент архитекткру в котором бы хранилась информация о метаданных.
если у клиента есть карта кластера (список здоровых OSD) то клиент может сам чисто по формуле высчитать на какой OSD
надо начать писать данные.  это как если бы клиент фс мог по формуле сам выситать в каких блоках сидит файл 
без обращения к каталогам

CRUSH берет как параметр входной id обьекта, прикладывает к нему некие "placement rules" и кластер мап и на выходе
по формуле получает список OSD куда надо запихать этот обьект x.

кластер мап состоит из devices и buckets. бакеты в себя включают другие бакеты и девайсы.
все эти хрени имеют веса.  девайс имеет вес назначенный админом . вес указывает обьем инфо который девайс
может хранить

дальше по тексту идет куча малопонятной хрени как раобтает crush 


вобщем клиенты и OSD демоны используют CRUSh чтобы самостоятельно определять для обьекта его группу OSD
вместо того чтобы для этого лазить кудато на сторону в кластер

неважно как клиент пытается работать с цеф - толи как с ФС, толи как с блочным устройством, толи как 
с оббьект сторажем => в любом случае внутри цеф влетевший кусок инфо записывается как обьект.

дальшер написнаан непонятная хрень = Ceph OSD Daemons handle read, write, and replication operations on storage drives.
это отличается от радос в котором вобще нет такого элемента архитектуры. репликацией там занимается примари OSD.
чтением занимается либо примари OSD либо он сообщит клиенту с какого OSD читать данные.
также это отличается от тго что выше было написано в доке про демона OSD = OSD демон проверяет свое состояние и состтоние других OSD юнитов и докалдывает об этом мониторам. пока непонятно.
хотя наверное я понял!!! osd daemon про которого говорится в ceph это  OSD в литературе по rados!
теперь все стало понятно. osd в терминах rados это osd daemon в терминах ceph! все теперь стало понятно.
тогда еще раз рассмотрим из чего состоит цеф:

ceph состоит из:
мониторы
OSD демоны
менеджеры
метадата серверы


менеджеры это мусор, метедатат это тоже мусор если мы к цеф неподключаемся как к ФС.
тоода остаются ровно теже комоеннты что и в радос литературе = кластер из мониторов и  OSD штуки. которые 
в цеф называют OSD демоны. 

далее OSD и OSD daemon это одно и тоже.

OSD хранит данные  в виде обьектов. информация об обьектах внутри OSD хранится в виде плоской таблицы. тоесть 
там нет никакой иерархии каталогов. идет просто идентиификатор обьекта + тело данных + доп метаданные.
считай что это как key-value база данных. метедаднные обьекта тоже имеют вид ключ+значение.
какие там метаданные будут прописаны для обьекта - цефу похер, метаданные опредеяет клиент цеф.

object ID уникален в рамках всего кластера OSD

в обычыных стораджах клиент обращается к центральному входному устройству. в цеф этого нет.
в цем клиент на основе CRUSH высчттыаеи к какому OSD ему надо обратиться и лезет сразу туда.
получаем децентрализацию. 



клиенты и OSD должны иметь актуальный "cluster map"

кластер мап состоит из 5 кусков:
- монитор мап
- osd мап
- pg мап
- crush мап
- mds мап


монитор мап содержит инфо о мониторах.
смотрим:

# microceph.ceph mon dump

epoch 4
fsid d64966ad-7849-4b7b-a2f9-79461128965c
last_changed 2023-05-04T14:05:18.608758+0000
created 2023-05-04T14:04:01.430028+0000
min_mon_release 17 (quincy)
election_strategy: 1
0: [v2:10.103.1.27:3300/0,v1:10.103.1.27:6789/0] mon.lxd-02
1: [v2:10.103.1.24:3300/0,v1:10.103.1.24:6789/0] mon.lxd-03
2: [v2:10.103.1.13:3300/0,v1:10.103.1.13:6789/0] mon.lxd-04
dumped monmap epoch 4


итак в микроцефе у нас три монитора.


osd мап содержмит инфо о пулах, osd, pg
смотрим:

# microceph.ceph osd dump

epoch 139
fsid d64966ad-7849-4b7b-a2f9-79461128965c
created 2023-05-04T14:04:03.133182+0000
modified 2023-05-08T19:10:01.088603+0000
flags sortbitwise,recovery_deletes,purged_snapdirs,pglog_hardlimit
crush_version 19
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client luminous
min_compat_client jewel
require_osd_release quincy
stretch_mode_enabled false

pool 1 '.mgr' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_change 19 flags hashpspool stripe_width 0 pg_num_max 32 pg_num_min 1 application mgr

pool 2 'lxd' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 25 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd

max_osd 3

osd.0 up   in  weight 1 up_from 125 up_thru 138 down_at 124 last_clean_interval [103,117) [v2:10.103.1.27:6802/1659,v1:10.103.1.27:6803/1659] [v2:10.103.1.27:6804/1659,v1:10.103.1.27:6805/1659] exists,up 45509eb5-d0a5-4455-b9d9-dc6286a1ba4d

osd.1 up   in  weight 1 up_from 126 up_thru 132 down_at 125 last_clean_interval [105,117) [v2:10.103.1.24:6802/1627,v1:10.103.1.24:6803/1627] [v2:10.103.1.24:6804/1627,v1:10.103.1.24:6805/1627] exists,up fb86c6af-5bab-4921-a9b0-8978f3637432

osd.2 up   in  weight 1 up_from 125 up_thru 138 down_at 115 last_clean_interval [109,113) [v2:10.103.1.13:6802/
1669,v1:10.103.1.13:6803/1669] [v2:10.103.1.13:6804/1669,v1:10.103.1.13:6805/1669] exists,up 74cc655c-6e8c-49c3-8902-dfe38343aa47

blocklist 10.103.1.24:0/2221645565 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/3638844332 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/2375246677 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:6811/834 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:6810/834 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/2720725004 expires 2023-05-09T19:09:28.925243+0000


pg мап содержит инфо о pg



crush map содержит инфо 
об сторедж девайсез. 
посмотреть можно через 

$ ceph osd getcrushmap -o {filename}
$ crushtool -d {comp-crushmap-filename} -o {decomp-crushmap-filename}

к соажалению на микроцефе это несрабатывает


mds мап содержит инфо об метадата серверах 
смотрим:

v# microceph.ceph fs  dump
e23
enable_multiple, ever_enabled_multiple: 1,1
default compat: compat={},rocompat={},incompat={1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap,8=no anchor table,9=file layout v2,10=snaprealm v2}
legacy client fscid: -1
 
No filesystems configured
Standby daemons:
 
[mds.lxd-03{-1:194107} state up:standby seq 1 addr [v2:10.103.1.24:6800/4107889023,v1:10.103.1.24:6801/4107889023] compat {c=[1],r=[1],i=[7ff]}]
[mds.lxd-02{-1:194112} state up:standby seq 1 addr [v2:10.103.1.27:6800/1283618052,v1:10.103.1.27:6801/1283618052] compat {c=[1],r=[1],i=[7ff]}]
[mds.lxd-04{-1:194131} state up:standby seq 1 addr [v2:10.103.1.13:6800/2866487613,v1:10.103.1.13:6801/2866487613] compat {c=[1],r=[1],i=[7ff]}]
dumped fsmap epoch 23


соотвестенно микроцеф неиспользует фс на цефе. поэтому сами метадата серверы есть. но как видно 
никкой цеф фс несоздано


прежде чем клиент начнет юзать цеф ему нужно получить кластер мап. для этого он лезет к монитору.
мониторы обетдиенны в кластер. чтобы был кворум мониторы должны иметь большинство доступных тоесть
1, 2:3, 3:5, 4:6



далее. для аутентификции клиента цеф юзает shared secret метод.
это метод кога и сервера и уклиента есть тот же самый secret key
аутентификация работает типа как у керберос так они пишут.
как я понял клиент обращается на монитор. тот его аутентиифицирует и обратно возвращает session тикет. причем этот тикет 
зашифрован тем же secret key что есть и у клиента. далее с помощью этого session тикет клиент повторно обращетеся
к мониторму и закаызаывает сервисы которые нужны от OSD. монитор возврашает новый тикет с помощью которого 
уже клиент будет аутентифицироваться+авторизоваться уже на OSD. все эти тикеты они временные. тоесть они протухают 
во времени и их нужно получать заново.

чтобы заюзать аутентификацию человеек должен обартиться к цеф и создать юзера. при этом цей создать учетку и secret key
и сообщит обратно. и также сохорнаить копию на мониторе.

и еще раз проговрим как раобтает аутентификация у цефа. вот мы завели юзера на цефе. и получили secret key.
теперь для аутентификации мы обращаемся через клиент к мониотору. вводим свой secret key. нам воттвет монитор 
создает session ticket , шифрует его нашим secret key и возвраащает нам. мы с помощьью нащего secret key расшироываем
и получаем на руки session ticket. он валиден какоето время. потом его надо заново получать. он валиден 
как говорится на период нашей сесссии.  тееперь юзая наш session ticket (правда непонятно как кокнретно) мы обращаемся
на монитор и он нам создаем еще один тикет (названия  у него нет). и именно этот тикет мы предьявляет на OSD
для аутентиификации+авторизации


в цефе клиент, мониторы, OSD все знают кластер мап. поэтому могут обаться друг с другом напрямую.

OSD периодически шлет на монитор мессаги о том что он жив здоров. если это прекратилось то монитор 
делает вывод что OSD сдох

OSD также может опредеить то что сосед OSD сдох и тоже об этом доложить монитору.

OSD ежедневно делает легкий scrub. тоесть обращется к соседним OSD на которых хранятся реплики PG.
и сравнивает метаданные у себя локальные с метаданными у соседей для конкретного PG.
а еженеделно OSD делает уже тяжелый scrub. когда уже сраванивает по контрольным суммам  тело или данные для PG 
у себя с тем же самым у других OSD у которых хрантся реплики данного PG

клиент как я понял по object id опредяет pool и PG для обьекта. и потом применяя формулу узнает primary OSD.
OSD делая туже хрень узнает все множствео OSD на которых должны хранится реплики для этого PG.
клиент пишет на примари OSD. а этот примари OSD пишет на все реплики. и уже когда все реплики записаны 
то пишет обратно клиенту что процесс записи успешно завершен

обьект в цеф имеет принадлежность к пулу.
кто опредяет параметры пула пока неясно
но ясно то что своствами пула являются

Ownership/Access to Objects
The Number of Placement Groups, and
The CRUSH Rule to Use.


пул имеет какое количество PG.
CRUSH алогоритм делает маппинг object-id --> pool --> pg --> список OSD 
так как кластер мап меняется то для разных кластер мапов для одного и того же object-id будет пполучатся
разный список OSD сереров

для того чтбы клиент узнал список OSD ему в качестве входных парамтров нужно:
- object-id
- pool-id
- cluster map

кластер мап клиент получает от монитора.
object-id клиент должен сам знать 
откуда брать pool-id пока неясно

применяя object-id + pool-id на кластер мап клиент получается список OSD серверов

у меня такое ощущение что пулы создает сам клиент предваретельно в цефе. и кода клиент хочет сохранить обьект 
то клиент должен сам определится в какой пул он хочет засунуть обьект.

насколько я понял все OSD которые хранят PG тестно друг с другом общаются провреяя здоровье друг друга.
и если чтото нетто то стучат об этом монитору

primary OSD - он один для PG. он и только он принимает запрос от клиента на запись в эту PG

весь набор OSD кооыре хранят PG назыается Acting set. те серверы который в Acting set находятся в состонии UP
называются UP SET.

erasure coding = чтото ттипа raid5 кодиования.  в чем прикол. прикол в том что экономитс место как я понял
если у нас голые реплики то мы теряем много места. например если у нас 2 реплики то три OSD хранят инфо по обьему
одного OSD. а если унас raid5 кодиорвание. то 3 OSD могут хранить инфо по обьему как 2 OSD. 
так вот как я понял уровень erasure coding определеяется на уровне пула.


из того что я понял про формулу эрейзинг кодирования. если указано 3+2 к прмиемеру это значит
что данные делятся на 3 части. каждая часть сохранятеся на свой OSD. и еще высчтываются 2 части доп данных 
это коды кодирования. эти части сохрнатяются на отдельные OSD. итого на 100% обьема данных будет еще 
дполнительно заниматься 40% под коды. 

у цефа есть еще такая прокладка как cache tier.
типа можно иметь кэш таир из быстрых дисков и обыкновенный бекенд из медленных дисков.
кэш работет прозрачно. детали надо читать дополниетельно

естьтакая штука bluestore. как я понял это метод с помощью котлрого хрнаятся данные на дисках на OSD
машинах. это как ихяяя цефоская файловая система на дисках.


BlueStore opens block devices in O_DIRECT and uses fsync frequently to ensure that data is safely persisted to media. 

я помотрел что значит O_DIRECT. значит в линуксе мы открваем файл на запись. или устойство на запись
и при этом указыаем флаги. флаг O_DIRECT формально означает что мы говорим ядру что мы нехотим чтобы
при записи использовася кэш линукса (page cache) при записи. мы хотим чтобы данные сразу летели в устройство.
однако как написано на стековерфлоу по факту это нихрена незначит что когда мы пишем на диск и нам прилетает 
подтверждение что данные приняты то данные реально записаны на диск. они могут застрять где то там в кэше диска
или еще где а до пластин диска еще не долететь. поэтому этот фалг негарантирует что данные записаны на диск
как нам о том сообщит ядро. а только как я понял дает то что данные не будут дублироваться в page cache линукса.

fsync как я понял - да. он гарантирует что данные были записаны на диск. 


You can evaluate a drive’s low-level write performance using fio. For example, 4kB random write performance is measured as follows:


# fio --name=/dev/sdX --ioengine=libaio --direct=1 --fsync=1 --readwrite=randwrite --blocksize=4k --runtime=300

далее они пишут что диск в линукск может работать в двух режимах : write back и write thgrouh.
когда на диске активирован его дисковый встроенный кэш то он работает в реэиме write back.
проверть в каком реэиме работает диск можно через 

# cat /sys/class/scsi_disk/*/cache_type

прикол в том что для дисков на яндекс облаке вобще такой папки нет. 
и у nvme дисков такой папки тоже нет.

вчем прикол с этим кэшем. прико в том что данные пишутся не надиск а в этот кэш а уэе потом переносятся на диск.
так вот если запускать fsync то эта команда говорит - перенеси все данные из этого кэша уже на пластины.
поскольку цеф постоянно запускает fsync то вместо того чтобы сазу писать на диск  ос пишет сначалаа в кэш 
диска а потом опустошает этот кэш перенося данные на пластины. как пишет дока это существенно повысить
лейтенси для иопсов. при записи иопса с выклченных кэшем у нас иопс будет писаться долго, а с включеным кэшем
у нас иопс пишется быстро но потом долго ждать пока опустошится буфер перенося все что в нем есть
из кэша на пластины. и якобы это будет суммарно дольше чем сразу писать на пластины


они даже предалгаюь udev правило чтоб руками это дело ненастраивать

# cat /etc/udev/rules.d/99-ceph-write-through.rules
ACTION=="add", SUBSYSTEM=="scsi_disk", ATTR{cache_type}:="write through"


вотт тут https://docs.ceph.com/en/latest/start/hardware-recommendations/ в самом низу
указано сколько ядер цпу и дисков должно быть на  мониторах и OSD и метадата нодах

получается cpu\RAM на минималках

OSD: 1cpu 
     4GB

монитор: 2cpu
         4GB

mds: 2cpu
     2GB




у цеф есть  алгоритм страйпинга. я не очень понял как он конфигурится. такое ощущение что это все настраивется на клиенте.
идея вробы бы такая - берется исходный обьект. и делится на несколько обьектов цефа. посолькуо каждый обьект 
хранится на своем списке OSD то запись идет так: пишется небольшой кусок первогоо обьекта. потов небольоой кусок 
втрого обьекта. причем писать на первый и второй обьект можно одновременно. и так достигается увеличение скорости. 

по архитектуре цеф вобщем то для начала все.


я продолжаю описывать как работает архитекутура цефа.
цеф на выходе выдает три типа ресурсов: блочное устройство (RBD),
файловую систему (CephFS), S3 (rados gateway)
s3 это чтото типа фтп сервера. еще s3 называют object storage.
я поискал в чем разница ftp vs s3 и зачем нужен s3 если есть ftp.
ничего ненашел. 


еще раз поговорим про компоненты цефа:

OSD - типа хрень на которой лежат диски на которых реально сохоаняются данные
это бекенд. как  я понял на одном физ компе можно поднять несклько OSD. 
пока мало понятно как это сделать . тем не менее.
OSD = Ceph Object Storage Daemon

manager 
monior
librados


object name, pool, cluster-map


pool.
для клиента пул это один из парамтров которыый нужно указать когда клиент хочеь 
записать обьект на цеф. клиет обязательно указывает пул в который он хочет это записать.

для самого цефа  это как LUN на рейд контроллере. это как раздел на диске. 
это первый такой уроень логический чтобы разрезать резделить весь кластер данных
на куски. 

пулы на цефе создает админ цефа. имя  или номер пула админ цефа передает клиенту
вместе с логином и паролем.

клиенту чтобы сохранить обьект на цефе нужно иметь:
- обьект который мы хотим сохранить. 
- имя пула
- логин пароль
- установленную на компе клиент цефа (который опирается на билиотеку librados)
- cluster-map от цефа который клиент должен получить от MON (монитора) цефа

данные хранятся на OSD юнитах. что такое OSD еще буду прояснять.

насколко я понял клиент высчитыывает на какой PG (placement group) нужно засунуть
обьект. высчиав PG клиент высчитывает на каком OSD (каждый OSD имеет IP адрес)
этот PG хранится. узнав IP клиент стучится на этот OSD и соощает ему мол запиши обьект
в такой то PG такого то пула. дальше уже работа OSD куда и как внуьрь себя пихать обьект.
что такое PG. наверно это некий аналог папки на ФС. как обьекты конкретно напиханы внутри PG сам цеф (его мониторы) незнают и не парятся. это некая внутреннняя кухня OSD. 
насколько я понял cluster-map которую хранят в себе MON цефа хранят в себе только OSD 
карту и как я понимаю карту распределения PG по этим OSD (но это пока неточно).

еще раз освящу момент как клиент работает с цефом.  админ цефа созддает на цефе
и логин пароль. и передает клиенту. клиент ставиит клиент цефа который основан (нез наю
зачем это они уточняют) на librados билиотеке. нам в принципе похуй на какой библиотеке.
также админ цефа сообщает какие IP адреса имеют мониторы цефа.
тогда клиент когда хочет читать писат на цеф некий обьект он . берет логин пароль 
и клиент цефа через логин пароль стучит на монитор цефа котоырй указан в конфиге 
и получается cluster-map. 
в нем как я понимаю прписаноы пулы, osd и PG(распредение pg по osd и пулам).
клиент говорит клиенту цефа что хочет записать обьект (файл например) в цеф в такой то пул.
клиент цефа выщитывает на какой PG будет записан этот обьект и на каком OSD этот PG лежит.
полсе этого клиент звонит на OSD и сообщает что хочет сделать. 

хочу поговоть про пулы и PG. пул предтсвляет собой набор PG на ряде OSD. 
PG этот чтото типа папки на ФС. потому что внтри PG сохранены обьекты клиентов.
кода создатеся пул то там укаызается сколько PG он будет содержать. причем что непонятно 
это то что никак не оговриывается размер кажодго PG. они динамические чтоли?
далее как я понял цеф он распределяет эти PG пустые по всем OSD равномерно. вот эти PG 
это как бытто папки . которые растут динамическт во времени. если колчиество OSD вырасстает 
то происходит пререаспредленеие PG по OSD. есть еще момент при созании пула оговаривается 
уроень редунданси данных. наприер 3. это значит что каждый обьект доолжен иметь три копии
в цефе. тоесть оригинал и еще две штуки. а так как обтект сохранятеся в PG то получается что
если мы записали обькт в цеф то он записался в какие то три PG. поэтму у нас полкчается что 
скажем у нас 10 OSD а scale=3. и получается что цеф старется разбрасыывать по три файла 
все время на раные oSD чтобы суммарно они были заполнены более менее равномерно по обьему.
может получсится такая ситууация . мы записали 10 000 файлов по 4KB  каждый из них имеет три
копии на 10 OSD. так как файлы мелкие то в целом заолнеение по обьемы будет более менее
равеноменое. поулчется что примерно кажлый OSD будет заполенен на 12MB каждый OSD.
а потм мы взяи и запиали 1 файл а 400МБ. поулчсется что на какие то три OSD будет 
записано по 400MB. и получется что все OSD заполенены на 12 MB а три OSD на 412MB.
вот так неравномерно.

на что влияет число PG при создании пула. представим что на кластер всего один пул так 
что про сам пул можно забыть. это как диск с одним разделом. то есть похеру на пул.
остаются PG. на что влияет число PG.  пусть  у нас 3 OSD. и какая разница у нас 3PG
или 3000 PG. 

если у нас 3 PG. и scale=3 то каждый обьеки будет помещатся на один OSD а его две копии
на два других OSD.  мне эти PG напомниают шарды в эластике. скажем у нас 
три ноды и мы создаем индекс . индекс это аналог пула. пусть у нас кластере эластика
из трех нод создан один индекс из трех шардов. один щард для записи и чтения а два для
чтения. мы пишем обьект в одну ноду в ее шард и остальые две копи улетают на
две другие ноды на ее шарды. по мне так если ноды три создавать более чем три шарда 
нет никакого смысла!  единственный смысл создавать более чем три шарда это если мы планиурем 
в дальнейшем расштряться расширять число OSD тогда при увеличении числа нод (OSD) нам надо 
и увеличивать число PG. число шардов потому что если шарда три а нод стало 10 то семь нод
просто будет стоять пустые.  также возможна друая ситуация у нас 10 OSD и у нас 10PG
и у нас сломалась одна нода. осталось 9 OSD это значит что шард (PG) с 10 умерешей ноды
будет создан скопирован склонирован на одну из оставихся нод.  получается на 8 нодах 
у нас по 1 PG а на девятой ноде у нас 2 PG. получается неравновесно некрасиво. 
а теперь положим что у нас было 10 OSD и 90 PG распределенных по этим 10 OSD. получатеся 9PG
на одну OSD
если одна нода сдыхает то нужно восстановить 9 PG. и распеделить их равномерно по 9OSD
и мы получаем красивую картину потому что 9 PG отлично делится на 9OSD.
и тоода у нас будет 10 PG на каждом OSD. будет равнмоменое распределение по обьему
или скажем по числу PG на кжадом OSD. это хорошо. плюс получсется что в случае кода 
 унас 90 PG было в пуле то каждый PG меньше по размеру чем размер PG кодга их было 10.
 это значит что воссоздать каждый pG из 9 пропавших гораздо быстрее поэтому 
 восстаовление потерынных даных будет гораздо быстрее. это тоже хорошо. как уже стало 
 понятно при поломке OSD данные восстанвливются не на уровен отделных обьектов а на уровне
 PG. в случае долбавеия либоу удаления OSD  у нас движуха между OSD идет на уровне
 PG а неотдельрых обьектов. как и в эластике между нодами дивгаются шарды а не отдельрые 
 обьекты. я не помню уже как в эластике можно ли там иметь неколько шардов на запись 
 в индексе или только один шард на запись а остальыне на чтение. но в цефе схема такая.
 у нас ест пул. он состоит из кучи PG. мы пишем обьект в некоторый PG и если scale =3
 то еще в два PG будут записаны копии. когда мы пишем другой обьект то он скорей всего 
 будет записан в другой PG и еще две другие копии в еще другие PG. поэтому у нас как бы полчается все время что меняется шард на запись. для разных обьектов будет другой 
 шард на запись. и получается вот что если  унас умирает две ноды (два OSD) 
 то для какойто части данных так совпадет что умрет две копии этих данных останется только 
 одна копия этих данных. если у нас умрет три ноды из всего набора то как я понимаю 
 для каойто части обьектов умрут все три копии. и тут получается как я понимаю похуй
 сколько PG было в пуле.  тоесть если у нас 4 ноды и  хоть 4 PG хоть 1044 Pg если
 умрет три ноды при scale =3 то для 1\3 всех данных у нас умрут все три копии. 
 и здесь спасает только либо увеличение scale. либо увеличение числа OSD. 
 действительно если у нас скажем 1ТБ данных разделить по 10OSD и умрет 3 нода при scale=3 то погибнет некотора ячасть данных. а если  у нас 100 OSD и умрет 3 OSD то тоже какая то 
 часть обьектов при этом потеряет все свои копии. но это будует гораздо меньшая часть данных.
получается интересная вещь - увеличение числа PG вобщем то никак не влияет на выжиываемость
дьюрабили данных. она зависит от другого. она зависит от scale. чем больше scale тем больше
выжиываеомсть. и чем больше OSD тем при томжк scake у нас погибнет меньше данных при гибели 
того числа нод чему равен scale. тоесть если scale=4 и у нас умерло 4 нода в составе 10 нод.
то точно данные будет потеряны какя то часть. и если умрет 4 нода в составе 100 нод то тоже
будут потери номеньше. но будут. увеличение числа PG позволяет при помирании ноды 
оставшие PG равномерно распределить по нодам . и восставновить их гораздо быстрее.
тоесть число PG влияет на равномерность забистости места на нодах при увеличении числа
OSD или уменьшении. и влияет на быстроту восстаноавления потерянных проавших PG при аварии.
PG напинают мух. а ноды напоминают банки. чем больше мух тем легче их распределить по банкам
равномерно. причем если мух много то увеличение и уменьшегие числа банок не будет влиять 
на равномерность рспределение.  прадв тут еще такое дополнение если мух становится болше
то их размер ставноися меньше. либо можно сравнить вот так - чем ментше мух тем
они заменяются более крупными живаотными скажем слонами а чем боьше мух тем они заменяются
микробаами. поэтому елси у нас скажем 10 банок и три слона то их тяежлело перетскивать с банки
в банку. а если у анс 10 банок и 90кошек . то случае поломки банки взять и засунуть в кажду
из 9 банок по одной кошке это оченб быстро. а если у нас 100 банок и 1000 мух. это получется
по 10 мух на одну банку. если разбить одну банку то надо восстаровить 10 мух. тоесть взят
10 банок и туда засунуть по одной мухе. это вобще быстро.
я бы сформулировал правило указания числа PG при создании пула вот так. - все зависит
от числа OSD. если  у нас 10 нод. то надо чтобы на одной ноде было 10-1 PG. 
это это занчит что суммарно должно быть (10-1)*10 PG. если n это число OSD
то число pg должны быть (n-1)*n.   тогда при поломке 1 OSD у нас   в каждй из оставищихся
oSD нао будет засунуть ровно 1 PG.  
если oSD = 10 то PG = 90
если OSD = 3 то PG = 6
ну и надо конечно прикидывать поломку скольктх OSD мы хотим заложить. если скажем
у нас 10 OSD а мы хотим захложить поломку 2 OSD . то надо чтобы PG равнмоерно раскладывался
и на 9 и на 8 OSD.  получается 90 на 9 делится. а на 90 на 8 нет. 
тость число должно делится на цело на 10 и 9 и 8 . получается надо найти наиментшее
общее кратное для 10 и 9 и 8 это 360. получается надо создавать пул из 360 PG.
это по 36 PG если все ок. и по 45 PG если оставлось 8 OSD. ну и если мы будем расширтся
до 12 OSD то более менее оно равнмерно ложится и на 11 и на 12 нод.

при записи в цеф мы пишем в один PG в один OSD. а этот OSD сам находит и пишет в два 
других OSD (если scale=3) и толко потом возрашвает программе сигнал что данные
записаны. 


отойду малек в сторону. цеф как софт состоит  из нескольких процессов демонов:
вот пример с хоста где микроцеф крутится

ceph-mds -f --cluster ceph --id nl-test-01
ceph-mgr -f --cluster ceph --id nl-test-01
ceph-mon -f --cluster ceph --id nl-test-01
ceph-osd --cluster ceph --id 2

тоесть когда мы говорим про например  OSD то это по факту прям один процесс "ceph-osd"
тоесть когда мы говоиим про MON, OSD, MGR то это на нижнем уровне прям конкретные сингл
процессы. 

OSD - этот демон имеет у себя на бекенде диск или диски. на них по факту и сохраняются
данные. это конечна точка куда прилетают данные. ниже уже нет ничего. (Object Storage Daemon)
OSd нетолько хранит данные или отдает данные. он еще обается с соседями. проверяет
их здоровье. делает репликацию PG. когда мы говорим про OSD мы представлем себе не 
комп вместе с демоном и дисками. а именно сам демон. это уже и есть OSD.



MON - эта хрень не про банальный мониторинг. нет. это супер важный демон.
он хранится cluster-map. также я прочитал что он отвечает за аутентификацию.
и он ответчает за мембершип других демонов кластера. A Ceph Monitor maintains a master copy of the cluster map. A cluster of Ceph monitors ensures high availability should a monitor daemon fail. Storage cluster clients retrieve a copy of the cluster map from the Ceph Monitor. (monitor)

MGR  - с этим демоном непонятно. якобы он просто делает мониторинг. но 
в последних версиях почемуто эта хрень является обязательной.. пока неясно с этим демоном
нахер он сдался.тем более обязстельно.  Ceph Manager acts as an endpoint for monitoring, orchestration, and plug-in modules. но пока это мало что говорит мне. (manager)

MDS - этот демон нужен вроде как для того если мы юзаем cephFS. если мы его неюзаем
то нахер он несдался. (MDS) manages file metadata when CephFS is used to provide file services. (metadata server)

далее. раньше на дисках OSD хранил данные на базе xfs.
но щас у них свой какойто родной формат хранения называется BlueStor. как это 
там выглядит на практике. как это можно посмотреть. какие утилиты это могут показать
пока хер его знает


из этих четырех видов демонов состоит цеф софт кластер

как я понял обьекты хратся на bluestor без папок. 
обьект в цефе имеет уникальный ID в рамках всего цеф кластера

цеф демоны цеф софт прдразумевает что клиенты и OSD демоны (сокращенно OSD) 
знаю топологию кластера. для этого они обращаются к мониторам и оттуда скачивают
cluster-map


переходм из чего состоит cluster-map:
она состоит из пяти кусков


1) monitor map.
ее можно заценить вот так

# microceph.ceph mon dump
epoch 4
fsid 2f48afc6-22a3-4688-a09f-4d8a011bb7da   <=== это id кластера
last_changed 2023-06-22T18:26:56.404865+0000
created 2023-06-22T18:19:09.236944+0000
min_mon_release 17 (quincy)
election_strategy: 1
0: [v2:172.16.10.10:3300/0,v1:172.16.10.10:6789/0] mon.nl-test-01  <== адреса мониторов
1: [v2:172.16.10.11:3300/0,v1:172.16.10.11:6789/0] mon.nl-test-02
2: [v2:172.16.10.12:3300/0,v1:172.16.10.12:6789/0] mon.nl-test-03
dumped monmap epoch 4


это буквально из чего состоит monitor map кусок



2) OSD map
ее можно буквально посмотреть вот так

# microceph.ceph  osd dump
epoch 100
fsid 2f48afc6-22a3-4688-a09f-4d8a011bb7da
created 2023-06-22T18:19:11.449007+0000
modified 2023-06-29T22:51:52.209296+0000
flags sortbitwise,recovery_deletes,purged_snapdirs,pglog_hardlimit
crush_version 13
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client luminous
min_compat_client jewel
require_osd_release quincy
stretch_mode_enabled false
pool 1 '.mgr' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_change 20 flags hashpspool stripe_width 0 pg_num_max 32 pg_num_min 1 application mgr
pool 2 'k8s' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 30 lfor 0/0/28 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
pool 3 'kubePool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 64 pgp_num 64 autoscale_mode on last_change 38 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
pool 4 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 50 lfor 0/0/46 flags hashpspool stripe_width 0 application cephfs
pool 5 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 50 lfor 0/0/46 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs
pool 6 'KubePool2' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 20 pgp_num 20 autoscale_mode on last_change 82 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
max_osd 3
osd.0 up   in  weight 1 up_from 92 up_thru 96 down_at 91 last_clean_interval [56,85) [v2:172.16.10.11:6802/6095,v1:172.16.10.11:6803/6095] [v2:172.16.10.11:6804/6095,v1:172.16.10.11:6805/6095] exists,up e40e7c92-e3d0-4dfc-bfeb-f55761e32f6e
osd.1 up   in  weight 1 up_from 91 up_thru 96 down_at 90 last_clean_interval [57,85) [v2:172.16.10.12:6802/4500,v1:172.16.10.12:6803/4500] [v2:172.16.10.12:6804/4500,v1:172.16.10.12:6805/4500] exists,up 83133952-1abc-420c-9db7-ee36b4edc540
osd.2 up   in  weight 1 up_from 96 up_thru 96 down_at 95 last_clean_interval [60,85) [v2:172.16.10.10:6802/4382,v1:172.16.10.10:6803/4382] [v2:172.16.10.10:6804/4382,v1:172.16.10.10:6805/4382] exists,up e012050f-a1c4-44b5-b248-1741caddf48c
blocklist 172.16.10.10:0/1291720937 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.10:0/1043716579 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.10:0/2242167631 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.10:6811/812 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.10:6810/812 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.10:0/1603527195 expires 2023-06-30T08:15:32.668281+0000
blocklist 172.16.10.11:6809/2585122472 expires 2023-06-30T08:15:12.258239+0000
blocklist 172.16.10.11:6808/2585122472 expires 2023-06-30T08:15:12.258239+0000


из того что я понимаю в этой карте. то тут есть список хостов
где сидят OSD демоны
нпример

osd.0 up   in  weight 1 up_from 92 up_thru 96 down_at 91 last_clean_interval [56,85) [v2:172.16.10.11:6802/6095,v1:172.16.10.11:6803/6095] [v2:172.16.10.11:6804/6095,v1:172.16.10.11:6805/6095] exists,up e40e7c92-e3d0-4dfc-bfeb-f55761e32f6e

его IP = 172.16.10.11


еще в нем есть инфо про пулы в кластере:
сразу скажу про два пула. это 'cephfs_data' и 'cephfs_metadata'. если мы развернули
MDS демон то эти два пула будут созданы автоматом.

пример пула из списка вверху
pool 6 'KubePool2' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 20 pgp_num 20 autoscale_mode on last_change 82 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd

пул имеет название 'KubePool2' его id=6,
 у него 20 PG (pg_num 20)
еще у него есть такая очень хуево описанная вещь как pgp_num = 20
вчем же разница между pg_num и pgp_num ? я искал пару часов пока наконец собрал
собираееьный образ и понял в чем разница и кто за что отвечает.
вот у нас есть pool . это по сути кучка PG. скажем 100 штук. тоесть пул это как коробка
а внутри нее кирпичики лего. PG это кирпичик лего.  значит для понимания скажу еще одну
вещь когда клиент цефа определяет в какой PG его пихать то он это делает на основе
CRUSH алгоритма я его будут ниже разбирать но в первом приближении то в какой PG надо
засунуть обьект зависит от hash значения вычисленного от имени обьекта. там берется
вычисляется хэш обьекта и берется число PG состоавляющих пул все это вместе
както суется в формулу и в итоге она выдает в какой из PG надо совать обьект. 
еще вжано понимать что клиент цефа берет информацию о том сколкьо  PG в составе пула
из cluster_map.  так вот насколько я понимаю pgp_num это сколько PG на данный момент 
может использовать клиент в своих расчетах. а pg_num это сколько PG  в реальности 
прописано в свойствах пула. но эта цифра как я понимаю не участвует в расчетах клиента цеф.
как же так может получится что pg_num отличается от pgp_num.  а вот как - можно задать команду
и она изменит число pg_num изменит число PG в пуле. что при этом произойдет. они это называют
так что часть или все PG будут расщеплены (split) на две части. если скажем было у нас
pg_num=16 а стало pg_num=32 то это будет занчит что каждый из PG будет расщепден на две части
действиетльно как из 16 поулчить 32. надо каждый кусок из состава 16 разделить по полам.
но эти суки они не пишут того что разделение выглядит так что старый PG он не трогается .
он остается как есть. а просто рядом с ним создается новый пустой PG. таким образом
при этой операции с данными ничего не проихсодит. со старыми PG тоже ничего не проиисходит.
прлсто нарезаются новые пустые PG. и фишка еще в том что эти новые PG на них неразрешается
ни писать новые данные от клиента ни перетаскивать данные из старых PG в новые PG. то есть
на самом деле никакого split суки не происходит. просто создается ряд пустых болванок. 
но в них даже новые данные писать нельзя. потому что как я уже сказал как я пнимаю клиент
когда смотритв cluster_map то не смотрит на pg_num он смотрит только на pgp_num.
поэтому если мы изеили только pg_num то кроме создания нвоых пустых PG  в которые 
ни данные от клиента новые ни данные из старых pG никогда не попадут (как они пишут усебя
pg_num не участвует в CRUSH алгоритме). тоесть скажем у нас было

pg_num=16 pgp_num=16. окей все понятно. мы изменили на
pg_num=32 pgp_num=16. по факту вобщем то почти что нихуя в пуле не изменилось.
а далее мы начинаем делать очень интерсуню операцию мы увеличиваем pgp_num скажем на 1
pg_num=32 pgp_num=17 и вот теерь начинает происходит очень важная хуйня.
клиент при запросе кластер мапа уже увидит что в пуле стало не 16 PG  17 PG 
поэтому +1 новый пустой Pg начинает участовать в том что в него начнут пихаться новые данные.
и также как я понимаю OSD сам автоматом начнет из какого то старого PG перекачивать часть
данных в этот +1 PG. если мы хотим чтобы у нас при этом процессе перформанс не ушел в ад
то мы будем уувеличивать pgp_num потихоньку. а если конечно мы увеличим pgp_num 
за один раз до 32 то конечно начнется ад. как я понимаю ад начентся не из за того что
из за клиентских запросов в эти новые +16 PG тоже полетят данные. а из за того что
цеф OSD начнет массово пеерносить часть данных из старых PG в новые PG.
кстати нахера цеф начнет пееносить данные. он начнет это делать чтобы небыол такой херни
то в новых PG лежат только новые данные и эти новые PG станут горячей точкой отказа.
когда унас и старые данные и новые перемещаны равномерно по всем PG это несоздает
узких точек отказа. 
поэтому pg_num это число Pg  в пуле вместе со старыми и новыми PG. одни с данными
вторые пустые. а pgp_num это то число PG которое доступно клиенту для использования
в том числе для алгоритма CRUSH. поэтому pgp_num это как бы внешняя цифра для клиента
а pg_num это цифра раскрыающая внутренюю кухню пула.
очень странно что значение pgp_num вооббще мегахуево описано в инете я заебался 
это искать. 

возврашаемся к выводу ceph osd dump

# microceph.ceph osd dump
epoch 132
fsid 2f48afc6-22a3-4688-a09f-4d8a011bb7da
created 2023-06-22T18:19:11.449007+0000
modified 2023-06-30T15:16:52.941387+0000
flags sortbitwise,recovery_deletes,purged_snapdirs,pglog_hardlimit
crush_version 13
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client luminous
min_compat_client jewel
require_osd_release quincy
stretch_mode_enabled false
pool 1 '.mgr' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 2 pgp_num 2 autoscale_mode on last_change 104 lfor 0/0/102 flags hashpspool stripe_width 0 pg_num_max 32 pg_num_min 1 application mgr
pool 2 'k8s' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 30 lfor 0/0/28 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
pool 3 'kubePool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 64 pgp_num 64 autoscale_mode on last_change 38 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
pool 4 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 50 lfor 0/0/46 flags hashpspool stripe_width 0 application cephfs
pool 5 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 50 lfor 0/0/46 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs
pool 6 'KubePool2' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 autoscale_mode on last_change 127 lfor 0/127/125 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd
max_osd 3
osd.0 up   in  weight 1 up_from 92 up_thru 96 down_at 91 last_clean_interval [56,85) [v2:172.16.10.11:6802/6095,v1:172.16.10.11:6803/6095] [v2:172.16.10.11:6804/6095,v1:172.16.10.11:6805/6095] exists,up e40e7c92-e3d0-4dfc-bfeb-f55761e32f6e
osd.1 up   in  weight 1 up_from 91 up_thru 127 down_at 90 last_clean_interval [57,85) [v2:172.16.10.12:6802/4500,v1:172.16.10.12:6803/4500] [v2:172.16.10.12:6804/4500,v1:172.16.10.12:6805/4500] exists,up 83133952-1abc-420c-9db7-ee36b4edc540
osd.2 up   in  weight 1 up_from 96 up_thru 121 down_at 95 last_clean_interval [60,85) [v2:172.16.10.10:6802/4382,v1:172.16.10.10:6803/4382] [v2:172.16.10.10:6804/4382,v1:172.16.10.10:6805/4382] exists,up e012050f-a1c4-44b5-b248-1741caddf48c

значит в нем есть список пулов с их свойствами
в нем есть спсок OSD демонов с их сокетами


расмммотрим что есть в описании пула

pool 6 'KubePool2' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 autoscale_mode on last_change 127 lfor 0/127/125 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd

 size 3 = это говрит что каждый обьект имеет 3 копии
pg_num 16  = в пуле 16 PG
pgp_num 16  = для клиентов доступно 16 PG

про разницу между pg_num и pgp_num смотри выше

autoscale_mode on = про это надо читать отдельно. как я прмиерно понимаю 
если я заменю pg_num на большее число то pgp_num нненадо менять руками его будет
менять сам цеф при чем потихоньку увеличивая на 5%

application rbd = показывает пока я незнаб то чно что но полагаю что опиывает 
какие типы обьектов храняться в этом пуле. в частности что в пуле есть обьекты типа "блочное
устройство"

3) PG MAP
следущий кусок cluster_map
как его посмотреть пока неопнятно

4) CRUSH MAP
посмотретье можно через

# micriceph.ceph osd getcrushmap -o  /tmp/01.map
# microceph.crushtool -d /tmp/01.map -o /tmp/01.map.decompiled
к сожалению последней команды нет в микроцеф

5) MDS MAP

посмотреть можно вотак

# microceph.ceph fs dump
e19
enable_multiple, ever_enabled_multiple: 1,1
default compat: compat={},rocompat={},incompat={1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap,8=no anchor table,9=file layout v2,10=snaprealm v2}
legacy client fscid: 1
 
Filesystem 'cephfs' (1)
fs_name  cephfs
epoch 19
flags 12 joinable allow_snaps allow_multimds_snaps
created  2023-06-22T22:42:57.812351+0000
modified 2023-06-29T08:15:27.928746+0000
tableserver 0
root  0
session_timeout   60
session_autoclose 300
max_file_size  1099511627776
required_client_features   {}
last_failure   0
last_failure_osd_epoch  88
compat   compat={},rocompat={},incompat={1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap,7=mds uses inline data,8=no anchor table,9=file layout v2,10=snaprealm v2}
max_mds  1
in 0
up {0=84142}
failed   
damaged  
stopped  
data_pools  [4]
metadata_pool  5
inline_data disabled
balancer 
standby_count_wanted 1
[mds.nl-test-02{0:84142} state up:active seq 7 addr [v2:172.16.10.11:6800/868450590,v1:172.16.10.11:6801/868450590] compat {c=[1],r=[1],i=[7ff]}]
 
 
Standby daemons:
 
[mds.nl-test-01{-1:84136} state up:standby seq 1 addr [v2:172.16.10.10:6800/196090353,v1:172.16.10.10:6801/196090353] compat {c=[1],r=[1],i=[7ff]}]
[mds.nl-test-03{-1:84139} state up:standby seq 1 addr [v2:172.16.10.12:6800/4167723508,v1:172.16.10.12:6801/4167723508] compat {c=[1],r=[1],i=[7ff]}]

пока что смысл тут маол понятен


с cluster-map разобрались.
теперь инфо том что мониторы у цефа они живут в кластере. они хранят в себе 
актуальную версию кластер мапа.  мониторы используют алгоритм Paxos
для того чтобы было понятно если кластер развалится какая версия кластер мапа
на данный момент актуальная.  на счет паксос не совсем понятно - в примере 
обьясеннеия как  работает паксос ( https://martinfowler.com/articles/patterns-of-distributed-systems/paxos.html ) показано что клиенты обращаются на ноды
с тем чтобы записать иземененеие. причем получается что кластер ноды живущий на паксос
он получается не имеет мастер ноды там получается что запрос на запись может придти
на любую ноду. далее эти ноды договаривбтся совместно чтобы эту запись записать. 
поэтому про монитры цефа непонятно - кто инициирует изменения в кластер-мапе внешние 
клиенты или кто? потому что еще раз скажу что в примере запрос на изменение прилетает в
кластер снаружи. непонятно как это есть в кластере мониторов цефа - кто присылает 
запрос на изменение кластер мапа.
но в люьом случае в паксос кластере нет мастер нод. любоая нода может прринять запрос
на запись а потом они начиают договариться как эту запись записать да так чтобы
ее реально все записали.

я опишу своим словами как работает паксос на еще боле упрлщенном примере чем это 
рассмотрено в статье. там у них ноды ломаются. в моем примере ноды ломаться не будут.
пусть у нас в системе есть пять нод. A, B, C, D, E
далее непонятный момент - то ли в у каждой ноды есть свой генератор натуральных чисел.
который называется "эпоха". то ли каждая нода отталкивается от эпохи которая была в прошлый раз и прибавляет один. непонятно. просто если у каждой ноды есть генератор натураьных чисел
то непонятно как они доаваются чтобы они были хоть как то согласоыван потому что 
позже станет понятно что это имеет какоето значение.

итак внешний клиент обращается к A и просит записать в кластер значение 'vasya'
A ставится так называемом "proposer". тоесть инициатором изменений в кластере.

A генерирует мессагу в которой есть ID ноды тоесть "A" в которой есть значение
которое мы хотим записат на все ноды кластера "a" и есть так называеоый номер эпохи
тоесть натуральное число только я не понимаю откуда он его берет. то ли из генератора
натуральных чисел который генерирует только числа на увеличение то ли он берет номер 
эпохи из текущей версии его cluster_map и прибавляет на один. 
мессага называется "prepare request" . итак как я поннял prepare request
содержит две хрени : Id ноды и номер эпохи. пусть номер эпохи =1 а id="A"
итак propose request = [1, A]
здес опять же вроде как есть тонкость если другая нода сгенерирует свой propose request
с тем же самым номером эпохи то побеждает тот реквест в котром больше node-id.
по мне это дебилизм. тоесть   [1,E] > [1,A] (где A и E это некие Id нод)
а если есть propose request с разными эпохами то ооднозначно реквес с тбольшей эпохой побеждает. итого   [2,A] > [1,E] > [1,A]  (согласно статье что я привел выше)

итак A посылает к B и C propose request c содержимым [1, A]
тем ему отвечают с потверждением. ответ называется "promise"
в  частности B и C обещают что не будут принимать другие "propose request" у которых (внимание)  пропоз реквесты у которых номер эпохи меньше чем в текущем принятом пропоз реквесте.

в это же время другой внешний клиент стучит на ноду E и просит записать в кластер 
значение [petya]. тогда нода E откуда то тоже беерт номер эпохи и шлет свой propose
request к нодам C и D. шлет им [1,E] где E это id ноды E.
нода D принимает и отвечает с "promise".
Нода C интереснее она же уже до этого ответила с промисом. а тут к ней опять прилетел
propos request. выше я уже сказал что такая нода должна отвергать пропоз реквесты
 у которых номер эпохи менььше чем у пропоз реквеста на который она ранее ответила.
 но здесь получается щекотличая ситация. в этот новом пропоз реквесте номер эпохи тот же самый. та же самая единица. поэтому как я понял из статьи в бой вступает то правило что сранивются Id нод. тоесть [2,A] > [1,E] > [1,A]
 так как исходный пропоз реквест был [1,A] а новый пропоз реквест [1,E] и 
 E>A то нода C принимает новый пропоз реквест и отвечает промисом на E.
поскольку A получил промис от двух нод то в сумме их стало три ноды что образует 
кворум. поэтому A переходит к следущей фазе. он шлет на B и C "accept message"
в котором содержится тоже самое что было в "propose request-е" и уже самое значение 'vasya'
итак accept мессага содержит [1,A] и ['vasya']
нода B подтверждает что оно приняло эту мессагу. и записывает внутри себя  [1,A] и ['vasya']
а вот C посылает нахер так как уже теперь работает с E.
сразу скажу что A на такой прикол реагирует следущим образом он увелиичивает значение
эпохи тоесть было 1 станет 2 и начинает всю шарманку заново. будет слать пропоз мессаги 
вида [2,A].
также непонятно из статьи что будет если на ноду которая "proposer" прилетит
propose request от другой ноды. в стаье это не рассматривется. 
итак подведем итог какие хрени записаны на даный момент во всех нодах

A = [2,A] [vasya]
B = [1,A] [vasya]
C = [1,E] [none]
D = [1,E] [none]
E = [1,E] [petya]

теперь пложим что E отсылает на D и C accept message вида [1,E] [petya]
D подтверждает и записыает к себе [1,E] [petya]
C подтрваждает и записыает к себе [1,E] [petya]

тогда у нас будет такая ситуация

A = [2,A] [vasya]
B = [1,A] [vasya]
C = [1,E] [petya]
D = [1,E] [petya]
E = [1,E] [petya]


теперь положжим что E сломался. это нам позводит увидеть еше один прикол паксос.
итак A прибавил эпоху на шлет на B и C новый пропозал = [2,A]
B отвечает подтверждая промисом записыая себе [2,A] а  [vasya] у него остался с прошлого
раза и шлет обратно
предыдущее значение [1,A] [vasya]
С тоже отвечат промисом потому что эпоха 2 больш предыдущей эпохи 1,
записывает себе [2,A] и шлет обратно [1,E] [petya]

значит мы имеем

A = [2,A] [vasya]
B = [2,A] [vasya]
C = [2,A] [petya]

таким макаром  у нас три ноды имеют ответ промис. тоесть есть кворум.
теперь A будет слать новый accept message но тут самое интересное
нода B в промисе как я уже сказал ответила [1,A] [vasya]
нода C в промисе ответиал [1,E] [petya]
так вот при подготовке accept мессаги A анализирует прилетвшие промисы 
и выбираем то знаение котрое имеет более приоритетный [эпоха + нода id] ответ.
так как [1,E] > [1,A] то значение выбираетс не vasya а petya!
поэтому в мессагу вкладыватся воот такая шняга  [2,A] [petya]
B и C прнинимают , подтверждают принятие

A = [2,A] [petya]
B = [2,A] [petya]
C = [2,A] [petya]


на последнем этапе A шлет коммит мессагу.
тут стьатя обрывается. непонятно что будет если коммиты не долетели обратно. или долетели.
в другой статье там вобще вводится какойто новый элемент в нодах новая фаза называется learner. якобы ноды подтверждение от примке accept мессаги шлют на лернер. 
короче на данном этапе я думаю хватит пока изучать этот paxos алгоритм. ясно что мудота.
иначе не было бы чехарды в его описании.

возвращаяс к нашим мониторам можно сказат что непонятно кто инициирует измеения в кластер_мап
какойто внешний клиент или одна из нод мониторов. из самого же паксос алгоритма следует 
что писать как бы можно на любую ноду тоесть как бы мультимастер но всеже между нодами
есть старшинство. да если на старшую ноду никтоне обратится то более младщая нода протащит
изменение а вот если на более старшую прилетит то ее занчение пересилит.
такой забавынй мульимастер но со старшинством.

двигаем далше. аутнтификация клиентво на цефе. аутнетифкацию делают мониторы.
аутентификация идет на оснвое симметричного шифрования. тоеть клиент имеет пароль.
и монитор тоже имеет пароль клиента. клиент может обратиться к лбому монитору. 
монитор шифрует паролем клиента ответ. клиент получает расшифроварыет и шлет обратно 
чтото там. тоогда монитор выдает клиенту тикет. и уже имея этот тикета как пропуск
клиент его предьявляет на OSD для аутентифкации\авторизации. итак аутентфикация 
идет по паролю. атентифкацию по паролю далет монитор. причем любой монитор. в конечном
итоге выдает клиенту тикет. и клиент по этому тикету аутенфицирутся на OSD.
тике во времени ограничен. тоесть он протухает в конеце концов.

вот пример создаия юзера

# microceph.ceph auth get-or-create-key \
                  client.k8ceph \
                  mds 'allow *' \
                  mgr 'allow *' \
                  mon 'allow *' \
                  osd 'allow * pool=KubePool2' 


здесь указывается юзер и его пермишнсы.
об подробнее позже.

еще раз ка работает аутентифкация клиента через монитор демон.
клиент шлет монитору свой user name. монитор шифрует с помощью юзерского ключа 
который монитор конено знает шифрует сессионный ключ. и отслыает оборатно.
получается что расширофвать может только реальный юзер а не злодей. юзер полуучает
с помощью своего шаред кей (другими словами пароля) расшифровывает  и получает сессионный
ключ. далее клиент обратно отслыаает на монитоо этот сессиооный ключ только конечно не в открытом видеа в каком виде незнаю потому что смысле его шифровать полчится тоже самое что
ему прислали. таким макаром и злодей может просто запросиь и получиь зашироыванный сессионный ключ и также его отпаврить не расшифроывая. скрей всего клиент чтото доблаяет 
к сесиооному ключу шифрует своим пралем и обратно отправляет. тогда монитор получает 
расшифровыает видит свой сессионный ключ и понимает что дейсивтетьно ему пишет
настоящий клиент. получаетс через сессионный ключ можно аутентифицроваться не раскрывая пароль. потому что если просто слать на сервер md5 от пароля то злдоей просто перхватит
этот md5  и да он пароль не знает но ему был бы и ненужен. md5 был бы такойже как пароль.
монитор создает тикет шифрует его паролем клиента и шлет обтано клиенту.
клиент расширофывает тикет. и потом он уже идет на OSD и с помощтью этого тикета 
там аутентифцицирется. опять же непонятно как клиент шлет тике на oSD. если он просто 
его защирфует то злодей просто перхыватывает этот пакет и также его шлет. вобщем както
с помощью тикета работае уже на OSD.

OSD демоны тоже скачивают cluster_map из мониторов. поэтому OSD они все знают про своих
соседей OSD.

OSD регулярно шлет мессаги на мониторы. поэтому мониторы знают что данный OSD
живой. также OSD проверяют своих соседей и тоже шлют инфо мониторам если сосед OSD
неотвечает.

OSD берет PG у себя и свереяет его контент с таким же PG (репликой) на другом OSD
где хранится реплика этого же PG.

также как клиент использует cluster_mal + CRUSH для опредленеия на каком OSD
находится primary PG. так вот также OSD использует cluster_mal + CRUSH чтобы 
опредеить OSD где хранятся реплики primary PG. чтобы туде реплицировать обьект
который прислал ему клиент.

итак клиент через CRUSH передает данные на osd где primary PG. а OSD где 
примари PG через crush определяет OSD где лежат реплики PG и туда 
пишет то что прислал клиент. и только после этого OSD на который обратися клиент
пришлет обратно овтет что данные записаны.
таким макаром OSD осваобождает клиента от записи на реплики. клиент пишет только на
один OSD а этот OSD пишет на остльыне где реплики этого PG.

когда мы делаем запрос  к цефу то всегда идет аутентифкцаия. нужно имя клиента.
и его shared key. если клиент не указан то по дефолту это client.admin
а деолфтовый шаред кей ищется в  /etc/ceph/ceph.client.admin.keyring

если мы говорим про microceph то его дефолтовый кейринг 
находится по адресу 

/var/snap/microceph/current/conf/ceph.client.admin.keyring

# cat ceph.client.admin.keyring 
[client.admin]
   key = AQCdkJRkGnGuChAADzgxVGQjZgs3b5j2k7/BsQ==
   caps mds = "allow *"
   caps mgr = "allow *"
   caps mon = "allow *"
   caps osd = "allow *"


получатся что в кейринге прорписываются не только шаред кей но и пермишнсы?

поэтмоу каждый раз когда мы просто вводим команду цеф клиент дописывает туда
дефолотовго юзера и путь к шаред кею.

тоесть команда

# microceph.ceph -s

это тоже самое что команда

# microceph.ceph -s -n client.admin --keyring=/var/snap/microceph/current/conf/ceph.client.admin.keyring


странно. если в кейринге уже прописан юзер нахер его указывать тогда 
отдеьно в командной строке

и действительно я поробовал вот так

# microceph.ceph -s  --keyring=/var/snap/microceph/current/conf/ceph.client.kubeAdmin.keyring 
2023-06-30T22:45:50.017+0000 7faad2ffd640 -1 monclient(hunting): handle_auth_bad_method server allowed_methods [2] but i only support [2,1]
[errno 1] RADOS permission error (error connecting to the cluster)

и получил ошибку. получается как и было сказано если мы не указываем юзера в явном
виде то клиент считает что он равен client.admin
а то что в кейрринге указан другой юзер ему похеру

а вот так сраобтало
# microceph.ceph -s  --keyring=/var/snap/microceph/current/conf/ceph.client.kubeAdmin.keyring  -n client.kubeAdmin


у цефа есть так называемые типы юзеров. один из типов это тип "client"
он предназначен для обычных  внешних клиентов. для которых цеф и создается.
есть и другие типы юзеров которые исопльзуются например для доступа OSD на мониторы.

так вот в цефе тип юзера указывается вместе с именем юзера. например client.admin
client это тип юзера 
а 
admin это имя юзера

в цефе есть несоклько ключей для указания юзера. если юзается ключ

-n или --name то надо указывать тип тоесть

--name client.admin

а если юзается --id или --user то тип можно опустить. но дока цефа рекомедует
юзать  имя юзера вместе с типом.

далее вот акое пока мало понятное - A Ceph Storage Cluster user is not the same as a Ceph Object Storage user or a Ceph File System user. The Ceph Object Gateway uses a Ceph Storage Cluster user to communicate between the gateway daemon and the storage cluster, but the Ceph Object Gateway has its own user-management functionality for end users. The Ceph File System uses POSIX semantics, and the user space associated with the Ceph File System is not the same as the user space associated with a Ceph Storage Cluster user.


пермишнсы в цефе называются "capabilities" или сокращенно "caps"

пул можно поделит дополнтельно на неймспейсы. и задать права чтобы юзер мог 
иметь доступ внутри пула только к обьектам принадлежащим к неймспейсу

про пермишнсы пдробно написано вот тут - https://docs.ceph.com/en/quincy/rados/operations/user-management/

посмтреть список юзеров типа client.   в microceph

# ceph auth ls | grep client
installed auth entries:

client.admin
client.bootstrap-mds
client.bootstrap-mgr
client.bootstrap-osd
client.bootstrap-rbd
client.bootstrap-rbd-mirror
client.bootstrap-rgw


а вот полный список юзеров

# ceph auth ls | grep -v key | grep -v caps
installed auth entries:

mds.nl-test-01
mds.nl-test-02
mds.nl-test-03
osd.0
osd.1
osd.2
client.admin
client.bootstrap-mds
client.bootstrap-mgr
client.bootstrap-osd
client.bootstrap-rbd
client.bootstrap-rbd-mirror
client.bootstrap-rgw
mgr.nl-test-01
mgr.nl-test-02
mgr.nl-test-03


отсюда можно увидеть какие типы юзеров есть у цефа.
например тип OSD. также видно что в качестве имени юзера может быть просто число.

постмреть инфо о конкретном юзере

# ceph auth get client.kubeAdmin
[client.kubeAdmin]
   key = AQB+qpRkkTw2KRAApyP1J1OH3OtOhFzVYcr8fA==
   caps mds = "allow *"
   caps mgr = "allow *"
   caps mon = "allow *"
   caps osd = "allow * pool=kubePool"
exported keyring for client.kubeAdmin


сравниваю его с файлом 

# cat /var/snap/microceph/current/conf/ceph.client.kubeAdmin.keyring 
[client.kubeAdmin]
   key = AQB+qpRkkTw2KRAApyP1J1OH3OtOhFzVYcr8fA==
   caps mds = "allow *"
   caps mgr = "allow *"
   caps mon = "allow *"
   caps osd = "allow * pool=kubePool"

отсьюда видно что строка 

exported keyring for client.kubeAdmin

нахер ненужна


разные сопосбы завести нового юзера

# ceph auth add = This command is the canonical way to add a user. It will create the user, generate a key, and add any specified capabilities.

# ceph auth get-or-create = This command is often the most convenient way to create a user, because it returns a keyfile format with the user name (in brackets) and the key. If the user already exists, this command simply returns the user name and key in the keyfile format. To save the output to a file, use the -o {filename} option.

# ceph auth get-or-create-key = This command is a convenient way to create a user and return the user’s key and nothing else. This is useful for clients that need only the key (for example, libvirt). If the user already exists, this command simply returns the key. To save the output to a file, use the -o {filename} option.


первая команда
$ ceph auth add client.john mon 'allow r' osd 'allow rw pool=liverpool'

add a client named john that has read capabilities on the Ceph monitor and read and write capabilities on the pool named liverpool

список пулов
# ceph osd lspools
1 .mgr
2 k8s
3 kubePool
4 cephfs_data
5 cephfs_metadata
6 KubePool2


$ ceph auth add client.vasya mon 'allow r' osd 'allow rw pool=k8s'
added key for client.vasya

# ceph auth get client.vasya
[client.vasya]
   key = AQCraZ9kBdmCJhAAkY8rbT0c3CtdTMtPmfjJCw==
   caps mon = "allow r"
   caps osd = "allow rw pool=k8s"


аналогичная команда 
# ceph auth get-or-create client.vasya2  mon  'allow r'   osd  'allow rw pool=k8s'
[client.vasya2]
   key = AQA0ap9keNKVFBAAL3uX8w+x7Sri96Cyb81DSg==

просто у нее другой вывод

еще одна аналогичная команда
# ceph auth get-or-create-key client.vasya5     mon 'allow r'     osd 'allow rw pool=k8sl'    
AQBla59kectMChAA8Vo4eFuOesH9tsPCC9oSQg==

# ceph auth get  client.vasya5
[client.vasya5]
   key = AQBla59kectMChAA8Vo4eFuOesH9tsPCC9oSQg==
   caps mon = "allow r"
   caps osd = "allow rw pool=k8sl"

что интересно - при создании юзера его  креды и права пишутся  в базу на мониторы.
а на хосте где мы создаем юзера никакого файла несоздается. 

ну а вытащить креды можно через команду. легко
# ceph auth get  client.vasya5
[client.vasya5]
   key = AQBla59kectMChAA8Vo4eFuOesH9tsPCC9oSQg==
   caps mon = "allow r"
   caps osd = "allow rw pool=k8sl"


еще вот такое нашел
Any user that has capabilities on OSDs will have access to ALL pools in the cluster unless that user’s access has been restricted to a proper subset of the pools in the cluster.


удалить юзера 
# ceph auth del client.vasya5


модификация пермишнсов юзера
# ceph auth caps client.john mon 'allow r' osd 'allow rw pool=liverpool'

напечатать ключ от юзера
# # ceph auth print-key   client.vasya3
AQC9ap9k/3PcAxAApx8PynVkb9iZu4ELs02QVw==


как примонтировать cephFS на хосте клиента
# mount   -t ceph                      \
          serverhost:/   /mnt/01      \
          -o name=client.user,secret=`ceph auth print-key client.user`


по поводу имени кластера. странно. его нельзя получить из cli.
его нет в конфигах. единственное как его можно идентифицировать это (внимание) согласно 
доке по имени главного конфига. это здец. если главный конфиг называется ceph.conf
значит мы конектимся к кластеру "ceph". когда мы вызываем любую команду то мы
должны указать конфиг. если мы неуказваем то клиент  счтает что мы конектися к 
кластуре по имени "ceph" и ищет "ceph.conf" у микроцеф конфиг лежит в 

/var/snap/microceph/current/conf/ceph.conf

еще раз подчеркну что сам конфиг имя кластер несодержит

$ cat /var/snap/microceph/current/conf/ceph.conf
# # Generated by MicroCeph, DO NOT EDIT.
[global]
run dir = /var/snap/microceph/338/run
fsid = 2f48afc6-22a3-4688-a09f-4d8a011bb7da
mon host = 172.16.10.10,172.16.10.11,172.16.10.12
auth allow insecure global id reclaim = false
public addr = 172.16.10.10
ms bind ipv4 = true
ms bind ipv6 = false


так вот я из экспермента вот что выяснил - походу цеф неимеет никакого имени кластера.
это полная наебка.

я переименовал файл /var/snap/microceph/current/conf/ceph.conf
в cat /var/snap/microceph/current/conf/ceph2.conf

ксатти также при конекте клиент цефа ищет  файл ceph.keyring
поэтому я его тоже переименовал в ceph2.keyring

далее заустил команду

# ceph health -v  /var/snap/microceph/current/conf/ceph2.conf
и комада успешно отрабтала. если бы в цефе дейтсивтельно был cluster name
то команда бы послала нахер. значит у цефа нет никаого cluster name. 
а есть только fsid.


кстати заценим разницу в кейринг файлах

# cat  ceph.keyring
# Generated by MicroCeph, DO NOT EDIT.
[client.admin]
   key = AQCdkJRkGnGuChAADzgxVGQjZgs3b5j2k7/BsQ==


# cat  ceph.client.admin.keyring
[client.admin]
   key = AQCdkJRkGnGuChAADzgxVGQjZgs3b5j2k7/BsQ==
   caps mds = "allow *"
   caps mgr = "allow *"
   caps mon = "allow *"
   caps osd = "allow *"

одини и тотже юзер. но водном файле прописаны пермишнсы а вдругом нет.


ладно. хотя бы теперь знаем другое что при вызове клиента ему нужен конфиг файл
чтобы он знал ip адреса мониторов к которым конектится и ему нужен  юзер 
и его щаред кей.  если мы это не указали он ищет дефолтовые конфиги.

еще аткой момент я выснил - если взять конфиги и скопроовать в левую папку 
даже подставиь в cli то цеф шлет нахер. видимо  путь к папке с конфигами важен.


дальше. вот у нас есть клиент client.vasya если мы укажем  -n cient.vasya
то цеф автомтом ищет кейринг с именем файла client.vasya.keyring

а вот еще навания файлов где цеф автоматом ищет кейринг для юзера

/etc/ceph/$cluster.$name.keyring

/etc/ceph/$cluster.keyring

/etc/ceph/keyring

/etc/ceph/keyring.bin

где $cluster это имя кластера, котоое как выяснили у цефа на самом деле нет.
это некий буллшит.

помимо утилит работы с юзерами что указал выше еще 
утилита ceph-authtool позволяет заводить юзеров с хоста клиента.

значит я выяснил что на  хосте с которого мы как клиенты хотим подключиться 
к цефу надо поставить клиенты от цефа то есть

#  apt-get install -y ceph-common

далее команда которая создать пустой кейринг ( кейринг это файл где храится шаред кей клиента
 и может быть его пермишнсы. пермишнсы храняться просто для српавки так как реальное 
 место их хренения это цеф база на мониторах).

создаем пустой кейринг

# ceph-authtool -C /etc/ceph/ceph2.keyring

по факту комана вобщем то беспоезная. она просто напросто создать пустой файл.
в чем прикол?

дока совует создавать кейринг файл с именем либо имя_кластера.keyring
либо client.имя_клиента.имя_кластера.keyring
тогда цеф клиент будет подхваывать кейринг автомтом его ненужно будет 
просывать руками

замечу что будет неприавлно назвать файл кейринга с окончанием .conf
тоесть client.имя_клиента.имя_кластера.keyring.conf
такой файл цеф искать не будет


отвлекемся немножко в сторону. дело в том что утилиита ceph-authtool как я поянял
предназнаена чобы работаь с юзерами цефа с хоста который не является нодой цефа.
так вот поработаем пока с юзерами на ноде цефа.
создадим юзера. запишем его кейринг в файл. дадим этому юзеру права читать с МОН 
демонов. поехали

создаем юзера

# ceph auth  add client.vasya5;

даем ему права

# ceph auth caps client.vasya5  mon 'allow r';

записываем его шаред кей в папку где должны храниться шаред кей у микроцефа

# ceph auth get client.vasya5 -o /var/snap/microceph/current/conf/ceph.client.vasya5.keyring

смотрим что там в файле

# cat /var/snap/microceph/current/conf/ceph.client.vasya5.keyring 
[client.vasya5]
   key = AQCNmKFkHgAOCRAA1uCTsTtbeiK98JCiGumIdw==
   caps mon = "allow r"


проверяем что доступ к цефу от имени vasya5 рабтает

# ceph -s -n client.vasya5
  cluster:
    id:     2f48afc6-22a3-4688-a09f-4d8a011bb7da
    health: HEALTH_OK
 
...


еще раз скажу что наличие описанные пермишов в кейринг файле 
самому цефу нахер ненужен. у цефа пермишны для юзера хранятся в мон базе.
в кейринг файле они записаны чисто для нас для справки

также еще раз скажу что  каждый раз когда клиент обращается к цефу 
он должен в комадной строке прописать :
1) путь к обшему конфигу цефа. где напримр лежат адреса мон серверов
2) указать юзера
3) указать файл кейринга с шаред кей юзера

если мы это недалаем то клиент пытваестся сам автомтом это все вычислить и найти.
если у него получается то ок. а если не получается то пошел нахер.
от того что мы чтото не указали в комадной строке незначит что это неиспользуется.

по дфеолту клиент ишет общий конфиг в папке конфигом ( как  ее опреедить ока я не знаю
знаю что у микроцефа папка с конфигами это /var/snaps/micrceph/current/conf а 
в класическом цефе это /etc/ceph) с именем конфига ceph.conf
если не указан юзер то он ищет в файле ceph.client.admin.keyring
если юзер указан но не указан кейринг файл то он ищет кейринг в файле ceph.client.имя_клиента.keyring

у цефа нет никаого имени клатера. это неаболово из документации. есть другое - если 
дефолтовое название конфиг файла ceph.conf они это называют именем кластера что полное 
вранье.


далее
я столкнулся с ошибкой
# ceph -s -n client.vasya
handle_auth_bad_method server allowed_methods [2] but i only support [2,1]

причина была в том что цеф искал кейринг с шаред кей для этого клеинта и немог 
найти. не мог найти потому что я неправильной назвал файл с кейрингом. поэтому цеф 
его не мог найти.

неправльное навание файла
  ceph.client.vasya.keyring.conf
правильное название файла
  ceph.client.vasya.keyring


можно всегда указать название кейринга вручную

# microceph.ceph -s  -n client.vasya   --keyring=/var/snap/microceph/current/conf/ceph.client.vasya.keyring 


еще приколно то что если дать команду клиенту но без опций что делать то мы попадем
в командую сессию цефа тоесть


# microceph.ceph   -n client.vasya   --keyring=/var/snap/microceph/current/conf/ceph.client.vasya.keyring 
ceph>

в этой сесии можно вводить тоже команды например status

ceph> status




таким образом по крайней мере на ноде где крутится цеф мы научились заводить юзера.
записывать его кейринг в файл. выдывать ему права . и конектится от его имени на цеф.
ура.



