ceph


установка это поделки.
документация хуйня полная.


во первых придется взять ununtu попоследнее. 
потому что хотя и заявлено что они новые релизы выкладыавют для 
нескольких версий ubuntu это хуйня полная. поэтому если хотим
релиз ceph попоследнее то придется использовать убунт попоследнее.

я взял ubuntu 20.
это новая жирная тупорылая версия которую сразу надо допиливать
	надо убрать netplan -  https://disnetern.ru/disable-netplan-ubuntu/
		sudo vim /etc/default/grub
		GRUB_CMDLINE_LINUX="netcfg/do_not_use_netplan=true"
		update-grub
		apt install ifupdown
		заполняем /etc/network/interfaces
		rm -rf /etc/netplan/*.yml
		
	надо убрать модуль floppy - онзаебет его искать и тормозить систему
	с ошибками :
			$ sudo rmmod floppy
			$ echo "blacklist floppy" | sudo tee /etc/modprobe.d/blacklist-floppy.conf
			$ sudo dpkg-reconfigure initramfs-tools

продолжаем ставить ceph

$ sudo wget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add -


$ sudo apt-add-repository 'deb https://download.ceph.com/debian-octopus/ focal main'

где focal это кодовое имя релиза ubuntu 20


проверяем какая версия ceph доступна

$ sudo apt-cache madison ceph
      ceph | 15.2.5-1focal | https://download.ceph.com/debian-octopus focal/main amd64 Packages


ставим ceph, для этого достаточно поставить только пакет ceph.
он остальное вытяент что нужно

~$ sudo apt-get -y install ceph=15.2.5-1focal





в процессе установки надо будет сгенерироваь UUID
для этого в убунте юзаем 

# uuidgen

получим чтото типа того 

badd757e-6ef9-4d70-8d8b-9f28eded1c08

когда мы потом это посдунем ceph 
он нас пошлет нафиг, и скажет что UUID неверный.

оказвыается это я ошибся! и пришлось прочитать что такое uuid
моя ошбка была в том что я скопировал uuid с экрана и потерял одну
цфиру.

так вот что такое UUID

по определению
uudi это число длинной 128 бит , если мы это число типа конвертрруем 
в буквоцифры то полуичм 32 символа. обычно принимается что в итоге 
мы дожны получить 36 символов. а у нас 32. значит надо вставить четыре
минуса. обычно по таком правиалу 8-4-4-4-12. 

по ходу установки могу рекомендовать вобще ни на  йоту не отходить
от варианту установки. например неменять назвыание кластера
на свое . пусть будет дефолтовое!!!! иначе вобще ничего незваедетсяэ!!!

в доке указано без sudo и оно так неработает и еще там мудацкое
описание а в доке от ред хат указана очень полезная опция  
-o /var/lib/ceph/mgr/ceph-test-ceph-01/keyring

так что команда в итоге будет такая

	~$ sudo ceph auth get-or-create mgr.test-ceph-01 mon 'allow profile mgr' osd 'allow *' mds 'allow *' -o /var/lib/ceph/mgr/ceph-test-ceph-01/keyring
	
		
		

sudo -u ceph mkdir /var/lib/ceph/mgr/ceph-test-ceph-01
		


тесты (бекенд один и тот же ssd диск)

локальный тест [r=6690,w=2280 IOPS]

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1000M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.16
Starting 1 process
test: Laying out IO file (1 file / 1000MiB)
Jobs: 1 (f=1): [m(1)][100.0%][r=26.1MiB/s,w=9121KiB/s][r=6690,w=2280 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2145: Thu Nov  5 14:09:17 2020
  read: IOPS=11.0k, BW=43.1MiB/s (45.2MB/s)(750MiB/17378msec)
   bw (  KiB/s): min=23896, max=94976, per=100.00%, avg=44445.88, stdev=23771.52, samples=34
   iops        : min= 5974, max=23744, avg=11111.47, stdev=5942.88, samples=34
  write: IOPS=3689, BW=14.4MiB/s (15.1MB/s)(250MiB/17378msec); 0 zone resets
   bw (  KiB/s): min= 8384, max=31608, per=100.00%, avg=14851.76, stdev=7864.41, samples=34
   iops        : min= 2096, max= 7902, avg=3712.94, stdev=1966.10, samples=34
  cpu          : usr=3.56%, sys=13.10%, ctx=60174, majf=0, minf=9
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=191887,64113,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=43.1MiB/s (45.2MB/s), 43.1MiB/s-43.1MiB/s (45.2MB/s-45.2MB/s), io=750MiB (786MB), run=17378-17378msec
  WRITE: bw=14.4MiB/s (15.1MB/s), 14.4MiB/s-14.4MiB/s (15.1MB/s-15.1MB/s), io=250MiB (263MB), run=17378-17378msec

Disk stats (read/write):
    dm-0: ios=190453/63911, merge=0/0, ticks=854328/220184, in_queue=1074512, util=85.00%, aggrios=191133/64159, aggrmerge=760/228, aggrticks=858349/221327, aggrin_queue=621576, aggrutil=84.71%
  sda: ios=191133/64159, merge=760/228, ticks=858349/221327, in_queue=621576, util=84.71%





ceph [r=1675,w=595 IOPS]

o# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=3000M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.16
Starting 1 process
Jobs: 1 (f=1): [m(1)][100.0%][r=6702KiB/s,w=2382KiB/s][r=1675,w=595 IOPS][eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2174: Thu Nov  5 14:15:07 2020
  read: IOPS=2484, BW=9939KiB/s (10.2MB/s)(2248MiB/231581msec)
   bw (  KiB/s): min=   96, max=53104, per=100.00%, avg=9937.84, stdev=5869.77, samples=463
   iops        : min=   24, max=13276, avg=2484.43, stdev=1467.45, samples=463
  write: IOPS=831, BW=3327KiB/s (3407kB/s)(752MiB/231581msec); 0 zone resets
   bw (  KiB/s): min=  272, max=17856, per=100.00%, avg=3333.73, stdev=1929.94, samples=462
   iops        : min=   68, max= 4464, avg=833.41, stdev=482.49, samples=462
  cpu          : usr=1.88%, sys=6.29%, ctx=752776, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwts: total=575394,192606,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=9939KiB/s (10.2MB/s), 9939KiB/s-9939KiB/s (10.2MB/s-10.2MB/s), io=2248MiB (2357MB), run=231581-231581msec
  WRITE: bw=3327KiB/s (3407kB/s), 3327KiB/s-3327KiB/s (3407kB/s-3407kB/s), io=752MiB (789MB), run=231581-231581msec


gluster [2810/975/0 iops]
(клиент размещен на хосте где и бекенд диски)

# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1500M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.2.10
Starting 1 process
Jobs: 1 (f=1): [m(1)] [100.0% done] [11240KB/3900KB/0KB /s] [2810/975/0 iops] [eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2712: Thu Nov  5 06:31:17 2020
  read : io=1124.5MB, bw=14888KB/s, iops=3722, runt= 77339msec
  write: io=384564KB, bw=4972.5KB/s, iops=1243, runt= 77339msec
  cpu          : usr=1.89%, sys=4.39%, ctx=158501, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=287859/w=96141/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=1124.5MB, aggrb=14888KB/s, minb=14888KB/s, maxb=14888KB/s, mint=77339msec, maxt=77339msec
  WRITE: io=384564KB, aggrb=4972KB/s, minb=4972KB/s, maxb=4972KB/s, mint=77339msec, maxt=77339msec




gluster [3733/1302/0 iops]
(клиент сидит ненахосте где бекенд диски)

1# fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=1500M --readwrite=randrw --rwmixread=75
test: (g=0): rw=randrw, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.2.10
Starting 1 process
Jobs: 1 (f=1): [m(1)] [100.0% done] [14932KB/5208KB/0KB /s] [3733/1302/0 iops] [eta 00m:00s]
test: (groupid=0, jobs=1): err= 0: pid=2081: Thu Nov  5 06:47:54 2020
  read : io=1124.5MB, bw=16712KB/s, iops=4178, runt= 68898msec
  write: io=384564KB, bw=5581.7KB/s, iops=1395, runt= 68898msec
  cpu          : usr=2.26%, sys=3.55%, ctx=215041, majf=0, minf=8
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=287859/w=96141/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=1124.5MB, aggrb=16712KB/s, minb=16712KB/s, maxb=16712KB/s, mint=68898msec, maxt=68898msec
  WRITE: io=384564KB, aggrb=5581KB/s, minb=5581KB/s, maxb=5581KB/s, mint=68898msec, maxt=68898msec
root@test-gluster-03:/mnt/01#



----------
новый этап установки 

rados = reliable autonomous distributed object storage

как я понял радос это как OSI некая теоретическая модель на которую опираютс но 
котоаря в жизни в чистом виде несуществует.

OSD  = object storage device. включает в себя цпу, RAM,nic, hdd\ssd\raid.

RADOS состоит из кучи OSD и мониторов.
мониторы это это процессы. еще мониторы требут (как они пишут) немного локального дискового пространства

еще я понял что есть cluster map. в нем как то описана вся карта кластера.
это картой управляюи мониторы.

каждый раз когда OSD ломается то меняется cluster map. меняется это epoque.

данные распрееляются по Placement Groups (PG)

Чем больше рзмер кластера тем больлше число PG

данные суются в PG на основе типа имени обьекта. 

наколько я понял  в PG находятся данные которые являются типа квантом данных в том плане
что данные реплицируются целиком размером с PG

далее как то непнятно. они пишут что данные суются в конкретный PG исходя из имени обьекта.
сами PG рассовываются по OSD неким равномерно- раномным способом.

пищут что увеличение ил уменьшение кластера не приводит к тому чтобы эти PG начали 
перетасовываться по OSD


далее они еще раз пишут что данные релицируются не науровне OSD. а на уровне PG.
реплицируются именно пэгэшки. обычно на одном OSD хранится порядка 100 PG


далее. cluster map имеет в сеебе инфо о всех здоровых и нездоровых OSD 
а также их сетевые адреса

для каждого PG кластер мап знает на каких OSD он сидит. и какие из этих OSD
живы  а какие сдохли

если в кластер мап записано об OSD что он  жив и здооров ( состояние up) и запиано что на нем сидит конкретный
PG (состояние in) то он обслуживает реквест (io) об данных в этом PG.

OSD может быть (согласно кластер мап) быть в состоянии down+in это значит что OSD недоступен  а PG который 
на нем сидел еще система неусмела среплицировать на здоровыый OSD восстановив заданный уровень репликации


длаее мало понятно. но  ясно одно что OSD обмениваются друг с другом  мессагами сообщая друг другу
о -- и вот тут мало понятно что они друг другу собщают. то ли о том какие PG на них хранятся. то ли 
собщая полный  кластер мап. еще OSD обмениваются инфо с мониторами.


клиент пишет данные на OSD. а OSD потом реплицирует эти данные самостоятельно по кластеру

далее есть три варианта  репликации у цефа.
- primary-copy
- chain
- splay

primary-copy = клиент пишет на первичный OSD. он в паралель обновляет все копии на других OSD. 
и после этого возрвашает клиенту инфо что запись состоялась.
также вот этот первый OSD он обаратывает не только записи но и операции чтения

chain= как я понял клиент пищет на первичный OSD тот обновляет копии непаралеьно 
а одну за другой по очереди. после обновления последнего OSD идет возврат клиенту
инфо о том что запись прошла успешно.
 при этом операции ччтения первичный OSD не обслуживает.
обслуживает их тот OSD который самый последний в очереди на обновление

splain == как этот метод репликации я непонял


как уже говорил что OSD друг с другом а также с монитором обвенимются  мессагами (messages)
о правда не сомвсес понятно о чем. то ли от тех PG которые хрантся на том или ином OSD. 
то ли о полной карте кластера.  так вот еще OSD посылвает такие же мессаги клиенту.
и может быть и клиен посылает к OSD мессаги но эт неточно.
точно то что месаги имеют epoque поэому типа OSD всегда знает какая мессага относится к более раннему
неактуальному состояию кластера чем это записано в OSD либо прищедшая месага относистя к более новой 
эпохе тоесть отаражает более атуальное состсоение кластера.

насколько я понял из описания - то клиенты цефа они получают карту с PG и таким образом не кластер изначально 
принимает реквесты от клиента и рооутит их на нужный OSD а сам клиент цефа имея карту направляет запрос 
на нужный OSD для доступа к данным с опреденного PG.


вот у нас есть PG и он лежит на таком то колчестве OSD.  так вот среди этих OSD есть первичный osd.
тот который как я понял прежде всего и принимает на себя операции записи.

далее может так случиться что OSD на чтение будет доустпен части клиентов а части небудет.
ии будет доступен части других OSD а части небудет.  тогда част клиентов будет продолжать с него считвать
втовреся как это делать ненадо. 

они вроде решабт проблему так. если копиия на чтение  не получила от своих peer товарией хартбит 
значит она больше операции чтения не обслуживает. дефотовй интервал хартбита 2с.
непонятно как это решает проблему если чтото случилось впределах меньше 2с.

из того что я понял OSD знает PG которые на нем харняться. и он знает для каких PG он не primary PG.
тогда он отправляет для primary PG OSD сообщение о том что тот по его инфо является примари PG.
примари PG узнает что он примари PG.
и этот примари также узнает где лежит реплика PG.
в ответ примари PG шлет всем этим репликам какую важную инфо по этой PG.

насколько я понял процессом восстановление на другие реплики руководит примари PG.
детали неясны.

на монииорах хранисят мастер копия  от cluster map.
нужно чтобы был кворум среди мониторов. чтобы они могли договориться и понять о том какая в итоге мастер 
копия верна.

выбирается некий мастер монитор .далее он собирает вокруг себя кворум мониторов. им разрешаается
рассылть амктуальную версию кластер мапа к OSD и клиентам.

далее есть lease time. по деолфту 2с. через 2с мастер монитор должен своим пирам прислать новый месседж
о том что он жив. тогда они понимаю что мастер жив. если он не прислал значит он сдох и выбирает
нового лидера среди мастеров


к мониторам обрашение за картой кластера от OSD или клиентов приходят редко если все окей.
оно приходит только если клиент обратился к OSD а он мертый. тогда он звонит к монитору. 
или OSD обнаружил мертвого соседа. а так если все норм то всем хватает информации о кластер мапе 
от соседей. клиент получает от OSD а OSD друг от друга. если поломоалась сразу куча OSD а на них лежала куча PG
то на монитор прилетит куча обращений.  чтобы этого небыло OSD  каждый полуслучаный интервал времени пигуют только я непонял
что . может соседей? и это как то охраняет монитор от шквала запрососв в случае обвала  кучи OSD,







до этого моменты мы рассматривали RADOS. это чисто сферический конь в вакуууме на котоором строится
ceph. но по факту цеф состоит из нескоько других компонертов.

ceph состоит из:
мониторы
OSD демоны
менеджеры
метадата серверы


мониторы содержат мастер копию кластер мапа. клиенты получают кластер мап от монитора. это странно
потому что в радосе написано что клтиенты получают кластер мап от OSD. 

OSD демон проверяет свое состояние и состтоние других OSD юнитов и докалдывает об этом мониторам.
это тоже странно. в радосе этого компоненты нет. OSD сами себя тестируеют и тестируют соседей. 
и если што докладывают мониторам.

A Ceph Manager acts as an endpoint for monitoring, orchestration, and plug-in modules. = это вобще
непоняно что значит. но вот еще нашел
A Ceph Manager daemon ( ceph-mgr ) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization, current performance metrics, and system load.
Тоесть походу это прсто типа мониторинговая хрень ни на что не влияющая.
хотя вот еще нашел = Since the 12.x (luminous) Ceph release, the ceph-mgr daemon is required for normal operations. The ceph-mgr daemon is an optional component in the 11.x (kraken) Ceph release. тоесть в 12 версии вроде бы он уже обязательно 
нужен . бардак какойто

метадата сервер хранить метадату файлов когда к цеф конектятся как  к файловой системе. получается если 
мы конектится к цеф как к блочному устроуству то метадата сервер нам нахер ненужен.

получется металата сервер нахен не встрался, менеждер тоже нахер невстрался, осатаются рельно важные компоенты
это мониторы и OSD демоны.

OSD = object based storage deice

в статеть они пишут что фишка OSD в том что они  содержат инфо не о блоках как на жестких дисках ибо этих блоков просто 
дохера а всего навсего об обьектах. обьектов мало по сравнению с блоками. тоесть блоки это некий лоу-левело инфо 
которая явлется внутрненней для OSD и для внешних чувачков она не предоставляется. наружу проеоставляется инфо 
об обьектах котораых хранстя на OSD и это типа компактная информация. поэтому типа реплиация блочных дисков это 
типа жопа. незнаю в ккаком смсыле. а репликация обьектов это типа очень компактно

далее они пишут вот о чем - что есть фундаметальная проблема сторадж у которого дохрена дисков или OSD без разницы.
проблема в том что если мы добавлем новые диски то они будут либо пустые. либо на них будут только новые даныные.
и прблема тут  в том что диски в системе будут загружены не равномерно. либо будут пахать толдько диски старые
со старыми данными либо только новые диски с новыми данными. а нам надо чтобы пахали все диски равномерно.
тогда приходит идея что если мы добавили новые диски то надо на них скопировать рандомные куски со старых дисков
тогда типа все дисики будут загружены равноемерно.

и вот  они пишут что они разработали алгоритм CRUSH (Controlled replication Under scalable hashing)
алгоритм береь обьект либо идетиификатор обьекта и применяя функцию рассчитывает список девайсов (видимо список OSD)
на которые надо засунуть этот обьект

фишка CRUSH в том что цефу ненужно иметь никакой элемент архитекткру в котором бы хранилась информация о метаданных.
если у клиента есть карта кластера (список здоровых OSD) то клиент может сам чисто по формуле высчитать на какой OSD
надо начать писать данные.  это как если бы клиент фс мог по формуле сам выситать в каких блоках сидит файл 
без обращения к каталогам

CRUSH берет как параметр входной id обьекта, прикладывает к нему некие "placement rules" и кластер мап и на выходе
по формуле получает список OSD куда надо запихать этот обьект x.

кластер мап состоит из devices и buckets. бакеты в себя включают другие бакеты и девайсы.
все эти хрени имеют веса.  девайс имеет вес назначенный админом . вес указывает обьем инфо который девайс
может хранить

дальше по тексту идет куча малопонятной хрени как раобтает crush 


вобщем клиенты и OSD демоны используют CRUSh чтобы самостоятельно определять для обьекта его группу OSD
вместо того чтобы для этого лазить кудато на сторону в кластер

неважно как клиент пытается работать с цеф - толи как с ФС, толи как с блочным устройством, толи как 
с оббьект сторажем => в любом случае внутри цеф влетевший кусок инфо записывается как обьект.

дальшер написнаан непонятная хрень = Ceph OSD Daemons handle read, write, and replication operations on storage drives.
это отличается от радос в котором вобще нет такого элемента архитектуры. репликацией там занимается примари OSD.
чтением занимается либо примари OSD либо он сообщит клиенту с какого OSD читать данные.
также это отличается от тго что выше было написано в доке про демона OSD = OSD демон проверяет свое состояние и состтоние других OSD юнитов и докалдывает об этом мониторам. пока непонятно.
хотя наверное я понял!!! osd daemon про которого говорится в ceph это  OSD в литературе по rados!
теперь все стало понятно. osd в терминах rados это osd daemon в терминах ceph! все теперь стало понятно.
тогда еще раз рассмотрим из чего состоит цеф:

ceph состоит из:
мониторы
OSD демоны
менеджеры
метадата серверы


менеджеры это мусор, метедатат это тоже мусор если мы к цеф неподключаемся как к ФС.
тоода остаются ровно теже комоеннты что и в радос литературе = кластер из мониторов и  OSD штуки. которые 
в цеф называют OSD демоны. 

далее OSD и OSD daemon это одно и тоже.

OSD хранит данные  в виде обьектов. информация об обьектах внутри OSD хранится в виде плоской таблицы. тоесть 
там нет никакой иерархии каталогов. идет просто идентиификатор обьекта + тело данных + доп метаданные.
считай что это как key-value база данных. метедаднные обьекта тоже имеют вид ключ+значение.
какие там метаданные будут прописаны для обьекта - цефу похер, метаданные опредеяет клиент цеф.

object ID уникален в рамках всего кластера OSD

в обычыных стораджах клиент обращается к центральному входному устройству. в цеф этого нет.
в цем клиент на основе CRUSH высчттыаеи к какому OSD ему надо обратиться и лезет сразу туда.
получаем децентрализацию. 



клиенты и OSD должны иметь актуальный "cluster map"

кластер мап состоит из 5 кусков:
- монитор мап
- osd мап
- pg мап
- crush мап
- mds мап


монитор мап содержит инфо о мониторах.
смотрим:

# microceph.ceph mon dump

epoch 4
fsid d64966ad-7849-4b7b-a2f9-79461128965c
last_changed 2023-05-04T14:05:18.608758+0000
created 2023-05-04T14:04:01.430028+0000
min_mon_release 17 (quincy)
election_strategy: 1
0: [v2:10.103.1.27:3300/0,v1:10.103.1.27:6789/0] mon.lxd-02
1: [v2:10.103.1.24:3300/0,v1:10.103.1.24:6789/0] mon.lxd-03
2: [v2:10.103.1.13:3300/0,v1:10.103.1.13:6789/0] mon.lxd-04
dumped monmap epoch 4


итак в микроцефе у нас три монитора.


osd мап содержмит инфо о пулах, osd, pg
смотрим:

# microceph.ceph osd dump

epoch 139
fsid d64966ad-7849-4b7b-a2f9-79461128965c
created 2023-05-04T14:04:03.133182+0000
modified 2023-05-08T19:10:01.088603+0000
flags sortbitwise,recovery_deletes,purged_snapdirs,pglog_hardlimit
crush_version 19
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client luminous
min_compat_client jewel
require_osd_release quincy
stretch_mode_enabled false

pool 1 '.mgr' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_change 19 flags hashpspool stripe_width 0 pg_num_max 32 pg_num_min 1 application mgr

pool 2 'lxd' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 25 flags hashpspool,selfmanaged_snaps stripe_width 0 application rbd

max_osd 3

osd.0 up   in  weight 1 up_from 125 up_thru 138 down_at 124 last_clean_interval [103,117) [v2:10.103.1.27:6802/1659,v1:10.103.1.27:6803/1659] [v2:10.103.1.27:6804/1659,v1:10.103.1.27:6805/1659] exists,up 45509eb5-d0a5-4455-b9d9-dc6286a1ba4d

osd.1 up   in  weight 1 up_from 126 up_thru 132 down_at 125 last_clean_interval [105,117) [v2:10.103.1.24:6802/1627,v1:10.103.1.24:6803/1627] [v2:10.103.1.24:6804/1627,v1:10.103.1.24:6805/1627] exists,up fb86c6af-5bab-4921-a9b0-8978f3637432

osd.2 up   in  weight 1 up_from 125 up_thru 138 down_at 115 last_clean_interval [109,113) [v2:10.103.1.13:6802/
1669,v1:10.103.1.13:6803/1669] [v2:10.103.1.13:6804/1669,v1:10.103.1.13:6805/1669] exists,up 74cc655c-6e8c-49c3-8902-dfe38343aa47

blocklist 10.103.1.24:0/2221645565 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/3638844332 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/2375246677 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:6811/834 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:6810/834 expires 2023-05-09T19:09:28.925243+0000
blocklist 10.103.1.24:0/2720725004 expires 2023-05-09T19:09:28.925243+0000


pg мап содержит инфо о pg



crush map содержит инфо 
об сторедж девайсез. 
посмотреть можно через 

$ ceph osd getcrushmap -o {filename}
$ crushtool -d {comp-crushmap-filename} -o {decomp-crushmap-filename}

к соажалению на микроцефе это несрабатывает


mds мап содержит инфо об метадата серверах 
смотрим:

v# microceph.ceph fs  dump
e23
enable_multiple, ever_enabled_multiple: 1,1
default compat: compat={},rocompat={},incompat={1=base v0.20,2=client writeable ranges,3=default file layouts on dirs,4=dir inode in separate object,5=mds uses versioned encoding,6=dirfrag is stored in omap,8=no anchor table,9=file layout v2,10=snaprealm v2}
legacy client fscid: -1
 
No filesystems configured
Standby daemons:
 
[mds.lxd-03{-1:194107} state up:standby seq 1 addr [v2:10.103.1.24:6800/4107889023,v1:10.103.1.24:6801/4107889023] compat {c=[1],r=[1],i=[7ff]}]
[mds.lxd-02{-1:194112} state up:standby seq 1 addr [v2:10.103.1.27:6800/1283618052,v1:10.103.1.27:6801/1283618052] compat {c=[1],r=[1],i=[7ff]}]
[mds.lxd-04{-1:194131} state up:standby seq 1 addr [v2:10.103.1.13:6800/2866487613,v1:10.103.1.13:6801/2866487613] compat {c=[1],r=[1],i=[7ff]}]
dumped fsmap epoch 23


соотвестенно микроцеф неиспользует фс на цефе. поэтому сами метадата серверы есть. но как видно 
никкой цеф фс несоздано


прежде чем клиент начнет юзать цеф ему нужно получить кластер мап. для этого он лезет к монитору.
мониторы обетдиенны в кластер. чтобы был кворум мониторы должны иметь большинство доступных тоесть
1, 2:3, 3:5, 4:6



далее. для аутентификции клиента цеф юзает shared secret метод.
это метод кога и сервера и уклиента есть тот же самый secret key
аутентификация работает типа как у керберос так они пишут.
как я понял клиент обращается на монитор. тот его аутентиифицирует и обратно возвращает session тикет. причем этот тикет 
зашифрован тем же secret key что есть и у клиента. далее с помощью этого session тикет клиент повторно обращетеся
к мониторму и закаызаывает сервисы которые нужны от OSD. монитор возврашает новый тикет с помощью которого 
уже клиент будет аутентифицироваться+авторизоваться уже на OSD. все эти тикеты они временные. тоесть они протухают 
во времени и их нужно получать заново.

чтобы заюзать аутентификацию человеек должен обартиться к цеф и создать юзера. при этом цей создать учетку и secret key
и сообщит обратно. и также сохорнаить копию на мониторе.

и еще раз проговрим как раобтает аутентификация у цефа. вот мы завели юзера на цефе. и получили secret key.
теперь для аутентификации мы обращаемся через клиент к мониотору. вводим свой secret key. нам воттвет монитор 
создает session ticket , шифрует его нашим secret key и возвраащает нам. мы с помощьью нащего secret key расшироываем
и получаем на руки session ticket. он валиден какоето время. потом его надо заново получать. он валиден 
как говорится на период нашей сесссии.  тееперь юзая наш session ticket (правда непонятно как кокнретно) мы обращаемся
на монитор и он нам создаем еще один тикет (названия  у него нет). и именно этот тикет мы предьявляет на OSD
для аутентиификации+авторизации


в цефе клиент, мониторы, OSD все знают кластер мап. поэтому могут обаться друг с другом напрямую.

OSD периодически шлет на монитор мессаги о том что он жив здоров. если это прекратилось то монитор 
делает вывод что OSD сдох

OSD также может опредеить то что сосед OSD сдох и тоже об этом доложить монитору.

OSD ежедневно делает легкий scrub. тоесть обращется к соседним OSD на которых хранятся реплики PG.
и сравнивает метаданные у себя локальные с метаданными у соседей для конкретного PG.
а еженеделно OSD делает уже тяжелый scrub. когда уже сраванивает по контрольным суммам  тело или данные для PG 
у себя с тем же самым у других OSD у которых хрантся реплики данного PG

клиент как я понял по object id опредяет pool и PG для обьекта. и потом применяя формулу узнает primary OSD.
OSD делая туже хрень узнает все множствео OSD на которых должны хранится реплики для этого PG.
клиент пишет на примари OSD. а этот примари OSD пишет на все реплики. и уже когда все реплики записаны 
то пишет обратно клиенту что процесс записи успешно завершен

обьект в цеф имеет принадлежность к пулу.
кто опредяет параметры пула пока неясно
но ясно то что своствами пула являются

Ownership/Access to Objects
The Number of Placement Groups, and
The CRUSH Rule to Use.


пул имеет какое количество PG.
CRUSH алогоритм делает маппинг object-id --> pool --> pg --> список OSD 
так как кластер мап меняется то для разных кластер мапов для одного и того же object-id будет пполучатся
разный список OSD сереров

для того чтбы клиент узнал список OSD ему в качестве входных парамтров нужно:
- object-id
- pool-id
- cluster map

кластер мап клиент получает от монитора.
object-id клиент должен сам знать 
откуда брать pool-id пока неясно

применяя object-id + pool-id на кластер мап клиент получается список OSD серверов

у меня такое ощущение что пулы создает сам клиент предваретельно в цефе. и кода клиент хочет сохранить обьект 
то клиент должен сам определится в какой пул он хочет засунуть обьект.

насколько я понял все OSD которые хранят PG тестно друг с другом общаются провреяя здоровье друг друга.
и если чтото нетто то стучат об этом монитору

primary OSD - он один для PG. он и только он принимает запрос от клиента на запись в эту PG

весь набор OSD кооыре хранят PG назыается Acting set. те серверы который в Acting set находятся в состонии UP
называются UP SET.

erasure coding = чтото ттипа raid5 кодиования.  в чем прикол. прикол в том что экономитс место как я понял
если у нас голые реплики то мы теряем много места. например если у нас 2 реплики то три OSD хранят инфо по обьему
одного OSD. а если унас raid5 кодиорвание. то 3 OSD могут хранить инфо по обьему как 2 OSD. 
так вот как я понял уровень erasure coding определеяется на уровне пула.


из того что я понял про формулу эрейзинг кодирования. если указано 3+2 к прмиемеру это значит
что данные делятся на 3 части. каждая часть сохранятеся на свой OSD. и еще высчтываются 2 части доп данных 
это коды кодирования. эти части сохрнатяются на отдельные OSD. итого на 100% обьема данных будет еще 
дполнительно заниматься 40% под коды. 

у цефа есть еще такая прокладка как cache tier.
типа можно иметь кэш таир из быстрых дисков и обыкновенный бекенд из медленных дисков.
кэш работет прозрачно. детали надо читать дополниетельно

естьтакая штука bluestore. как я понял это метод с помощью котлрого хрнаятся данные на дисках на OSD
машинах. это как ихяяя цефоская файловая система на дисках.


BlueStore opens block devices in O_DIRECT and uses fsync frequently to ensure that data is safely persisted to media. 

я помотрел что значит O_DIRECT. значит в линуксе мы открваем файл на запись. или устойство на запись
и при этом указыаем флаги. флаг O_DIRECT формально означает что мы говорим ядру что мы нехотим чтобы
при записи использовася кэш линукса (page cache) при записи. мы хотим чтобы данные сразу летели в устройство.
однако как написано на стековерфлоу по факту это нихрена незначит что когда мы пишем на диск и нам прилетает 
подтверждение что данные приняты то данные реально записаны на диск. они могут застрять где то там в кэше диска
или еще где а до пластин диска еще не долететь. поэтому этот фалг негарантирует что данные записаны на диск
как нам о том сообщит ядро. а только как я понял дает то что данные не будут дублироваться в page cache линукса.

fsync как я понял - да. он гарантирует что данные были записаны на диск. 


You can evaluate a drive’s low-level write performance using fio. For example, 4kB random write performance is measured as follows:


# fio --name=/dev/sdX --ioengine=libaio --direct=1 --fsync=1 --readwrite=randwrite --blocksize=4k --runtime=300

далее они пишут что диск в линукск может работать в двух режимах : write back и write thgrouh.
когда на диске активирован его дисковый встроенный кэш то он работает в реэиме write back.
проверть в каком реэиме работает диск можно через 

# cat /sys/class/scsi_disk/*/cache_type

прикол в том что для дисков на яндекс облаке вобще такой папки нет. 
и у nvme дисков такой папки тоже нет.

вчем прикол с этим кэшем. прико в том что данные пишутся не надиск а в этот кэш а уэе потом переносятся на диск.
так вот если запускать fsync то эта команда говорит - перенеси все данные из этого кэша уже на пластины.
поскольку цеф постоянно запускает fsync то вместо того чтобы сазу писать на диск  ос пишет сначалаа в кэш 
диска а потом опустошает этот кэш перенося данные на пластины. как пишет дока это существенно повысить
лейтенси для иопсов. при записи иопса с выклченных кэшем у нас иопс будет писаться долго, а с включеным кэшем
у нас иопс пишется быстро но потом долго ждать пока опустошится буфер перенося все что в нем есть
из кэша на пластины. и якобы это будет суммарно дольше чем сразу писать на пластины


они даже предалгаюь udev правило чтоб руками это дело ненастраивать

# cat /etc/udev/rules.d/99-ceph-write-through.rules
ACTION=="add", SUBSYSTEM=="scsi_disk", ATTR{cache_type}:="write through"


вотт тут https://docs.ceph.com/en/latest/start/hardware-recommendations/ в самом низу
указано сколько ядер цпу и дисков должно быть на  мониторах и OSD и метадата нодах

получается cpu\RAM на минималках

OSD: 1cpu 
     4GB

монитор: 2cpu
         4GB

mds: 2cpu
     2GB




у цеф есть  алгоритм страйпинга. я не очень понял как он конфигурится. такое ощущение что это все настраивется на клиенте.
идея вробы бы такая - берется исходный обьект. и делится на несколько обьектов цефа. посолькуо каждый обьект 
хранится на своем списке OSD то запись идет так: пишется небольшой кусок первогоо обьекта. потов небольоой кусок 
втрого обьекта. причем писать на первый и второй обьект можно одновременно. и так достигается увеличение скорости. 

по архитектуре цеф вобщем то для начала все.



