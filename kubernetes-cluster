kubernetes HA cluster

когда мы поставили кубернетес.
то следущий научиться делать что control plane имел 
реданданси. вот только тогда такой куб можно использовать на практике 
в продакшн.

делается на комбинации: haproxy+keepalived 
таким образом мы имеем отказоустойчивый  хапрокси 
это входная точка . а за ней 
несколько контрол плейнов - несколько kube-apiserver а данные он читает
из etcd которая тоже кластеризована отказоучтойчива и на каждом сервере имеет одни и те же данные. получили отказоустойчивый контрол плейн.

теперь можно накатывать поды.

откоазоустойчивый контрол плейн нужен нетолько для того чтобы 
накатывать новые поды и потому что контрол плейн постоянно следит 
есть ли связь с подами  работают ли они. и если контрол плейн теряет
связь с подами то например он начинает их раскатывать на другом сервере.

контрол плейн это как vcenter с функцией HA включенной.

 keepalived использует vrrp
 vrrp использует мультикаст
 
 что такое ip multicast 
 понять как ip multicast увязывается с L2 какие mac адреса он исполтзует
 
 мультикаст ip адреса лежат в диапазоне 224.0.0.0/4
 224 = 1110|0000 учитвая маску получаем что первые 4 бита = 1110
 получается если мы горорим про первый октет такого IP адреса то 
 минимальный октет = 224 =  1110|0000
 а максимальный октет = 239 =  1110|1111
 
 если мы говорим про полный IP адрес то минимальный выглядит так
 224.0.0.1 = 1110|0000.00000000.00000000.00000001
 а максимальный выглядит так
 239.255.255.254 = 1110|1111.11111111.1111111.11111110
                   
 как видно это непрерывный блок адресов.
 
 про мак адреса таких IP пакетов мы еще поговорим.
 
 а пока в целом захрена нужен мультикаст. он нужен для того чтобы 
 вещать чтото в сеть чтобы это массово получала куча народа.
 например передавать в сеть пакеты с видеофильмом.
  а в чем прикол? прикол в том что на уровне L2 комп сервер видеофильма
  вещает в сеть один пакет в L2 канал до свича. а свич этот пакет 
  сам рассылает сразу всем людям во все порты свича. то есть серверу видео
  ненужно слать каждому участнику просмотра пакет отдельно персонально.
  для этого и был выделен в диапазоне IP адресов блок под эту задачу.
  и назвали это мульиикастом.
  
  диапазоном мультикаста может пользоваться каждый желающий.
  но все же некоторые адреса зарезервированы под определенные нужды.
  например 224.0.0.18 испльзует VRRP протокол.
  224.0.0.5 испольщует OSPF
  но в целом почти все адреса свободны для свободного юзания.
  мультикаст адреса это на сервере будет dst ip адрес.
  
  опять же пока я не касаюсь dst mac адресов таких фреймов.
  об этом позже. но если мы вощьмем рассмотрим IP пакет который долетает 
  до компа в котором стоит скажем dst ip = 224.1.1.6 то это не адрес
  компа получается и получается что софт на компе тоже должен 
  быть в курсе что такое мультикаст адреса и неотбрасывать а принимать
  такой ip пакет.

  поговорим как dst mac используется при отправке мультикаст IP пакета внутри фрейма. то есть дело в том что если внутри фрейма сидит мультикаст IP  то dst MAC у такого пакета будет тоже непростой.
  
  значит mac адрес состоит из 6 байт. и записывается в hex форме в виде
  00:00:00:00:00:00
  
  так вот dst mac имеет первые три байта всегда в виде
  01:00:5e: = 00000001 00000000 1011110
  
  поговорим про последние два байта MAc адреса. они равны последним 
  двум байтам IP адреса. 
  
  то есть если dst мультикаст ip = 224.2.0.18 то его последние 2 байта = 0.18
  переводим их в hex формат 00:12 подставляем в mac
  
  01:00:5e:??:00:12
  
  осталось выяснить про 3 байт с хвоста в mac адресе. для этого берем 3 байт с хвоста в ip адресе и заменяем самый старший бит на 0. это  и есть 3 байт с хвоста mac адресе.
  
  третий байт с хвоста в ip = 2 (dec) = 00000010 
  старший байт у него уже 0 , в итоге = 00000010 = 0x02 (hex)
  
  в итоге мак адрес = 01:00:5e:02:00:12
  
  вот такой dst MAC адрес будет для находящего внутри него мулттикаст пакета
  dst ip = 224.2.0.18
  
  посмотрим на первый байт mac адреса он равен = 01
  в бинарном виде это = 00000001
  почему взяли именно такой первый байт для мак адреса.
  дело в том что биты передаются по проводам нетак как написано слева
  направо а наоборот справа на налево так что первым будет передан 
  бит = 1.
  так вот как я понял нет ни одного мак адреса у реальных физ карточек 
  у которых этот бит = 1. он  у них всегда равено 0. 
  поэтому свичи знают что если первый прилетевший бит =1 то это либо броадкаст
  мак адрес либо получается мультикаст адрес.
  что это дает . это дает то что в любом случае это означает что начинающий
  прилетать в свич фрейм надо пересылать во все порты свича (в данном вилан конечно). именно поэтому именно такой первый байт мульткаст мак адреса 
  был выбран.
  
  почему фрейм с мультикаст мак адресом всегда будет флудиться во все порты.
  потому что через порты никогда не пролетит такой mac адрес в качестве
  src mac адрес. и он никогда не попадет в fdb таблицу свича. а раз его
никогда небывает в таблице то такие фреймы всегда будут пересылаться во 
все порты  свича.

чтобы свич на уровне L2 поддерживал мультикаст прием передачу фреймов
не нужно ничего специально настраивать. все сразу работает. формально 
свич получает мак адрес которого никогда нет и небудет в его таблице
поэтому он его как нам и нужно всегда посылает во все свои порты.

таким образом мы выяснили что на физ свиче реальном ничего настраивать ненужно.

возникает другой вопрос. если мы знаем заранее в каких портах
будет отправака и прием мультикаст трафика как на свиче ограничить
чтобы он его в другие порты непосылал.

также надо узнать а как у сферы ее vswitch работает с мультикастом. 
может он позовяляет как то управлять им по портам.
  
  то ест с vrrp надо все выяснять начиная с L2 уровня и потом подниматься 
  выше уже.

насклько я понял программа клиент которая хочет слущать мултьтикаст трафик
она может послать в сеть igmp пакет в котором она высказывает завявление 
что она хочет слушать такой то мультикст ip. зачем это делается.
обычно клиент если чтото хочет он сам обрашается к серверу. а в случае мультикаста клиент никуда необраается он сидит и только принимает
так вот поэтому свич шарашит этот трафик во все порты. а если бы свич знал 
за каким портом сидит клиент которому нжужен этот мульикамт страфик он бы только ему и посылал. так вот igmp это заявка от клиента для свича о том что
ему такой трафки нужен и свич тогда получив от сервере будет срать только в порт клиента. единсвтенное я непонял igmp пддержку имеют рутеры или свичи.
рутеры точно ибо мульткст можно рутить хитрыйми протоколами поэтому рутеру надо знаь в какой порт ему срать этим траификом дальше. ибо понятно что мульттикмтт ip это не dest ip конечного компа как мы привыкли в классичемком режиме. а вот прдерживают ли igmp свичи пока незнаю.

но возможно можно в тупом реиме прописать на свиче статик arp для мультикаст ip конктеного и портами свича.  ибо для свича важно только MAC и порты. а между мульикаст ip и мультикси mac есть четкоая взаимосвязь.
поэтму если свич неподерживет igmp то мжоно все равно его завтсавить срать 
мультикасм только в оплереденные порты

поэтому в частности непонятно когда пишут что свич неподдерживает мультикаси.
свич его всегда поддежвает. другое дело что он срет по все порты. а это жопа.

  
  в мультикасте нет чуда.
  чтобы на свиче он работаел ничего ненужно самый тупой l2 свич
на неи мудльикаст дует работать
если бы мы  юзали кипэлайв для дефолт гейвтея то нам нужно было бы
лепить кластер IP и для lan и для wan карт. а так у нас будет 
только лан карта. 
кипэлайв пзволяет юзать юникаст  а не мульттикаст
vrrp помимо своих адвертайз фреймов которые он шлет на мультикаст группу
от которой мы избаивлись уже также юзает кластер IP и несущестующий мак адрес
поэтому опять же трафик на этот мак будет летет на все порты свича.
чтобы от этого избавиться надо на свиче прописать статик мак.
тепрь вспомим что у нас виртуалки а не физ сервера и у нас
перед физ свичом еще стоит esxi vswitch.
всвич сферы на уровне L2 работает так - он заранее знает какой порт его 
имеет какой mac за ним. поэтому у него нет такой штуки которая есть у реально
ого физ свича  - физ свич если получает фрейм dst mac которого он видит 
впревые то физ свич бросает этот фрейм во все свои порты. всвич такого неделает если он получает фрейм мак адрес котрого незрнает он его никуда 
небросает. поэтому если мы хотим чтобы наши фреймы которые имеют относятся
к кластер IP доходили надо виртуалку н акотлрой кипэлайв выносить на всвич
в отдельную группу портов и наэтой группе портов включить режим промискус
это дает то что все виртулаки которые входят в эту группу портов будут 
получать весь l2 трафик который влетает во весь vseiwtch. 
пришла в голову такая мысль - если вспомнит реальный физ свич то ведь там 
по идее на первый взгляд свич должен выучить кластер мак. но этого не происходит. как там раотает . клиент шлеь arp запрос каклой мак у
кластер IP. комп котрый держит кластер айпи в ответ кидает arp ответ.
и щас я покажу как он выглядит. потому что он хитрый.

пусть у нас 
клиент мак=мак-клиент
клиент ip = ip-клиент
кластер мак = мак-кластер
кластер ip=ip-кластер
сервер ip=сервер-ip
сервер-мак=сервер-мак

если бы сервер кидал в ответ как обычный arp ответ то было бы

[L2 src mac=кластер-мак dstmac= [ARP src mac= кластер мак dst mac= src ip= кластер ip dst ip=]   

  но он кидает совсем другое
  
[L2 src mac=сервер-мак dstmac= [ARP src mac=кластер-мак dst mac= src ip= кластер ip dst ip=]   
  
  что при этом получается. сам свич он в arp часть не заглядывает.
  свич анализирвет только L2 часть поэтому свич узнает что из такого то порта
  прилетел фрейм с src mac = сервера. и он заносит в таблицу fdb
  
  порт 13 = сервер-мак
  
  но он незаносит порт 13 = кластер -мак !
  
  комп когда получает фрейм он в L2 несмотрит. он смотрит в arp 
  часть и узнает что  для кластерIp mac = кластер-мак
  
  таким макаром свич никогда неузнает за каким потом сидит кластер -мак
  и будет сдлать фреймы для него во все свои порты. 
  
  как я понял в свич у него нет такого что ага такойто фрейм имеет src mac 
  и прилетел из такогто порта занесука я егов атблицу. сфера
  заранее формирует этутатблицу. процесса обучения нет. 
  
  
  окей клиент отослал фрейм на клстер мак и кластер ip он ултете 
  во все поты физ свича. теперь кипэлайв должен послать ответ .
  как я понимаю кипэлайв шлет ответ в котором
  
  src mac = сервер-мак ( а не клстер-мак)  src ip = кластер-ip
  
  при этом свич опять же неувидит в L2 части никаого кластерного мака.
  
  а для нашего клиентского компа нет никакой проблемы что он послал фрейм 
с dst mac = кластер-мак а получил обратно фрейм с src mac  = сервер-мак.
потому что комутация это не связь а уровне l3 где если был dst ip 
то мы ждем ответ на это от того же src ip.

таким макаром и в ту и другую сторону на уровне l2 кластер-мак никогда 
в свиче не появляется.

итак если мы даже на уровне адвертайз фремов избавились от мульикаста
то на уровне юникаст общения в vrrp все равно есть флудинг.
чтобы от него избавиться надо на свиче протпсать кластерный мак
и порты на которых сидят кипэлайв члены.тогда флудин будет толькн на 2-3
порта где сидят кипэфайв виртуалки.

так вот на всвич такой возможности нет. 
получается что чтобы все было боее менее надо вставить виртуалки с кипэлайв
в пор группу в котроой будети мпнимальной колчиество виртуалок только 
кипэлайв члены и влкючить промискус режим.
в чем минус такой штуки - если на сервере есть много виртуалок других
которые активно сосут трафик то весь этот ненужный трафик будет придетат
на вртуалку с кипэлайвов и засирать ей эфир. промск моде нужен толко
длоя того чтобы на фоне всего говно эфира долетали фреймы у которых
dst mac = кластер-мак
поэтому вывод - если хочешь чтобы виртуалке с кипэжлайв был макс комофортно
по сетиеовму трафику на этом esxi сервере сажай к ней толькь виталки с 
миимальным сетевым траификом.



  ближайий плна - наолхохозить keepalive
  потом красиво расписать то что выше уже описал
  
   кипэфлайв + хапрокси
првиести конфиги
наппистаь пр проблемы

#  apt-get install -y keepalived haproxy ipset
# systemctl enable keepalived haproxy

edit confs

создаем скрипты для кипэлайвдэ
chmod 700 на скрипты
прмиер


# touch keepalived.state.sh; chmod +x keepalived.state.sh; chmod 700 /usr/local/bin/keepalived.state.sh


# systemctl enable keepalived haproxy

в хапрок юзаем такую фишку что указвыаем биндин в виде
 bind *:6443
 
 а не к вирт IP. так как если нода бэкапная то у нее на данный момент
 нет вирт IP и биндинг не поулчится.  а через bind *:6443 сервис во первых 
 стартует и на беэкап ноде и потом коогда полвяистя вирт IP то хапрокси
 и на нем будет слушать!
 

делать на трех нодах.




1. пробелма
SECURITY VIOLATION - scripts are being executed but script_security not enabled

2.
 Unable to load ipset library - libipset.so.3: cannot open shared object file: No such file or director

3. (test_instance): Warning - nopreempt will not work with initial state MASTER

заработало на 2 нодах.
третью помтавлю потом.


теперт ставим куб контроль плейн.


ставим первый контрол плейн
ставим как описано в основном документе

# kubeadm init --pod-network-cidr=10.253.0.0/16 --apiserver-advertise-address=172.16.102.34 --control-plane-endpoint "172.16.102.100:6440" --upload-certs

далее ставим втоорой контрол плейн

для этого надо на первом контрол плейне получить там всяко разно токены

(первый control plane)# kubeadm token generate
(первый control plane)# kubeadm token create <generated-token> --print-join-command --ttl=0

и после это мастер нода выдаст строку вида

>kubeadm join 172.16.102.31:6443 --token s59914.k4ku8hhl6ityqpj2     --discovery-token-ca-cert-hash sha256:485f93d02e587d9286b2c3a439c59fbc7277d7181644f48099a459abeb53e22f

но ее нам недостаточно.
проожаеим получать нужные токены и штуки


на первом контрол плейне на мастере запукаем

(первый control plane)# kubeadm init phase upload-certs --upload-certs
[upload-certs] Using certificate key:
cbec82f4e3eed8f5ac7522cfb4137baf38c1f4c2d2bd4f6b6db27714cd126fd9


вот теперь хосте где мы собираемся установить мастера второго контрол плейна 
запускам вот такую строку

(будущий мастер второго контрол плейна)# kubeadm join 172.16.102.100:6440 --token isinbt.lecpp3t1nenpqlt3     --discovery-token-ca-cert-hash sha256:3b2a317f993d7ebeace52eb0d72de6a489133ac6180765a9e21787f1aa29ddf8 
--control-plane --certificate-key cbec82f4e3eed8f5ac7522cfb4137baf38c1f4c2d2bd4f6b6db27714cd126fd9

итоги дня - устанвил основной контрол плейн и запасной.
на одном мастере стоит кипэлайвдэ+харпокси.
на втором не стоит keepalived ни хапрокси.ю



>>>>>> следующий шаг.
поставить тертйи мастер  в kubeadn --join заюзать флаг --apiserver-advertise-address=172.16.102.34
на всех матсерах поставит keepalived+ha[proxy
прибавить к этому кластеру одну дата ноду
потом начать гасить мастера и проверять что все равбоатет



  