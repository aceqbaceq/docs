| http

все началось с того что меня заебал вопрос на собесах о том
что в чем разница между HTTP/1.1 и HTTP/2

честно говоря - меня неколышет какая там разница. но пришлось
начать читать

значит HTTP формат байтов или протокол он базируется на TCP а тот на IP а тот на Ethernet
плюс ARP

тоесть у нас когда по локалке летит мегапакет то он снаружи имеет формат ETH(ethernet)
внутри него вложен пакет IP, внутри него вложен пакет TCP внутри него вложен пакет в формате HTTP

когда этот мегапакет влетает в комп то с него ядром сдираются пакеты ETH,IP,TCP
и уже в приложение (который процесс который юзер код) через файл дескриптор влетает уже
только HTTP пакет. тоесть юзер код скажем так понятия не имеет что на самом деле по сети 
летит мегапакет в котором и Ethernet и IP и TCP хрени. для процесса (браузер или curl или жинкс)
все выгляди так что у него открыт файл дескриптор в который он пишет байты  в формате HTTP
и принимает читает из этого файл дескриптора байты в формате HTTP а то что потом это в сеть
улетает оказывается в ETH+IP+TCP формате матрешки он (процесс) скажем так почти что понятия 
не имеет.  ну он как бы имеет это понятие опосредованно когда через запросы к ядру просит
создать этот файл дескриптор но не более того. формально процесс просит у ядра создать
IP\TCP коннект к удаленному компу и создать в памяти TCP сокет а как результат создания
этого обьекта ядро возвращает процессу новый файл дескриптор. через который процесс и может
работать с TCP соединением. формально процесс просит у ядра создать в памяти ipv4+TCP сокет
который в народе называется упрощенно TCP сокет. и ядро возвращает файл дескриптор через 
который процесс может пихать байты в этот сокет и читать байты из этого сокета. процесс
пихает байты в этот файл дескриптор. ядро берет эти байты. оборачивает их снаружи в TCP+IP+ETH 
пакет и шлет на удаленный комп. так вот ядру плевать какие байты мы будем пихать в этот 
дескриптор. HTTP клиент или HTTP сервер пихают в этот дескриптор байты в формате HTTP.
но с таким же успехом они могут пихать в этот сокет байты в любом другом формате (протоколе)
который базируется на TCP. это может быть FTP или IGMP итд итд итд итп
получается что за формирование байтов в формате HTTP это обязанность нашего юзер процесса
и пихнуть его в файл дескриптор. а обернуть этот набор байтов в TCP а потом еще сверху в IP
а потом еще сверху в ETH пакеты. еще раз скажу ядру плевать какие байты мы ему передаем 
через дескриптор. ядро любую последовательность байтов которую ему преедал юзер процесс
оберенет сверху (запаккует) в TCP+IP+ETH мегапакет и пихнет в сеть. 
соотвесвтенно за HTTP поток его формирование отвечает исключительно наш юзер процесс
за обертывание его в TCP+IP+ETH отвечает ядро. ядро же пихает этот мегапакет в живую сеть.
юзер процесс в этом не принимает ни хрена никакого участия. сотвсвтенно и обратная хрень - приле
тает из сети в сет карту мегапакет ETH+IP+TCP+HTTP. так вот ядро распакоывает эту матрешку
и вытаскиает из него только HTTP и уже только этот контент и сует в файл дескриптор. и далее
тололько HTTP контент поступает в процесс. тоесть с точки зрения двух процессов между которыми
натянут TCP конект - они друг с другом через дескрипторы обмениваются исключтельно HTTP 
поток байтов. а как и во что они там дальше пакуются в какие форматы и в какие хрени
процессы скажем так не знают и не парятся. это забота ядра. ну как я уже сказал не совсем
так ибо процессы понятие то имеют но никакого участия в этом не принимают. процесс говорит 
ядру - эй ядро. вот я суют в дескиптор HTTP поток доставь его на удаленный комп. как ты
это сделаешь мне похеру. и вот хренась на удаленном компе тот процесс через свой сокет 
считывает этот чистый HTTP поток. 

в этом эббяснении я хотел показать за что отвечает процесс а за что ядро. также хотел 
показать что в целом процесс может передавать любой поток байтов который процессу взбредет
в голову а не только HTTP и этот поток байтов ровно также успешно будет доставлен на удаленный
комп. 

так как ядро между компами натягивает TCP конект то это значит что оба компа могут друг другу
посылать байты. тоесть как два человека разговаривая по телефону могу каждый инициировать реплики.
а не так что один чтото говорит а второй только отвечает. тоесть это значит что каждый комп 
может посылать на другой комп куски байтов. когда захочет. а не так что только один комп
посылает байты а второй на это отвечает а сам не может инициировать свой поток байтов. это не так.
в частности это обозначает что если у нас два процесса работают по HTTP который как мы уже
знаем базируется на TCP\IP то это значит что после того как TCP конект устанолвен то и веб 
сервер может посылать на клиент данные и клиент может посылать на сервер данные потому что 
TCP это позволяет. к чему я это говорю. вот мы браузером (или курл) устанавливает TCP содениение
с веб сервером. далее после создания. мы в дескриптор пихаем HTTP поток, запрос GET 
далее сервер нам отвечает. так вот сервер он после того может спокойно и сам чтото послать 
к клиенту , какойто запрос. а клиент может ответить.  это абсолютно возможно. потому что TCP.
а то что веб сервер обычно только отвечает на HTTP запрос от клиента после установки TCP 
конекта но сам нихрена с клиента не запрашивает - это не вина TCP это вина HTTP потому что 
просто так написали протокол этот.  а TCP это спокойно позволяет.

в целом я эти аспекты описал подробно в файле C+assembly.txt искать через "| INET_ADDRSTRLEN
"  там все супер подбробно расписано как на C между двумя процессами создать TCP коннект
и обменяться мессагами

еще замечу что IP позволяет доставить пакет от одного компа до друогого компа.
а TCP позволяет доставить пакет который долетел до удаленного компа до конкретного
приложения. 

а мы двигаемся дальше.

итак чтобы можно было через HTTP чтото доставить до удаленной машины нужно прежде всего 
открыть TCP коннект до удаленной машины. а уже поверх него совать HTTP трафик.

итак мы открыли тцп конект к удаленной машине. получили от ядра дескриптор. наш процесс
на нашем компе который знает HTTP и удаленный процесс на удаленной машине который тоже знает 
что такое HTTP. мы шлем с нашего процесса через дескриптор кусок байтов в HTTP формате 
на удаленный комп. наш процесс это типа клиент HTTP а удаленный комп это сервер HTTP.
замечу такую вещь что после того как наш процесс который веб клиент соединился с удаленным
компом который веб сервер то с точки зрения тцп конекта нет никакого ни сервера ни клиента.
оба участника конекта после того как тцп конект устанолвен могут послать соседу сообщение. они
могу друг другу слать собощение все время как конект устанолвен. с точки зрения тцп - клиент 
и сервер означает тольлко то кто должен первым делать конект. кто должен инициировать соединение.
тот кто тцп клиент тот и должен инициировать соедиеннеие. а когда соединение устанолвено то 
уже нет никаких ни клиентов ни серверов. все могут слать байты. все. оба участника. поэтмоу 
когда мы достучались до веб сервера то по факту с точки зрения тцп на который опираются
и веб клиент и веб сеурвер могут друг другу слать байты тоесть запросы. а нетолько веб клиент
имеет право слать веб серверу реквесты. другое дело что в самом HTTP протоколе записано что 
только клиент может слать запросы к веб серверу. а веб сервер не может делать запросы к 
клиенту. сам тцп конект на который оба они опираются такого ограничения не накладыает!
окей двигаем дальше.

итак мы создали тцп конект от нашего процесса. и мы сунули в этот конект HTTP запрос.
тоесть байты в формате HTTP
в HTTP версии 1.0 веб сервер кидает нам обратно через свой tcp конект ответ в формате HTTP
и после этого согласно стандарта HTTP 1.0 сервер обязан закрыть tcp конект. тоесть 
процесс который веб серевер должен послать ядру запрос на закрытие тцп конекта. 
а что значит открыть тцп конект или закрыть тцп конект. это значит ядра обоих компов
создают в памяти ядра буферы и переменные которые буудут нужны для оборадботки конкретно
этого конекта. тоесть некоторая работа с памятью ее инициализация. и также происходит
между ядрами обмен стартовыми пакетами. от клиента к серверу летит тцп пакет с установленным
флагом SYN


     клиент -----SYN-----> server


сервер шлет обратно тцп пакет с устанолвенными флагами SYN и ACK и обозначает что
пакет с флагом SYN успешно принят

     server -----SYN, ACK-----> client

клиент шлет обратно пакет тцп с флагом ACK о том что он тоже пакет принял

     клиент -----ACK-----> server


причем эту пересылку этих пакетов делает ядро! юзер процесс об этом не имеет никаокго 
понятия!

получется что иницаилизация тцп конктат состоит в том что ядра обоих машин обениваются
тремя пакетами.и каждоая машина инициализирует кусок памяти ядра под обрабоатку конкртено
этого конекта. српшаиатся а что из этого долльше? я думаб что самое долгое это полеты

этих трех пактов. скажем до гугла пакет летит 60-100мс. это значит что три пакета летят
200-300мс а это дохрена. после этого в памяти ядра отечающей за процесс на коммпе первом будет заисано
что у нас есть "конект" у котрого 

    src_port=56165    dst_port=443

а на втором компе в ядре будет заисано что есть "конект" с параетрами 

    dst_port=56165    src_port=443

и если у нас на комп влетает пакет с такими параметрами. то ядро будет принтмать 
такие пакеты и обрабатывать их. 

если у нас не было пролета этих трех пакетов и правильной иницлизации памяти ядра то 
информации о параметрамх пакетов влетающих в комп у нас нет. и если с другого компа влетит
пакет на порт 443 или 56165 то ядро скажет я знать незнаю какого хрена этот пакетв меня 
влетел и отошьет этот пакет. 
вот что значит установить конект на практике.

теперь что значит если процесс попросить ядро уничтожить тцп конект. это значит что ядро
вычистить память от параметров конекта. в частности 


    src_port=56165    dst_port=443

    dst_port=56165    src_port=443

и также между двумя компами будет серия из трех пакетов


     клиент -----FIN, ACK-----> server
     server -----FIN, ACK-----> client
     клиент -----ACK-----> server

и после этого на обоих компах вся память будет вычищена. вот что значит тцп конект
уничтожается.

заметим то что если один из участнмков хочет удалить у себя параметры конекта то 
он шлет об этом пакеты на ту сторону. и если все хорошо то оба вычищают у себя
параетры конекта. если же один вычистит а второй нет то смысла в этом нет. потому что
если мы шлем на комп пакет о параметраах src_ip dest_ip + src_port +dst_port нет на компе
то ядро такой пакет отвергнет.

так как при разруении конкета шлется 3 пакета то это занимает 200-300мс.
что долго!

также замечу то что протокол тцп таков что когда ядро принимает пакет в рамка конекта то 
оно само (без ведома процесса) шлет обратно пакет подверждающий что ядро получило успешно
пакет. так вот на стадии создания содениения этот закон частично нарушается!
вот мы послали пакет SYN. и нам в ответ шлют подверждение что мы его полчили пакет SYN+ACK
мы потом шлем пакет ACK но вответ уже мы ничего не получаем!

но тут тоже тонкий момент на счет подвержения. а именно если каждый будет слать пакет подтвер
ждения о том что он получен то у нас будет бесконечная серия пакетов подрвеждений. поэтому
это не совсем так. тоесть одна сторона шлет другой пакет а вторая в ответ шлет подрвеждение
о получении. и на этом все заканчивается. а не так что в ответ бы слался пакет подверждения
снова и так до бесконечности. такого нет. и это любопытно. тоесть получется после того
как соединение инициализровано. то у нас есть пакеты с данными а есть пакет с подрвеждением
но без данных так вот правило такое что на каджый полученный пакет с данными шлется обратно
пакет с подверждением. а на пполученный пакет с подверждением обратно пакет с подверждением
не шлется! иначе будет бесконечны круг пакетов.

      процесс1 ------пакет с данными ---> процесс2
      процесс1 <-----пакет с подтвеждением --- процесс2
      все! конец!


а не вот вот так вот 


      процесс1 ------пакет с данными ---> процесс2
      процесс1 <-----пакет с подтвеждением --- процесс2
      процесс1 ------пакет с подтвержением подвеждания ---> процесс2
      процесс1 <-----пакет с подтвеждением --- процесс2
      ...
      ...

такого нет!!!!

в tcpdump тцп пакет с флагом ACK обозначается как точка [.]
что я считаю дебильным. 

вот так выяглядит иницилизация тцп конекта


    127.0.0.1.48404 > 127.0.0.1.3490: Flags [S]     (SYN) 
    127.0.0.1.3490  > 127.0.0.1.48404: Flags [S.]   (SYN ACK)
    127.0.0.1.48404 > 127.0.0.1.3490: Flags [.]     (ACK)


вот так выгядит трафик когда одна сторона другой послала данные

    127.0.0.1.3490  > 127.0.0.1.48404: Flags [P.]
    127.0.0.1.48404 > 127.0.0.1.3490: Flags [.]



[P] это tcp PUSH флаг и он указывает ядру что данные в этом пакете когда они поступили 
в ядро что они  доджны быть переданы
как можно быстрее в приложение в юзер приложение в процесс 

так вот первая строчка это пакет с данными 
а вторая строчка это пустой пакет но с подверждением. 
и больше никаикх пакетов нешлется!


а вот как выгляит трафик когда одна из сторон информирует больше не хочет передачи
данных и вычистит всю память отвечающую за этот конект и дальнейшие приемы передачи
пакетов от второй стороны небудут приниматься тоесть хочет "закрыть конект"

    127.0.0.1.48404 > 127.0.0.1.3490: Flags [F.]
    127.0.0.1.3490  > 127.0.0.1.48404: Flags [F.]
    127.0.0.1.48404 > 127.0.0.1.3490: Flags [.]


еще раз замечу что в процессе "инициализации" конекта и в процессе "закрытия" конекта
нарушается правило об подтвержении получения. ибо число передаваемых пакетов нечетное.
это конечно отстой.  этто сделано так возможно потому что все эти пакеты не несут данных
а являются служебными управляющими поэтому тут правило кто и сколько должен подверждать 
другое. но все равно это оотстой.


так вот теперь когда я показал про то что такое тцп конект. то 
возвращаюсь к тому что согласно HTTP 1.0 после того как веб сервер процесс кинул в
тцп сокет  ответ на запрос от клиента то HTTP 1.0 стандарт приписывал процессу который
выполняет роль веб сервера послать к ОС запрос на закрытие тцп сокета! 
вроде бы за HTTP 1.0 стнадарт отвечает rfc1945  который был выпущен в 1996 году когда 
интернет был на модемах. так вот в те времена это еще было нормально. но в наши времена
такая хрень абсолютно неприемлима. потому что получается при каждом ревквесте к веб серверу
нам нужно заново создавать тцп конект. а это по крайней мере с точки зрения ожидания пока
три хендшейк пакета долетят до цели займет 200-300мс. Если мы сидим на ютубе то нам нет
никакой выгоды при каждом запросе закрыывать тцп конект и потом создавать его заново!
опятб же повторюсь - если одна из сторон закроет тцп конект а именно если веб сервер вычистит
у себя куск памяти отвечающие в ядре за конект а клиент не станет этого делать то при попытке
клиента послать пакеты в рамках этго конекта то ядро компа где сидит веб сервер просто
напросто не примет эти пакеты. потому что с точки зрения ядра где сидит веб сервер никакого
конекта нет. тоест это значит что пакеты прилеатающие являются нелигитимные неожидаемыми
невалдиными и они будут нахрен отброшены. еще раз скажу что значит с точки зрения ядра то 
что "устанолвен конект" это значит что я ядре записано что ожидаются входящие пакеты
с такого то src_IP и такого то src_port ! а если таких данных нет. то пакеты прилетающие
в ядро и имеющие 

    src_IP+src_port 

являются неожидамеыми и дальнейшей обработке не подлежат!

так вот еще раз согласно рфц1945 (1.3  Overall Operation) указано что HTTP базируется на
любом транспортном протоколе (а нетолько TCP) главное чтобы он был надежный ( это значит что
ядро на базе этого транспотртного протокола должно заботится чтобы отправленный HTTP текст
был доставлен на ту сторону 100% и без измеений. тоесть сам HTTP о доставке никак не должен 
забоиттся). и там якобы говотрится о том что когда веб севрер послал ответ то он этот веб 
сервер этот процесс должен послать к ОС запрос чтобы она ОС уничтожила "конект" 
этого надежного траспортного протокола. я привожу абзац из этого рфц

Except for experimental applications, current practice requires that
   the connection be established by the client prior to each request and
   closed by the server after sending the response. Both clients and
   servers should be aware that either party may close the connection
   prematurely, due to user action, automated time-out, or program
   failure, and should handle such closing in a predictable fashion. In
   any case, the closing of the connection by either or both parties
   always terminates the current request, regardless of its status.


я привжу преревод этого предлжения "Except for experimental applications, 
current practice requires that
the connection be established by the client prior to each request and
closed by the server after sending the response." = "За исключением 
экспериментальных приложений, текущая практика требует, 
чтобы соединение устанавливалось клиентом перед каждым запросом 
и закрывалось сервером после отправки ответа."


тут я скажу что мы можем открыть локальный UNIX сокет на компе. в отиличие от пайпа
он разрешает преедачу в оба направления. и через него между клиентом и сервером организовать
передаручу данных по HTTP. правда это пртивочречит этому рфц потому что у нас при передаче
данных не будет использован никакой транспортный протокол при передаче данных. хотя
передача данных будет точно надежная. надежность обеспечить ядро. но тогда нужно чтобы схема
работала так что клиент каким то макаром звонит на сервер. ядро создает между ними
индивидуальнйы сокет временный. через него идет запрос-ответ по HTTP и после этого 
веб сервер просит ядро удалить этот сокет и ядро должно его удалить. при новом реквесте
от клиента между клиентом и сервером ядро должно создавать новый сокет.

в случа когда трасмпортный проткол выбран как TCP то процесс ожидания пока бует создан 
конект а вместе с ним и процессу будет выдан файл дескрпиор это долгий прцесс из за 
того что три пакета хендшейка будут летить 200-300мс в случае когда мы стучим на сайт
в интернете. а это очень долго. и это не имеет нкиакого практического смысла если мы сидим
на одном и томже сайте. зачем нам закрыть тцп конект. нам нужно его использовать 
от начал и до конца как мы сидим на этом сайте и посылать через него неодин реквест а 
все реквесты которые нам нужны от этого веб сервера!

тоест еще раз как работает схема в случае HTTP 1.0 через TCP
клиент просит у ядра создать тцп конект с веб сервером. ядро нашего компа обенивается
тремя хендшейк пкетами с удаленным компом с его ядром. 
наше ядро шлет туда пакет. оттуда ядро шлет нам пакет. и наше ядро шлет на то ядро пакет.
это занимает 200-300мс.
после этого наш процесс получает от нашего ядра ссылку. а на той стороне тоот процесс получает
от того ядра ссылку.
теперь наш процесс сует в эту ссылку байты в формате HTTP текста.  этот текст наше ядро 
пакует в TCP+IP+ETH и сует в сеть. оно летит по интернету. поступает на то ядро. тоядро
распакоывает и сует в тот процесс только HTTP текст. тот юзер процесс его обрабатывает и сует
оюратно в ссылку свой HTTP текст (ответ) и к нам прилетает ответ. при этом тот процесс
посылает запрос к своему ядру чтобы то ядро закрыло тцп конект. между тем ядром и нашим ядром
присходит обмен тремя пакетами. и  оба ядро вычищают все структуры в ядре отвечающие за этот 
конект. а именно в частности параметры src_IP, src_port, dst_ip,dst_port которым должны
обладать пакеты этого конекта. это происходит в ядрах с обоих сторон. и после этого ни та
ни эта сторона не могут посылать друг другу пакеты с параметрами src_IP, src_port, dst_ip,dst_port
при этом ядро как я онимаю уничтожает и ссылку которую он выдавал процессу на кажой стороне.
и если процесс попробует через тот же файл дескриптоп чтото в него записать ядро пошлет
процесс нахер. ядро скаже прцесу что такого файл деескриптора нет в ядре.

таким образом процессу клиенту нужно перед длянового HTTP реквеста просить свое ядро создать 
новый тцп конект заново!

так вот (согласно этой статье https://en.wikipedia.org/wiki/HTTP_persistent_connection#cite_note-1)
уже в HTTP 1.0 начали колхозить. 
начали писать такие веб клиенты и веб севверы которые начали понимать неофицивальную
настройку в http а именно

		Connection: keep-alive


она сообщала веб сереру чтобы он незакрывать тцп конект после того как он отошлет ответ
веб клиенту. сообщала что веб клиент будет через тот же самый тцп конект отсылать хттп новый 
реквест на веб сервер через этот же тцп конект.
повторюсь такого поля нет в официалном http 1.0 стандарте. это люди того времени самого 
колхозили. создвавали веб клиенты и веб серера  которые в обход стандарта добавлялли 
функционал.

итак получается официальный стандарт HTTP 1.0 он заставляет веб сервер просить ос закрывать 
тцп конект после отсылки ответа. соотвесвтенно это заставлят веб клиент при новом реквесте
создавать новый тцп конект на веб сервер.  но люди когда был этот стандарт сами колхозили
создавали кастомные веб клиенты и веб серверы которые бы понимали нестандартную натсроуйку

		Connection: keep-alive

которую веб клиент посылал к веб серверу . и просил веб сервер не закрывать незакрывть тцп
конект после  того как веб сервер отослал ответ. и далее веб клинте для нового реквеста
юзал этот же тцп конект. а веб севрер принимал этот реквест через этот тцп конект.

значит в народе эту неофициальную настройку называли 

	HTTP keep-alive

работала она так. клиент слал на веб сервер в HTTP тексте строку

	Connection: keep-alive

если веб сервер понимал эту фичу то он в ответе тоже добавлял эту строку. если серевер 
или клиент далее уже не хотели использовать эту фичу. то они либо убирали эту строку
из своего http текста. либо всставляли в свой хттп текст другую строку

	Connection: close


даже с этоим неофиициальным расширением мы имеем проблемы - если мы послали запрос чрез тцп
конект то мы потом сидим и ждем ответ. в это время ничего не происходит. если мы хотим
еще запрос отправить в это время то мы не можем в этот конект его пихать. нам нужно 
открыть еще один тцп конект.

если веб клиент делает запрос на веб сервер через тцп конект и просит его незакрывать
тцп конект после ответа то такой конект далее стали называть HTTP persistent conecttion.
тоесть до этого его называли HTTP keep-alive а потом стали называть HTTP persistent connection
на самомо деел это тца конекшн внутри котрого ходят HTTP реквесты.

в HTTP 1.1 решили что теперь веб сервер по дефолту никогда незакрывает тцп конект после 
ответа. тоесть веб сверер теперь всегда ождает что через открытый тцп конект будет лететь
не один хттп реквест а их будет много. веб сервер ожидает что веб клиент будут через один
и тот же тцп конект пихать реквест за реквестом. много штук. поэтому он незакрывает 
тцп конект после ответа.  теперь для этого строку

	Connection: keep-alive

вставлять больше было ненадо.
а тцп конект теперь веб сервер закрывал по таймауту. ели скажем в течение 3с новый хттп
не прилетал то веб сврер закрывал тцп конект.

также написано что какое то время веб серверы http 1.1 по прежнему позвояли чтобы от веб
клиета прилетала в запросе сторчка

	Connection: keep-alive

и видимо фишка была в том что если клиент шлет строку

	Connection: close

то веб севрер понимал что тцп конект можно закрывать. 

также HTTP 1.1 добавл поле 

   Host:

в котоором в запросе указываетс тот домен к котрому мы ломимся на веб серервере. 
это дает возможность нашему веб серверу сидящему на одном IP адресе одноврменно отвечать
для нескольких доменов. тоесть хостить несколько веб сайтов.
вот пример

 $ curl -v -x socks5h://172.16.10.11:2080 -4 http://google.com
 ...
 ...
 Host: google.com

мы видим это поле

как я уже скзаал HTTP persistent connections ( а ля HTTP keep-alive) фича в HTTP 1.1
стала уже официальной фичей. 

в HTTP 1.1 также появилась еще одна супер фича HTTP pipelining. Она дает то что можно 
в тцп конект сунуть сразу несколько реквестов собранных в одну кучку. а потом сидеть и ждать
ответа. в HTTP 1.0 даже с фичей keep-alive было не так. там можно было сунуть в тцп конект
один реквест. а потом сидеть ждать ответ. потом в тот же тца конект сунуть новый реквест.
потом опять ждать ответ.  в HTTP 1.1 все стало лучше. мы можем сразу несколько реквестов
сунуть в тцп конект. и сидеть ждать ответа. описание это фичи читаю тут

		https://en.wikipedia.org/wiki/HTTP_pipelining

написано что веб сервер должен нам прислать ответы ровно в том же пордке в каком ему были
направлены реквесты.
проблема этой фичи в том что -  положим у нас в запросе 4 реквеста. первый нужно долго формировать
а остальные три формировать очено быстро. так вот веб сврер неможет нам отослать три последним
реквеста. он обязан первым отослать именно ответ на первый реквест. поэтому мы сидим и ждем 
когдаже наконец сформируется первый реквест. а остальные три мы тупо неотсылаем хотя они готовы
чисто из за строго порядка в ответе. также я нпонял положим мы направли 4 реквеста в пачке.
положим еще не прилетело ни одного ответа или прилетела часть ответов  - можем ли мы недождаясь
когда все ответы прилетят направти новую пачку. или нужно долждаться когда все ответы прилетят
до последнего?
вот эта вот проблема что у нас реквесты должны вовзрашаться в ответе в том же порядке и получается
что медленный один из реквестов задерживает все остльные за ним стоящие реквесты по анлийски
эта пробелма называтся как Head-of-line blocking


и вот наконец в HTTP 2.0 допилили эту штуку до максимально удобного варианта. мы шлем 
через тцп конект пачку запроов и веб сервер может возвращать ответы в ЛЮБОМ порядке. это макси
мально удобно в практическом плане. кстати HTTP 2.0 также называют HTTP/2
читаю про него тут
	
		https://en.wikipedia.org/wiki/HTTP/2


он пояивлся в 2015 году в  RFC 7540
что забавано HTTP 1.0\1.1 поток байтов это был просто напросто ТЕКСТ в кодировке ASCII
так вот HTTP/2 это уже не текст это уже как они пишут некий бинарный поток. непонятно.
дело в том что байты в кодировке ascii это все теже байты. а байты это все тот же бинарный поток.
бинарный поток это поток из нулей и единиц. поэтому непонятно
фишки HTTP/2

  * сжатие заголовков
  * HTTP pipeline доапгреженный до multiplexing
  * server push

HTTP pipeline доапгреженный до multiplexing - это как раз про то что теперь мы в тцп конект
можем кидать сразу кучу реквестов. и веб севрер может нам возвращать ответы в любом порядке
а нетольк в том в которомы мы накидали реквесты. я не знаю но подрзреваю что по идее можно 
добавлять новые реквесты в этот тцп конект не дожидаясь пока все ответы нам прилетят

server push - эта такая фича что веб севрер может возвращать больше конента чем запросил 
клиент. как бы пытаясь предугадать будущие запросы клиента. чтоб у него сразу были нужные
данные. вот стрница описывающая эту фичу

		https://en.wikipedia.org/wiki/HTTP/2_Server_Push

так вот там написано что в итоге эту фичу выпилили из бразуеров за последение годы.
так как она оказалась хренью.

по поводу фичи мультиплексинг - так как обычно HTTP опирается на TCP. а у этого протокола
все данные разбиваются на пронумеррованные куски. и этот протокол он как я понимаю наверх 
из ядра выдает данные только строго  в порядке нумерации. то это может привести вот к чему.
положим мы направли на веб сервер 5 урлов(1,2,3,4,5) которые мы хотим получить. веб сервер
быстро сформировал четыре урла скажем 2,3,4,5 а первый урл 1 веб серевер все еще формирует.
далее наш веб сервер начинает нам через тцп конект слать нам обратно урлы 2,3,4,5 
ну понятно что через один тцп конект он неможет их послать как то там паралельно. он будет
их слать все равно один за одним. пускай он первым шлет урл2. точнее ответ на урл2.
теперь положим что это картинка. размером 3МБ. протоокол TCP эту картинку за один пакет не
сможет переслать. он скажем разбивает ее на условно 10 сетевых пакетов. пакет1,пакет2,...пакет10.
и ядро сует в сеетвую карту все эти 10 пакетов. они улеели в сеть. сточки зрения веб сврера
процесса это как работает. он условно через функцию 

    write(fd,) 

пишет в файл дескриптор. далее мы вспоминаем что операции ввода вывода могут быть блокирующие
и неблокирующие. пусть у нас операция блокирующая. как  я примерно понимаю то управление
вернется обратно к процессу только тогда когда ядро получит из сети подтвержение с той стороны
что все 10 пакетов успешно дошли. а теперь преставим что в наш бразуер прилетело 9 пакетов.
а один пакет все еще не прилетает например пакет номер 5 никак не может долететь.
 наше ядро шлет тому ядру запрос мол повтори отправку этого 
пакета. и кстати все это время в браузер наше ядро не передает ни один из пакетов ну или может
он преедал содержимое всех пакетов 1-4. и пока пакет 5 не прилетит больше ничего в браузер 
не передается. и получается такая ситуация что у нас нетолько ответ  на данный url наш 
бразуер не получил. но и из за этого я полагаю что ответы на другие урлы тоже не могут быть
получены нашим браузером. потому что если у нас не прилетел тцп пакет номер 5 то ядро 
в процесс все пакеты которые идут число больше 5 передавать не будет. поэтому на уовне HTTP
мы вроде как быстрые урлы от медленных смогли разделить на веб сервере. но из за транспорт
ного протокола TCP если есть недолеты пакетов мы можем получить конкретный затык. что из за
одного нерпилетающего пакета который обслуживает какото урл  - информация по осталным урлам
будет не потупать в браузер.
вот что по этому же поводу тоже самое написано в википедии

Although the design of HTTP/2 effectively addresses 
the HTTP-transaction-level head-of-line blocking problem by allowing multiple 
concurrent HTTP transactions, all those transactions are multiplexed over a 
single TCP connection, meaning that any packet-level head-of-line blocking 
of the TCP stream simultaneously blocks all transactions being accessed via 
that connection. This head-of-line blocking in HTTP/2 is now widely regarded 
as a design flaw, and much of the effort behind QUIC and HTTP/3 has been devoted 
to reduce head-of-line blocking issues.[61]


в этом плане выходм является ипользование UDP вместо TCP. потому что в этом случае ядро те 
пакеты что получает оно их сразу передает юзер приложению. а уже оно само а не ядро проверяет какие
пакеты не долетели и нужно ли их перезапршаитвать. и главное что при этом ничего немешает 
приложению получать все остальные пакеты с бОлшьими номерами.  так вот UDP использует HTTP/3
он же QUIC. UDP нам позвяет в двухсторонне пордке обмениваться байтами между двумя процесами
просто при этом ядро котрое отправило кусок данных в сеть не ждет подтверждения о том что 
посылка дошла от ядра с той стороны. а так тоже самое. также ядро незанимается такой задачей
что если пакеты прилетели в разном порядке чтобы их перегруппироаывать попорядку. пакеты просто
передаются в юзер приложение а уже оно само дожлно этим заниматься.

хотя HTTP/2 не требует шифрования. тоесть шифрование само по себе это некая прозрачная хрень.
и она не входит в требования этого стандарта. но написано что известыне браузеры согласны
работать на HTTP/2 только при использовании шифрования
повтрорюсь что сам стандарт нетреубует шифрования. это просто браузеры самовольничают.


HTTP/3
появился в 2022
он в целом придуман только ради того чтобы избавиться от TCP поскольку TCP это наиболее часто 
используемый протокол у веб серверов для передачи HTTP текста от веб серера до веб клиента
через интернет. прблема с TCP изложена выше. и состоит грубо говоря в том что TCP поток
это поток пронумерованных пакетов. и ядро получает эти пакеты из интернета. они могут прилетать
в разном порядке по времени. какието могут вообще недолететь. так вот ядро собирает эти
пакеты в буфер. переупорядочивает их ровно в строгом порядке их нумерации. и только потом
передает юзер процессу. так вот если у нас не прилетел пакет номер 5 но при этом уже прилетели
пакеты 6-10 итд но ядро будет перезапращивать ту сторону заново отправти нам пакет номер 5.
и пока мы его не получим то пакеты с номерами 6-10 итд не будут переданы юзер процессу.
теперь представим что наша html страница состоит из 20-ти ссылок. и пакет номер 5 это всего
навсего кусочек неболшой кусочек только одного урла. и из за этого кусочка у нас застопорился
процесс закачки всех остальных урлов. что как бы жопа. 

так вот очень хотелось от TCP перейти к использованию UDP. который нас от этой проблемы 
вылечивает. но при этом так как HTTP требует так наываемый надежный траспорт. тоесть
сам HTTP нехочет нив коей мере заниматься проблемой надежной доставки своего текста
до удаленного процесса то наш процесс на компе который сгенерировал HTTP текст он должен
этот текст пихать в сокет который связан с каким либо надежным транспортным протоколом
который будет сам заниматься наежной доставкой нашего HTTTP текста. 
еще раз HTTP стандарт или протокол нам генериурет всего навсего текст формтированный в HTTP 
формате. скажем наш юзер процесс смог сгенерировать такой HTTP текст. теперь намнужно этот 
текст както доставит до удаленного процесса. HTTP об этом никкого понятие не имеет. как это 
сделать. HTTP протокола всего навсего описывает как формтировать текст и конечны продоуктом
этого проктола явялется просто текст в некотором формтированном виде. далее этот текст нужно
дотсавить на удаленный процесс. и надо это сделать надежно. тоетть чтобы текст неизменился.
и чтобы мы точно значли доставлен он или нет. Это все HTTP делать не умеет. это должен сделат
ктот другой.  надежной доставкой любых байтов умеет делать TCP+IP. оба эти проткола вшиты 
в ядро. поэтому наша программа формиурет HTTP текст. потом обращается к ядру. мол создай
тцп конект. потом сует в ядро наш тект. а ядро его доставляет. и нам рапортует что текст 
реально доставлен. и процесс это понимает . и все окей. если же мы выбррыаем использовать
связку UDP+IP  как средство доставки нашего текста до удаленного процесса то нам получается
нужно теперь фнкции которые делал TCP и которых нет в UDP брать на себя брать и реализовывать
в коде юзер процесса.  потому что нам по любому нужно надежно доставит текст до удаленного
процесса а UDP этого недалает. 
спрашивается так мы что возвращаетя обратно к TCP коду только он получается частично теперь
буде реализован в ядре через UDP а остльаян част будет перенесена в юзер спейс? 
ответ да. спрашивается на хера мы это делаем если типа в итоге мы как бы заново переприду
мываем TCP ? только мы тпер его размазали между ядром и юзер процессом. 
фишка в том что мы перепридумываем более гибки и более хитрый TCP таким макаром. 
вот это как будет работать. мы через UDP сокет запросим скажем 15 ссылок к веб серверу.
каждая ссылка в итоге потребует скажем 10 UDP пакетов. веб сервер их нам отсылает.
нам на комп начинают прилетать эти пакеты. в разном порядке. ядро просто получает эти пакеты
и тупо сразу передает их нашему юзер процессу. ядру плевать какие пакет долетели до нас
какие нет. в каком порядке. это все тпер забота нашего юзер процесса. 
а наш юзеро процесс увидит что например 10 пакетов от первой ссылки приелетели целиком. 
и он их соберет в кучку , вытащит из них HTTP контент и отрендерит на экране (потому что наш
юзер процесс это бразуер). скажем из 10 пакетов от второй ссылки у нас часть пакетов не 
прилетела и наш юзер процесс направить пвоторый запрос к веб серверу чтобы он эти пакеты
недостаюие нам заново отослал. и вторая ссылка у нас пока неренедрится в итоге на экране.
зато скажем остальные урлы тоже прилетели целиком все 10 пакетов для каждого урла. 
в итоге у нас хренова часть содрежимого HTML страницы будет отрисована на экране. тоесть
получается если к нам недолетела часть UDP пакетов это неблокирует нам отрисовку тех 
урлов из HTML статраницы от которых все UDP пакеты прилетели. 
поэтому связка или стек из двух протколов QUIC+UDP (где UDP ненадежный траспорт) 
в сумме нам дают такую же надежность как протокол TCP. тоесть  cвязка этих проткоолово в
конечном итоге нам дает функционал надежного протокола несмотрят на то что UDP входя
щий в эту связку протокол ненаежный. и QUIC он более хитромудрый и более гибкий и более
умный в плане HTTP тоесть для него полученный UDP пакеты это не просто пакеты  с асбстрактной
инфомацией а он знает какие пакеты относят к какому запрошшенноу  урлу. поэтому то он и 
более выгоден относиельно TCP. и такак связка QUIC+UDP нам дает функционал надежного транапорта
то поэтому над ними на их базе на их связке можно использовать TLS . потому что TLS он как и 
HTTP трубет только надежный траанспорт. поэтому для HTTP/2 работала связка

HTTP
TLS
TCP

а для HTTP/3 успено рабоатет связка

HTTP
TLS
QUIC
UDP

повторюсь что конечно сам UDP это ненадежный транспорт. но связка QUIC+UDP дает уже 
надежный транспорт. поэтому над ними или на из базе и можно юзать и TSL и HTTP

по факту это раобатет так 
прцоесс генериурет HTTP текст. этот текст этим же процессом шифруется через TLS.
потом эта аракадабра передается в юзер процесе в функции которывае заведуют QUIC
там тоже формруется какотой еще болееновй поток байтов. 
и потом у ядра запариваыте сяоткрыть UDP сокет с удаленной системой. ядро выдывает 
нам файл дескскриптор от UDP .
юзер процесс пихает байтовй поток в файл дескриптор. ядро облекает этот байто поток в UDP+IP+ETHER
пакет и сует в сеть. и он поелетел на удаленный процесс.
если какйото UDP пакет долетел не долетел и прочие хрени за этим наблюдает юзер код который 
обслуживает QUIC. TLS шифрует дешифрует.

я считаю что я более менее сформировал ответ на вопрос чем главным образом в плане
крутизны HTTP/1.x от HTTP/2

!!!надо показать как через курл можно послать сразу неслкько запрсово и получить
в рамках  одного тцп конекта несклоько ответов


ссылки:
https://golang.cafe/blog/how-to-reuse-http-connections-in-go.html
https://golang.cafe/blog/golang-httptrace-example.html
https://developer.mozilla.org/en-US/docs/Web/HTTP/Connection_management_in_HTTP_1.x







