| tcp



 $ sudo ss -4npOi | grep -E "Recv|pid=2128228,fd=46"
Netid State  Recv-Q Send-Q       Local Address:Port    Peer Address:Port   Process 
tcp   ESTAB  0      0              172.16.10.1:35350   172.16.10.11:2080   users:(("firefox"))

cubic   (congestion алгоритм)

wscale:6,7 

rto:203.333 (tcp retransmission в миллисекундах)

rtt:2.619/4.043  (первое это среднее время туда обратно пакет\подтвержд. второе это среднее 
отклонение.  время указано в миллискундах)

ato:40 

mss:1448   (Max Segment Size)

pmtu:1500   (Path MTU value)

rcvmss:1448   
advmss:1448 
cwnd:10 

bytes_sent:993  (сколько байтов было отослано)

bytes_acked:994 

bytes_received:4428  (сколько байтов было получено)

segs_out:17 
segs_in:19 
data_segs_out:10 
data_segs_in:9 

send 44230622bps   (скорость аплоада в битах в секунду)

lastsnd:34364   ( как давно в милисекундах было с момента последний пакет был отослан)

lastrcv:34234   ( как давно в милисекундах было с момента последний пакет был получен)

lastack:34234 

pacing_rate 88444352bps   ( это максимальная скорость отправки пакетов в сеть  , эту скорость
ядро опрееляет из практики путем замера разных параметров)

delivery_rate 83638984bps 
delivered:11 
app_limited busy:39ms 
rcv_space:14480 
rcv_ssthresh:76604 
minrtt:0.239 
snd_wnd:64576 
rcv_wnd:76672                                


----
Отличный вопрос! Параметры **MSS** и **PMTU** имеют важное значение для того, как ядро будет отправлять данные по сети, особенно в контексте TCP-соединения. Давайте разберемся, как эти параметры влияют на размер передаваемых данных.

### 1. **Что такое MSS (Maximum Segment Size)?**
   **MSS** — это максимальный размер сегмента TCP, который может быть отправлен в одном пакете, **без учета заголовков IP и TCP**. Он определяет максимальный размер полезных данных, которые могут быть отправлены в одном TCP-сегменте. MSS обычно устанавливается в 1460 байт, если используется стандартный Ethernet-канал (с MTU 1500 байт), так как TCP и IP заголовки обычно занимают 40 байт (20 байт для TCP и 20 для IP).

   Когда ядро устанавливает соединение, оно договаривается о максимальном размере сегмента, который может быть отправлен. Это значение будет передаваться в параметре **MSS** и будет учитывать максимальный размер данных, которые могут быть отправлены в одном TCP-сегменте.

### 2. **Что такое PMTU (Path Maximum Transmission Unit)?**
   **PMTU** — это максимальный размер пакета, который может быть передан по сети от источника до получателя без фрагментации. В отличие от **MSS**, который ограничивает размер только данных, **PMTU** также включает в себя заголовки, и определяет максимально допустимый размер **всего пакета** (данные + заголовки).

   Например, если максимальный размер пакета в сети (PMTU) равен 1500 байт, то **пакет** не может быть больше этого размера, включая заголовки (IP + TCP). Если значение **MSS** будет равно 1448 байт, то для отправки данных с заголовками (TCP + IP) размер пакета не должен превышать 1500 байт, иначе произойдет фрагментация.

### 3. **Как эти параметры влияют на отправку данных?**
   Теперь, давайте подумаем, как эти параметры влияют на то, как ядро хоста-А отправляет данные на хост-Б.

   - **MSS** определяет максимальный размер полезных данных, которые могут быть отправлены за один раз в одном TCP-сегменте.
   - **PMTU** указывает на максимальный размер пакета, который может пройти по сети без фрагментации.

Предположим, что у нас есть следующее:

- **MSS = 1448 байт** (то есть ядро на хосте-А может отправлять данные размерами до 1448 байт в одном сегменте TCP).
- **PMTU = 1500 байт** (это общий максимальный размер пакета, включая заголовки TCP и IP).

Теперь рассмотрим, что произойдет при передаче данных:

1. **Размер данных в каждом сегменте**: 
   - Ядро хоста-А будет отправлять данные размерами до **MSS** (в данном случае — до 1448 байт).
   - Это значение определяет, сколько данных может быть помещено в одном TCP-сегменте. В случае, если данные превышают 1448 байт, они будут разделены на несколько сегментов.

2. **Как учитывается PMTU?**
   - Если PMTU установлено на 1500 байт, это значит, что каждый пакет может быть **не больше 1500 байт**, включая заголовки IP и TCP.
   - Учитывая стандартные размеры заголовков (IP + TCP = 40 байт), максимальное количество данных, которое можно отправить в одном пакете, будет 1460 байт.
   - Но поскольку **MSS** на хосте-А равен 1448 байт, это ограничение важнее. Хост-А будет отправлять сегменты по 1448 байт данных, чтобы соответствовать **MSS**.

3. **Как работает отправка?**
   - Допустим, хост-А собирается отправить 5000 байт данных:
     - Первые 1448 байт отправляются в одном сегменте.
     - Следующие 1448 байт — в другом сегменте.
     - Остаток (если не делится на 1448) — в последнем сегменте.
   - Таким образом, хост-А будет отправлять данные **порциями по 1448 байт** (MSS), если данные достаточно большие.

4. **Что делает ACK?**
   - Когда хост-Б отправляет **ACK-пакеты**, он может также информировать хост-А о состоянии своего **receive window** (размера окна приема). Это помогает хосту-А адаптировать скорость отправки, чтобы не переполнить буфер на хосте-Б.
   - Если хост-Б подтвердил, что готов принимать еще данные (например, окно 4096 байт), хост-А будет продолжать отправлять данные, но всегда в пределах **MSS** (в нашем случае 1448 байт).

### 4. **Как размер окна (Recv-Q) и MSS/PMTU работают вместе?**
   - **Размер окна (Recv-Q)** на хосте-Б говорит о том, сколько данных он готов принять в данный момент. Это может изменяться во время соединения.
   - **MSS** (на хосте-А) указывает, сколько данных хост-А может отправить в одном TCP-сегменте.
   - **PMTU** (по пути) указывает максимальный размер пакета, который может пройти без фрагментации.
   
Если PMTU меньше MSS (например, из-за ограничений на маршруте), то ядро будет фрагментировать пакеты, что может привести к снижению производительности. Если PMTU больше MSS, то фрагментация не происходит, и ядро может отправлять пакеты, максимально используя **MSS** для эффективной передачи.

### 5. **Пример отправки данных:**

Предположим, что на хосте-А MSS = 1448, и на хосте-Б размер окна (Recv-Q) = 4096 байт.

1. Хост-А отправляет пакет данных размером 5000 байт.
2. Ядро хоста-А разделяет данные на несколько сегментов, каждый размером **не более 1448 байт** (MSS). Эти сегменты передаются по сети в виде TCP-пакетов.
3. Хост-Б подтверждает получение данных с помощью **ACK** и сообщает о размере окна.
4. Хост-А адаптирует свою отправку в зависимости от размера окна и продолжает отправлять данные, соблюдая ограничения **MSS**.

### Заключение:
- **MSS** и **PMTU** ограничивают размер данных, которые могут быть отправлены в одном TCP-сегменте и в одном пакете.
- **MSS** в первую очередь ограничивает размер полезных данных в TCP-сегменте, а **PMTU** ограничивает общий размер пакета, включая заголовки.
- Ядро хоста-А будет использовать **MSS** для деления данных на сегменты и **PMTU** для определения максимального размера пакетов, который можно отправить без фрагментации.
- Скорость передачи зависит от **размера окна** на стороне хоста-Б, который регулируется через **ACK пакеты**.

Таким образом, хост-А будет отправлять данные "порциями", учитывая как **MSS**, так и текущее состояние буфера на хосте-Б, что гарантирует эффективную и надежную передачу данных по сети.
---

4. Пример проверки с ping (Path MTU Discovery):

Ты можешь проверить Path MTU с помощью утилиты ping:

ping -M do -s 1472 <IP-адрес_хоста>

Здесь:

    -M do: Запрещает фрагментацию пакетов.
    -s 1472: Указывает размер полезных данных, оставляя 28 байт для заголовков ICMP и IP. Это эквивалентно пакету размером 1500 байт (типичный MTU для Ethernet).

Если хост не сможет передать пакет без фрагментации, ты получишь сообщение об ошибке.
---
фрагментация идет на уровне IP

IP-заголовок: Флаги и фрагментация

В IP-заголовке есть два поля, которые отвечают за фрагментацию:

    Флаг DF (Don't Fragment): Если этот флаг установлен, то IP-пакет не может быть фрагментирован. Если пакет слишком большой и не может быть передан, то будет отправлено ICMP-сообщение о необходимости фрагментации.

    Флаг MF (More Fragments): Этот флаг используется, если пакет был фрагментирован. Все фрагменты, кроме последнего, устанавливают этот флаг в 1, а последний фрагмент устанавливает его в 0.


если пакет требует фрагменатции то руотер обратно пришет ICMP с месагой - нужна фрагментация.


---
В выводе утилиты `ss` нет явного поля, которое бы напрямую сообщало о том, что на ваш хост прилетел фрагментированный IP пакет. Однако, есть косвенные признаки, которые могут указывать на возможную фрагментацию, а именно:

1. **pmtu (Path MTU)**:  
   Это значение указывает на максимальный размер пакета, который может быть передан по пути от хоста-А к хосту-Б без фрагментации. Если это значение меньше, чем максимальный размер пакета (например, если PMTU меньше MTU канала), это может свидетельствовать о фрагментации пакетов на промежуточных маршрутизаторах.

   - Если `pmtu` отображается как значение меньше, чем стандартное значение MTU (например, 1500 байт), это может означать, что по пути может происходить фрагментация.

2. **Механизм TCP**:
   - TCP не работает напрямую с фрагментацией на уровне IP, но **MSS (Maximum Segment Size)** в комбинации с **pmtu** может косвенно свидетельствовать о возможной фрагментации. Если `mss` и `pmtu` отличаются, это может быть результатом того, что путь между хостами использует фрагментацию для передачи пакетов.

3. **Показатели сыпучести пакетов**:
   - Параметры, такие как **segs_out** (количество отправленных сегментов) и **segs_in** (количество принятых сегментов), могут дать некоторые признаки того, как данные передаются по сети, но они не дают точной информации о том, что IP-пакеты были фрагментированы.

4. **Параметры `rcv_wnd`, `snd_wnd` и другие параметры окна**:
   - Эти параметры показывают размер окна для приёма и отправки данных. Например, если в окне приёма данных есть небольшое пространство, это может косвенно говорить о том, что трафик перегружен и фрагментация могла бы быть полезной. Однако это также не даёт прямого доказательства фрагментации.

### Где искать явное указание на фрагментацию:
Для явной диагностики фрагментации на уровне IP-пакетов, вам нужно использовать другие утилиты, например:

- **tcpdump**: с помощью этой утилиты вы можете перехватывать и анализировать трафик, включая IP-фрагментацию. Используя `tcpdump`, вы можете увидеть флаг **MF (More Fragments)** в заголовке IP, который будет указывать на то, что пакет был фрагментирован.

Пример команды `tcpdump` для поиска фрагментированных пакетов:

```bash
tcpdump -i eth0 'ip[6:2] & 0x1fff != 0'
```

Эта команда фильтрует IP-пакеты и показывает только те, которые являются фрагментами (флаг **MF** установлен).

- **ip -s link**: Также вы можете использовать команду `ip -s link` для диагностики статистики по интерфейсу. Там будет видно, сколько пакетов было фрагментировано.

### Вывод:

В выводе `ss` нет прямого индикатора фрагментации на уровне IP, но значения `pmtu` и `mss` могут дать косвенные признаки. Для точной диагностики фрагментации следует использовать такие инструменты, как `tcpdump`.


---
Размер буфера, который ядро Linux выделяет для TCP-сокета, зависит от нескольких факторов и может быть настроен. Этот буфер используется для хранения данных, которые были получены от сети (входящий буфер) или отправляются в сеть (исходящий буфер). Размер этих буферов определяется настройками ядра и системными параметрами.

### Основные параметры для настройки буферов:

1. **`net.core.rmem_default` и `net.core.rmem_max`** – эти параметры определяют размер по умолчанию и максимальный размер входного (приемного) буфера для сокетов.
   - `rmem_default` — это размер буфера, который будет выделен по умолчанию при создании сокета.
   - `rmem_max` — это максимальный размер буфера, который может быть выделен для сокета.
   
   Пример:
   ```bash
   sysctl net.core.rmem_default
   sysctl net.core.rmem_max
   ```

2. **`net.core.wmem_default` и `net.core.wmem_max`** – эти параметры определяют размер по умолчанию и максимальный размер исходящего (отправляющего) буфера для сокетов.
   - `wmem_default` — это размер буфера по умолчанию для отправки данных.
   - `wmem_max` — это максимальный размер исходящего буфера.

   Пример:
   ```bash
   sysctl net.core.wmem_default
   sysctl net.core.wmem_max
   ```

3. **`tcp_rmem` и `tcp_wmem`** – эти параметры настраивают размеры буферов для TCP-сокетов.
   - `tcp_rmem` определяет минимальный, средний и максимальный размер входящего буфера для TCP-сокетов.
   - `tcp_wmem` задает те же параметры для исходящего буфера.

   Пример:
   ```bash
   sysctl net.ipv4.tcp_rmem
   sysctl net.ipv4.tcp_wmem
   ```

   Формат этих параметров:
   ```
   min default max
   ```
   Например, для TCP-сокета входящий буфер может быть настроен так:
   ```bash
   sysctl net.ipv4.tcp_rmem="4096 87380 4194304"
   ```

   Где:
   - `4096` — минимальный размер буфера.
   - `87380` — размер буфера по умолчанию.
   - `4194304` — максимальный размер буфера.

4. **`tcp_mem`** – параметр для контроля общего объема памяти, который TCP-соединения могут использовать на всей системе.
   - Это трехзначное значение, которое указывает минимальные, средние и максимальные значения памяти для всех TCP-сокетов.
   
   Пример:
   ```bash
   sysctl net.ipv4.tcp_mem
   ```

   Где:
   ```
   min default max
   ```

5. **Размер буфера, выделяемого для конкретного сокета** может быть изменен программно через функции **`setsockopt()`** в приложении. Например, можно изменить размер буфера для входящих или исходящих данных с помощью следующих параметров:
   - **`SO_RCVBUF`** — размер буфера для приемных данных.
   - **`SO_RCVBUF`** — размер буфера для отправляемых данных.

   Пример в C:
   ```c
   int size = 1024 * 1024;  // 1 MB
   setsockopt(socket_fd, SOL_SOCKET, SO_RCVBUF, &size, sizeof(size));
   ```

### Размер буфера по умолчанию
Для большинства систем в Linux, параметры буферов по умолчанию обычно следующие (но могут варьироваться в зависимости от конфигурации и версии ядра):

- **`rmem_default`** — 212992 байта (по умолчанию для приемного буфера).
- **`rmem_max`** — 16777216 байт (16 МБ, максимальный размер буфера для приема).
- **`wmem_default`** — 212992 байта (по умолчанию для отправляющего буфера).
- **`wmem_max`** — 16777216 байт (16 МБ, максимальный размер буфера для отправки).

### Как посмотреть текущие параметры:

Чтобы посмотреть текущие значения параметров буферов для TCP-сокетов, можно использовать команду:

```bash
sysctl net.core.rmem_default
sysctl net.core.rmem_max
sysctl net.ipv4.tcp_rmem
sysctl net.ipv4.tcp_wmem
```

Или можно получить все параметры с помощью команды:

```bash
sysctl -a | grep rmem
```

### Пример настройки:

Если вы хотите изменить размер буфера для TCP-сокетов, вы можете изменить системные параметры через `sysctl`. Например, для увеличения размера приемного буфера:

```bash
sysctl -w net.core.rmem_max=10485760   # Установить максимальный размер буфера 10 МБ
sysctl -w net.ipv4.tcp_rmem="4096 87380 10485760"   # Установить настройки для TCP
```

### Итог:

Размер буфера для TCP-сокета зависит от множества факторов, включая параметры ядра Linux, системные настройки и настройки приложения. В Linux, по умолчанию, размер буфера обычно составляет несколько сотен килобайт или больше, в зависимости от конфигурации. Однако вы можете настроить эти значения с помощью параметров в `sysctl` или программно через API, если хотите использовать больше или меньше памяти для сокетов.
---
Когда буферы приема и отправки сокета заполняются полностью, ядро предпринимает следующие действия в зависимости от того, какой буфер переполнен — для приема или для отправки.

### Буфер приема (SO_RCVBUF):
Если буфер для приема данных (`SO_RCVBUF`) заполняется полностью, ядро выполняет следующие действия:

1. **Для TCP-соединений:**
   - Если на стороне отправителя данные продолжают поступать, но на стороне приемника (вашей программе) нет возможности прочитать данные (например, программа не читает данные из сокета), тогда ядро начнет отбрасывать входящие пакеты.
   - Это происходит потому, что TCP использует механизм управления потоком и защиты от переполнения буфера. Когда буфер приема заполняется, и программа не читает данные, ядро сообщает удаленной стороне (через окно приема в TCP-заголовке), что доступное окно для получения данных уменьшилось или вовсе закрыто.
   - Это может привести к замедлению передачи данных, так как отправитель будет уменьшать скорость отправки или даже приостанавливать ее, ожидая освобождения места в буфере.

2. **Как это влияет на отправителя?**
   - Отправитель получит уведомление о том, что его окно получения данных стало меньше или полностью закрыто. Он замедлит или приостановит отправку новых данных, чтобы избежать переполнения буфера на принимающей стороне.

3. **Что будет происходить с пакетом, если приемный буфер заполнен?**
   - Пакеты могут быть отброшены, если их нельзя принять, и программа не успевает их обработать. Однако, так как TCP — это протокол с гарантией доставки, потерянные данные будут перезапрошены отправителем.

### Буфер отправки (SO_SNDBUF):
Когда буфер отправки (`SO_SNDBUF`) заполняется, то поведение будет следующим:

1. **Для TCP-соединений:**
   - Если буфер отправки полностью заполнен (то есть ядро не может поместить в буфер больше данных, пока не получит подтверждение о доставке хотя бы части отправленных данных), то ядро приостановит отправку данных до тех пор, пока не получит подтверждения от удаленной стороны.
   - Этот процесс известен как **backpressure**. Система не будет отправлять данные, пока не получит подтверждения от получателя, что данные были доставлены и освобождены соответствующие части буфера.

2. **Что происходит, если буфер отправки переполнен?**
   - Когда программа пытается отправить данные, и буфер отправки заполнен, она будет блокироваться (если используется блокирующий сокет) или получать ошибку (если используется неблокирующий режим). В случае блокирующего сокета, программа будет ждать, пока в буфере не освободится место, прежде чем продолжить отправку данных.
   - В случае неблокирующего сокета программа получит ошибку `EAGAIN` или `EWOULDBLOCK` и должна будет повторить попытку позже.

### Важные моменты:
- **Backpressure:** Это важный механизм в TCP, который помогает избежать переполнения буферов и гарантирует корректную доставку данных.
- **Приоритеты:** Ядро будет решать, какие данные пропускать и как реагировать на переполненные буферы в зависимости от настроек, состояния сети и других факторов.
- **Отбрасывание пакетов:** Если буфер приема полностью забит и данные не могут быть прочитаны, пакеты могут быть отброшены, что приведет к необходимости повторной отправки данных.

Таким образом, при переполнении буферов ядро будет пытаться защитить систему от потери данных (в случае отправки) или переполнения (в случае приема), замедляя или приостанавливая процесс передачи данных.
---
Да, ты правильно понял! Если какой-то TCP сегмент, который ты отправил, не был успешно доставлен, то при попытке следующего `write()` или при других операциях с сокетом ядро может вернуть ошибку.

Вот как это работает:

### Когда произойдет ошибка:

1. **Ошибка при записи (write)**: 
    Если TCP стек не может доставить данные, например, из-за проблем с соединением (например, хост-Б сбросил соединение или сеть стала недоступной), то на уровне системы может возникнуть ошибка при вызове `write()` или других операций с сокетом.
    
    - Ошибка может быть, например, `ECONNRESET`, если соединение с хостом-Б было неожиданно разорвано.
    - Ошибка может быть связана с переполнением буфера или с отказом в записи на сокет.
    - Также может быть ошибка `EAGAIN` или `EWOULDBLOCK`, если сокет настроен в неблокирующем режиме, и данные не могут быть записаны, потому что буфер отправки переполнен.

2. **Повторные попытки доставки**:
    - TCP стек в ядре будет продолжать пытаться доставить данные, если оно не получило ACK для отправленных данных.
    - Если проблема с доставкой сохраняется долгое время (например, TCP не может установить соединение или не может доставить сегмент), то это может привести к разрыву соединения, и программа получит ошибку, пытаясь писать в сокет.

### Что нужно сделать для обработки ошибок:

1. **Для неблокирующих сокетов**:
    Если ты используешь неблокирующие сокеты, то возможно получить ошибку `EAGAIN` или `EWOULDBLOCK`, если данные не могут быть отправлены в данный момент (например, из-за переполнения буфера).
   
2. **Для блокирующих сокетов**:
    Если ты используешь блокирующий сокет и при этом возникают проблемы с сетью (например, хост-Б не отвечает или потеряно соединение), то программа может получить ошибку при вызове `write()`. В этом случае процесс не получит данные обратно, пока не произойдет сбой соединения или не возникнут проблемы с сетью.

3. **Использование `getsockopt()` для проверки состояния**:
    Чтобы узнать о возможных ошибках сокета или текущем статусе соединения, ты можешь использовать `getsockopt()` с параметром `SO_ERROR`, чтобы получить информацию о сетевых ошибках на сокете.

### Пример кода:

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <errno.h>

int main() {
    int sockfd;
    struct sockaddr_in server_addr;
    
    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd < 0) {
        perror("Socket creation failed");
        exit(1);
    }

    memset(&server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(8080);
    server_addr.sin_addr.s_addr = INADDR_ANY;

    if (connect(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr)) < 0) {
        perror("Connection failed");
        close(sockfd);
        exit(1);
    }

    char message[] = "Hello, Server!";
    ssize_t bytes_sent = write(sockfd, message, sizeof(message) - 1);
    if (bytes_sent < 0) {
        perror("Write failed");
        close(sockfd);
        exit(1);
    }

    // Если бы ошибка TCP произошла, получаем информацию о сокете
    int error = 0;
    socklen_t len = sizeof(error);
    if (getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &error, &len) < 0) {
        perror("getsockopt failed");
        close(sockfd);
        exit(1);
    }

    if (error != 0) {
        printf("Socket error: %d\n", error);
    } else {
        printf("Data successfully sent\n");
    }

    close(sockfd);
    return 0;
}
```

### Важные моменты:
- Ошибки с отправкой данных могут быть обнаружены только в случае проблем с сетью или разрывом соединения.
- Чтобы контролировать повторные попытки и управление ошибками, можно использовать асинхронные механизмы (например, `select()`, `poll()`, `epoll()`) или обработку ошибок через `getsockopt()`.

Таким образом, да, ты прав — при ошибках или проблемах с доставкой данных ядро может вернуть ошибку на уровне системного вызова, когда ты попробуешь снова записать данные в сокет.
---
Да, это именно то, что я пытался объяснить. Ответ, который ты прочитал на Stack Overflow, очень точно отражает реальность работы с TCP-сокетами. Вот ключевые моменты:

### 1. **`send()` и "bytes sent"**
Когда ты вызываешь `send()` на сокете в неблокирующем режиме (или в блокирующем, если данные есть для отправки), **возвращаемое значение** будет означать, сколько байтов данных **успешно записано** в буфер ядра для отправки. Но это не означает, что данные уже **дошли до получателя**. Ядро просто гарантирует, что данные поступили в его буфер, а не что они были отправлены через сеть или что они были подтверждены получателем.

### 2. **TCP и отправка пакетов**
Как только данные оказываются в буфере ядра, TCP-стек будет пытаться отправить эти данные в сеть. Однако, TCP — это протокол с **гарантией доставки**, и он может повторно передавать данные, если они не были доставлены по какой-то причине (например, потеря пакетов или временные проблемы с сетью). Процесс повторной отправки, как правило, выполняется автоматически и скрыт от приложения.

### 3. **Не 1:1 соответствие между `send()` и TCP пакетами**
Как было правильно замечено, данные, которые ты передаешь в `send()`, могут быть **упакованы** в TCP-пакеты различным образом. Ядро может комбинировать данные из нескольких вызовов `send()` в один TCP-пакет или, наоборот, разделить данные одного вызова на несколько пакетов. Это делает невозможным для приложения точно отслеживать, какой TCP-пакет соответствует какому вызову `send()`.

### 4. **Как узнать, что данные были доставлены?**
Ты действительно не можешь точно узнать, был ли конкретный пакет доставлен, если только не получишь явное подтверждение от принимающей стороны. Это может быть сделано с помощью приложения, которое обменяется информацией о полученных или пропущенных данных.

- **ACK в TCP**: ACK подтверждает, что данные были доставлены на уровень ядра хоста Б, но не сообщает, что данные были переданы приложению на хосте Б. Если важно отслеживать точную доставку данных на уровне приложения, нужно использовать дополнительные механизмы, такие как запросы подтверждений от получателя (например, простые номера последовательностей на уровне приложения или другие механизмы).

### 5. **Обработка с потерями пакетов и повторная отправка**
Если соединение разорвано или пакеты теряются, приложение, используя только стандартный TCP, не будет иметь прямого способа узнать, какие конкретно байты не были доставлены. Ядро может повторно отправить эти данные, но приложение будет об этом знать только через последующие ошибки в `write()`, если такие возникнут. Чтобы контролировать ситуацию с потерей данных на более высоком уровне, можно добавить ручное отслеживание состояния данных, например, с использованием последовательных номеров пакетов в приложении и запросов к получателю о подтверждении.

### 6. **Возможное решение**: 
Если ты хочешь, чтобы приложение точно знало, что именно было доставлено, можно использовать **прикладные протоколы** (например, над TCP), которые позволят:
- Передавать **номера пакетов** или **метки** с данными.
- Использовать механизмы подтверждения на уровне приложения, чтобы получать уверенность, что получатель действительно получил конкретный пакет данных.

### В итоге
**TCP** решает задачи гарантии доставки и управления потоком на уровне сети, но **не предоставляет** удобных механизмов для отслеживания, что конкретно было доставлено на уровень приложения. Для этого приложения часто используют дополнительные техники, такие как собственные протоколы или запросы подтверждений от получателя.

Это сложный компромисс между надежностью и производительностью, и не всегда очевидно, как правильно отслеживать статус доставки данных.
---
ПЕРВОЕ

и также я провео эксеримент через 267.c и 268.c
и я рпроверял что shutdown(SH_RD) не приводит к посылке по сети ничего.
и в тоже время оттуда к нам будут прилетать пакеты успешно и склывадться в буфер.
но мы итать просто не моемжем поэтому они буудут прилетать пока наш буфер не забьется в ноль
я посылал 4к месссаги пока на 268 не закнонился буфер в ядре. и тода я дро  в ответ 
послало  win 0 таким обазом обьяснив что  место в буфере у приемника закончилось
и боольше пока слать нихрена ненадо

01:37:36.206481 IP 127.0.0.1.36516 > 127.0.0.1.5001: Flags [.], ack 127361, win 0, options [nop,nop,TS val 3735891358 ecr 3735891357], length 0
01:37:36.416428 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [.], ack 1, win 512, options [nop,nop,TS val 3735891567 ecr 3735891358], length 0
01:37:36.416470 IP 127.0.0.1.36516 > 127.0.0.1.5001: Flags [.], ack 127361, win 0, options [nop,nop,TS val 3735891568 ecr 3735891357], length 0
01:37:36.843191 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [.], ack 1, win 512, options [nop,nop,TS val 3735891994 ecr 3735891568], length 0
01:37:37.666526 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [.], ack 1, win 512, options [nop,nop,TS val 3735892818 ecr 3735891568], length 0




ВТОРОЕ 
заккончил на том что разбирал tcpdmump
01:36:53.991455 IP 127.0.0.1.36516 > 127.0.0.1.5001: Flags [.], ack 45057, win 546, options [nop,nop,TS val 3735849143 ecr 3735849142], length 0
01:36:55.991774 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [P.], seq 45057:49153, ack 1, win 512, options [nop,nop,TS val 3735851143 ecr 3735849143], length 4096
01:36:55.991807 IP 127.0.0.1.36516 > 127.0.0.1.5001: Flags [.], ack 49153, win 520, options [nop,nop,TS val 3735851143 ecr 3735851143], length 0
01:36:57.992070 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [P.], seq 49153:53249, ack 1, win 512, options [nop,nop,TS val 3735853143 ecr 3735851143], length 4096
01:36:57.992108 IP 127.0.0.1.36516 > 127.0.0.1.5001: Flags [.], ack 53249, win 494, options [nop,nop,TS val 3735853143 ecr 3735853143], length 0
01:36:59.992371 IP 127.0.0.1.5001 > 127.0.0.1.36516: Flags [P.], seq 53249:57345, ack 1, win 512, options [nop,nop,TS val 3735855143 ecr 3735853143], length 4096


а именнно что значит вот это 
seq 45057:49153

и что значит вот это 
win 494

---

про сокеты и netfilter.про их связь
сокет у нас имеет прааметры будуещего пакета. два ип и два порта. 
так вот если пакет исходящий то ядро создает пакет с таакими ип и портами как 
указано в сокете. а потом уже пихает их в нетфильетре где это может преобвазоваться
и только потом улететь в сеть.  но юзер процесс этого уже не занет не счусствует. 
для входящего пакета набортот. он вналач прходит тарнсацрмаицию в нетфильтрер цеопках
а тлокьо потом полуив новые ип и порты попдаеает на какйото сокет и уже в приоежжение

исходящий трафик
====>
(start) приложеие ---> сокет (ip1+port1,ip2+port2)--> ядро, пакет (ip1+port1,ip2+port2) --> netfiler
преобразование в пакет (ip1+port1,ip2+port2) --> сеть  (finish)


входящий трафик
исходящий трафик
<====
(finish)приложеие <--- сокет (ip1+port1,ip2+port2)<-- ядро, пакет (ip1+port1,ip2+port2) <-- netfiler
преобразование в пакет (ip1+port1,ip2+port2) <-- сеть (start)


тоесть я показал связь между прамтрами пакета в свойствах сокета и этими же параметрами 
при проходении пакет внути потрохов нетфильмтер. и этими парамтерами в сети. и этими пармтерами 
внутри юзер приложения.



---

tcp конект это труда одна штука. у нее два конца. 


          ==================================================
   socket1                                                  socket2
          ==================================================


так вот с каждого конца сидит сокет. этот конец этот сокет регулирует что можно 
с этим концом трубы делать. можно ли в конец писать или можно ли из этого конца читать.
на каждом конце могут быть свои настройки. 



                   ==================================================
процесс1 -- socket1                                                  socket2 -- процесс2
                   ==================================================


тоесть процесс обращается к конекту через конец , через сокет. если в сокете запрещена 
запись то с этой стороны процесс не сможет ничего записать. 

итак tcp конект это труба одна штука. но у нее два конца. на кажом конце сидит сокет.
в сокете написано можно ли в трубу с этого конца писать или читать. процесс получает доступ 
к трубе через сокет. если в сокет1 запрещена запись то процесс1 не сможет записат в трубу.
а  в сокете2 запись может быть разрешена. пэтому процесс2 сможет записать в трубу.

управлять настройками в сокете в частности можно через команду shudown() и ее флаги
SHUT_RD, SHUT_WR, SHUT_RDWR

	SHUT_RD  - чтения из сокета запрещена процессу с этой стороны
	SHUT_RD  - запись в сокет запрещена процессу с этой стороны
    SHUT_RDWR - чтение+запись запрещена процессу с этой стороны

так вот эта команда мало того что меняет пермишнс на этом конце , так еще при ее запуске
наше ядро посылает удаленному ядру tcp пакет который меняет настройки на том сокете тоже.

запуск shutdown(SHUT_RD)  меняет настройки на нашем сокете , при этом в сеть никакой пакет 
не посылается. тоесть на той стотороне настройка сокета остается прежняя.
это приводит к тому что :

   на нашей стороне процессу нельзя читать но можно писать
   на удаленной стороне процессу можно читать и писать 
   это приводит к ситуации что нам оттуда будут прилетать новые байты но мы их в процесс
   прочитать не можем
   если до запуска shutdown(RD) на обоих концах было состояние ESTABLISHED, то после запуска
   на нашей стороне будет как ни странно по прежнему состояние ESTABLISHED и на той стороне
   уже логично что тоже будет ESTABLISHED


запуск shutdown(SHUT_RD)  меняет настройки на нашем сокете , при этом в сеть посылается пакет [F]
тоесть на той стотороне настройка сокета остается прежняя.


---
connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr("172.16.10.11")}, 16) = -1 EHOSTUNREACH (No route to host)
ssh: connect to host 172.16.10.11 port 22: No route to host
+++ exited with 255 +++
connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr("172.16.10.11")}, 16) = -1 EHOSTUNREACH (No route to host)
ssh: connect to host 172.16.10.11 port 22: No route to host
+++ exited with 255 +++
connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr("172.16.10.11")}, 16) = -1 EHOSTUNREACH (No route to host)
ssh: connect to host 172.16.10.11 port 22: No route to host
+++ exited with 255 +++
connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr("172.16.10.11")}, 16) = 0
connect(4, {sa_family=AF_UNIX, sun_path="/home/noroot/.ssh/ssh-agent.lenovo.sock"}, 110) = 0
connect(7, {sa_family=AF_UNIX, sun_path="/home/noroot/.ssh/ssh-agent.lenovo.sock"}, 110) = 0



--

| connect 
| EHOSTUNREACH
| ssh 


значит все началось вот с чего - я запустил ssh 


	$ ssh 172.16.10.100

на хост который выключен. я при этом вижу на экране 


	$ ssh 172.16.10.100
	ssh: connect to host 172.16.10.100 port 22: No route to host


я вижу в strace 


	connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr("172.16.10.100")}, 16) = -1 EHOSTUNREACH (No route to host)



и у меня пришел вопрос - а на основе чего каких шагов механизмов ядро приходит к выводу
что   EHOSTUNREACH (No route to host) ?


я обратился к ИИ. далее я пишу суммано то что сказал ии и то что  я нашел из практики.

значит когда ядру надо достучаться до  tcp 172.16.10.100:22  то ядру нужно понять через какой
маршрут это делать. 

---


чтение из файла
	 $ pv < /dev/zero 1>/dev/null
	7,2GiB 0:00:03 [7,11GiB/s]                              

скорость преедачит через пайп
	 $ pv < /dev/zero | cat 1>/dev/null
	46GiB 0:00:02 [1,77GiB/s]                              


скорость предачи через named unix local socket
	$ nc -l -U /home/noroot/temp/nc/un6 1>/dev/null
	$ pv < /dev/zero | nc  -U /home/noroot/temp/nc/un6 
	65GiB 0:00:03 [1,25GiB/s]                              


скорость предачи через UDP конект
  $ nc -u -l 127.0.0.1 5010  1>/dev/null
  $ pv < /dev/zero | nc  -u 127.0.0.1 5010
57GiB 0:00:07 [ 966MiB/s] 


скорость предачи через TCP конект
 $ nc -t -l 127.0.0.1 5010  1>/dev/null
 $ pv < /dev/zero | nc  -t 127.0.0.1 5010
9GiB 0:00:09 [ 478MiB/s] 


в тцп конекте ядру нужно нетлоько отправлять пакеты как это есть у UDP
но еще нужно после отправки ждать ответного пакета уже потом только отправлять
следущий пакет. плюс надо траить цпу мощности нетолько на сборку пакетов туда но 
и на обработку подтрвеждающего пакета прилтевшего обратно.
незнаю что бльше влияет на уменьшение скорости - то что мы неможем отправлять
очередной пакет туда пока не получим ответ обратно. или то что нужно процессить
обратные пакеты. но факт есть факт. тцп работает в 2 раза медленее чем udp   в этом
опыте

--

| traceroute
| tracepath

рассмотрим эти проги.
во превых tracepath это более простецкйи вариант от traceroute 

далее для начала посмотрим покажу как выглядит сетевой дамп для icmp потока


	$ sudo tcpdump -i eth0 -n -v    'icmp'

06:54:10.887696 IP (tos 0x0, ttl 64, id 42015, offset 0, flags [DF], proto ICMP (1), length 84)
    159.89.20.99 > 1.1.1.1: ICMP echo request, id 37, seq 1, length 64
06:54:10.890611 IP (tos 0x0, ttl 57, id 35901, offset 0, flags [none], proto ICMP (1), length 84)
    1.1.1.1 > 159.89.20.99: ICMP echo reply, id 37, seq 1, length 64

06:54:11.889011 IP (tos 0x0, ttl 64, id 42258, offset 0, flags [DF], proto ICMP (1), length 84)
    159.89.20.99 > 1.1.1.1: ICMP echo request, id 37, seq 2, length 64
06:54:11.890405 IP (tos 0x0, ttl 57, id 61576, offset 0, flags [none], proto ICMP (1), length 84)
    1.1.1.1 > 159.89.20.99: ICMP echo reply, id 37, seq 2, length 64


значит это 4 пакета. в виде
   запрос
   ответ

   запрос
   ответ


посмтоим на запрос
06:54:10.887696 IP (tos 0x0, ttl 64, id 42015, offset 0, flags [DF], proto ICMP (1), length 84)
    159.89.20.99 > 1.1.1.1: ICMP echo request, id 37, seq 1, length 64


значи то что в скобках это параметра заголвка IP
IP (tos 0x0, ttl 64, id 42015, offset 0, flags [DF], proto ICMP (1), length 84)

tos 0x0 = это задаает качесвто сервиса. в нашем случае обычныое качство. типа срочности нет
ttl 64 = эта такой счетчик когда пакет влетает в мрашрутизатор то тот сразу уменьшает значение
этого поля на 1. и если оно равно 0 то паке уничтожается в ответ шлется спец ICMP пакет 
который имеет вот такое название 

		ICMP time exceeded in-transit

но об этом позже
id 42015 = это порядоковый номер ип пакета
offset 0 = если ип пакет был фргментирован то номер фрагмента. как раз первый фрагмент 
имеет нмоер 0. 
flags [DF] = это флаг чтобы ип пакеты нельзя было фргментирвать 
proto ICMP = это какой протокол вложен внутрь ип пакета

далее вот это это уже инфомрация относииельно протокола котоырй лежит внутри ип пакета
в нашем случае это подрбность icmp пакета

    159.89.20.99 > 1.1.1.1: ICMP echo request, id 37, seq 1, length 64

ICMP echo request = это тип ицмп пакета ибо их много видов. 
id 37 = это вот что. вот у нас есть процесс. и он шлет пинги. так вот 
seq 1 

---
После того как TCP-соединение переходит в состояние CLOSE-WAIT, оно будет существовать в ядре на обоих хостах до тех пор, пока не будет корректно закрыто. Когда на одном из хостов будет вызван close() или отправлен FIN (когда процесс завершит работу с сокетом), соединение перейдет в другие состояния, такие как LAST-ACK или TIME-WAIT, и в конечном итоге будет закрыто. Однако важный момент — в системе могут быть установлены таймауты для этих состояний, и по истечении времени соединение будет автоматически закрыто.
Как долго соединение остается открытым в CLOSE-WAIT?

    CLOSE-WAIT — это состояние, которое в первую очередь зависит от приложения. Это состояние не имеет фиксированного таймаута. Когда одно из приложений (например, на хосте-Б) получает FIN и переходит в CLOSE-WAIT, оно ожидает завершения обработки оставшихся данных и вызова close(). В случае если процесс не завершает свою работу с сокетом, соединение будет оставаться в этом состоянии неопределенно долго.
        Системное время жизни сокета в этом состоянии не ограничено. Это становится проблемой, если процесс не вызывает close(), потому что соединение не будет закрыто автоматически.

Таймауты для других состояний

Для других состояний TCP-соединения, таких как TIME-WAIT и FIN-WAIT, существуют настройки, которые контролируют, сколько времени они будут оставаться активными в ядре.

    TIME-WAIT:

        Когда соединение закрыто с обеих сторон (оба хоста отправили FIN и получили ACK), оно переходит в состояние TIME-WAIT. Это состояние важно для того, чтобы гарантировать, что все сегменты старого соединения были доставлены, а также чтобы предотвратить случайное повторение пакетов, если они прибывают после открытия нового соединения на том же порту.

        Таймаут для TIME-WAIT на стандартных системах обычно составляет 2 минуты (или 4 * MSL — Maximum Segment Lifetime, что эквивалентно 2 минутам по умолчанию).

        Этот таймаут можно настроить с помощью параметра в ядре:

            В Linux, параметр для настройки таймаута TIME-WAIT называется tcp_fin_timeout. Он определяет время, которое система будет ждать в состоянии TIME-WAIT после того, как соединение было закрыто.

            Для того чтобы узнать текущие настройки:

sysctl net.ipv4.tcp_fin_timeout

Чтобы изменить значение:

        sysctl -w net.ipv4.tcp_fin_timeout=<new_value>

        Значение в секундах.

TCP Keepalive:

    В случае если соединение находится в состоянии CLOSE-WAIT (или других "зависших" состояний) и продолжает существовать, даже если приложение не завершило его закрытие, можно настроить параметры TCP-keepalive для обнаружения "мертвых" соединений и их закрытия.

Основные параметры, которые регулируют TCP-keepalive:

    tcp_keepalive_time: время (в секундах) ожидания перед тем, как ядро начнет отправлять пакеты TCP keepalive для проверки состояния соединения.
    tcp_keepalive_intvl: интервал между попытками отправки keepalive пакетов, если предыдущие попытки не дали ответа.
    tcp_keepalive_probes: количество неудачных попыток keepalive, после которых соединение будет считаться мертвым.

Например, чтобы изменить эти параметры в Linux:

    sysctl net.ipv4.tcp_keepalive_time=7200       # время в секундах
    sysctl net.ipv4.tcp_keepalive_intvl=75        # интервал в секундах
    sysctl net.ipv4.tcp_keepalive_probes=9        # количество попыток

    Значения по умолчанию могут быть разными в разных системах, но обычно:
        tcp_keepalive_time по умолчанию — 7200 секунд (2 часа)
        tcp_keepalive_intvl — 75 секунд
        tcp_keepalive_probes — 9 попыток

    Эти параметры позволяют ядру работать с соединениями, которые не активны, и закрывать их, если они не отвечают на keepalive пакеты.

Настройки, связанные с таймаутами:

    tcp_fin_timeout (для состояния TIME-WAIT).
    tcp_keepalive_* (для контроля за состоянием соединений и их автоматическим закрытием, если они не активны).

Заключение

    Соединение в состоянии CLOSE-WAIT останется активным в ядре до тех пор, пока процесс не вызовет close(), что приведет к отправке FIN и завершению соединения. В этом состоянии нет стандартного таймаута в ядре, он зависит от приложения.

    Для состояний TIME-WAIT и других завершенных состояний есть системные таймауты, например, tcp_fin_timeout (по умолчанию 60 секунд в Linux), а также настройки для TCP keepalive для управления соединениями, которые могут оставаться активными долгое время.

Если ваше приложение не закрывает соединения должным образом, соединение может застрять в CLOSE-WAIT.

--
Хороший вопрос, давайте разберемся подробнее!

Когда я сказал, что в состоянии CLOSE-WAIT соединение не может быть использовано для дальнейшей передачи данных, я имел в виду, что в контексте TCP-соединения на уровне ядра дальнейшая передача данных в одном направлении уже невозможна. Однако флаги SHUT_WR и SHUT_RD имеют свойственные им особенности, которые могут влиять на работу соединения и управлять тем, как оно будет себя вести в разных состояниях. Давайте проясним, как они работают.
Что такое SHUT_WR и SHUT_RD?

Эти флаги используются в системных вызовах shutdown(), чтобы контролировать закрытие различных направлений соединения:

    SHUT_WR: Этот флаг используется для того, чтобы завершить передачу данных в выходном направлении (т.е. от приложения к другому хосту). При этом отправляется TCP-сегмент с флагом FIN. После этого приложение на стороне отправителя больше не сможет отправлять данные по этому соединению, но оно всё еще может получать данные (то есть входная сторона остаётся открытой для получения).

    SHUT_RD: Этот флаг используется для того, чтобы завершить приём данных (закрыть входное направление). При вызове shutdown() с флагом SHUT_RD закрывается только возможность чтения, но отправка данных всё ещё возможна. То есть приложение больше не может принимать данные, но оно может продолжать отправлять их по соединению.

    SHUT_RDWR: Это комбинация SHUT_RD и SHUT_WR, которая полностью закрывает как возможность отправки, так и возможность приёма данных.

Что происходит при вызове shutdown() с этими флагами?

    SHUT_WR:
        Когда процесс вызывает shutdown() с флагом SHUT_WR, оно сообщает ядру, что больше не будет отправлять данные по этому соединению, но оно ещё может принимать данные (например, получать ответ от удалённого хоста). Это приводит к тому, что ядро отправляет FIN в сторону другого хоста, тем самым сигнализируя, что передача данных в эту сторону завершена.
        При этом соединение на другой стороне переходит в состояние CLOSE-WAIT (если другой хост получает этот FIN и не закрывает сокет).
        После этого соединение остаётся "полузакрытым" — одна сторона может ещё получать данные, а другая — только отправлять.

    SHUT_RD:
        Когда процесс вызывает shutdown() с флагом SHUT_RD, это сигнализирует, что он больше не будет получать данные по соединению. Однако передавать данные ещё можно.
        В этом случае, на другом хосте соединение остаётся открытым для отправки данных, но если другой хост тоже закрывает свой приём (вызывая shutdown(SHUT_RD)), он отправляет FIN, и соединение переходит в CLOSE-WAIT на вашем хосте.

Что влияет на состояние CLOSE-WAIT?

    CLOSE-WAIT возникает, когда другая сторона (например, хост-А) отправила вам FIN, и теперь ваше приложение должно завершить обработку данных и отправить свой собственный FIN, чтобы закрыть соединение. Пока ваше приложение не вызовет close() или не отправит свой FIN, соединение остаётся в CLOSE-WAIT.

    Если ваше приложение вызовет shutdown(SHUT_WR), оно сигнализирует ядру, что оно больше не будет отправлять данные, но при этом может продолжать получать их. То есть, на уровне TCP-соединения ваше приложение продолжает "видеть" данные, отправленные с другой стороны, но не может больше отправлять данные. Когда ваш процесс завершит обработку полученных данных и вызовет close(), будет отправлен FIN, и соединение перейдёт в состояние TIME-WAIT (или LAST-ACK, если это последний шаг для вашей стороны).

Суммируем:

    В CLOSE-WAIT соединение не может использоваться для дальнейшей передачи данных в выходном направлении (то есть приложение не может отправлять новые данные), но оно всё ещё может получать данные.
    SHUT_WR позволяет завершить только отправку данных. После его вызова процесс может продолжать получать данные, но отправка данных будет невозможна. Если другой хост завершит приём данных, то он отправит вам FIN, и вы окажетесь в CLOSE-WAIT.
    SHUT_RD позволяет завершить только приём данных, но вы всё ещё можете отправлять данные, пока другая сторона не закроет свою сторону приёма данных (вы также можете использовать shutdown(SHUT_RDWR) для полного закрытия обоих направлений).

Таким образом, SHUT_WR и SHUT_RD позволяют управлять направлением закрытия соединения, но CLOSE-WAIT возникает только тогда, когда удалённая сторона отправила FIN, а ваша сторона ещё не завершила закрытие (не отправила свой FIN).

--
Когда в TCP-соединении происходят такие события, как вызов shutdown() и обмен FIN-сегментами, состояние соединения на каждом хосте изменяется в зависимости от того, какие операции выполняются.
1. Хост-Б:

    Процесс-Б вызывает shutdown(3, SHUT_WR), что означает завершение передачи данных в одном направлении — из хоста-Б в хост-А. Этот вызов закрывает только передачу данных от процесса-Б к процессу-А, но не закрывает полностью соединение.

    Ядро-Б отправляет сегмент FIN, чтобы уведомить хост-А о завершении передачи данных в этом направлении.

    После того как хост-А подтвердит получение FIN-сегмента (отправив ACK), соединение на хосте-Б переходит в состояние FIN-WAIT-2.

    В состоянии FIN-WAIT-2 хост-Б еще не может закрыть соединение полностью, потому что он ждет, когда хост-А также завершит передачу данных и отправит свой FIN-сегмент. На этом этапе процесс-Б не может писать данные в соединение, так как передача в сторону хоста-А завершена. Однако процесс-Б может продолжать читать данные, если они приходят от хоста-А.

2. Хост-А:

    Когда хост-Б отправляет FIN-сегмент, ядро-А подтверждает его отправкой ACK. В ответ на это, соединение на хосте-А переходит в состояние CLOSE-WAIT, что означает, что хост-А теперь знает, что хост-Б завершил передачу данных в одном направлении.

    В состоянии CLOSE-WAIT хост-А должен решить, что делать дальше:
        Если процесс-А захочет завершить соединение (т.е. также вызвать shutdown() или close()), хост-А отправит FIN-сегмент в сторону хоста-Б. После этого соединение перейдет в состояние LAST-ACK и далее — CLOSED.
        В то время как соединение в состоянии CLOSE-WAIT, процесс-А может продолжать читать данные, но не может писать в соединение, поскольку его передача была завершена.

Итак, в этих состояниях:

    Процесс-Б не может писать в соединение, но может продолжать читать данные.
    Процесс-А не может писать в соединение, но может продолжать читать данные (пока не завершит процесс завершения соединения).

Таким образом, оба процесса могут читать данные, но не могут писать в соединение, так как они находятся в состоянии, когда передача данных с одной стороны была завершена и ожидается завершение с другой стороны.

--
я проверю хорошо ли я тебя понял. хост-А  процесс-А запускает shutdown(3,SHU_WR) при этом ядро-А шлет FIN и при этом соединение на хосте-А переходит в состояние FIN-WAIT-1 
хост-Б принимает FIN пакет и отправляет в ответ ACK при этом соеднение на хосте-Б переходит в состояние CLOSE-WAIT . хоста-А принимает FIN и переводит состояние в FIN-WAIT-2
верно?
ChatGPT said:
ChatGPT

Да, ты правильно понял! Давай пройдем шаг за шагом:

    Процесс-А на хосте-А вызывает shutdown(3, SHUT_WR):
        Это означает, что процесс-А завершает передачу данных в одном направлении (от А к Б).
        Ядро-А отправляет FIN-сегмент хосту-Б, уведомляя его, что больше данных от хоста-А не будет отправляться.
        После отправки FIN-сегмента соединение на хосте-А переходит в состояние FIN-WAIT-1. Это состояние означает, что хост-А ждет подтверждения (ACK) от хоста-Б.

    Хост-Б принимает FIN-сегмент от хоста-А:
        Хост-Б подтверждает получение FIN-сегмента, отправляя ACK-сегмент обратно на хост-А.
        В это время соединение на хосте-Б переходит в состояние CLOSE-WAIT, так как хост-Б теперь знает, что хост-А завершил передачу данных в одном направлении.

    Хост-А получает ACK от хоста-Б:
        После получения ACK для своего FIN-сегмента хост-А переходит в состояние FIN-WAIT-2. Это состояние означает, что хост-А завершил свою часть обмена сообщениями и теперь ждет, когда хост-Б отправит свой FIN-сегмент, завершив соединение с его стороны.

Итак, итоговый порядок событий:

    Шаг 1: Процесс-А вызывает shutdown(3, SHUT_WR) → хост-А отправляет FIN → состояние хоста-А становится FIN-WAIT-1.
    Шаг 2: Хост-Б принимает FIN и отправляет ACK → состояние хоста-Б становится CLOSE-WAIT.
    Шаг 3: Хост-А получает ACK → состояние хоста-А становится FIN-WAIT-2.

Ты правильно понял, и это абсолютно верный порядок переходов состояний!


--
можешь также аналогично рассказать какие будут состояние у соединения с обоих сторон на стадии устаноления соединения через FIN,FIN+ACK, ACK
ChatGPT said:
ChatGPT

Конечно! Давай рассмотрим установление соединения через обмен сегментами FIN, FIN+ACK и ACK в контексте завершения соединения. Это процесс завершения TCP-соединения (и не установления), но его можно обсудить в аналогии с тройным рукопожатием для установления соединения, чтобы понять, как это происходит с состояниями.
Важное замечание:

Завершение соединения TCP происходит через 4 шага (4-way handshake), а не 3, как при установлении. Установление соединения происходит через SYN и его ответы (SYN-ACK, ACK), а завершение через FIN и его подтверждения.
Сценарий: Завершение соединения с использованием FIN, FIN+ACK, ACK

Предположим, что хост-А и хост-Б имеют активное TCP-соединение, и один из них решает завершить это соединение.
1. Хост-А инициирует завершение соединения:

Процесс на хосте-А вызывает shutdown(3, SHUT_WR), что означает завершение передачи данных в одном направлении (от хоста-А к хосту-Б). Ядро хоста-А отправляет FIN-сегмент хосту-Б.

    Хост-А отправляет FIN, переходя в состояние FIN-WAIT-1.
    Хост-Б на этот момент еще продолжает получать данные от хоста-А, но при получении FIN переходит в состояние CLOSE-WAIT.

2. Хост-Б отвечает на FIN (отправляет FIN+ACK):

Хост-Б, получив FIN, отправляет обратно FIN+ACK — это сигнализирует хосту-А, что хост-Б готов завершить соединение. Хост-Б также уведомляет хост-А, что завершение соединения будет двусторонним.

    Хост-Б переходит в состояние LAST-ACK, поскольку он отправил FIN и ожидает подтверждения от хоста-А.
    Хост-А в это время получает FIN+ACK от хоста-Б и отправляет ACK.

3. Хост-А подтверждает завершение (отправляет ACK):

Хост-А получает FIN+ACK от хоста-Б и отправляет ACK, подтверждая, что он получил этот FIN-сегмент.

    Хост-А переходит в состояние FIN-WAIT-2, ожидая, когда хост-Б закроет соединение.
    Хост-Б после того как получит ACK от хоста-А, переходит в состояние CLOSED, завершив соединение.

Итоговое состояние:

    Хост-А:
        После отправки FIN (шаг 1) — состояние FIN-WAIT-1.
        После получения FIN+ACK (шаг 2) — состояние FIN-WAIT-2.
        После отправки ACK в ответ на FIN+ACK (шаг 3) — состояние CLOSED.

    Хост-Б:
        После получения FIN (шаг 1) — состояние CLOSE-WAIT.
        После отправки FIN+ACK (шаг 2) — состояние LAST-ACK.
        После получения ACK от хоста-А (шаг 3) — состояние CLOSED.

Краткая схема шагов завершения соединения:

    Шаг 1: Хост-А отправляет FIN
        Хост-А переходит в FIN-WAIT-1.
        Хост-Б — CLOSE-WAIT.

    Шаг 2: Хост-Б отправляет FIN+ACK
        Хост-Б переходит в LAST-ACK.
        Хост-А получает FIN+ACK и переходит в FIN-WAIT-2.

    Шаг 3: Хост-А отправляет ACK
        Хост-А переходит в CLOSED.
        Хост-Б, получив ACK, переходит в CLOSED.

Примечание:

Завершение соединения требует 4 этапов (4-way handshake), и на каждом из этапов один хост отправляет сообщения (FIN или ACK), а другой — подтверждает эти сообщения. После того как оба хоста обменялись завершительными сигналами (FIN и ACK), соединение считается закрытым.

Если у тебя есть дополнительные вопросы по этой теме или нужно более подробное объяснение, не стесняйся спросить!
---
так я ошибся. имел ввиду процесс SYN,SYN+ACK,ACK
ChatGPT said:
ChatGPT

Ах, понял! Ты хочешь узнать, как работают состояния соединений SYN, SYN+ACK, и ACK, то есть процесс установления соединения в TCP, который осуществляется через тройное рукопожатие (3-way handshake).
Процесс установления соединения через SYN, SYN+ACK и ACK

Установление TCP-соединения состоит из 3 шагов, которые происходят в результате обмена сегментами SYN (сигнал начала соединения), SYN+ACK (сигнал подтверждения) и ACK (окончательное подтверждение). Вот как это работает:
Шаги установления соединения (3-way handshake):
1. Хост-А инициирует соединение:

    Процесс-А на хосте-А хочет установить соединение с хостом-Б. Он отправляет SYN-сегмент в сторону хоста-Б.

    SYN — это сегмент, который говорит: "Я хочу начать соединение".

    Сегмент SYN содержит начальный номер последовательности (ISN — Initial Sequence Number), который хост-А выбирает случайным образом.

    Хост-А переходит в состояние SYN-SENT, которое означает, что он ожидает ответ от хоста-Б на свою попытку установить соединение.

2. Хост-Б отвечает (SYN+ACK):

    Хост-Б получает SYN-сегмент от хоста-А и, если он готов установить соединение, отправляет в ответ SYN+ACK-сегмент.

    SYN+ACK — это два флага в одном пакете: SYN подтверждает запрос на установление соединения, а ACK подтверждает получение сегмента SYN от хоста-А.

    Хост-Б также выбирает случайный начальный номер последовательности и отправляет его обратно в своем SYN+ACK-сегменте.

    Хост-Б переходит в состояние SYN-RECEIVED, потому что он получил запрос на соединение и теперь ожидает подтверждения от хоста-А.

3. Хост-А подтверждает (ACK):

    Хост-А получает SYN+ACK от хоста-Б и отправляет ACK-сегмент обратно хосту-Б, подтверждая, что он получил SYN+ACK.

    Сегмент ACK подтверждает, что хост-А получил SYN+ACK и подтверждает установление соединения.

    Номер подтверждения в ACK соответствует следующему ожидаемому номеру от хоста-Б.

    Хост-А теперь переходит в состояние ESTABLISHED, потому что соединение установлено и готово к передаче данных.

    Хост-Б также переходит в состояние ESTABLISHED, так как он получил окончательное подтверждение от хоста-А, и соединение установлено.

Таблица состояний на каждом шаге:
Шаг	Хост-А (инициатор)	Хост-Б (приемник)	Описание шагов
1	SYN-SENT	-	Хост-А отправляет SYN.
2	SYN-SENT	SYN-RECEIVED	Хост-Б получает SYN, отправляет SYN+ACK в ответ.
3	ESTABLISHED	ESTABLISHED	Хост-А получает SYN+ACK, отправляет ACK и соединение установлено.
Резюме по состояниям:

    Хост-А (инициатор):
        После отправки SYN он переходит в состояние SYN-SENT.
        После получения SYN+ACK от хоста-Б он отправляет ACK и переходит в состояние ESTABLISHED.

    Хост-Б (приемник):
        После получения SYN от хоста-А он переходит в состояние SYN-RECEIVED и отправляет SYN+ACK.
        После получения ACK от хоста-А он переходит в состояние ESTABLISHED.

Важные моменты:

    SYN — это первый пакет, который инициирует установление соединения. Он содержит начальный номер последовательности (ISN).
    SYN+ACK — это ответный пакет, который подтверждает запрос на соединение и также содержит свой ISN.
    ACK — это подтверждение того, что хост-А получил SYN+ACK и соединение установлено.

Этот процесс гарантирует, что оба хоста готовы к передаче данных и синхронизированы в номерах последовательностей.

Если нужно еще что-то уточнить или есть дополнительные вопросы, не стесняйся спрашивать! :)




---
можешь  рассказать в каком случае для tcp соединения мы получаем TIME-WAIT
ChatGPT said:
ChatGPT

Состояние TIME-WAIT в TCP-соединении — это важный этап в процессе завершения соединения (второй этап 4-стадийного завершения соединения TCP). Оно возникает на стороне инициатора завершения соединения после того, как он отправил последний FIN-пакет, получив от другой стороны ACK на свой FIN. Давайте разберем, что это за состояние, почему оно возникает и какие роли оно выполняет.
Когда возникает состояние TIME-WAIT?

TIME-WAIT возникает на стороне, которая инициирует завершение соединения, после того как она отправила свой последний FIN-пакет и получила ответ от другой стороны (в виде ACK). Это происходит на заключительном этапе процедуры завершения соединения.

Процесс завершения соединения по TCP состоит из четырех стадий:

    Первый FIN: Одна сторона (например, хост-А) отправляет пакет с флагом FIN, чтобы начать процесс завершения соединения. Это говорит другой стороне, что данные больше не будут отправляться.

    Ответный ACK: Получив FIN, другая сторона (например, хост-Б) отправляет ACK, подтверждая получение FIN. Теперь соединение между хостами находится в состоянии CLOSE-WAIT на хосте-А и FIN-WAIT-1 на хосте-Б.

    Второй FIN: Хост-Б отправляет свой собственный FIN-пакет, чтобы закрыть соединение в другом направлении.

    Ответный ACK: Хост-А подтверждает получение FIN от хоста-Б с помощью ACK.

После того как хост-А отправил свой ACK на второй FIN, соединение на его стороне переходит в состояние TIME-WAIT.
Что происходит в состоянии TIME-WAIT?

    TIME-WAIT возникает на стороне инициатора завершения соединения после того, как он получил ACK на свой FIN.

    В этом состоянии соединение будет оставаться в течение определенного времени — обычно 2 * MSL (Maximum Segment Lifetime), где MSL — это максимальное время, которое пакет может оставаться в сети, прежде чем быть уничтоженным (обычно MSL = 2 минуты).

    То есть, соединение будет находиться в состоянии TIME-WAIT обычно 4 минуты (2 минуты для каждого хоста). Это позволяет:
        Убедиться, что все пакеты, которые могли быть потеряны или задержаны в сети, были обработаны.
        Дать возможность любому последнему FIN-пакету (или ACK) быть доставленным, если он был утерян.

Причины состояния TIME-WAIT:

    Поглощение утерянных пакетов: Это состояние необходимо для того, чтобы гарантировать, что все пакеты, связанные с этим соединением, действительно дошли до своей цели. Например, если какой-то пакет FIN или ACK был потерян в сети, его повторная доставка возможна только в этом промежуточном состоянии.

    Предотвращение конфликтов с будущими соединениями: Когда соединение завершается, данные на сокетах больше не используются, но если бы они были немедленно освобождены, могут возникнуть проблемы, если будет установлено новое соединение с тем же адресом и портом. Состояние TIME-WAIT предотвращает такие проблемы. Это позволяет будущим соединениям с тем же локальным и удаленным портом избежать конфликтов с предыдущими соединениями, так как старые пакеты не могут быть приняты за новые.

    Дожидание уничтожения старых пакетов: В течение времени в TIME-WAIT система позволяет старым пакетам (например, утерянным) быть окончательно уничтоженными и не мешать новым соединениям.

Пример завершения соединения с TIME-WAIT:

    Хост-А инициирует завершение соединения, отправляя FIN.
    Хост-Б получает FIN и отправляет ACK. Состояние на хосте-А теперь CLOSE-WAIT, а на хосте-Б — FIN-WAIT-1.
    Хост-Б отправляет свой FIN.
    Хост-А получает FIN и отправляет ACK.
    Хост-А теперь находится в состоянии TIME-WAIT.

На хосте-А состояние TIME-WAIT будет длиться определенное время, чтобы гарантировать, что все пакеты правильно доставлены.
Почему время в TIME-WAIT важно?

    Безопасность передачи: Время в TIME-WAIT важно для того, чтобы любые утерянные пакеты в сети не стали причиной неправильной обработки новых соединений. Например, если старый пакет от предыдущего соединения случайно попадет в новое соединение с тем же адресом и портом, это может вызвать ошибки или неожиданные результаты. TIME-WAIT позволяет старым пакетам исчезнуть из сети и не мешать новым соединениям.

    Реализация в операционных системах: Большинство операционных систем (например, Linux, Windows) реализуют это состояние с целью корректного завершения соединений и предотвращения сетевых конфликтов. Обычно оно длится 2 минуты или 4 минуты в целом.

Пример вывода ss для состояния TIME-WAIT:

Если посмотреть на состояние соединений с помощью утилиты ss, вы увидите соединение в состоянии TIME-WAIT примерно так:

$ ss -t -a
State      Recv-Q Send-Q    Local Address:Port   Peer Address:Port
TIME-WAIT  0      0          192.168.1.100:12345   192.168.1.200:80

Здесь вы видите, что соединение на хосте 192.168.1.100 находится в состоянии TIME-WAIT после завершения соединения с хостом 192.168.1.200 на порту 80.
Заключение:

    TIME-WAIT — это важное состояние в TCP-соединении, которое гарантирует правильное завершение соединения и предотвращает проблемы с повторным использованием старых портов и пакетов.
    Оно возникает на стороне, которая инициирует завершение соединения (отправив FIN).
    Оно сохраняет соединение на некоторое время (обычно 4 минуты), чтобы гарантировать, что все старые пакеты из сети исчезнут, и новые соединения с теми же портами не будут перепутаны с предыдущими.

Если будут дополнительные вопросы или что-то нужно уточнить, всегда рад помочь! 😊

---
мое понимание зачем нужен TIME-WAIT.
предположим что хост-А инциирует конец соединения и шлет FIN.
хост-Б отвечает ACK. далее хост-Б шлет FIN. далее хост-А шлет ACK.
насколько я понимаю когда хост-А отправил ACK то это совсем не значит что этот пакет дейстивтельно долетел до хоста-Б , поэтому   если  такая ситуация возникла а хост-А незнает возникла она или нет то хост-Б повторно направить пакет FIN . поэтому хост-А сидит и ждет прилетит ли пакет FIN повторно или нет.  если он прилетит то хост-А поймет что его ACK не долетел до хоста-Б и повторно отправит ACK а если FIN за 2-4 минуты не прилетит то хост-А его ядро уже тогда полностью  уничтожит соединение.   тоесть мое понимание зачем нужен TIME-WAIT то только из за того что  если хост-А отправил ACK то совершенно не понятно долетел ли он до хоста-Б или нет.   а если хост-Б не получил ACK то он пошлет FIN снова но   хоста-А  к этому моменту закроет это соединение если бы не было состояния TIME-WAIT  и тогда на хосте-Б  соединение будет висеть в состоянии FIN-WAIT-2 что не хорошо.   что скажешь
ChatGPT said:
ChatGPT

Ты абсолютно правильно понимаешь, и твое объяснение довольно точное! Состояние TIME-WAIT действительно служит для того, чтобы гарантировать корректность завершения соединения в условиях возможных потерь пакетов. Давай немного подробнее разберем основные моменты и подтвердим, что ты правильно понял.
Зачем нужен TIME-WAIT?

    Потеря ACK и повторный FIN:
        Когда хост-А отправляет ACK в ответ на FIN, этот пакет может не дойти до хоста-Б из-за сетевых проблем (например, потеря пакета или проблемы на уровне маршрутизации).
        Хост-Б, не получивший ACK от хоста-А, может подумать, что его FIN не было подтверждено, и в итоге решит повторно отправить FIN. Это стандартное поведение для TCP в случае потери пакетов.
        В этом случае, если бы хост-А сразу завершил соединение (например, перешел бы в состояние CLOSED после отправки ACK), хост-Б остался бы в состоянии FIN-WAIT-2 (то есть ожидал бы подтверждения завершения), и это привело бы к "висящему" соединению, что, как ты правильно сказал, было бы не очень хорошей ситуацией.

    TIME-WAIT на хосте-А**:
        После отправки ACK на второй FIN хост-А переходит в состояние TIME-WAIT и ожидает определенное время (обычно 2 * MSL, где MSL — это максимальное время жизни сегмента в сети, обычно 2 минуты).
        Это время дается для того, чтобы убедиться, что старый FIN или ACK из предыдущих состояний (если они потерялись) не "всплывут" и не приведут к неправильному завершению соединения. Если повторный FIN от хоста-Б все же приходит, хост-А сможет повторно отправить ACK.
        В то время, как хост-А находится в TIME-WAIT, он не закрывает соединение полностью и ждет, что может произойти повторная передача FIN (и в случае её повторного получения, отправляет ACK).

Подтверждение твоего понимания:

    TIME-WAIT гарантирует, что хост-А не закроет соединение сразу после отправки ACK, а подождет, чтобы удостовериться, что все пакеты, включая возможный повторно отправленный FIN, смогут дойти до него.
    Если повторный FIN не придет в течение этого времени, хост-А удаляет соединение и завершает процесс.
    Это предотвращает ситуацию, когда хост-Б остается в состоянии FIN-WAIT-2, ожидая завершения от хоста-А, который уже давно "забыл" о соединении.

Процесс завершения соединения:

    Хост-А отправляет FIN и переходит в состояние FIN-WAIT-1.
    Хост-Б отправляет ACK и переходит в CLOSE-WAIT.
    Хост-Б отправляет свой FIN, хост-А получает его, отправляет ACK и переходит в TIME-WAIT.
    Хост-Б в FIN-WAIT-2 ждет ACK на свой FIN.
    Хост-А в TIME-WAIT проверяет, не пришел ли повторно FIN (в случае потери ACK). Если FIN не приходит в течение времени TIME-WAIT, хост-А завершает соединение.

Ключевая роль TIME-WAIT:

    TIME-WAIT важен именно для того, чтобы избежать ситуации, когда хост-Б остается в FIN-WAIT-2, потому что хост-А мог бы уже закрыть соединение, не получив всех пакетов.
    Это состояние позволяет хосту-А проверить, не потерял ли он ACK на второй FIN (если бы оно не дошло до хоста-Б).
    В случае потери ACK хост-А сможет увидеть повторное FIN и снова подтвердить его с помощью нового ACK, предотвращая зависание соединения в состоянии FIN-WAIT-2 на хосте-Б.

Дополнительные моменты:

    Сколько времени длится TIME-WAIT? Это время обычно равно 2 * MSL (Maximum Segment Lifetime), и оно варьируется от 1 до 4 минут в зависимости от операционной системы и её настроек.
    В случае, если система переживает большую нагрузку и большое количество закрытых соединений (например, на сервере), то могут возникать ситуации, когда слишком много соединений остаются в состоянии TIME-WAIT, что может привести к исчерпанию доступных портов. Это одна из причин, почему в некоторых системах существует настройка для уменьшения длительности TIME-WAIT или использования других техник (например, TCP reuse).

Резюме:

    Ты правильно понял, что TIME-WAIT нужно для того, чтобы гарантировать корректное завершение соединений, даже если ACK потерялся в сети.
    Оно важно для того, чтобы предотвратить ситуации, когда хост-Б не получает подтверждения и повторно отправляет FIN, а хост-А уже закрыл соединение, что может привести к "висящему" соединению в FIN-WAIT-2 на хосте-Б.

Твоё объяснение вполне правильное, и ты разобрался в сути состояния TIME-WAIT! Если есть дополнительные вопросы или что-то неясно, не стесняйся уточнять! 😊

---
смысл TIME-WAIT  на хост-А

он нужен только для того чтобы хост-Б  если он не получил ACK от хоста-А 
и поэтому содение на хосте-Б находится в состоянии TIME-WAIt-2 могло отправить 
повтно FIN а мы могили оптравить повторно ACK. все остальыне пкеты будут хостом А 
проионоирваны!

==

| tcp 
| SYN
| RST

SYN он содержит в себе tcp порт. 
когда этот пакет прилетает на удаленнй ядро. то ядро провереяет есть ли процесс
который слушает этот порт. и если его нет то ядро обратно ШЛЕТ RST пакет

пррграмма 272.c


 "   $ cat 272.c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <errno.h>

int main() {
    int sockfd;
    struct sockaddr_in server_addr;

    // Создаем сокет
    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd == -1) {
        perror("Socket creation failed");
        return 1;
    }

    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(45);  // Порт, на котором нет сервиса
    server_addr.sin_addr.s_addr = inet_addr("172.16.10.11");

    // Пытаемся подключиться
    int result = connect(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr));
    if (result == -1) {
        // Ошибка подключения, проверяем errno
        perror("Connect failed");


int sock_error = 0;
socklen_t len = sizeof(sock_error);
if (getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &sock_error, &len) == -1) {
    perror("getsockopt failed");
} else {
    printf("Socket error: %s\n", strerror(sock_error));
}



        // Печатаем ошибку из errno
        switch (errno) {
            case ECONNREFUSED:
                printf("Connection refused (ECONNREFUSED)\n");
                break;
            case ETIMEDOUT:
                printf("Connection timed out (ETIMEDOUT)\n");
                break;
            case EHOSTUNREACH:
                printf("Host unreachable (EHOSTUNREACH)\n");
                break;
            default:
                printf("Other error: %s\n", strerror(errno));
        }
    } else {
        printf("Connected successfully\n");
    }

    sleep(120);
    close(sockfd);
    return 0;
}


значит мы шлем SYN  на 172.16.10.11 на порт 45
в ответ ядро шлет RST 
в ответ на это наше ядро в юзер процесс возвращает ошибку  для connect() = -1
а глобальную прееменную errno ядро записывает более точную причину ошибки. мы 
туда смотрим. 

также мы сюда смотрим	
	getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &sock_error, &len)
провермиьь а внуртри сокета регистриуется какято ошибка на уровне сокета? ответ нет.

что видим на экране
$ ./272.exe
Connect failed: Connection refused
Socket error: Success
Connection refused (ECONNREFUSED)





также я шас покажу нетворк дамп



==
| tcp

основные моменты

CLOSE-WAIT
я начал с того увдоеляет ли яядро процесс от того что приелетел FIN и конект 
пееешел в  ссоятние CLOSE-WAIT? 
отет -не увдоеляет. посто если процес попрует прочитать из сокета то получит 0


send-V, recv-R их смысл. и связка с UDP

TIME-WAIT



---
links

https://serverfault.com/questions/1019447/on-a-tcp-connection-can-the-recipient-control-the-tcp-window-size-that-the-send

https://networkengineering.stackexchange.com/questions/57484/tcp-correlation-between-acks-and-receive-window


https://networkengineering.stackexchange.com/questions/12485/window-size-and-ack-number
https://en.wikipedia.org/wiki/Nagle%27s_algorithm

https://datatracker.ietf.org/doc/html/rfc896

https://stackoverflow.com/questions/22124098/is-there-any-significant-difference-between-tcp-cork-and-tcp-nodelay-in-this-use
https://stackoverflow.com/questions/3761276/when-should-i-use-tcp-nodelay-and-when-tcp-cork

https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/tcp_nodelay_and_small_buffer_writes#TCP_NODELAY_and_small_buffer_writes

https://gist.github.com/nh2/9def4bcf32891a336485

https://adaptivesupport.amd.com/s/article/75077?language=en_US

https://networklessons.com/cisco/ccie-routing-switching-written/tcp-header


https://orhanergun.net/a-guide-to-understanding-the-tcp-psh-header
https://stackoverflow.com/questions/13059323/how-does-tcp-psh-work/13059521#13059521

https://stackoverflow.com/questions/67494127/msg-more-in-send-of-unix-stream-socket-is-not-effective-on-the-peers-recv

https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment

https://datatracker.ietf.org/doc/html/rfc813
https://datatracker.ietf.org/doc/html/rfc2581#ref-Bra89



https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/8/html/optimizing_rhel_8_for_real_time_for_low_latency_operation/assembly_improving-network-latency-using-tcp_nodelay_optimizing-rhel8-for-real-time-for-low-latency-operationhttps://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/8/html/optimizing_rhel_8_for_real_time_for_low_latency_operation/assembly_improving-network-latency-using-tcp_nodelay_optimizing-rhel8-for-real-time-for-low-latency-operation


https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/8/html/optimizing_rhel_8_for_real_time_for_low_latency_operation/assembly_improving-network-latency-using-tcp_nodelay_optimizing-rhel8-for-real-time-for-low-latency-operation

https://stackoverflow.com/questions/3761276/when-should-i-use-tcp-nodelay-and-when-tcp-cork



https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/9/html/understanding_rhel_for_real_time/assembly_socket-options-in-rhel-for-real-time_understanding-rhel-for-real-time-core-concepts

https://news.ycombinator.com/item?id=10607422
https://baus.net/on-tcp_cork/



https://medium.com/@The_Anshuman/what-is-mss-mtu-f4e0f1e0c317

https://www.pynetlabs.com/difference-between-mtu-and-mss/

https://www.cloudflare.com/learning/network-layer/what-is-mtu/

https://en.wikipedia.org/wiki/Maximum_transmission_unit



https://networkengineering.stackexchange.com/questions/17426/why-pptp-l2tp-pppoe-are-in-osi-layer2



https://sturmflut.github.io/linux/ubuntu/2015/01/17/unprivileged-icmp-sockets-on-linux/

https://courses.cs.vt.edu/cs4254/fall04/slides/raw_1.pdf
https://joekuan.wordpress.com/2017/05/30/behaviour-of-identifier-field-in-icmp-ping-as-udp-between-linux-and-osx/
https://joekuan.wordpress.com/2017/05/30/behaviour-of-identifier-field-in-icmp-ping-as-udp-between-linux-and-osx/
https://lwn.net/Articles/422330/
https://raw.githubusercontent.com/JoeKuan/ping_demo/refs/heads/master/ping.c

https://www.rfc-editor.org/rfc/rfc793.txt






---