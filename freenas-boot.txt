
freebsd

==================================================================================
==================================================================================
как перенести его на другой диск

надо работать с нормального полноустановленного фрибсд или фринас.
а не из livecd потому что на livecd может неоказаться нужных файлов.
итак работаем не с livecd а с рабочего фрибсд или фринас.


смотрим какие диски есть 
# camcontrol devlist
<NECVMWar VMware IDE CDR10 1.00>   at scbus1 target 0 lun 0 (pass0,cd0)
<VMware Virtual disk 1.0>          at scbus2 target 0 lun 0 (pass1,da0)
<VMware Virtual disk 1.0>          at scbus2 target 1 lun 0 (pass2,da1)

наш новый диск da1

смотрим что наш диск пустой

# gpart show
=>     9  383743  cd0  MBR  (750M)
       9  383743       - free -  (749M)

=>     9  383743  iso9660/FREENAS  MBR  (750M)
       9  383743                   - free -  (749M)

=>      40  33554352  da0  GPT  (16G)
        40      1024    1  freebsd-boot  (512K)
      1064  33521664    2  freebsd-zfs  (16G)
  33522728     31664       - free -  (15M)

мы вообще невидим da1 в выводе.

здесь  я хочу обьяснить что значит вывод gpart show
на примере

gpart show
=>       34  312581741  ada0  GPT  (149G)
         34          6        - free -  (3.0K)
         40        128     1  freebsd-boot  (64K)
        168  304086904     2  freebsd-ufs  (145G)
  304087072    8388608     3  freebsd-swap  (4.0G)
  312475680     106095        - free -  (52M)


GPT - значит что у нас GPT разметка таблицы разделов(слайсов) диска а не MBR
тут надо сразу сказать то что в линуксе называется partition в bsd называется slice.
а уже внутри слайса можно создавать partitions с точки зрения терминологии bsd.
дальше эти два термина будут постоянно использоваться в одном значении


первый столбик это номер начало раздела в секторах (сектор = 512б)
=>       34  312581741  ada0  GPT  (149G)

здест начало начинается на 34-м секторе.

второй столбик  это длинна раздела в секторах. 312581741.

        168  304086904     2  freebsd-ufs  (145G)
начало раздела с сектора 168
длинна раздела 304086904 секторов

из man gpart видно что

freebsd-boot = тип слайса. это раздел под bootstrap code для freebsd

freebsd-ufs = тип слайса. раздел имеет UFS\UFS2 файл систем.

freebsd-swap = свап слайс



далее создаем таблицу разделов и тип таблицы разделов = GPT

# gpart create -s GPT da1

ключ -s как задает тип таблицы разделов -s GPT

создаем слайс freebsd-boot

# gpart add -b 40 -s 1024 -t freebsd-boot da1

-b 40 = первый сектор слайса
-s 1024 = размер слайса в секторах

-t freebsd-boot = тип слайса


далее делаем несовсем понятно что . но это позволит грузиться с этого диска :
Embed bootstrap code into the partitioning scheme's metadata on the geom	(using -b bootcode)
		   
команда сработает только если мы ее запускаем из установленного фрибсд.
из под загрузочного фринас диска эта команда несработает. потому что там не будет файла /boot/pmbr

Write the bootstrap code from the file /boot/gptzfsboot  into	the geom partition 1 specified by	-i 1.  

# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da1
partcode written to da1p1
bootcode written to da1



bsdlabel ов в современом фринасе вообще нет. походу оно больше ненужно. или ненужно если 
мы в качестве фс будем использовать zfs



root@freenas[~]# gpart list da0
Geom name: da0
modified: false
state: OK
fwheads: 255
fwsectors: 63
last: 33554391
first: 40
entries: 128
scheme: GPT
Providers:
1. Name: da0p1
   Mediasize: 524288 (512K)
   Sectorsize: 512
   Stripesize: 0
   Stripeoffset: 20480
   Mode: r0w0e0
   efimedia: HD(1,GPT,60332aaa-a01f-11ea-9b9b-005056a31a4e,0x28,0x400)
   rawuuid: 60332aaa-a01f-11ea-9b9b-005056a31a4e
   rawtype: 83bd6b9d-7f41-11dc-be0b-001560b84f0f
   label: (null)
   length: 524288
   offset: 20480
   type: freebsd-boot
   index: 1
   end: 1063
   start: 40
2. Name: da0p2
   Mediasize: 17163091968 (16G)
   Sectorsize: 512
   Stripesize: 0
   Stripeoffset: 544768
   Mode: r1w1e1
   efimedia: HD(2,GPT,603ca0f4-a01f-11ea-9b9b-005056a31a4e,0x428,0x1ff8000)
   rawuuid: 603ca0f4-a01f-11ea-9b9b-005056a31a4e
   rawtype: 516e7cba-6ecf-11d6-8ff8-00022d09712b
   label: (null)
   length: 17163091968
   offset: 544768
   type: freebsd-zfs
   index: 2
   end: 33522727
   start: 1064
Consumers:
1. Name: da0
   Mediasize: 17179869184 (16G)
   Sectorsize: 512
   Mode: r1w1e2


rawtype. он строго определен.


freebsd-boot 
это микрораздел без файловой системы. ее там нет.
и там нахоится код для биоса который его читает. и это бывает тока в случае когда диск GPT.
то есть это тип как бутто тот самый MBR который читает биос тока в случае GPT он читает freebsd-boot раздел.

туда помещается вот такая информация

/boot/gptboot  (если на корневом разделе будет UFS)
/boot/gptzfsboot (если корневой раздел будет ZFS)

записывается оно через команды gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da5 либо gpart bootcode -b /boot/pmbr -p /boot/gptboot -i 1 da5

получается к файловой системе уже загруженной системы
этот раздел не виден и не имеет никакого отношения.


создаем раздел с zfs

# gpart add -a 1m -t freebsd-zfs  da1
da1p2 added


root@freenas[~]# gpart show da1
=>      40  41942960  da1  GPT  (20G)
        40      1024    1  freebsd-boot  (512K)
      1064       984       - free -  (492K)
      2048  41938944    2  freebsd-zfs  (20G)
  41940992      2008       - free -  (1.0M)

походу строка с таким значком 

=>      40  41942960  da1  GPT  (20G)

показывает слайс
а внутри него показаны уже партишоны.

команда с ключом -p 

]# gpart show -p da1
=>      40  41942960    da1  GPT  (20G)
        40      1024  da1p1  freebsd-boot  (512K)
      1064       984         - free -  (492K)
      2048  41938944  da1p2  freebsd-zfs  (20G)
  41940992      2008         - free -  (1.0M)



покажет da1p1 и da1p2 для разделов.  (вместо бессмысленных  1 и 2 как раньше)

далее делаем gpt label для zfs раздела

 # gpart modify -i 2 -l freebsd-boot-hotspare da5

 задаем для слайса что размер сектора 4К (чтоб фрибсд это знала)

 # gnop create -S 4096 /dev/gpt/freebsd-boot-hotspare

 
 # mkdir /mnt/1
 # zpool create -f -o altroot=/mnt/1  zroot /dev/gpt/freebsd-boot-hotspare.nop

далее две строчки это манипуляция чтобы подключит пул но чтоб небыло автомонтирования датасетов
нашего пула куда мы будем клонировать наш исходный пул
# zpool export zroot
# zpool import -fo altroot=/mnt/1 -N zroot


# zfs snapshot -r freenas-boot@migrate

# zfs send -R freenas-boot@migrate | pv | zfs receive -F zroot

# zpool set bootfs=zroot/ROOT/default zroot

эта команда выствляет значение опции  bootfs для пула zpool.
в этой опции пула она прописывает к какому датасету 
должен обращаться загрузчик в поисках ядра и прочего.
в данном случае мы выбираем датасет = zroot/ROOT/default
именно данный датасет к нему будет обращаться
загрузчик на фоне всех других датасетов.
это еще раз скажу опция пула недатасета.
в пуле указывается загрузочный датасет.
таких опций у zfs разделов вагон. разделы в zfs зовутся dataset.
(проверить zfs get all zfs-dataset-name )

(про bootfs написано в man gptzfsboot)

втыкаем флэшку.
но загрузиться с нее поканеомжем.
нам надо переименовать наш пул.
потому что питон джанго вэб морда фринас она помнит 
прежнее название пула и будут ошибки.
корче нам над перимновать пул в его исходное название.
на рабочей системе мы немогли так сделать так как нельзя иметь два пула 
с одним именем.

грузимся  с live cd

# zpool import -o altroot=/mnt -f zroot freenas-boot

# zpool export freenas-boot

вот и все мы переименовали пул. перманентно.

теперь можно грузиться с флэшки.
---------------------------------------------------------




]# zfs list
NAME                                                            USED  AVAIL  REFER  MOUNTPOINT
freenas-boot                                                   1.26G  14.7G    88K  none
freenas-boot/.system                                           6.19M  14.7G    96K  legacy
freenas-boot/.system/configs-445a1355f3314ba4946bd845d9821e43    88K  14.7G    88K  legacy
freenas-boot/.system/cores                                      636K  14.7G   580K  legacy
freenas-boot/.system/rrd-445a1355f3314ba4946bd845d9821e43      4.83M  14.7G  4.77M  legacy
freenas-boot/.system/samba4                                     164K  14.7G   100K  legacy
freenas-boot/.system/syslog-445a1355f3314ba4946bd845d9821e43    320K  14.7G   184K  legacy
freenas-boot/.system/webui                                       88K  14.7G    88K  legacy
freenas-boot/ROOT                                              1.25G  14.7G    88K  none
freenas-boot/ROOT/Initial-Install                                  0  14.7G  1.24G  legacy
freenas-boot/ROOT/default                                      1.25G  14.7G  1.24G  legacy



freenas-boot =  имя пула. аналогично  блочному устройству /dev/sda
freenas-boot/ROOT - аналогично разделу /dev/sda1

поэтому все что в строках это считай разделы виртуальные.
именно поэтому они и фигурируют в df 


]# df -h
Filesystem                                                       Size    Used   Avail Capacity  Mounted on
freenas-boot/ROOT/default                                         16G    1.2G     15G     8%    /
devfs                                                            1.0K    1.0K      0B   100%    /dev
tmpfs                                                             16G    9.3M     16G     0%    /etc
tmpfs                                                            2.0G    8.0K    2.0G     0%    /mnt
tmpfs                                                            1.5T     28M    1.5T     0%    /var
fdescfs                                                          1.0K    1.0K      0B   100%    /dev/fd
freenas-boot/.system                                              15G     96K     15G     0%    /var/db/system
freenas-boot/.system/cores                                        15G    580K     15G     0%    /var/db/system/cores
freenas-boot/.system/samba4                                       15G    100K     15G     0%    /var/db/system/samba4
freenas-boot/.system/syslog-445a1355f3314ba4946bd845d9821e43      15G    184K     15G     0%    /var/db/system/syslog-445a1355f3314ba4946bd845d9821e43
freenas-boot/.system/rrd-445a1355f3314ba4946bd845d9821e43         15G    4.8M     15G     0%    /var/db/system/rrd-445a1355f3314ba4946bd845d9821e43
freenas-boot/.system/configs-445a1355f3314ba4946bd845d9821e43     15G     88K     15G     0%    /var/db/system/configs-445a1355f3314ba4946bd845d9821e43
freenas-boot/.system/webui                                        15G     88K     15G     0%    /var/db/system/webui


то есть видно что вместо привычных блоных устройств разделов у нас


 
freenas-boot/ROOT/default монтируется как /

итп.

пул freenas-boot аналогичен  диску sda

все что показывает zfs list оно аналогичено партициям. /dev/sda1 и  их поэтому можно использоват как точки монтирования.



вопрос из за снэпшота неначнети ли место увеличивться.
може его удалить ?


накатил бэкап из конфига.
и после этого чтото у него слетело
и граб тупо входит в бесконечный loop.
попробовал переделать загрузку через zfs загрузчик  - несработало. а жаль.

на полноценном freebsd cd-1-bootonly 330MB есть все файлы в /boot

очень важная настрйка это network - general - DNS сервер.
нужно хотя бы один указать иначе из  за этого у вэб морды крыша едет.
кажое изменнеие вызывает кучу ошибок в консоли. и походу именно изза этого
и накатиить конфи ииз бэкапа вызыало оошибку.

перегнать флэшку черз zfs send zfs receive неполуичлось так как на ней уже она нечитается.
и снэпшот считать нгельщя.

приглось ставить туже версию фринас с нуля. и потом на нее накатывать вэбовский бэкап.


попробвать для тренироваки фринас который на граб - перевести на zfs загрузчик на виртуалке.

geom это какойто слой абстракциию

с zfs и fstab ненужен

da8 geom problem

vlan15 - igb0 - IP,

проверить лог на ошибки чтения usb

описать схему загрузки фрибсд с грабом и с zfs зашгрузчиком.

отписать что нужно чтобы восстановить фринас когда ставим с нуля + накатываем конфиг, а потом сетвые настройки
и днс.

описать что fstab ненужен для zfs

описать еще раз что df -h вид смущает когда у нас zfs


получается пул - это как бы блочное устройство. и zfs позволяет удобно снимать бэкапы 
с этого блочного устройства (пула). со всей его внутренней требухой ( zfs разделами ).



есть zpool import
zpool import -fo altroot=/import -N 15879539137961201777

но этого походу недостаточно чтоли.

чтобы увидеть датасеты нужно еще

# zfs mount zroot


если отключена текстовая консоль то ее можно запустить как

/usr/libexec/getty freenas

разобраться как все же смотреть слайсф  а как партиции 

замечу что никакой раздел ненужно помечать как активный

вопрос когда сняли снэпшот - что потом как будем место разрастаться. а что будет если я удалю 
снэпшот с данными. они потеряются или что.

не совсем понятно что происходит когда мы пересылаем снэпшот с одного пула на другой через
zfs send\receive

датасеты это как бы партиции. и эти партиции можно монтировать в папки.
у партиции в свойствах ( zfs get all имя-датасета ) можно указать точку монтирования и тогда
zfs будет монтировать датасет в эту папку автоматом. 

прежде всего df -h показвыает какой датасет в какой mountpoint подключен.
а zfs list в графе mountpoint показывает в какую папку датасет должен быть по идее по дефолту
системой автоматом примаунчен. то есть zfs list показывает как должно быть а df -h показывает 
как по факту есть

# zfs list
NAME                                USED  AVAIL  REFER  MOUNTPOINT
freenas-boot                        755M  14.6G    64K  none
freenas-boot/ROOT                   748M  14.6G    29K  none
freenas-boot/ROOT/Initial-Install     1K  14.6G   740M  legacy
freenas-boot/ROOT/default           748M  14.6G   740M  legacy
freenas-boot/grub                  6.95M  14.6G  6.95M  legacy
zroot                               975M  16.4G    88K  none
zroot/ROOT                          967M  16.4G    88K  none
zroot/ROOT/Initial-Install             0  16.4G   954M  legacy
zroot/ROOT/default                  967M  16.4G   955M  legacy
zroot/grub                         7.85M  16.4G  7.85M  legacy



так вот в zfs list можно увидеть странные моунтпоинты - none и legacy
если указан lagacy это значит что система zfs автоматом при загрузке данный датасет 
небудет монттроавть никуда.
но можно указать через /etc/fstab куда его монтировать если захотеть.
в общем legacy указывается для тех датасетов которые мы хотим монтировать через файл /etc/fstab


руками можно такой датасет смонтировать вот так

# mount -t zfs zroot/grub /mnt/2


датасет с none также можно примонтировать руками через 
# mount -t zfs zroot/ROOT /mnt/3

насколько я понимаю такие датасеты они не преднахзначаются для монтирования вообще.
то есть технически их можно руками подмонтровать но автоматом самой zfs или через fstab
они не будут монтироваться.


и все же какже изящно все сделано в zfs . сложно но изящно


вот у нас список датасетов с их предплагаемыми точками монтироания

 # zfs list
NAME                                USED  AVAIL  REFER  MOUNTPOINT
freenas-boot                        976M  16.4G    88K  none
freenas-boot/ROOT                   967M  16.4G    88K  none
freenas-boot/ROOT/Initial-Install      0  16.4G   954M  legacy
freenas-boot/ROOT/default           967M  16.4G   955M  legacy
freenas-boot/grub                  7.85M  16.4G  7.85M  legacy

а вот фактическая картина монтирования датасетов в папки.

 # df -h
Filesystem                   Size    Used   Avail Capacity  Mounted on
freenas-boot/ROOT/default     17G    955M     16G     5%    /
devfs                        1.0K    1.0K      0B   100%    /dev
tmpfs                         32M     10M     22M    32%    /etc
tmpfs                        4.0M    8.0K    4.0M     0%    /mnt
tmpfs                        3.0G     35M    3.0G     1%    /var
freenas-boot/grub             16G    7.9M     16G     0%    /boot/grub
fdescfs                      1.0K    1.0K      0B   100%    /dev/fd
tmpfs                        1.0G     39M    985M     4%    /var/db/collectd/rrd

видно что freenas-boot/grub имеет точку монтирования плановую  = legacy
и видно что пофакту он смотнтрован в /boot/grub

значит это сделано через /etc/fstab 
и действительно я там нашел строку его прописыавющую.  я ее оттуда убрал.
так как теперь мы грузимся не через граб а через zfs boot loader

в целом - получилось. взять фринас который себя устанавил так что он грузится через grub
и перенести этот фринас на новый диск и чтобы он грузился через zfs boot loader

надо разобраться с деталями разбиния диска ( начальные сектора и прочее).

]# gpart show -p da1
=>      40  41942960    da1  GPT  (20G)
        40      1024  da1p1  freebsd-boot  (512K)
      1064       984         - free -  (492K)
      2048  41938944  da1p2  freebsd-zfs  (20G)
  41940992      2008         - free -  (1.0M)
  

надо разобраться как делать несколько слайсов а не один.

надо подчеркнуть что bsdlabel нам неважны вообще больше.

надо разораться с этим вот трехступенчатым процессом заггрузки фрибсд

надо разораться установка снэпшота. она как с местом потом отражается оно растет ?
удалние снэжпштоа вдеет к потере даных ?

почему то удаление строки про grub из /etc/ftasb все равно она там появляется.
на ладно. немешает.

в итоге

 # df -h
Filesystem                   Size    Used   Avail Capacity  Mounted on
freenas-boot/ROOT/default     17G    955M     16G     5%    /
devfs                        1.0K    1.0K      0B   100%    /dev
tmpfs                         32M     10M     22M    32%    /etc
tmpfs                        4.0M    8.0K    4.0M     0%    /mnt
tmpfs                        3.0G     25M    3.0G     1%    /var
fdescfs                      1.0K    1.0K      0B   100%    /dev/fd
tmpfs                        1.0G     39M    985M     4%    /var/db/collectd/rrd

если мы отбросим всякие там tmpfs которые вирт фс системы

то остается
# df -h
Filesystem                   Size    Used   Avail Capacity  Mounted on
freenas-boot/ROOT/default     17G    955M     16G     5%    /
freenas-boot/grub             16G    7.9M     16G     0%    /boot/grub


ну граб понятно в /etc/fstab прописан
 а freenas-boot/ROOT/default     монтируется в / потому что в свойствах пула
 указано что bootfs=/freenas-boot/ROOT/default
 
 вот мы и разгадали тайну  что куда и почему монтиирутся в фрибсд из zfs датасетов.
 
 самое прикольно е что я немог понять сначала забыл это то что в df -h вместо привычных устройств типа
 
 /dev/da0p1 ... стоят freenas-boot/ROOT/default
 
 а это же прикол zfs
 
 у которой имена партиций как раз так и выглядят freenas-boot/ROOT/default
 
 еще раз 
 
 диск  в линуксе 			/dev/sda
 диск в freebasd+zfs 		freenas-boot
 
 раздел в линуксе			/dev/sda1
 датасет в freebas+zfs		/freenas-boot/ROOT/default
 
 а я думал что за папки что за папки в именах вместо sda1
 
 по факту получается что в фрибсд перенести 
 систему на другой диск. сделать диск загрузочных в 100раз проще чем в линукс.
 прям прост и приятно это делать.
 
zfs надо собирать на метках а не именах дисков. разобрраться как это делает фринас.


фринас образует пулы на основе gpt меток.
как быстро найти соотвествие какая pgt метка соответует какому диску

смотрим из каких меток составлен пул

root@freenas:~ # zpool list -v
NAME                                     SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
HDDx4                                   9.06T   940G  8.14T         -     8%    10%  1.00x  ONLINE  /mnt
  mirror                                5.44T   588G  4.86T         -     6%    10%
    gptid/117aacf2-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/18342775-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
  mirror                                3.62T   353G  3.28T         -    11%     9%
    gptid/1e932b20-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/1f64f5ac-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
log                                         -      -      -         -      -      -

метки получили.

теперь смотрим какая метка сотвтетует какому диску

 # gpart list | grep -E "Name|1f64f5ac|117aacf2|18342775|1e932b2"
2. Name: da2p2
   rawuuid: 18342775-4aab-11ea-8a35-80c16e650184
2. Name: da3p2
   rawuuid: 117aacf2-4aab-11ea-8a35-80c16e650184
2. Name: da4p2
   rawuuid: 1e932b20-4aab-11ea-8a35-80c16e650184
2. Name: da5p2
   rawuuid: 1f64f5ac-4aab-11ea-8a35-80c16e650184

и видим что это диски da2 da3 da4 da5

ну а теперь можем легко смотреть по ним статистику через 

# gstat

интересно конечно разобраться с загрузкой ОС через uefi bios.
может она круче удобнее чем MBR загрузка

дописать статю красиво.

----------

MBR и GPT

MBR такая разметка диска на разделы.

*!!! надо научиться понимать где лежат куски загрузчика фрибсд и на MBR и на GPT разбивках диска,
уметь их туда записывать. 
уметь записывтаь для разных FS = UFS, ZFS *!!!


в первом секторе (512 байт) его читает биос кладет его в память. и тупо напрямую запускает
исполнение того кода который там есть. причем из 512 байт этот код может занимать
максмум 440 байт.

далее идует 4 байта это идентификатор жесткого диска.

потом типа еще 2 байта вроде как тоже на идентификацию жесткого диска ( это нечень понятно )

далее идет таблица разделов жесктого диска. 
она занимает 64 байта. 
так как на жетском диске может быть только 4 раздела. то получается по 16 байт на один раздел.

итого 510 байт мы уже израсходовали.
и как я понял два байта в конце забиты спец значением AA55h (это 43605).
она как раз занимает два байта.

вот таково строение MBR сектора 512 байт. в котором находится загрузчик (какя понимаю на асемблере),
таблица разделов и признак конца MBR.

все про все 512 байт или 1 сектор.

минус MBR  втом что он может работать только с диском макс 2ТБ размером.
как уже скзаал 440 байт доступно для кода загрузчика.
далее 6 байт может использваться для идентификации номера диска.
но если ОС его неиспользует то размер загрузчика можно увеличить за счет этого до 446 байт.
далее 64 байта на таблицу разделов и 2 байта на спец идентификатор конца MBR

440+6+64+2 = 512 байт

получается что таблица разделов начинается на 446 байте (нумерация с нуля) = hex-1be

64 байта на описание 4 разделов. по 16 байт на 1 раздел.

в этих 16 байтах для одного из разделов указывается 
какой раздел активный то есть это значит что именно с этого раздела
нужно грузиться.
также в этих 16 байтах указан тип раздела.

это интересно. опишу что там скрыто в этих 16 байтах.

диски состоит из блинов. их может быть несколько.
к кажому блину подходит головка.
блин разделен на цилиндры (окружности) и сектора.
получается что адрес сектора это  сторона опредленного блина - то есть номер головки,
номер цилиндра и номер сектора . вот полный адрес сектора на жестком диске. = C\H\S
поэтому в описании партиции указывают первый и последний сектор партиции через C\H\S



один байт - признак что раздел активный
три байта - С\H\S первого сектора раздела 
один байт - код типа раздела
три байта - номер C\H\S последнего сектора раздела 
четрые байта - LBA номер первого сектора раздела
четыре байта - размер раздела в секторах LBA

итого 16 байт.

головки и цилиндры нумеруются с нуля. а сектора с единицы.
под C выделен 10 бит , под H выделен 1 байт. под S выделено 6 бит. 
поскольку под C - цилиндры выделено 10 бит то цилиндры имеют номера 0-1023.
так как под сектора выделено 6 бит значит сектора имеют номера 1-64
так как на головки выделен байт значит головки имеют номера 0-255.

значит максимальный обьем который можно через C\H\S адресовать это = 256*1024*64=8GB

был еше прикол. из за реализации биос. ядро ОС должно было помещаться целиком 
 на нулевой головке не дальше последнего цилиндра нулевой головки.
то есть H=0, C=0-1023, S=0-63. вот тока эти сектора были доступны 
для размещения кода ядра вместе с загрузчиками.
то есть первые 1023 цилиндра.
это не ограничивает первый раздел по размеру. но на этом разделе
код ядра должен лежать на первых 1023 цилиндрах.

первые 0-1023 цилиндра ( по 64 сектора) = 32 768 кб. = 32МБ
 
поэтому получается что выгоно первый раздел делать таким маленьким.
и туда пихаем кернел. и он точно сможет быть загружен.

насколько я понял. далее биосы эту проблему (загрузки ядра далее 1023 цилиндра ) преодолели.
и щас это уже необязательно.
 


в целом. из за этой всей мудоты очень трудно понимать адресацию сектора через C\H\S
и дальше я ее рассмтривать небуду. 
нашел что макс что можно адресовать через CHS это 8 ГБ пространства.

есть факт. что между MBR и началом первого раздела всегда находится минимум 63 сектора.
тоесть 
сектор MBR - 62 сектора (неменьше) - первый сектор первого раздела

насколько я понимаю в этих 62 неиспользуемых секторах (31кб) загрузчик который сидит в MBR 
может использовать тоже под свои нужды для хранения своего кода.


до 8GB в MBR должно быть четкое коректное соответвие между CHS и LBA
адресацией.

когда диск более 8 GB то три  байта  CHS отвечающие за последний сектор раздела устанавливают как
= FF FF FF либо FE FF FF  



рассмотрим MBR на примере (пример будет из линукса)

# dd if=/dev/sda of=/tmp/mbr.txt bs=512 count=1

 я нашел а hex редакторе байт с адресом 1be. это первый байт уже таблицы разделов.
 от нее налево я увидел воттакие 6 байтов
 
 С9 02 9А 55 00 00 
 
 это по идее номер жесктого диска.
 
 а вот что мне написал fdisk
 
# fdisk -l /dev/sda
Disk /dev/sda: 
Disk identifier: 0x559a02c9

как видно номер совпадает. только почему то байты надо читать в обратном порядке.

посмотрим что сидит в 16 байтах таблицы разделов

80 |20  21 00|  |83| FE  FF FF | 00 08  00 00 | 00 F0  7F 02


80 - признак что раздел данный раздел (загрузочный) активный.
20 21 00 - первый сектор раздела (сектор раздела а не сектор MBR) H\S\C 
83 - тип раздела . для 83 это значит Linux раздел.
FE FF FF - последний сектор раздела H/S/C 
00 08  00 00 - LBA номер первого сектора раздела(помним что надо вводить биты наоборот)  = 2048 сектор 
00 F0  7F 02 - размер раздела в LBA секторах (помним что надо вводить биты наоборот) 41 938 944 = 20 478 MB


итак мы выяснили что первый раздел это линукс раздел.
она начинается с 2048 сектора.
он загрузочный
его размер ~ 20 GB

сравним что показывает fdisk


# fdisk -l /dev/sda
Disk /dev/sda:
Device     Boot Start      End  Sectors Size Id Type
/dev/sda1  *     2048 41940991 41938944  20G 83 Linux

все совпадает.


получается кстати что MBR находится в 0 LBA секторе.
потом идет огромная дырка
а первый раздел начинается с 2048 сектора

дырка ~ 2kb между MBR и началом первого раздела.

также получается что мы можем начинать первый раздел откуда угодно.
условно говоря хоть с 10GB от начала диска.

это позволяет легко выравниват раздел относительно физ структуры диска.

загрузчик freebsd который лежит в mbr называется boot0
потому что нулевая стадия загрузки.




пока неочень понял но походу в фрибсд процесс загрузки назыавют bootstraping

стадии загрузки - четыре.

стадиия  0 - запуск загрузичка записанного в MBR = boot0
стадия 1
стадия 2
стадия 3

в MBR  пишет загрузчик утилита 
boot0cfg

( man boot0cfg очень хорошо ее описывает )

и использует файл /boot/boot0

типа вот как выглядит меню от boot0

F1 Win
F2 FreeBSD

Default: F2


проверим.

тут я сразу хочу сказать что boot0cfg 
она с голым диском с магазина работать небудет.
а именно ей надо чтобы диск уже имел коректно оформленную таблицу  слайсов в секторе MBR.
причем более того, мы же указываем с какого слайса надо грузиться. 
так она еще проверят как я понял чтобы тип этого слайса был фрибсдэшный. ( проверяет 
тип загрузочного слайса) и если он ей ненравится она напишет ошибка bad magic number.
как я понял magic number это либо два последних байта в MBR (AA55h)
либо тип слайса с которого мы хотим грузится не фрибсдэшный.

поэтому перед запуском boot0cfg
нам надо разбить диск на слайсы. и уже только потом 
устанавливать MBR загрузчик boot0 через boot-cfg


 простой и быстрый способ это  fdisk
 
 проеряем что диск новый с магазина. смотрим его таблицу слайсов
 
  # fdisk -p da2
fdisk: invalid fdisk partition table found
fdisk: read_s0: No such file or directory


создаем таблицу слайсов MBR.  унас будет один слайс на весь диск

~ # fdisk -I da2
******* Working on device /dev/da2 *******
fdisk: invalid fdisk partition table found

смотрим таблицу слайсов

root@freenas:~ # fdisk -p da2
# /dev/da2
g c1044 h255 s63
p 1 0xa5 63 16771797
a 1

 у нас один слайс. его тип 0xa5 (это тип freebsd) .  первый LBA сектор слайса 63 . размер слайса 16771797 секторов.
 и a =1 то есть загрузочный(активный) слайс =1.
 
 посмотрим тоже самое через GPART (насколько я понял разницу. fdisk предназначен для MBR работ с диском. а
 gpart предназначаен для GPT работ с диском но gpart также может делать и mbr работу с диском).
 
 ~ # gpart show da2
=>      63  16777153  da2  MBR  (8.0G)
        63  16771797    1  freebsd  [active]  (8.0G)
  16771860      5356       - free -  (2.6M)

расшифроывраываю.

=>      63  16777153  da2  MBR  (8.0G)

это инфо о диске. da2.
63 это первый LBA сектор который может быть использован под слайсы.
16777153 последний сектор который может быть использован под слайсы.

так как в 1 секторе лежит MBR. потом 62 сектора которые немогут быть использованы в разделах. 

  63  16771797    1  freebsd  [active]  (8.0G)
  
 это инфо о первом слайсе.
видим тоже самое что в fdisk. тип слайса freebsd, активный, первый сектор слайса 63, размер слайса  16771797 секторов.
кстати удобно что указыают непоследний сектор в размер. потому что иначе пришлось бы постоянно высчитывать 
размер слайса руками.
 
 16771860      5356       - free -  (2.6M)
 
 это инфо про то что в конце диска есть свободное место.
 16771860 - первый сектор свободного места
 5356 - размер свободного места в секторах.
 
теперь когда мы диск разбили на слайсы через MBR можем в MBR писать загрузчик.


# boot0cfg -B  -b /boot/boot0 -s 1 -t 180 da0

-B  устанавливает интерактивный boot0 менеджер. при этом таблица слайсов неперетирается.

-b boot0 = уазываем что зарузчик брать из /boot/boot0

-s 1 = слай с которого грузится по дефолту

-t 180 = устанавливает таймер сколько ждать в тиках. один тик ~ 1/18 секунды

da0  = диск на который пишем


я потверждаю что после установки boot0 и перезагрузки 
у нас на экране будет 


F1 FreeBSD

Default: F1

вот к чему приводит установка boot0


далее. когда мы разбили диск на слайсы. то надо узнать какой адрес теперь у этого слайса.
смотрим список слайсов на компе


# gpart show -p
=>      40  33554352    da0  GPT  (16G)
        40      1024  da0p1  bios-boot  (512K)
      1064  33553320  da0p2  freebsd-zfs  (16G)
  33554384         8         - free -  (4.0K)

=>      63  16777153    da2  MBR  (8.0G)
        63  16771797  da2s1  freebsd  [active]  (8.0G)
  16771860      5356         - free -  (2.6M)

получается вот что. если диск MBR (da2) то его слайсы будут иметь адрес
/dev/da2s1

если диск GPT (da0)  то его слайсы будут иметь другое имя
/dev/da0p1, /dev/da0p2


fdisk к сожалению непоказыывает адрес слайса.


далее. разница между fdisk и bsdlabel.

fdisk - он для манипуляций с таблицей слайсов на MBR диске.

bsdlabel он не создает слайсы. он работает с уже готовыми слайсами.
он позволяет внутри слайса нарезать партишэны.
эти партишены они невидны другим ОС. разбиение на партишены внутри слайса видно 
и понятно только фрибсд.

bsdlabel создает таблицу партишенов внутри слайса.

таблица MBR позволяет нам разить диск на слайсы.

а таблица bsdlabel позволяет нам разбить слайс на партишены.

получается то что fdisk делает с диском то bsdlabel делает со слайсом.

еще раз скажу что с точки зрения MBR разбиения диска на куски - есть только слайсы.
и нет никаких партишенов внутри слайсов. впрочем все что внутри слайсов MBR уже некасается.


я уже не стал читать как у нас в виндовсе разбивается раздел на логические диски.
и где это записывается.
но вот она аналогия.  во фрибсд партишены внутрислайса.
в виндовсе логические диски внутри слайса.

получается что когда мы диск разрезали на слайсы которы может быть в MBR максимум 4, 
то после этого у нас нет никаких партишенов внутри слайсов.

чтобы создать партишены на слайсе надо знать адрес слайса. - da2s1

# bsdabel  -w /dev/da2s1
# bsdlabel -e /dev/da2s1

разбиение слайса на партишены идет в интерактивном режиме.
загружается vi и текстовый файл. 
и надо его отредактировать.

выход из редактора чтобы незаписыать измененеия :q!
записать измнения :w
выход :q

пример таблица партишенов

           size     offset    fstype   [fsize bsize bps/cpg]
  a:      10000         16    unused        0     0
  b:      10000      10016    unused        0     0
  c:   16771797          0    unused        0     0     # "raw" part, don't edit
  d:      10000      20016    unused        0     0
  e:      10000      30016    unused        0     0
  f:      10000      40016    unused        0     0
  g:      10000      50016    unused        0     0
  h:   16711781      60016    unused        0     0

тут я хочу указать на очень важную вещь. о ней возможно даже в хэнюуке написано.
а именно. о том что offset смещение указывается относительно начала слайса.
то есть если указано что оффсет = 16 это значит что надо отступить 16 сектоов от начала слайса.

про число 16 секторов. в них фрибсд записывает не таблицу партишенов. нет.
в них фрибсд оставляет место чтобы мы туда записали boot=boot1+boot2

и тут я сразу говорю как это сделать. это можно сделать через bsdlabel

# bsdlabel -B /dev/da2s1
(при этом насоклько я понимаю запись boot1+boot2 никак неперетирает существущую таблицу партишенов
если она есть)

партишенов может быть максимум 8 штук(а не как в виндовсе дофига). они имеют имена

a b c d e f g h

c - зарезервирован и он генерируется автоматом и означает партишен который охватывает весь 
слайс целиком. c служит для служебных целей.

насколько я понял свапу обычно дают партишен с 'b'

offset  - это первый сектор партишена
size - это размер партишена в секторах.

единственное что первый партишен он начинается с 16 сектора. так как фрибсд нужно вначале
слайса 16 секторов чтобы как раз туда и записать таблицу партишенов.

в общем сидим считаем офсеты и сайзы. вбиваем. 
далее :w и :q (это я про редактор как с ним работать)
если ошиблись то :q!


если все сделали правильно то прочитать таблицу партишенов можно так:

 # bsdlabel /dev/da2s1
# /dev/da2s1:
8 partitions:
#          size     offset    fstype   [fsize bsize bps/cpg]
  a:      10000         16    unused        0     0
  b:      10000      10016    unused        0     0
  c:   16771797          0    unused        0     0     # "raw" part, don't edit
  d:      10000      20016    unused        0     0
  e:      10000      30016    unused        0     0
  f:      10000      40016    unused        0     0
  g:      10000      50016    unused        0     0
  h:   16711781      60016    unused        0     0

или через gpart

root@freenas:~ # gpart show da2s1
=>       0  16771797  da2s1  BSD  (8.0G)
         0        16         - free -  (8.0K)
        16     10000      1  !0  (4.9M)
     10016     10000      2  !0  (4.9M)
     20016     10000      4  !0  (4.9M)
     30016     10000      5  !0  (4.9M)
     40016     10000      6  !0  (4.9M)
     50016     10000      7  !0  (4.9M)
     60016  16711781      8  !0  (8.0G)



я думаю что виндовс так же как и фрибсд он хранит информацию о разбиении слайса
на логические диски внутри слайса. то есть технолгия одинаковая.

думаю что разбинение на партишены придумали из за того что MBR позволяет 
разбить диск только на 4 части. этого мало для оптимального количества
разбиения наших данных в ОС по независимым кускам для точек монтиирования.
чтобы потом гибко данные мигрировать можно было.
условно говоря из мира линукс. 
/boot - один кусок
/var/log второй
/var третий
/home четвертый
ну наверно там еще всякого. и очевидно что нам надо больше чем 4 точки монтирования
по отдельным разделам (слайсам\партишенам неважно кускам короче говоря).
поэтому партишены были придуманы как дополнительные слайсы силами самого фрибсд.
как надстройка разбиения диска на большее число кусков чем четыре как это дает 
возожность MBR, таким образом мы обошли ограничение MBR.


таким образом мы получили что мы диск разбили на MBR слайсы. один из слайсов помечен как загрузочный
и внутри слайса мы его разбили на партишены.

и установили boot0 загрузчик ( стадия ноль ) в MBR 

далее надо форматировать партишены\слайсы и ставить дальнейшие загрузчики.

еще раз вспомним фазы загрузки

фаза 0 - файл /boot/boot0 - лежит в mbr

остальные фазы пока я непознакомился

остальные стадии называются boot1 boot2 и loader. будем с ними знакомиться
эти стадии записаны в файлы в одноименные файлы в каталоге boot.

/boot/boot0
/boot/boot1
/boot/boot2
/boot/loader

из этих файлов код можно записать на диску в те места где ему положено быть.
мы будем это делать далее.


при отработке boot0 мы увидим

 	
F1    FreeBSD
F2    BSD
F5    Disk 2

при отработке boot2 
мы увидим

>>FreeBSD/i386 BOOT
Default: 1:ad(1,a)/boot/loader
boot:

этого я пока невидел.

когда отработает loader 
мы увидим

BTX loader 1.00 BTX version is 1.02
Consoles: internal video/keyboard
BIOS drive C: is disk0
BIOS 639kB/2096064kB available memory

FreeBSD/x86 bootstrap loader, Revision 1.1
Console internal video/keyboard
(root@snap.freebsd.org, Thu Jan 16 22:18:05 UTC 2014)
Loading /boot/defaults/loader.conf
/boot/kernel/kernel text=0xed9008 data=0x117d28+0x176650 syms=[0x8+0x137988+0x8+0x1515f8]

этого я пока тоже невидел

когда отрадтает загрузка kernel мы увидим

Copyright (c) 1992-2013 The FreeBSD Project.
Copyright (c) 1979, 1980, 1983, 1986, 1988, 1989, 1991, 1992, 1993, 1994
        The Regents of the University of California. All rights reserved.
FreeBSD is a registered trademark of The FreeBSD Foundation.
FreeBSD 10.0-RELEASE #0 r260789: Thu Jan 16 22:34:59 UTC 2014
    root@snap.freebsd.org:/usr/obj/usr/src/sys/GENERIC amd64
FreeBSD clang version 3.3 (tags/RELEASE_33/final 183502) 20130610

этого я тоже пока тоже невидел. в смысле недошел до этого


как я понимаю boot0 дает возможность выбрать с какого раздела диска грузиться 
через текстовый интерфейс
 	
F1    FreeBSD
F2    BSD
F5    Disk 2


то есть можно грузиться с каждого из четырех разделов.
просто один раздел является разделом загрузки по умолчанию
но мы можем грузиться с каждого.

и еще мы можем грузиться и с другого диска, не стого на котором мы запутили MBR

только один из слайсов должен быть помеен как активный. если так сделать для нескольких
разделов( технически так можно сделать) то код boot0 откажется работать.

приколльно что я узнал как формируется эта картинка

F1    FreeBSD
F2    BSD
F5    Disk 2

boot0 сканирует таблицу разделов и смотрит на типа раздела.
если тип раздела 0x83 он пишет  - Linux , если тип раздела 0xa5 он пишет BSD итп.

также boot0 сканирует таблица разделов на других дисках и выводит и для них таблицу

насколько я понял далее boot0 читает 
первый сектор слайса (либо дефолтового либо того  слайсы который мы выбрали руками в меню).
в этом секторе должна быть следущая часть загрузчика - boot1

итак

фаза 0  - boot0 - запиисан в MBR , размер один сектор
фаза 1 - boot 1 - записана в первом секторе слайса , размер один сектор

напоимнаю как можно записать boot0 на диск

# boot0cfg -B  -b /boot/boot0 -s 1 -t 180 da0

насколько я понял начиная с первого сектора слайса туда записывается файл 
/boot/boot

этот файл является склейкой файлов

/boot/boot= /boot/boot1+/boot/boot2

boot1 = 512 байт
boot2 = 7 680 байт

таким образом в первом секторе слайса оказывается boot1
а в последущих секторах лежит boot2

общий размер boot1+boot2 = 8KБ (16 секторов по 512 байт)

наскольк я понимаю boot=boot1+boot2 можно записать на диск просто через команду dd
зная сектор где начинается слайс.

например

root@freenas:~ # gpart show -p da2
=>      63  16777153    da2  MBR  (8.0G)
        63  16771797  da2s1  freebsd  [active]  (8.0G)
  16771860      5356         - free -  (2.6M)


# dd if=/boot/boot of=/dev/da2s1 bs=512 count=16

таким  образом boot1 и boot2 оказался на диске.


работает это так.

boot0 скачивает первый сектор со слайса то есть boot1 и передает ему управление.

boot1 в свою очередь уже считывает весь boot со слайса целиком и передает ему управление.

(почему это так все устроено я не обсуждаю).

далее интересно то что boot2 (который часть boot) он уже (внимание) считывает уже непосредственно с файловой
системы (то есть непросто какиое то там сраное чтение диска через сектора) да да уже он типа понимает 
что такое файловая система , оно считывает /boot/loader с файловой системы. boot2 понимает что такое
файловая система умеет с нее читать.

boot1 называется BTX server
boot2 называется BTX client

loader называется BTX client тоже.

loader считывает kernel и запускает его.


насколько я понимаю loader уже нетребует никаких хитрожопых записываний на диск. 
loader уже просто должен лежать на файловой системе в /boot

ура. 



насколько я понял. когда у нас не zfs файловая система а любоая другая скажем UFS
то фрибсд неможет быть установлен на слайс. фрибсд может быть установлен только на 
фрибсл партишн те которые с буковками. только партишены можно смонтировать в /etc/fstab
и с них загрузиться.

также получается что отформатировать слайсы в UFS нельзя можно отформатировать в UFS 
только партишены.

получается при UFS без bsdlabel необойтись.

теперь становится понятно вот что: при создании певрого партишена на слайсе оффсет  = 16 секторов.
то есть первый партишен начинается не в самом начале слайса а нужно пропустить 16 секторов.

первый сектор слайса - пропускаем 16 секторов - первый сектор первого партишена.

както так.

это сделано потому что как раз в эти 16 секторов вначале слайса мы записываем boot=boo1+boot2
иначе их было бы некуда писать. если бы небыло этого отступа.

итак что мы имеем,
диск на слайсы MBR мы разбили. в MBR boot0 записали.
вначале первого слайса мы boot=boo1+boot2 с помощью dd мы можем записать.

внутри слайса с помощью bsdlabel мы нарезали партишенов.

на работающей системе монтируем партишен нового диска в /mnt  
копируем в эту папку /boot 
в котором есть loader, loader.conf, kernel

и по идее мы можем загрузиться с такого диска. 
и  на нем должны отработать 

boot0
boot1
boot2
loader 

и даже кернел должен загрузиться до какойто степени.

главное что все загрузчики должны отработать.

если мы в /mnt разаривириуем полный бэкап
подправим /etc/fstab если нужно 
то у нас должен получиться полностью полноценный фрибсд который должен полностью загружаться.

теперь надо это проделать.

главная цель это проверить что мы правильно все поняли и научились записыать все 
boot0
boot1
boot2
loader

в нужные места таким образом создавать загрузочный диск. на который можно перенести фрибсд.

оказывается что UFS может делать снэпшоты. это очень хорошо.


теперь в рабочей системе делаем UFS снэпшот, монтируем этот снэпшот, 
берем новый hdd, делаем MBR слайсы, пишем boot0, пишем boot=boot1+boot2
разбиваем слайс на партишены и форматиируем, монтируем все эти партишены в папку, копируе файлы 
со снэпшота в эту папку, по идее система готова , она перенесена, тесттруем загрузку с новой системы.

поехали,по шагам

/в рабочей системе делаем UFS снэпшот: 
по дефолту на UFS нельзя сделать снэпшот выдаст ошибку.

 # tunefs -p /da0s1a
tunefs: soft update journaling: (-j)                       enabled

потому что вот этот параметр должен быть disabled
для этого надо либо перевести систему в single-user режим
либо смонтировать фс в read-only режим
(прикрольно то что получатся на продакшн среде снэпшоты наживую неснять
это отстой по отношению к ufs. но для тестовых целей подойдет)

поскольку у нас фс корневого раздела то сделаем через single-user режим

# shutdown now
# tunefs -j disabled /dev/da0s1a
# exit

прикольно что в  отличие от линукса чтобы перейти  в single-user режим
и обратнов multi-user ненужно ребутть систему.

создаем теперь снэпшот корневого раздела

# mksnap_ffs / /var/snapshot/os-snapshot

/монтируем этот снэпшот
# mdconfig -a -t vnode -o readonly -f /var/snapshot/os-snapshot -u 4
# mount -r /dev/md4 /mnt
(взял это отсюда https://www.freebsd.org/doc/handbook/snapshots.html)

пркольно что во фрибсд добавляет диск налету и он автоматом налету распознается
и сразу виден через camcontrol а не как в линукс нужно перескаировать руками шину.


/берем новый hdd
готово

/делаем MBR слайсы
# fdisk -I da1

/пишем boot0
# boot0cfg -B  -b /boot/boot0 -s 1 -t 180 da1

/пишем boot=boot1+boot2
# bsdlabel -B /dev/da1s1
у меня почемуто неполучилось сделать тоже самое руками через команду dd
ведь мы знаем куда писать файл /boot/boot .
нужно писать в первый сектор слайса. 16 секторов. boot и есть ровно такого размера.
пока оставляю разбор причины почему через dd запись boot1+boot2 недает результат

/разбиваем слайс на партишены и форматируем
# bsdlabel -w /dev/da1s1
# bsdlabel -e /dev/da1s1

#          size     offset    fstype   [fsize bsize bps/cpg]
  a:   35648156         16    4.2BSD        0     0     0
  c:   35648172          0    unused        0     0     # "raw" part, don't edit

# newfs -U /dev/da1s1a

#монтируем все эти партишены в папку,
# mkdir /tmp/1
# mount /dev/da1s1a /tmp/1

/копируе файлы  со снэпшота в эту папку
# cp -rp /mnt/ /tmp/1
(этот раздел пока вызывает вопрос как это сделать лучше)


на исходной системе был свап раздел
в новой его нет поэтому я отредактируровал /новый фс/fstab

# vi /tmp/1/etc/fstab
# Device        Mountpoint      FStype  Options Dump    Pass#
/dev/da0s1a     /               ufs     rw      1       1
#/dev/da0s1b    none            swap    sw      0       0

/тесттруем загрузку с новой системы
все сработало.
более того.
я несколько раз делал тест. и система успешно загрузилась даже при 
неверном bsd лейбеле вот таком

#          size     offset    fstype   [fsize bsize bps/cpg]
  a:   35648156         16    unused        0     0     0
  c:   35648172          0    unused        0     0     # "raw" part, don't edit

то есть для a указано что он якобы неотформатирован.
то есть я отформатировал но забыл поменять инфо в бсд лейбеле. и все равно 
бсд успешно полностью загрузилась. типа ей пофиг?

также. я подтверждаю вот что.
если поставить только boot0 + boot1 + boot2
и все. без какой либо файловой системы то на экране мы получим вот такое


 	
F1    FreeBSD
F2    BSD
F5    Disk 2


и чуть ниже вот такое

>>FreeBSD/i386 BOOT
Default: 1:ad(1,a)/boot/loader
boot:

это еще раз подтверждает как выглядит интерфейс boot0 и boot1+boot2
и доказывает что boot1+boot2 уже понимает что такое чтение с файловой системы. а непросто
читает сектора как boot0. 

неочень понятна конечно такая нотация
Default: 1:ad(1,a)/boot/loader

но этот вопрос мы  пока оставляем.

итак это был успешный перенос с  UFS системы на  UFS+MBR систему. 
итак boot0 лежит в MBR, boot1+boot2 лежит на самом начале слайса в его первых 16 секторах.
важно понять что boot1+boot2 лежит вне файловой системы.
loader лежит уже на партишене на файловой системе  в форме файла.
важно что при этом переносе на уровне файлов я ничего неменял. только 
fstab поравил и только изза того что поленился на новой системе swap нарезать.

биос читает boot0, boot0 смотрит какой слайс активный. читает с него boot1+boot2
они читают уже фс loader а он кернел. при этом с точки зрения устновки boot0 boot1 boot2
ненадо делать никаких настроек конфигов что и откуда им чиать. это фантастика.
только нужный слайс пометить как активный вот и все конфигурирование. для сравннеия в grub
нужно просто миллион строк написать и миллион команд выполнить. ужас. grub это полный гроб.

loader нетребует никаого конфигурирования, boot1+boot2 тоже нетребуют просто их 
надо записать в нужное место и все. boot0 из конфигурирования требует только чтобы 
мы верно пометили загрузочный слайс.

это фантастика как мало надо конфигурировать.
при этом в плане загрузчика мы использовали файлы
/boot/boot0
/boot/boot
/boot/loader
/boot/loader.conf (его я не конфигурировал но он тоже участвует для фрибсд на UFS он пустой)



теперь надо перенести фрибсд с UFS на ZFS+MBR систему.
и посмотреть а какие там файлы используются для записи загручиков.


теперь надо протестировать перенос с ZFS системы на UFS+MBR систему.

надо перенести систему на ZFS+GPT


---> научиться разбивать mbr на слайсы(научился), партишены(научился), ставить загрузчики и загрузчики 
правильные (научился для UFS+MBR) и  грузится с ufs(научился), zfs. 
потом тоже самое для GPT




*!!! теперь работаем с GPT
GPT

как я понял изнаально такая разбивка диска чтобы с нее загрузиться
требует новую фоорму биоса на компе  = uefi

uefi это новая форма биос а efi это тип раздела на диске с GPT разбивкой.

новая система разбиения диска GPT - guid partition table
она позволяет иметь 128 разделов на диске.
также позволяет работать с дисками более 2ТБ.

классическая старая разбивка диска через MBR она идет в купе ос старыми биосами.
тоесть MBR разбивка дисков была придумана непросто из головы а для связки с БИОС
связка БИОС компа - MBR диска.
чтобы используя такую связку можно было в итоге загрузиться.

новая разбивка  диска GPT по крайней мере изначально подразумевала
что загрузиться с нее может только новый биос-UEFI.
новая связка UEFI биос - GPT  разбивка диска.

незнаю как там в целом. но freebsd может загрузиться с GPT диска испольщуя старый биос.
то есть оказыавется все таки можно имея старый биос загрузиться с GPT диска.

фишка   GPT одна из разбиения в том у него две таблица. основная и запасная. у меня флэшка 
имела поврежденную основную и фрибсд читала запасную это кул. поэтому
это сразу лучше чем MBR 

насколько я понял в чем огромаднейший плюс UEFI биоса это то что диски с которых он грузится
больше недолжны иметь никакие хитрожопые загрузочные сектора. а загрузочный код 
теперь хранится исключительо в файлах. это просто охуенно. это значит что загрузочный
диск для uefi можно подготовить теперь путем копирования файлов в нужные папки. больше
ненужны хитрожопые утилиты которые пишут хитрожопые загрузчики в сектора. теперь все
по человечески - взял диск . создал файловую систему FAT32 в ней папки  , в папки поло
жил загрузчик в виде файла. все загрузочный диск готов. это охуенно.

UEFI понимает файловую систему FAT16\FAT32 короче FAT. умеет оттуда читать файлы.
вэтом огромная фишка. и там она ищет в определенной папке загрузчик.

подгтовка загрузочного диска и перенос системы с диска на диск должно очень упростться.
все сводится к файловому копированию без хитрожоых утилит и секторных загрузчиков
которые надо хитрожоопо записывать в на секторном уровне.

насколько я понял чтобы сдлеать загрзочный для UEFI диск 
надо создать раздел с меткой efi, отформатировать его в FAT\fat32
и записать загрузчик в определенную папку. и все готово.

---> надо научиться делать UEFI загрузочный виндовс диск, линукс диск, фрибсд диск


структура GPT разбивки.
первый сектор полностью соотсвтвует MBR спецификации. это сделано для того чтобы 
если будем какая то тупая операционка которая незнает что такое GPT диски
чтобы она непопортила GPT диск.  таблица в MBR секторе записана так что на диске
один раздел занимающий весь диск.

далее идут сектора как раз описывающие таблицу разделов.
вроде бы 128 разделов макс поддерживается.

также как я понял в самом конце диска сидит копия GPT таблицы разделов.
как я понял есть CRC код который удостоверяет целостность таблица разделов.
как я понял ОС может проверить целотность через CRC и если оно несовпадает значит
таблица разделов запорчена и тогда ОС может начать работать с копией таблицы
разделов в конце диска.

вспомним что при MBR разбивке у нас есть как минимум 62 сектора после MBR сектора которые
неиспользуются и туда например GRUB пишет часть своего загрузчика.

при GPT разбивке никаких дырок неиспользуемых нет.

вопрс - да нахера нам какието дырки. нам больше нет нужды записывать тело загрузчика в секторах.
этого больше нет. весь загрузчик теперь целиком в форме одного файла должен лежать
на FAT32(efi раздел) и все. ответ да все верно если мы используем UEFI биос.

но оказывается мы можем грузится с GPT диска используя старый биос.
как это выглядит.

старый биос читает MBR в первос секторе GPT диска.  а там же можно загрузчик разместить.
отлично. но проблема в том весь же загручик у нас невлезает в 446 байта в MBR нам надо кудато 
сохранить остальное тело загрузчика. как мы помним для класического MBR диска boot0 требовал чтобы
boot1 был сохранен в первом секторе загрузочного слайса.

насколько я понимаю при GPT разбивке мы можем действовать также.
boot0 в MBR, boot1 вначало первого слайса. но походу фрибсд уже так неделает.
хотя ничего немешало. вобщем они помещают boot1 на отдельный микрораздел.


научиться разбивать gpt диск с кастомным началом первого раздела.
берем чистый диск
root@freebsd-03:~ # gpart show da1
gpart: No such geom: da1.

разбиваем его как GPT


root@freebsd-03:~ #
root@freebsd-03:~ # gpart  create -s GPT da1
da1 created
root@freebsd-03:~ #
root@freebsd-03:~ #
root@freebsd-03:~ # gpart show da1
=>      40  35651504  da1  GPT  (17G)
        40  35651504       - free -  (17G)


видно что первый доступный сектор для раздела это 40 LBA
странно что это 40 а не 34 как нарисовано в вики для GPT.
ну да ладно.

кстати по аналгии для MBR разбивки

root@freebsd-03:~ # gpart show da1
=>      63  35651521  da1  MBR  (17G)
        63  35651521       - free -  (17G)


видно что первый доступный сектор 63 для раздела.

возвращаемся к GPT

для указания начала раздела можно либо указать первый сектор раздела  ключ -b

root@freebsd-03:~ # gpart add -t freebsd -b 8192  -s 20480 da1
da1s1 added
root@freebsd-03:~ #
root@freebsd-03:~ # gpart show da1
=>      63  35651521  da1  MBR  (17G)
        63      8129       - free -  (4.0M)
      8192     20480    1  freebsd  (10M)
     28672  35622912       - free -  (17G)




либо указать выравнивание (ключ -a) относительно какого размера куска мы хотим ровнять слайс 

root@freebsd-03:~ # gpart add -t freebsd -a 4M -s 24M da1
da1s1 added
root@freebsd-03:~ #
root@freebsd-03:~ #
root@freebsd-03:~ # gpart show da1
=>      63  35651521  da1  MBR  (17G)
        63      8129       - free -  (4.0M)
      8192     49152    1  freebsd  (24M)
     57344  35594240       - free -  (17G)


замечу что ключ -a он выравнивает слайс нетолько относительно начала диска (стартоый сектор) но
и сам размер слайса.   если бы я указал что слайс по размеру -s 10M то ключ -a подрезал бы слайс с 10M до 8M
чтобы размер слайса тоже кратно укладывался в 4M куски.

итак мы научились начинать раздел с такого сектора с какого хотим.
то есть научились ровнять слайс относительно начала диска.

чтобы удалить таблицу разделов с диска вначале нужно удалить все слайсы с него
а потом уже удалится и таблица разделов

root@freebsd-03:~ # gpart delete -i 1 da1
da1s1 deleted
root@freebsd-03:~ # gpart destroy da1
da1 destroyed


далее.
имеем GPT диск со слайсом на нем

root@freebsd-03:~ # gpart show da1
=>      40  35651504  da1  GPT  (17G)
        40      8152       - free -  (4.0M)
      8192     20480    1  freebsd  (10M)
     28672  35622872       - free -  (17G)


как мы помним GPT поддерживает добавку label для слайсов.

на данный момент мы видим что у нас слайс номер =1  и тип слайса freebsd

посмотрим есть ли на данном слайсе метка label

root@freebsd-03:~ # gpart show -l da1
=>      40  35651504  da1  GPT  (17G)
        40      8152       - free -  (4.0M)
      8192     20480    1  (null)  (10M)
     28672  35622872       - free -  (17G)

null - метки нет.

добавим ее


root@freebsd-03:~ # gpart modify -i 1 -l ssd10G-1 da1
da1s1 modified
root@freebsd-03:~ # gpart show da1
=>      40  35651504  da1  GPT  (17G)
        40      8152       - free -  (4.0M)
      8192     20480    1  freebsd  (10M)
     28672  35622872       - free -  (17G)

root@freebsd-03:~ # gpart show -l da1
=>      40  35651504  da1  GPT  (17G)
        40      8152       - free -  (4.0M)
      8192     20480    1  ssd10G-1  (10M)
     28672  35622872       - free -  (17G)

root@freebsd-03:~ #


итак у da1s1 повяилас метка ssd10G-1
как я понял метка прописывается кудто то в хвост слайса

насколько я понял после этого к слайсу можно обращаться не черезе /dev/da1s1 а через
/dev/gpt/ssd10G-1

что вообще нам дает метка для слайса.
дает то что мы вытащим диск вставим в другую дырку и путь к слайсу поменяется станет /dev/da2s1
и это плохо а вот путь к слайсу через метку останется тем же самым /dev/gpt/ssd10G-1
а это уже хорошо. но пока просто хорошо но безсполезно.

оно станет полезно когда мы слайс разобьем на партишены.


root@freebsd-03:~ # bsdlabel -w /dev/gpt/ssd10G-1
root@freebsd-03:~ # bsdlabel  /dev/gpt/ssd10G-1
# /dev/gpt/ssd10G-1:
8 partitions:
#          size     offset    fstype   [fsize bsize bps/cpg]
  a:      20464         16    unused        0     0
  c:      20480          0    unused        0     0     # "raw" part, don't edit

форматируем раздел

root@freebsd-03:~ # newfs -U /dev/gpt/ssd10G-1a

теперь мы можем прописать в fstab путь в виде
/dev/gpt/ssd10G-1a
и при этом нам теперь абсолютно насрать в какую дырку воткнут диск. путь к партишену 
теперь от этго независит.

абсолютно полезная фишка которую нужно использовать также при создании zfs пула.
чтобы пул со слайсами не через имена дисков а через gpt метки слайсов.
чтобы мы могли вытащить диски пула вставить в комп в любому порядке и пул успешно импортнулся .
вот для чего нужны gpt метки. которые выставляет gpart.
он их выставляет для gpt дисков а для mbr нет потому что сама разбивка должна поддерживаеть метки.
то есть это фишка разбивки а не gpart.

итак ровнять слайсы научились. 
поняли что такое label в gpart\gpt

возвращаемся к проблеме о том как грузиться с GPT диска через старый биос.
первую часть загрузчика пишем в MBR впервый сектор. 
поскольку мы можем в GPT начать первый раздел с сектора какого хотим то 
по мне небыло проблем чтобы писать вторую фазу граба как это было в protected MBR (при GPT разбивке
первый сектор диска ) между таблицей
разделов и началом раздела. технически к этому нет никаикх препятсвий. но я понял почему они это
неделают они под вторую фазу граба делают микрораздел. окей. вот так они решили.
что касается бсд нет никаких проблем как и в случае MBR разбивики писать boot1 на первый сектор слайса.
посмотрим как они делают на самом деле.

на самом деле они сделали вот как(man gptboot). в protected MBR они пишут /boot/pmbr
он запускает загрузчик из раздела на диске у котрого тип freebsd-boot там лежит код из 
файла /boot/gptboot
тот сканирует разделы ufs на диске выбирает грузиться с раздела у котрого установлено свойство bootme.
и вот дальше непонятно. непонятно что он с него грузит. наверное loader.

а вот как эта шарманка устанавливается:

пишем загрузчики куда следует
# gpart bootcode -b /boot/pmbr	-p /boot/gptboot -i 1 ada0
устанавливаем у нужного слайса атрибут bootme
# gpart set -a	bootme -i 1 ada0

вот так делается загрузочным GPT диск для UFS фс.
ну и понятно что нужно будет предвариетлно создать микрораздел типа freebsd-boot
в который мы сможем записать /boot/gptboot

насколко я понимаю аналогично делается загрузочным GPT диск для загрузки из старого биос
для zfs (man gptzfsboot)

создается микрораздел типа freebsd-boot

туда в portected mbr и на freebsd-boot помещаются соответвующие загрузчики из соотвтсвующих файлов

# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada0

и все. готово.

останется только на в свойствах zfs пула указать какой датасет является загрузочным.


схема (ключ -s) в теримнах gpart это тип разбивки - MBR,GPT,BSD
отсюда следует что gpart умеет работать нетолько с GPT но и MBR (и даже BSD разбивкой)
для него это просто разные так называемые схемы. то есть gpart умеет полноценно разбивать
MBR диски.
про labels. какая то из разбивок может поддерживать labels.
MBR неподдеживает label, а GPT поддерживает label.

получается если старый биос и GPT диск. то испольщуются другие файлы.
вместо /boot/boot0  используют /boot/pmbr который пишут как и раньше в первый сектор.

а вместо boot1+boot2 используется другой файл /boot/gptboot или /boot/gptzfsboot
который пишут невначале слайса а на отдельный микро слайс . тип слайса freebsd-boot

итак разобрались как делать GPT загрузочным для UFS,ZFS если грузимся со старого биос.



---> надо научиться ставить либо переносить фринас чтобы он грузился не с одной флэшки а с миррора
флэшек. это очень усилит резилиенси. итак научитсть делать boot from zfs mirror.


---> надо научиться делать загрузочным диск с GPT для UEFI биоса для линукс и виндовс и фрибсд.


--
получается что все что умеет делать fdisk умеет делать gpart
поэтом можно смело все делом gpart

различные файлы в каталоге /boot/
это части загрузчиков на разные случаи жизни

почти всегда можно набрать 

# man имя-файла-из-/boot

и мы получим справку для чего он


--
болезнь freenas
без указания DNS сервера  у него все настройки очень долго сохраняются,
или даже не сохраняются, весь интерфейс тормозит , в консоли куча ошибок
от djanhgo.

так что надо указать DNS сервер в первую очередь.
---

важная вещь:
пул надо создавать используя не имена дисков как это сделано вот тут

 # zpool list -v
NAME                                     SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
HDDx4x4TB                               7.25T  3.09T  4.16T         -    49%    42%  1.00x  ONLINE  /mnt
  mirror                                3.62T  1.52T  2.11T         -    49%    41%
    da0                                     -      -      -         -      -      -
    da1                                     -      -      -         -      -      -
  mirror                                3.62T  1.57T  2.06T         -    49%    43%
    da2                                     -      -      -         -      -      -
    da3                                     -      -      -         -      -      -


а используя gpt guid метки

 # zpool list -v
NAME                                     SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
HDDx4                                   9.06T  1.06T  8.00T         -     8%    11%  1.00x  ONLINE  /mnt
  mirror                                5.44T   685G  4.77T         -     6%    12%
    gptid/117aacf2-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/18342775-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
  mirror                                3.62T   402G  3.23T         -    11%    10%
    gptid/1e932b20-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/1f64f5ac-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -

почему. потому что пул который построен на именах дисков (da0,da1 итд) если 
эти диски вытащить и вставить в другой комп то чтобы такой пул собрался
и завелся на другом компе надо чтобы эти диски получили на том компе
теже самые имена. это маловероятно.

а пул который испольщует guid метки ему все равно какие имена имеют диски. он их неиспользует
и если мы такой набор дисков вставим в другой комп то у нас
пул соберется и заведется без проблем. имена дисков могут измениться а вот метки gpt guid
на них останутся прежними.

имена дисков например могут легко меняться если мы вытащим диск и вставим его
в другой слот.  когда пул построен на gpt guid метаках
то диски можно переставлять в любые слоты это нам будет абослютно пофиг.

---

проблема выравнивания.

на MBR дисках у  нас 1 сектор под MBR потом минимум 62 сектора пустоты и первый сектор раздела
может начинаться с 64 сектора или более.

пусть у нас первый сектор раздела начинается с 64 сектора.

LBA адресация начинается с нуля. LBA= 0,1, ...

посмотрим на таблицу разделов MBR теперь такого диска где первый раздел начинается с 64 сектора

=>      63  16777153  da2  MBR  (8.0G)
        63  16771797    1  freebsd  [active]  (8.0G)
  16771860      5356       - free -  (2.6M)

сектор = 512 байт для zfs. (это отдельно рассмотреть как zfs сообщить что сектор = 4k и надо ли)
 
 63 сектора х 512 байт = 31.5 кБ
 
 если у нас физ сектор = 4 кБ то  
 
 31.5 / 4 =  7.875
 
 то есть начало раздела лежит не на начале 4К сектора а где то в середине 4К сектора.
 это значит что чтения одного сектора с такого раздела потребует чтения двух физ 4к секторов
 с диска. тоже самое с записью. запись 1 сектора на раздел потребует двух записей на
 физ диск.
 
 
 в этом проблема выравнивания.
 
 посмотрим еще на один диск в пуле.
 он был разбит через графический интерфейс фринаса
 
 =>        40  7814037088  da5  GPT  (3.6T)
          40          88       - free -  (44K)
         128     4194304    1  freebsd-swap  (2.0G)
     4194432  7809842688    2  freebsd-zfs  (3.6T)
  7814037120           8       - free -  (4.0K)

смотрим на раздел с zfs. откуда он начинается 

     4194432  7809842688    2  freebsd-zfs  (3.6T)

 4194432 секторов = 2097216 кБ
 
 2097216 / 4 = 524304
 
 получается что zfs раздел его начало лежит на начале 4к сектора.
 значит проблем с выравниванием нет.
 
 
 посмотрим еще на один диск который был разбит граф оболочкой фринас
 
 root@freenas:~ # gpart show
=>         40  11721045088  da2  GPT  (5.5T)
           40           88       - free -  (44K)
          128      4194304    1  freebsd-swap  (2.0G)
      4194432  11716850688    2  freebsd-zfs  (5.5T)
  11721045120            8       - free -  (4.0K)

раздел zfs начинается с 4194432 сектора

2097216 кБ / 4 кБ = 524304 

проблем с выравниванием нет.

отсюда мы видим что если это новый фринас.
если это GPT разбивка
если мы разбивали диск на слайсы через граф оболочку
то проблем с выравниванием у таких дисков нет.

вывод - можно смело пользоваться граф оболочкой фринас при разбивке дисков
и быть увереннеым что проблем с выравнивемем нет.

это мы рассматривали диски которые во фринас используются для хранения данных.


посмотрим ради интереса есть ли проблема с выравниваием у фринас с разделами
на загрузочных флэшках. ведь их разбивал фринас инстоллер.

=>      40  30850992  da9  GPT  (15G)
        40      1024    1  bios-boot  (512K)
      1064  30849960    2  freebsd-zfs  (15G)
  30851024         8       - free -  (4.0K)

раздел zfs на 1064 секторе

1064 секторов =  532 кБ 

532 / 4 = 133

значит и на флэшке разбивка такая что zfs раздел лежит на начале 4К сектора.


все отлично.


далее следущий момент.
когда у нас есть пул. который лежит на выровненном разделе то  унас есть еще одна проблема.

назвыается ashift. ashift это размер минимального логического блока на чтение\запись
которым фигурирует пул.

по умолчанию он = 512 байт.  а на дисках с 4к нам надо чтобы он был равен 4к

ahift задается на стадии создания пула и потом его непоменять.

есть аналогия с виндовс. там 
когда мы форматируем раздел то мы указываем размер блок ntfs.
и после этого его непоменять.

ashift задается как степень двойки. то есть для 
512 байт ashift = 9

для 4к 
ashift = 12

проверим чему равен ashift для пулов которые мы создали через графический интерфейс фринас.

# zdb -U /data/zfs/zpool.cache | grep -E "name|ashift"
    name: 'HDDx4x4TB'
    hostname: ''
            ashift: 12
            ashift: 12
            ashift: 12

видим что ashift = 12 то ест 4кБ

то есть все хорошо с этим.

ashft это тоже часть решения проблемы с выравниванием.

есть еще одна серьезная проблема если нет выравивания. при записи если мы попадаем между 4к секторами.
то нужно считать два сектора. потом внутри них поменять куски. а потом их обратно записать.
и жопа тут большая в том что процесс записи теперь требует чтения. то есть мы форммально записываем
на диск но при этом у нас попрует паразитные чтения. а жопа чтений в том что чтение всегда
медленное по природе. запись всегда мжоно сделать отложенно в кэш и записать потом поэтому
запис на массиве обычно вобще непроблема. всегда проблема это чтение. чем больше операций чтения
тем быстрее ложиться массив. а тут получится что при записи у нас навалися куча паразитных чтений.
это все убьет сокрость массива. именно поэтому сверхважно иметь все выравненное.


когда мы собрали раельный сервер. то возникает вопрос как тестироваь выровненность
нам постоянно будет мешать кэши ARC и L2ARC. 
нам надо их выключить на время тестирования что все выравнено.
это можно сделат если в свйоствах то ли пула то ли датасета отключить опции про
primarycache и secondary кэш как то  так , главное сама идея понятна.
только когда мы убеидились что у нас все выровнено. что сетевые карты также 
работают все стройно . только после этого можрно активировать кэши.


вывод - значит графическйи интерфейс фринас для шпиндельных дисков с 4кБ физ сектором
коректно создает разделы и пулы. и нам ненужно об этом париться руками.

хороший тест на то что все выровнено - писать 4к блоками при отклбченном ARC и L2ARC
и смотреть что нет чтений а только запись. хотя нет там так неработает. запись всегда
идет большими макроблоками. хотя прм непопадании в блоки он должен считывать блоки
менять а потом уже писать.


есть еще одна проблема связанная с выравниванием фундаментальная.
вот мы все сдеали все что описано и далее через iscsi мы отдаем LUN для сферы.
а дальше получается все на смарку. во первых сфера как то там отступает от начала луна 
и использует свои размеры для чтения записи блоки, потом на фс сферы создаются диски 
виртуалок на которых виртуалочные ОС делают свои отступы от начала их дисков
и свои размеры блоков чтения записи. в итоге получается отсутствие кккого либо контроля
и полная жопа с отступом и и размерами блоков на чтение запись.
так что в целом когда мы отдаем наш zfs кому то по iscsi то проблема выравнивания
нерешается.  на это есть только одно более менее решение - это отдавать zfs по NFS.
когда доступ к zfs идет на уровне файлов а не блочного устройства. вот тут более менее
ситуацию с выравнивнием можно взять под контроль. с NFS загвоздка что нужны 10GB карты  и такиеже свичи. 
это не глобальная проблема но отчасти проблема. 


-----------

*!!! далее остается проблема и вопрос . а как нам разбивать диски и какой использовать
ashift при работе с SSD дисками. у них размер физ сектора тот еще вопрос.


с ssd такая ситуация. у ssd есть такие структуры как page size.
это единица минимаьная которую он может считать. типа аналог физ блока на крутящихся дисках.

но.

запись на ssd идет не так.  запись возможна только блоком.

например бывают такие цифры.  
page size = 4k
block size = 4MB

запись в ячейку размером page size возможна . но только если все соседниие пейджы пустые.


поэтому запись в пейдж обычно происходит так.

контроллер ssd читает блок. меняет в нем отдельный пейдж.
и записывает обратно блок.

на самом деле выяснилось что запись идет на ssd еще более хитро.

запись идет на ssd всегда в режиме Copy-on-write:

у нас есть блок. который состоит из пейдже. как биты в байте.

мы записали блок. в нем какие то пейджи заняты какието свободны.
если мы еще раз хотим записать в этот блок то ненеможем. ssd память так неможет делать.
и неважно что у нас часть пейджей пустые  блоке. мы можем писать только в полностью пустой блок.
так вот если мы хотим писать в тот же блок изменит какието пейджы то система читает текущий блок.
меняет в нем новые пейджы и записывает этот блок в новый пустой блок. и перенезначает LBA 
что мол вот такой LBA теперь лежит вот в том физ блоке.
таким образом каждый раз когда мы пишем в LBA блок заново он считывается меняется и записывается 
в совершенно другое место. а тот физ блок который освободился его система потихоньку задним
числом обнуляет чтобы после этого он был доступен для записи.

отсюда становится понятно почему так важно отрезать от ssd область и делать ее невидимой.
потому что при записи супер важно постоянно иметь большой кусок свободного места.
в который можно записать прям здесь прям сейчас. а то место которое освободилось
система будет в бэкграунд режиме обнулять чтобы сделать его доступным для записи.
таким образом LBA адрес физически постоянно прыгает по диску.
система также старается чтобы каждый физ блок перетирался одинаковое колиество раз.
чтоб ресурс диска стирался равномерно.


в связи с этим на мой взгляд самое правильное для пула из SSD дисков
считать что его "физ сектор" = размеру блока записи на SSD а не размеру пейджа на ssd.
 и выставит для пула ashift = block size.

и выравнивание надо делать на таких дисков в соотвествии с block size.

например если block size = 4MB
то раздел первый надо начинать с 20MB. а ashift брать 4MB
ashift = 22

может конено у нас чтение будет неоптимальное. мы будем читать не 2-4КБ блоками а 4МБ.
ну и что.. думаю небудет большой потери скорости.
но зато в плане запила дисков у нас будет все оптимально.

вот хорошая статья обьясняет как работает запись на ssd - https://site.aleratec.com/blog/2011/09/22/overview-pages-blocks-ftls-solidstate-drive-ssd/

надо этот вопрос еще прояснять. 
по поводу оптимального ashift для ssd дисков.

думаю также это важный момент который нужно както указыать zfs когда 
мы используем ssd в качестве ZIL


я посмотрел через

# db -U /data/zfs/zpool.cache | grep -E "name|ashift"

для пула у котрого диски крутящиеся и ZIL составлен из двух ssd в мирроре

так вот там видно что для ZIL миррора ашифт такой же как для крутящихся выставлен = 12.

значит для такого случая надо руками создавать zil миррор а не через графику.
и уже потом через графику подсовывать в пул. както примерно так.

что еще оказалось очень интересно:

оказалось что диски под zil они тоже разбиваются фринасом на GPT и на них формируется zfs раздел 
( а не просто какието там абстрактные сырые разделы )

вот пример пула у которого миррор из ZIL двух дисков

root@freenas:~ # zpool list -v
NAME                                     SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
HDDx4                                   9.06T  1.06T  8.00T         -     8%    11%  1.00x  ONLINE  /mnt
  mirror                                5.44T   685G  4.77T         -     6%    12%
    gptid/117aacf2-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/18342775-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
  mirror                                3.62T   402G  3.23T         -    11%    10%
    gptid/1e932b20-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/1f64f5ac-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
log                                         -      -      -         -      -      -
  mirror                                7.94G  13.7M  7.92G         -     0%     0%
    gptid/3fece146-4b6f-11ea-bb91-80c16e650184      -      -      -         -      -      -
    gptid/43dbf316-4b6f-11ea-bb91-80c16e650184      -      -      -         -      -      -
cache                                       -      -      -         -      -      -
  gptid/4f9a0780-4b6f-11ea-bb91-80c16e650184   420G   380G  39.9G         -     0%    90%


по их guid определяем имена дисков


root@freenas:~ # gpart list | grep -E "name|3fece146-4b6f-11ea-bb91-80c16e650184|43dbf316-4b6f-11ea-bb91-80c16e650184"
Geom name: da0
   rawuuid: 3fece146-4b6f-11ea-bb91-80c16e650184
Geom name: da1
   rawuuid: 43dbf316-4b6f-11ea-bb91-80c16e650184

то есть da0 и da1

смотрим разбивку на разделы на этих дисках

root@freenas:~ # gpart show da0 da1
=>      40  20971440  da0  GPT  (10G)
        40        88       - free -  (44K)
       128   4194304    1  freebsd-swap  (2.0G)
   4194432  16777040    2  freebsd-zfs  (8.0G)
  20971472         8       - free -  (4.0K)

=>      40  20971440  da1  GPT  (10G)
        40        88       - free -  (44K)
       128   4194304    1  freebsd-swap  (2.0G)
   4194432  16777040    2  freebsd-zfs  (8.0G)
  20971472         8       - free -  (4.0K)


отсюда становится очевидно что диски для ZIL  на них можно настроить 
и выравнивание начала раздела коректно 
и ashift выставить.

так что ssd диски можно полностью коректно подготовить для оптимального запила
даже когда они используются недля данных а для ZIL.

потомучо по дефолут фринас ssd диски неважно для данных или для zil форматирует
как бутто у них block size = 4KB
 а это ведь нетак.
 это лучше чем 512 байт. но все же неоптимально.

-----

есть еще проблема. 
производители они нередко непишут ни page size для ssd 
ни block size

и его только остается выяснять экспериментальным путем

https://superuser.com/questions/728858/how-to-determine-ssds-nand-erase-block-size

--------

разобраться с geom

--
еще проблема

мы можем на фринас орнанизовать сторадж на одном сервере.

и лить снэпшоты на другой.

но как сделать чтобы между ними чтобы можно было переключаться онлайн прозрачно для виртуалок

как из них сделать кластер хотя бы с ручным переключением


---

zfs

на обычной фс для того чтобы понять какие у нас есть точки монтирования и какие разделы
монтируются куда обычно юзаешь только 

#df -h

но на компе с zfs этого недостаточно. 

вначале нужно посмотреть какие есть датасеты
поскольку датасеты являются аналогом слайсов\партишенов

root@frebsd-zfs:~ # zfs list
NAME                 USED  AVAIL  REFER  MOUNTPOINT
zroot                628M  4.72G    88K  /zroot
zroot/ROOT           626M  4.72G    88K  none
zroot/ROOT/default   626M  4.72G   626M  /
zroot/tmp             88K  4.72G    88K  /tmp
zroot/usr            352K  4.72G    88K  /usr
zroot/usr/home        88K  4.72G    88K  /usr/home
zroot/usr/ports       88K  4.72G    88K  /usr/ports
zroot/usr/src         88K  4.72G    88K  /usr/src
zroot/var            568K  4.72G    88K  /var
zroot/var/audit       88K  4.72G    88K  /var/audit
zroot/var/crash       88K  4.72G    88K  /var/crash
zroot/var/log        128K  4.72G   128K  /var/log
zroot/var/mail        88K  4.72G    88K  /var/mail
zroot/var/tmp         88K  4.72G    88K  /var/tmp

разобравшись с ними также обратив внимание в какие моунтточки они подразумеваются
быть примонтированными можно заглядывать в df



root@frebsd-zfs:~ # df -h
Filesystem            Size    Used   Avail Capacity  Mounted on
zroot/ROOT/default    5.3G    626M    4.7G    11%    /
devfs                 1.0K    1.0K      0B   100%    /dev
zroot/tmp             4.7G     88K    4.7G     0%    /tmp
zroot                 4.7G     88K    4.7G     0%    /zroot
zroot/usr/home        4.7G     88K    4.7G     0%    /usr/home
zroot/usr/src         4.7G     88K    4.7G     0%    /usr/src
zroot/var/audit       4.7G     88K    4.7G     0%    /var/audit
zroot/var/log         4.7G    128K    4.7G     0%    /var/log
zroot/var/crash       4.7G     88K    4.7G     0%    /var/crash
zroot/var/mail        4.7G     88K    4.7G     0%    /var/mail
zroot/usr/ports       4.7G     88K    4.7G     0%    /usr/ports
zroot/var/tmp         4.7G     88K    4.7G     0%    /var/tmp


также мжоно посмотреть из какиз дисков составлен пул

 # zpool list -v
NAME         SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
zroot       5.50G   628M  4.89G        -         -     0%    11%  1.00x  ONLINE  -
  da0p3     5.50G   628M  4.89G        -         -     0%    11%


теперь мы имеем представление какие диски разделены на какие датасеты которые 
примонтированы уже в конкретные папки.


интересно сколько много датасетов наклепал фрибсд при установке на zfs.
он сам столько сделал. порядка 10 точек монтирования.

------------

я узнал что BSD поддерживает разбивку диска нетолько MBR и GPT но и BSD разбивку.

проблема в том что с такой разбивкой насолько я понимаю - с такого диска нельзя будет загрузиться.
так что в целомтакая разбивка нам неинтересна.

по факту как я понял bsdlabel записывает вначале диска информацию понятуню только для
фрибсд. это таже информаия что bsdlabel записывает вначале слайсов.

поэтму с точки зрения биоса такой диск это просто пустой диск. на нем 
нет ни MBR разделов ни GPT разделов.

его понимает только фрибсд что диск содержит только партишены без слайсов.

и как я понял такой диск можно использовать только для монтирования в какую то 
папку типа /home итд.

в целом больше на этот тип разбивки обрашать внимания небудем

как распознать какой тип разбивки диска мы имеем


 # gpart show da0
=>      40  16777136  da0  MBR  (8.0G)

 # gpart show da0
=>      40  16777136  da0  GPT  (8.0G)


 # gpart show da0
=>      40  16777136  da0  BSD  (8.0G)



------

меня заинтересовал вопрос вот у нас есть какая файловая система.
какой при этом loader.conf

этот вопрос меня заинтересовал с той точки зрения
что если я скажем захочу перенести фрибсд установленый на одной фс на другую фс
и чтоб он конечно при этом мог загрузиться.

для zfs 

# cat /boot/loader.conf
kern.geom.label.disk_ident.enable="0"
kern.geom.label.gptid.enable="0"
opensolaris_load="YES"
zfs_load="YES"

Я ПРОВЕРИЛ ТАК И ЕСТЬ,  надо активировать эти хрени.
перезаурзуиться и  в папке /dev/gptid/...
появтся rawuuid котоыре есть у партишенов и тодгда можно создавать zfs pool
используя /dev/gptid/..


я выяснил что если его очистить то ядро грузится
но неможет найти корень. точнее неможет его примонтировать.

для UFS 

loader.conf 
пустой.

получается если фрибсл был устанолвен на UFS а мы хотим его перенести на zfs
то придется дописать loader.conf

-----------------

по поводу того как работать с пулом zfs 
когда мы загрузилис с live cd.

вначале надо узнать имена пулов которые можно было бы импортировать

#zpool import

оно выведет список пулов которые можно импортировать

пул можно импортировать по имени или по его номеру

по номеру бывает нужно импортровать если пул который мы хотим примонтирвать имеет 
такое же имя как пул который уже смонтирован
тогда одноменный пул можно примонтировать по его номеру .
чтобы примонтировать по номеру ненужен никакой доп флаг. просто вместо имени пула указыаем номер
гениально

# mkdir /tmp/1

монтируем наш пул который хотим починить

# zpool import -f -o altroot=/tmp/1 10000102010201021

о каких монтированиях автоматом идет речь.
напомню что  датасет в свойих свойствах имеет опцию которая может указыавть в какой маунтпоинт
монтировать датасет автоматом. ( и никакой fstab ненужен)

# zfs list
NAME                 USED  AVAIL  REFER  MOUNTPOINT
zroot                628M  4.72G    88K  /zroot
zroot/ROOT           626M  4.72G    88K  none
zroot/ROOT/default   626M  4.72G   626M  /

-f = эта опция заставляет импортировать пул

-o altroot=/tmp/1 = эта опция делает то что она для каждого датасета у которого указана точка монтрования
добавляет перед путем монтирования еще вот этот вот altroot.
например

имеем датасет
NAME                 USED  AVAIL  REFER  MOUNTPOINT
zroot                628M  4.72G    88K  /zroot

видно что  у него автоматическая точка монтирования = /zroot

вместе с опцией altroot даный датасет будет примонтирован в папку

/tmp/1/zroot

если мы не укажем опция altroot то  у нас при импорте пула его датасеты примонтируются в нашу систему
в наши системыне папки и нарушат работу нашей системы.
поэтому мы указываем altroot и в итоге датасеты пула примонтируюися в смешенный корень.

если мы нехотим чтобы датасеты монтируемого пула автоматом монтировались 
то вместо altroot можно укзаать опция -N

-N = эта опция говорит чтобы ОС немонтировала датасеты в моунтпоинты автоматом.
необязательная опция но иногда может пригодится.


если мы указали опцию -N то конечно аltroot указывать нет смысла так как датасеты небудт автоматом
примонтированы а монтировать их нужно будет руками

опция altroot она одноразовая. после перезагрузки она обнулится

в итоге нащи наши датасеты примонтируются в /tmp/1

но есть подьебка для датасета /zroot/ROOT/default


root@frebsd-zfs:~ # zfs list
NAME                 USED  AVAIL  REFER  MOUNTPOINT
zroot/ROOT/default   626M  4.71G   626M  /

хотя для данного датасеты указана точка автоматического монтирования 
но данный датасет небудет примонтирован.
и его придется по любому монтирован руками

дело в том что у данного датасета есть свойство

# zfs get all zroot/ROOT/default | grep canmount
zroot/ROOT/default  canmount              noauto                 local

эта опция говорит чтоб данный датасет автоматом немонтировать.

монтируем руками
# mount -t zfs /zroot/ROOT/default /tmp/1

таким образом мы примонтировали все датасеты импортируемго пула в /tmp/1
и можем  редактировать файлы в папках.

также хочу напомнить еще раз что с точки зрения точек монтрования в в свойствах 
датасетов могу быть указаны не папки   а "none" и "legacy"

# zfs list
NAME                                USED  AVAIL  REFER  MOUNTPOINT
freenas-boot                        751M  14.6G    64K  none
freenas-boot/ROOT                   742M  14.6G    29K  none
freenas-boot/ROOT/Initial-Install     1K  14.6G   740M  legacy
freenas-boot/ROOT/default           742M  14.6G   740M  legacy
freenas-boot/grub                  6.95M  14.6G  6.95M  legacy


legacy  = означает что этот датасет небудет автоматом никуда монтировться. его 
подразуевается монтировать через /etc/fstab

none = как я понял подразумевает что данный датасет вообще небудет монтироваться. хотя
при желании его можно смонтировать руками.

-------------

смотрим статистику работы zfs

# gstat

# zpool iostat -v имя-пула 1

чтобы определить по guid имя диска 

# gpart list | grep -E "name|3fece146-4b6f-11ea-bb91-80c16e650184|43dbf316-4b6f-11ea-bb91-80c16e650184"

Geom name: da0
   rawuuid: 3fece146-4b6f-11ea-bb91-80c16e650184
Geom name: da1
   rawuuid: 43dbf316-4b6f-11ea-bb91-80c16e650184

попадание в ARC и ARC2 кэш
#  zfs-stats -A -L

для пример пул у нас 9TB
RAM ~ 55GB

ARC
        Cache Hit Ratio:                43.40%  188432535
        
L2ARC
        Hit Ratio:                      3.24%   32574454
  
  
получается попадает в кэш 43.4% запросов. 
из оставишихся 57% еще 3.24% попадает в ssd cache.

итого до дисков шпиндельных доходит 56% запросов.

отсюда кстати видно что размер RAM имеет в 1000 000 раз более важное значение
для увеличения попадангия в кэш нежели чем размер ssd кэша на чтение. а он немалый 420G
нужно прежде всего добавлять оперативку. 


посмотреть запил SSD

# smartctl -a -H /dev/daX


(неьольшая статья про сбор статистики zfs - https://blog.lexa.ru/2019/10/04/pro_zfs_i_l2arc.html )


проверить что у нас для всех датасетов разрешено исполтьзования ARC и L2ARC

root@freenas:~ # zfs get all | grep -i cache
HDDx4                                          primarycache             all                                            default
HDDx4                                          secondarycache           all                                            default
HDDx4/zvol-sparse-hddx4                        primarycache             all                                            default
HDDx4/zvol-sparse-hddx4                        secondarycache           all                                            default

еще мжоно юзать iostat

# iostat -xn 3 1

о ней в man почиать


остается главный вопрос который  я ненашел как увидеть.

вот приеетел запрос на zfs и что  в рилтайме видеть сколько времени заняло чтобы его обслужить.
суммарная статистика рил тайм.

а так мы только видим активность на конечных дисках.
и статистику по попаданию в кэш.

ну и приходится примерно прикидыывать.

скажем если среднее время считывания запроса с конечного бэкенд диска 7мс.
и частота попадания в кэш 50% то типа примерно в в среднем 4мс.

хотелось бы чтобы zfs считал и выдвавал сам среднюю время 
отвеат на реквесты за единицу времени рил тайм.

еще что касается архитектуры сборки пула то видно что под L2arc можно 
использовать 1 SSD или вообще неиспользовать ssd cache. так как туда попадает только 3-12% запросов
у меня. зато надо использовать два диска ssd под zil. потому что если сломается cache диск
то это буквально почти никакнескажется на скорости работы пула. а вот если сломается zil 
то скорость работы пула упадет сразу ниже плинтуса при записи. 
поэтому если в серверер нехватает дырок то 1 дырка под кэш (то есть l2arc дублировать в зеркало
нет большого смысла) или вообще незанимать дырки под l2arc а вот под zil надо 
обязательно заюзать две дырки. тогда у нас будет надежный пул на случай поломки одного из zil.

еще раз - поломка l2arc почти никак нескажется на скрости пула.
поломка zil сразу убьет скорость записи на пул заодно и скорость чтения тоже ксатти.

поэтому zil обязательно создаем в зеркале. а l2arc совсем необязатоельно миррорить. l2arc если 
совсем туго сдырками то можнои неиспользовать.

и сто чки зрения попадания в кэш то 99% играет роль обьема RAM и 1% наличие ssd l2arc

поэтому про обьем и наличие l2arc можно почти непариться. а вот супер самое главное
это как можно больший обьем RAM. это влияет на скрость чтения.
 
скоростной zil дает большую скорость записи. 

--------------------

полезнашка
как оперативно узнать имена слайсов и партишенов 

список слайсов
root@freebsd-03:~ # gpart show -p da0
=>      63  33554369    da0  MBR  (16G)
        63         1         - free -  (512B)
        64  33554368  da0s1  freebsd  [active]  (16G)

зная слайс список партишенов на нем

root@freebsd-03:~ # bsdlabel da0s1
# /dev/da0s1:
8 partitions:
#          size     offset    fstype   [fsize bsize bps/cpg]
  a:   31457280          0    4.2BSD        0     0     0
  b:    1677312   31457280      swap
  c:   33554368          0    unused        0     0     # "raw" part, don't edit


важно помнить что файловая система нарезается именно на партишенах.
----
еще такой момент нужно проработаь это то что на 1GB сетевых карточках
фринас как я помню показывает высокий latency.
надо узнат как подстроить сетевой стек на фрибсд для zfs для iscsi

или такое искать freebsd low latency network tuning

-----

поиграться с 58-м zfs сервером на площадке.

---
загрузчик который записывается в первый сектор слайса называется в нефрибсдшной документации
как volume boot record или volume boot sector

если загрузчик лежащий в MBR передает управление коду лежащему в volume boot sector а так
в случае с фрибсд и есть то такой тип загрузчки наызывается chain loading

grub он тоже одну свою часть записывает в mbr (это у него назвыается стадия зазгрузки один)
вторую свою часть grub записывает в сектора 1-62  (это у граб назвыается стадия 1.5)
ну а стадия 1.5 уже понимает что ттакое файловая система и грузит с фс /boot/grub

та часть gruи которая записывается в mbr  имеет файл boot.img
та часть что записывается за MBR в неиспользуемых секторах имеет файл core.img
---

насколько я нашел в википедии bsdlabel таблица разделов хранится якобы там же где boot1 
в первом секторе слайса.
то есть как я понимаю в первых 16 секторах слайса хранится нетолько boot1+boot2 но и bsdlabel таблица разделов.
может быть поэтому boot1+boot2 нужно записывать на диск с помощью утилиты bsdlabel а не через dd
потому что bsdlabel пишет туда нетолько boot1+boot2 но делает так чтобы boot1+boot2 неперетер таблицы
разделов.
ровно тоже самое как мы имеет с boot0 и MBR таблицей слайсов. мы некопируем boot0 в MBR с помощью dd 
потому что это перетрет таблицу слайсов.

также я нашел про bsdlabel что обычно

a - относится к / точке монтирования
b - раздел под свап

--------

(прикол если мы выбираем разбивку MBR по она гарантированно будет невыровненной
это жопа. если только мы руками непередвинем первый раздел.)

------------

чето я позабыл как в фрибсд кастомно разметить таблица рпазделов диска на слайсы
так чтобы слайс началася с такого сектора скоторого я хочу

наскольо я понимаю через fdisk

надо разбить диск в MBR  с кастомным началом раздела.


----
zfs нужно ставить только на GPT диски. ( на MBR ненужно).
потому что GPT разбиение подерживает gpt labels для слайсов.
именно благодаря им можно собрать zfs пул из слайсов с путями в виде меток. 
эти метки они неменяются в какую бы дырку компа мы диск невоткнули в отличии от классических путей
которые зависят от дырки.

пример 
классическтй путь к слайсу /dev/da1s1
путь на основе метки /dev/gpt/zfs-root-1

именно пул собранный на основе меток дает нам возможность вытащить диски из сервере
перемешать их вставить обратно как попало любой диск в любую дырку и пул этого незаметит.

если же пул собирать на основе классических путей то чтобы пул собрался нужно чтобы соотвествующий
диск был вставлен в соотвествующую дырку. это полный пиздец.
если к примеру вставить такие диски в другой hba контроллер там таких путей вообще может и небыть.

поэтому zfs только на gpt разбивке. никаких MBR.

едиснвтенное то что я непопробовал собрать пул на основе других меток.
freebsd может выдавать метки свои собственные на основе glabel
эти метки имеют совсем другую природу чем gpt метки.
gpt метки выдает gpart 
а фрибсдщные метки выдает glabel
вот насколько будет выживучим пул если его собрать через метки glabel я непробовал.
если пул на основе glabel меток такойже универсльный как и на основе gpt меток 
тогда можно собирать нармальный пул на MBR связка будет такая MBR+glabel

покаже собираем на основе GPT+gpt labels.



----

перенос zfs на mirror чтобы можно было грузиться с зеркала

на системе которую переносим все делаем.

# zpool list -v
NAME         SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
freenas-boot  15.9G   757M  15.1G         -      -     4%  1.00x  ONLINE  -
  da0p2     15.9G   757M  15.1G         -      -     4%

# camcontrol devlist
<NECVMWar VMware IDE CDR10 1.00>   at scbus1 target 0 lun 0 (cd0,pass0)
<VMware Virtual disk 1.0>          at scbus2 target 0 lun 0 (pass1,da0)
<VMware Virtual disk 1.0>          at scbus2 target 1 lun 0 (pass2,da1)
<VMware Virtual disk 1.0>          at scbus2 target 2 lun 0 (pass3,da2)

чистим новые диски
# gpart delete -i 1 da1
# gpart delete -i 1 da2
# gpart destroy da1
# gpart destroy da2


root@freenas:~ # gpart create -s gpt da1
root@freenas:~ # gpart create -s gpt da2

root@freenas:~ # gpart show da0 da1 da2
=>      40  33554352  da0  GPT  (16G)
        40      1024    1  bios-boot  (512K)
      1064  33553320    2  freebsd-zfs  (16G)
  33554384         8       - free -  (4.0K)

=>      40  16777136  da1  GPT  (8.0G)
        40  16777136       - free -  (8.0G)

=>      40  16777136  da2  GPT  (8.0G)
        40  16777136       - free -  (8.0G)


root@freenas:~ # gpart add -b 2048 -s 512K -t freebsd-boot da1
root@freenas:~ # gpart add -b 2048 -s 512K -t freebsd-boot da2

freebsd-boot должен бьть менее 545кб (man gpart) иначе при загрузке вылезет ошибка "boot loader too large"

root@freenas:~ # gpart add -a 1M -t freebsd-zfs -l zfs-bootmirror-1 da1
root@freenas:~ # gpart add -a 1M -t freebsd-zfs -l zfs-bootmirror-2 da2

root@freenas:~ # gpart show -l da1 da2
=>      40  16777136  da1  GPT  (8.0G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  16771072    2  zfs-bootmirror-1  (8.0G)
  16775168      2008       - free -  (1.0M)

=>      40  16777136  da2  GPT  (8.0G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  16771072    2  zfs-bootmirror-2  (8.0G)
  16775168      2008       - free -  (1.0M)


root@freenas:~ # gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot  -i 1 da1
root@freenas:~ # gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot  -i 1 da2

# mkdir /mnt/1
# zpool create -o altroot=/mnt/1 zroot mirror /dev/gpt/zfs-bootmirror-1 /dev/gpt/zfs-bootmirror-2
создаем и подключаем к пулу hot spare диск
# gpart create -s gpt da0
# gpart add -b 2048 -s 512K -t freebsd-boot da0
# gpart add -b 4096 -s 16771072 -t freebsd-zfs -l zfs-bootmirror-hotspare da0
# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot  -i 1 da0
# zpool add freenas-boot spare /dev/gpt/zfs-bootmirror-hotspare

# zpool export zroot
# zpool import -N -o altroot=/mnt/1 zroot

перед тем как делать снэпшот надо зайти в GUI freenas -> System ->Tunables
и прописать ряд параметров для /boot/loader.conf

vfs.root.mountfrom="zfs:freenas-boot/ROOT/default"
kern.cam.boot_delay="60000"
kern.cam.scsi_delay="60000"

(это очень важные три строки настройки. иначе пеориодически при загрузке фрибсд
будет немочь найти корневой zfs датасет и выввливаться в кернел-паник,
чтобы это исправить мы увеличиваем таймаут перед тем как ядро будет искать корневой раздел.
и мы еще раз прописываем explicitely где искать этот корневой раздел.
данная проблема вылезла больше похоже изза того что я перенес фринас который грузился с grub
на загрузку с zfsloader может изза этого чтото несовсем срослось. при переносе фрибсд который изначально
грузился с zfsloader на миррор никаких таких проблем и настроек непришлось делать )

и еще нужно туда же в /boot/loader.conf через tunables добавить

kern.vty=vt
hw.vga.textmode=1

(это заставит ядро при загрузке в консоли неперключаться в графический режим а оставить текстовый.
это очень важно. ибо по дефолту видеодрайвер переключиться из текстового в  графический режим 640x480
в консоли и если мы подключаемся к серверу через ilo у которого ilo-100 то это ило оно дебильное
и на экране у нас будут вместо буква квадраты. вот чтобы в ilo-100 небыло квадратор в консоли
мы затсвляем фрибсд в консоли оставить текстовый режим)


# zfs snapshot -r freenas-boot@migrate
# zfs send -R freenas-boot@migrate | pv | zfs receive -F zroot
# zpool set bootfs=zroot/ROOT/default zroot
# zfs set  mountpoint="/" zroot/ROOT/default
# zfs set  canmount="noauto" zroot/ROOT/default




перезагружаемся и грузимся с live cd
нужно переименовать пул

# zpool import -f -o altroot=/tmp -N zroot(старое-название-пула) freenas-boot(новое-название пула)
# zpool export freenas-boot

далее нам нужно переименовать старый пул.
импортируем старый пул через цифры. 
(мы неудаляем его сразу на всякий случай чтоб если что
с него можно было загрузиться.) иначе у нас будет два freenas-boot пула и 
система в итоге загрузит root датасет именно со старого пула. 
и нам надо это исключить. 

# zpool import -f -o altroot=/tmp -N 123123123123123213(старый freenas пул) freenas-old(новое-название)
# zpool export freenas-old


проверить что zfsd загружается автоматом.

грузимся. готово.

что я для себя открыл.
что GUI freenas несодержит в себе zfs пул с которого он грузится.
поэтому получается через gui мы неможем к загрузочному зеркалу добавить spare
значит надо это делать на стадии создания пула либо в любое другое время но руками (командная строка)

-----------------------------------------------



замена диска тоже с приколами.
zpool deatch
zpool attach


добавка spare


autoreplae и hot spare эторазные вещи


offline не приводи к использованию hot spare

autoreplace =on


также остается загадкой как ак

значит я вроде как нашел вдокументации от фринас.
что когда мы добавляем к пулу hot spare drive то фринас сам автоматом активирует 
zfsd . так что эту службу активировать где то там лазить руками ненужно. очень удобно и умно сделано.

ну а в голой фрибсл обязательно надо zfsd активирвать автозагрузку.

/etc/rc.conf
zfsd_enable="YES"

надо преровреть когда добавлю к загрузочному миирору spare через граф интерфейс то
запутститься ли zfsd


-----------
примеательно что когда мы грузимся и файловая система zfs то фрибсд испольщует не loader
а zfsloader
при этом конфигурационный файл loader.conf используется по прежнему.
--------
остается вопрос как ставить zfs на uefi в мирроре

-------

посмтреть список служб которые запущены на фрибсд

# service -e

-------

важная вещь.
вот  у нас диск со слайсами 

root@freenas:~ # gpart show -p da1
=>      40  16777136    da1  GPT  (8.0G)
        40      2008         - free -  (1.0M)
      2048      1024  da1p1  freebsd-boot  (512K)
      3072      1024         - free -  (512K)
      4096  16771072  da1p2  freebsd-zfs  (8.0G)
  16775168      2008         - free -  (1.0M)

для такого диска создаются вот такие файлы в /dev/

root@freenas:~ # ls -1 /dev/da1
da1%   da1p1% da1p2%

под такими именами можно создать пул. 
/dev/da1p1 итп.

также я задал gpt labels  для этих слайсов через gpart

root@freenas:~ # gpart show -l da1
=>      40  16777136  da1  GPT  (8.0G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  16771072    2  zfs-bootmirror-1  (8.0G)
  16775168      2008       - free -  (1.0M)


и фрибсд (незнаю как) но знает об этом и создало для таких слайсов которые получили gpt labels
файлы в /dev/

# ls -1 /dev/gpt
zfs-bootmirror-1
zfs-bootmirror-2
zfs-bootmirror-hotspare

сотвественно юзая /dev/gpt/zfs-bootmirror-1 можно создавать пул из этих слайсов.
то есть на основе gpt labels для которых что очень важно система создает в папке /dev/gpt/
файлы-идентификаторы.

так вот у слайса помимо gpt label (который опциональный и мы сами добавили
к слайсу руками)  у слайса есть gpt UUID (который обязательнеый идентификатор у GPT слайса 
и есть всегда) но конкретно у меня фрибсд несоздал автоматом файлы-идентификаторы
в папке /dev/gptid/  у меня там пусто.

так вот фрибсд можно заставить создавать и те метки и эти метки или только часть меток.

надо разобраться как регулируется создание /dev/gpt и /dev/gptid

по идее через /boot/loade.conf
 и строки в  нем вида (это надо еще уточнять)
kern.geom.label.gptid.enable=0
kern.geom.label.disk_ident.enable=0
 
так вот что важно. что пишут что якобы так бывает что экспортнул пул собранный на gpt label
импортнул его а он оказался собранный на основе gpt uuids.

вот это меня и заинтересовало.

посмотреть gpt UUID для слайса можно через

# gpart list
2. Name: da2p2
   rawuuid: 32ac1b1e-a67b-11ea-b1d4-005056a31a4e
   label: zfs-bootmirror-2
   
тутже видна и gpt label  

вот пример когда пул создан через gpt labels
# zpool list -v
NAME                            SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
freenas-boot                   7.94G   976M  6.98G         -     0%    12%  1.00x  ONLINE  -
  mirror                       7.94G   976M  6.98G         -     0%    12%
    gpt/zfs-bootmirror-1           -      -      -         -      -      -
    gpt/zfs-bootmirror-2           -      -      -         -      -      -



-

команда позволяет узнать какие "модули" содержатся в самом ядре.
а какие были загружены в форме внешних модулей.


# kldstat -v 

---

можно для пула как я помню установить опцию autoreplace =on
оно дает то что если вытащить диск из дырки и обратно вставить то система автоматом
включит этот диск в пул изагонит туда данные.

по умолчанию выпавший диск нужно дбавлять в пул руками

и важно что эта опция autoreplace она не имеет ничего обещего с hot spare.
чтобы вместо поломанного диска начал использоватся hot spare для 
этого нет флагов на пуле. для этого должен работать сервис zfsd

тоесть это совсем разные вещи
---

live cd

как загрузиться и чтобы консоль была в текстовом режиме а не графическом

коогда появится меню жмем  6

потом

set kern.vty=vt
set hw.vga.textmode=1
boot 

bootbank esxi раздел несмог примонтировать
----
чтобы флэшки незапиливались надо перенести /var с фринаса с флэшек
на пул который лежит на крутящихся дисках

-----------

как перенести его на другой диск

==================================================================================
==================================================================================



==================================================================================
==================================================================================
процесс загрузки freebsd
продожение


boot0 = boot manager

boot = boot1+boot2 = bootstrap процедуры


boot0 ставится в MBR
boot ставится на первый сектор слайса MBR диска

gptzfsboot = тоже самое что boot но есть отличия:
почемуто его уже неназвыают bootstrap процедура а называют bootcode,  
ставится на GTP диск, 
ставится на отдельный выделенный
только для него раздел. 
размер раздела неболее 544кб чтоли. 
ставится чтобы далее делать загрузку с фс ZFS.
ищет zfsloader чтоб передать ему управление. хотя нефакт. возможно вначале грузится loader а тот грузит
zfsloader

они постоянно нечеткр пользуют термины.
загрузка кода из MBR - bootstrat stage 0
загрузка кода из бутблока слайса - bootstrat starge 1 и 2
загрузка кода из фс - boostrap stage 3

итого 4 стадии

код стадий 0, 1, 2 то есть тот который читается как секторы называется boot blocks.

а loader который считывается уже некак сектора а через фс называется по другому.


командная строка 
boot:
появляется только при загрузке boot ( 1+2 стадии )

картина загрузки

для MBR диска
MBR - boot1+boot2 - loader

для GPT диска
PMBR - bootcode - loader

притом это все я описвыаю для загрузки со старого биоса.

под boot1+boot2 я подразумеваю далее стадию загрузчика между MBR\PMBR и loader, то есть это либо
/boot/boot = /boot/boot1+/boot/boot2 либо gptboot либо gptzfsboot

что интереесно для boo1+boot2 загрузчика есть конфиг файл /boot/boot.config

что интересно.

стадию MBR\PMBR вобще непоймать.
если тыкнуть ESC то загрузка остановится на стадии boot1+boot2

и вывалится меню

 >>	FreeBSD/x86 BOOT
     Default: 0:ad(0,a)/boot/loader
     boot:

в этом меню нельзя ничего выбрать. здесь можно только руками указать где искать loader
больше из этого меню ничего невыжать. никаких опций.

дале когда мы тыкнем мол грузи нам loader

если по экрану полетят буквы

Looking up /BOOT/LOADER... Found
Relocating the loader and the BTX
Starting the BTX loader

BTX loader 1.00 BTX version is 1.02
Consoles: internal video/keyboard
BIOS CD is cd0
BIOS drive C: is disk0
BIOS drive D: is disk1
BIOS 636kB/261056kB available memory


это значит что уже грузится loader

а вот когда мы увидим картинку 


Welcome to FreeBSD!

1. Boot FreeBSD [default]
2. Boot FreeBSD with ACPI disabled
3. Boot FreeBSD in Safe Mode
4. Boot FreeBSD in single user mode
5. Boot FreeBSD with verbose logging
6. escape to lader prompt
7. Reboot


это значит что мы попали в loader.
он загрузился и мы попали в его меню.

именно в этом меню уже можно  прописать кучу параметров.
это меню в каком то смысле похоже на меню загрузки GRUB. можно выбрать ядро и параметры
загрузки этого ядра.

таким образом только если загрузится loader мы сможем сделать чтото полезное для себя.

это значит что мы попали в меню loader


насколько я понял  если мы грузимся с MBR диска то в MBR в boot0 можно прописать таймаут.

если мы грузимся через старый биос через PMBR на GPT то туда таймаут 
непрописать. там вообще параметров никаких нет.

далее когда отрабатвыает boot1+boot2 то здесь тоже нет никаких ключей чтобы указать время на
таймаут. надо тупо успеть нажать кнопку и тогда загрузка останвится на стадии boot1+boot2

как я понял загрузка работает так:
комп из биоса читает какой диск типа загрузочный. и с него читает MBR\PMBR загрузчик.

тот в свою очередь обращается к boot1+boot2 загрузчику.
как видно что никаких параметров на этих фазах быть и неможет.

 
 boot1+boot2 уже имеет параметры загрузки.
 
 >>	FreeBSD/x86 BOOT
     Default: 0:ad(0,a)/boot/loader
     boot:


параметры которые он имеет это все что укаазано в строке 
0:ad(0,a)/boot/loader

то есть ему надо знать откуда брать loader

вот это и можно в него вносить.

по умолчанию он берет "первый" диск из биоса 
далее на нем он ищет либо партишн "a" если это UFS
либо первый zfs пул на диске и на нем берет датасет который  в пуле прописан как bootfs.

далее он грузит файл /boot/loader либо /boot/zfsloader

я к тому что boot1+boot2 отлично справляется с тем где ему искать loader без всяких
файлов конфигурации. он ищет скажем так по дефолтовому пути.


вот эту строку если она у  нас недефолтовая можно указать в файле

/boot/boot.config

или руками при загрузке

но повторю если путь у нас к loader дефолтовый то никаких файлов конфигурционных ему ненужно.


разберем эту строку

0:ad(0,a)/boot/loader


0 = номер диска с точки зрения БИОСа. фиг знает как этот номер опредеелить.

ad = это неназвание диска. нет. это тип контроллера к которому прикреплен диск.

ad - значит ide контроллер
da - значит scsi контроллер
(0, = номер диска с точки зрения контроллера на котором диск висит. тоже непонятно как его определять и 
непонятна связь между номером диска с точки зрения БИОСА и номером диска с точки зрения контроллера.
по мне в теории это должно быть одно и тоже. но неясно.
a = буква слайса с которго грузится. 
 
вообще запись  (0,а)  она укороченная. ибо партишн диск и партишн мы указали а где же номер слайса.
а может у нас четыре слайса на диске и на каждом есть партишены. и на каждом слайсе есть 'a' партишен и с
какого грузится ? так что полный путь выгляди так (0,1,a)
где 1 - номер слайса. если слайс неуказан то берется активный слайс , если и такого нет
то слайс 1 берется. обращаю внимание что номер слайса ставится перед буквой партишена.

/boot/loader = путь к loader

это так выглядит путь к лоадер когда  у нас UFS 
когда у нас zfs то путь к zfsloader выглядит на стадии boot1+boot2 вот так 

Default: zroot/ROOT/default:/boot/zfsloader

zroot/ROOT/default: = путь к датасету
/boot/zfsloader = путь к файлу


далее. я попробвал . если грузиися с CD-rom то как кнопки нетыкай попадаешь в loader меню

Welcome to FreeBSD!

1. Boot FreeBSD [default]
2. Boot FreeBSD with ACPI disabled
3. Boot FreeBSD in Safe Mode
4. Boot FreeBSD in single user mode
5. Boot FreeBSD with verbose logging
6. escape to lader prompt
7. Reboot

то есть более раннее меню boot+booot2 уже непопасть.

вот как выглядит путь к zfsloader для фринас инсталляции 

default: freenas-boot/ROOT/default:/boot/zfsloader


когдмы мы попадае в boot1+boot2 меню

>	FreeBSD/x86 BOOT
     Default: 0:ad(0,a)/boot/loader
     boot:
	 
	 помимо указания пути к loader мы еше можем нажать ?
	 и он покажет файлы в папке /boot
	 
	 это все что мы можемв  этом меню сделать
	 
	 

прикол. экспериментальным путем я выяснил что обычный БИОС с успехом 
грузится с диском который разбит как BSD .
видимо они весь нужный код уместили в теже самые 446 байтов. так что  он как бы
совместим с MBR спецификацей. 
так что BSD разбивка она успешно грузится обычнм биосом.
опасность только одна. что если такой диск увидит другая ОС то она посчтает что он пустой.
а так все отлично.

вот у меня есть диск BSD

$ gpart show
=>       0  16777216  da0  BSD  (8.0G)
         0  15935488    1  freebsd-ufs  (7.6G)
  15935488    839680    2  freebsd-swap  (410M)
  16775168      2048       - free -  (1.0M)


загрузка на уровне boot1+boot2 к loader имеет путь

     Default: 0:ad(0,0,a)/boot/loader
	 
	 насколько я понял номер слайса 0 потому что слайсы есть тольк в MBR и GPT разбивке. в BSD разбивке
	 слайстов просто нет. поэтому номер слайса 0
	 

путь к loader для boot1+boot2 стадии загрузки для MBR диска с UFS

default: 0:ad(0,1,a)/boot/loader

кстати то что можно смотреть список файлов на стадии boot1+boot2 через '?' 

ad(0,0,e)?

то есть пишем полный путь к партишену. и в конце добавляем '?'
и boot1+boot2 покажет список тамошних файлов. 
думаю если папку добавить он и список файлов внутри папки покажет

еще раз подвтерждает что boot1+boot2 умеет читать файловую систему а не просто сектора.
ну а как иначе . ведь он иначе бы несмог прочитать loader

жалко что на этой стадии нельзя посмотреть список доступных дисков.


что  у меня получилось. на  da0 диске на 1 слайсе я создал партишен d 
и скоприровал туда пару файлов.

в итоге посмотрел спмсок файлов через такую строку

0:ad(0,1,d)?


также посмотрел список файлов внутри папки /boot/kernel

0:ad(0,1,a)/boot/kernel/?

далее я взял da1 диск ( то есть второй ). на нем создал слайс  1 и на нем партишен 'a' и скопировал файлы
смог их посмотреть через команду

1:ad(1,1,a)/?

походу пьесы  первое число и второе число то есть номер диска вбиосе и номер диска 
на контроллере всегда совпадают

надо помнить что для партишена когда мы его редактируем через bsdlabel -e то надо самому 
вписывать тип файловой системы 4.2BSD потому что форматирующая команда newfs этого неделает.

 я попрбовал с помощью boot1+boot2 прочитать содержимое gpt диска. и  у меня неполучилось.
далее выяснилась куче всего интересного.
для того чтобы загрузитьс с GPT+UFS диска нужен другой bootcode(boot1+boot2) нужен /boot/gptboot
это прояснило почему boot1+boot2 неумеет читать UFS с GPT диска.
далее ожидаемо что gptboot ставится на выделенный микрораздел freebsd-boot
но это невсе. оказалось что bsdlabel система она ненужна на GPT диске.
на GPT диске создается раздел с типом freebsd-ufs и newfs умеет сразу с ним работаь и форматировать
и на нем ненужно использовать bsdlabel чтоб можно было слайс отформатировать.
итак можно через gpt отрезать слайс и сразу его форматировать без нанесения предвариетлно на него
bsdlabel. 
в fstab такой раздел будет иметь путь /dev/da0p1  (больше ненужно всяких там букв на конце типа da0p1a)
да на GPT можно создать слайс с типом freebsd  и на такой слайс можно наносить bsdlabel
но в man написано что это прошлый век и ненадо юзать bsdlabel с gpt.
таким образом получается что bsdlabel это штука чисто из мира MBR дисков.
на GPT про нее можно благополучно забыть. 
bsdlabel придумали тока изза того что MBR позволяет иметь всего 4 слайса. а надо было всегда больше.
вот и изголялись как могли.
в GPT 128 слайсов так что хватит навсе провсе. и от bsdlabel откзались наконец.
поэтому с GPT можно работаь как в линукс. без букв наконце и доп разбивок bsdlabel
но и это еще не все.
когда я загрузился с gptboot то вот как выглядит для gptboot путь к загрузчику

0:ad(0p2)/boot/loader

вместо классического (0,a) теперь (0p2)
причем синтаксис таких путей уже неописан в man gptboot  а жаль.
также когда мы юзаем gptboot то он ищет  слайс который имеет атрибут bootme
атрибут можно установить такой командой

# gpart set -a	bootme -i 2 ada0

таким образом загрузка идет по разному для разных случаев через разные загрузчики
которые работают по разному. зависит от MBR\GPT + UFS\ZFS.

думаю с bootcode загрузчиками можно закончить. 
в них особо выбирать нечего. поэтому он либо грузится либо нет. а если негрузится
скорей всего проблема уже с фс.

кстати man boot говорит о том что boot2 может загрузить ядро сам без участия loader
для этого мол надо вместо пути к loader указать путь к ядру. прямо вот так

0:ad(0,a)/boot/kernel/kernel

я попробовал и ничего неполучилось. система просто выпала в полный осадок и вывела
halt.
и каково же было мое удивление когда я на багзилле фрибсд нашел что я неодин такой
и что так оно и есть уже много лет. что boot2 по факту неможет загрузить ядро
напрямую. вроде когда то он это умел когда работал на 32 битных процессорах.
так что получается фрибсд нетакой уж охуенно сделанный тщательно.
по крайней мере маны в ней тщательно не выверяются. да и я почитал отношение
разработчиков на отклики людей на этот баг. ну и им вобщем то похуй.
очень жаль. что вот такое отношение. такая ситуация. получается документации
нельзя верить на 100% фрибсдэшой. там может быть и полная хуйня.

получается главня цель boot1+boot2 это найти loader и его запустить. и все. 
ему только надо знать диск, слайс, партишн (если он есть), папку и файл.
вот и вся цель boot1+boot2 загрузчика. вот и все его возможные параметры.

будем считать что загрузку bootsect=(MBR-boot1+boot2) я освоил и понял, как ее ставить 
в каком случае какие файлы юзаются, и какие опции можно руками там выставлять.



Переходим к loader 
к следущему этапу загрузки,
тут уже реально много полезных вариантов что можно подкручивать.

статическая линковка библиотек к программе означает что те куски кода которые 
прилинкованы статически значит они физически вмонтированы в бинарник тела программы.
она все свое носит с собой. так и есть у loader. потому что нам надо загрузиться и тут не до 
понтов. динамическая линковка означает что бибилтотеки которые программма использует 
они лежат еще где то там на файловой системе и их нужно найти и прочитать чтобы  в итоге 
программа заработала.

loader как то там связан с языком Forth. и он читает конфиги на этом языке.
захера нужен этот форт. да еще в этом месте.
вобщем на этом языке как я понял код получается очень маленький по размеру.
и на какойто стадии загрузки ОС типа удобно применять этот форт. и встраивать его 
удобно изза размера во встраиваемые системы. вобщем плюс форт то что он дает 
функционал и при этом его код файла занимает очень мало места

> lsdev

покажет диски и разделы которые видит loader

если мы грузимся с zfs то в loader можно посмотреть список файлов в датасете

> lszfs /freenas-boot/ROOT/default

команда show показывает всякие разные перменные загрузки
в том числе kern.*

> show

очень удобная вещь это то что можно сдлеать так что когда ядро будет грузится
то после каждой линии выведенной на экран будет пауза и нужно будет нажать кнопку чтобы грузиться дальше
и чтобы показалас следующая линия.

> set boot_pause=1

1 это не время задержки это означает включить режим паузы.

очень удобно если мы хотим посмотреть на режим загрузки ядра шаг за шагом.
как он определяет устройства итд.

(полнй выввод как мы помним можно помтом посмотреть через dmesg)












процесс загрузки freebsd
продожение

==================================================================================
==================================================================================


идентификация дисков в пуле

root@freenas-202:~ # camcontrol devlist
<ATA Samsung SSD 850 2B6Q>         at scbus0 target 31 lun 0 (pass0,da0)
<ATA WDC WD6003FRYZ-0 1H01>        at scbus0 target 32 lun 0 (pass1,da1)
<ATA WDC WD6003FRYZ-0 1H01>        at scbus0 target 33 lun 0 (pass2,da2)
<ATA ST4000NM0033-9ZM SN04>        at scbus0 target 38 lun 0 (pass3,da3)
<ATA ST4000NM0033-9ZM 0001>        at scbus0 target 39 lun 0 (pass4,da4)
<ATA D2CSTK251M14-012 2.25>        at scbus0 target 43 lun 0 (pass5,da5)
<ATA INTEL SSDSC2CW24 400i>        at scbus0 target 44 lun 0 (pass6,da6)
<JetFlash Transcend 16GB 1100>     at scbus2 target 0 lun 0 (pass7,da7)
<JetFlash Transcend 16GB 1100>     at scbus3 target 0 lun 0 (pass8,da8)
<JetFlash Transcend 16GB 1100>     at scbus4 target 0 lun 0 (da9,pass9)

тут видим какой диск (da0)  сколько у него размер


вот так мы видим имя диска  (da0) и какие guid-ы слайсов на нем

root@freenas-202:~ # gpart list | grep -E "Geom name|rawuuid"
Geom name: da0
   rawuuid: 4f9a0780-4b6f-11ea-bb91-80c16e650184
Geom name: da1
   rawuuid: 1823a5f1-4aab-11ea-8a35-80c16e650184
   rawuuid: 18342775-4aab-11ea-8a35-80c16e650184
Geom name: da2
   rawuuid: 1167a0ea-4aab-11ea-8a35-80c16e650184
   rawuuid: 117aacf2-4aab-11ea-8a35-80c16e650184
Geom name: da3
   rawuuid: 1e87ddd8-4aab-11ea-8a35-80c16e650184
   rawuuid: 1e932b20-4aab-11ea-8a35-80c16e650184
Geom name: da4
   rawuuid: 1f580da3-4aab-11ea-8a35-80c16e650184
   rawuuid: 1f64f5ac-4aab-11ea-8a35-80c16e650184
Geom name: da5
   rawuuid: 3fd475c6-4b6f-11ea-bb91-80c16e650184
   rawuuid: 3fece146-4b6f-11ea-bb91-80c16e650184
Geom name: da6
   rawuuid: 43c38918-4b6f-11ea-bb91-80c16e650184
   rawuuid: 43dbf316-4b6f-11ea-bb91-80c16e650184
Geom name: da7
   rawuuid: 248cfc21-a77e-11ea-bb91-80c16e650184
   rawuuid: 2cc48ec9-a77e-11ea-bb91-80c16e650184
Geom name: da8
   rawuuid: 27205075-a77e-11ea-bb91-80c16e650184
   rawuuid: 2ddd61c6-a77e-11ea-bb91-80c16e650184
Geom name: da9

а вот так мывидим какие guid слайсы входят в тот или пул.

root@freenas-202:~ # zpool list -v
NAME                                     SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
HDDx4                                   9.06T  1.07T  7.99T         -    10%    11%  1.00x  ONLINE  /mnt
  mirror                                5.44T   690G  4.76T         -     9%    12%
    gptid/117aacf2-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/18342775-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
  mirror                                3.62T   406G  3.23T         -    13%    10%
    gptid/1e932b20-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
    gptid/1f64f5ac-4aab-11ea-8a35-80c16e650184      -      -      -         -      -      -
log                                         -      -      -         -      -      -
  mirror                                7.94G  15.5M  7.92G         -     0%     0%
    gptid/3fece146-4b6f-11ea-bb91-80c16e650184      -      -      -         -      -      -
    gptid/43dbf316-4b6f-11ea-bb91-80c16e650184      -      -      -         -      -      -
cache                                       -      -      -         -      -      -
  gptid/4f9a0780-4b6f-11ea-bb91-80c16e650184   420G  42.2G   378G         -     0%    10%
freenas-boot                            14.6G  1003M  13.6G         -     0%     6%  1.00x  ONLINE  -
  mirror                                14.6G  1003M  13.6G         -     0%     6%
    gpt/zfs-bootmirror-1                    -      -      -         -      -      -
    gpt/zfs-bootmirror-2                    -      -      -         -      -      -

 
 и еще вот так посмореть gpt labels
 
 root@freenas-202:~ # gpart show -l
=>       40  880803760  da0  GPT  (420G)
         40         88       - free -  (44K)
        128  880803664    1  (null)  (420G)
  880803792          8       - free -  (4.0K)

=>         40  11721045088  da1  GPT  (5.5T)
           40           88       - free -  (44K)
          128      4194304    1  (null)  (2.0G)
      4194432  11716850688    2  (null)  (5.5T)
  11721045120            8       - free -  (4.0K)

=>         40  11721045088  da2  GPT  (5.5T)
           40           88       - free -  (44K)
          128      4194304    1  (null)  (2.0G)
      4194432  11716850688    2  (null)  (5.5T)
  11721045120            8       - free -  (4.0K)

=>        40  7814037088  da3  GPT  (3.6T)
          40          88       - free -  (44K)
         128     4194304    1  (null)  (2.0G)
     4194432  7809842688    2  (null)  (3.6T)
  7814037120           8       - free -  (4.0K)

=>        40  7814037088  da4  GPT  (3.6T)
          40          88       - free -  (44K)
         128     4194304    1  (null)  (2.0G)
     4194432  7809842688    2  (null)  (3.6T)
  7814037120           8       - free -  (4.0K)

=>      40  20971440  da5  GPT  (10G)
        40        88       - free -  (44K)
       128   4194304    1  (null)  (2.0G)
   4194432  16777040    2  (null)  (8.0G)
  20971472         8       - free -  (4.0K)

=>      40  20971440  da6  GPT  (10G)
        40        88       - free -  (44K)
       128   4194304    1  (null)  (2.0G)
   4194432  16777040    2  (null)  (8.0G)
  20971472         8       - free -  (4.0K)

=>      40  30850992  da7  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  zfs-bootmirror-1  (15G)
  30849024      2008       - free -  (1.0M)

=>      40  30850992  da8  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  zfs-bootmirror-2  (15G)
  30849024      2008       - free -  (1.0M)

=>      63  30851009  da9  MBR  (15G)
        63       177       - free -  (89K)
       240  30850832    1  (null)  (15G)



таким образом  понятно что da9 никуда невходит.

--
разметить флэшку\диск и добавить как hotpare к пулу


 а вот пример как  я разметил da9 чтобы она была такой же как da8
 
 root@freenas-202:~ # gpart show da9
=>      63  30851009  da9  MBR  (15G)
        63       177       - free -  (89K)
       240  30850832    1  !12  (15G)

root@freenas-202:~ #
root@freenas-202:~ #
root@freenas-202:~ # gpart show da8
=>      40  30850992  da8  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  freebsd-boot  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  freebsd-zfs  (15G)
  30849024      2008       - free -  (1.0M)

root@freenas-202:~ #
root@freenas-202:~ #
root@freenas-202:~ # gpart delete -i 1
gpart: Invalid number of arguments.
root@freenas-202:~ # gpart delete -i 1 da9
da9s1 deleted
root@freenas-202:~ # gpart destroy da9
da9 destroyed
root@freenas-202:~ # gpart create -s gpt da9
da9 created
root@freenas-202:~ #
root@freenas-202:~ # gpart add -t freebsd-boot -b 2048 -s 1024 -i 1 da9
da9p1 added
root@freenas-202:~ # gpart add -t freebsd-zfs -b 4096 -s  30844928 -i 2 da9
da9p2 added
root@freenas-202:~ #
root@freenas-202:~ #
root@freenas-202:~ # gpart show da9 da8
=>      40  30850992  da9  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  freebsd-boot  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  freebsd-zfs  (15G)
  30849024      2008       - free -  (1.0M)

=>      40  30850992  da8  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  freebsd-boot  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  freebsd-zfs  (15G)
  30849024      2008       - free -  (1.0M)


далее я создаю gpt label на da9

root@freenas-202:~ # gpart modify -i 2 -l zfs-bootmirror-hotspare da9
da9p2 modified
root@freenas-202:~ #
root@freenas-202:~ #
root@freenas-202:~ # gpart show -l da8 da9
=>      40  30850992  da8  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  zfs-bootmirror-2  (15G)
  30849024      2008       - free -  (1.0M)

=>      40  30850992  da9  GPT  (15G)
        40      2008       - free -  (1.0M)
      2048      1024    1  (null)  (512K)
      3072      1024       - free -  (512K)
      4096  30844928    2  zfs-bootmirror-hotspare  (15G)
  30849024      2008       - free -  (1.0M)

root@freenas-202:~ #

далее я добавляю da9 слайс zfs-bootmirror-hotspare в пул как hotspare раздел

root@freenas-202:~ # zpool add freenas-boot spare /dev/gpt/zfs-bootmirror-hotspare
root@freenas-202:~ #
root@freenas-202:~ #
root@freenas-202:~ # zpool status -v freenas-boot
  pool: freenas-boot
 state: ONLINE
  scan: none requested
config:

        NAME                           STATE     READ WRITE CKSUM
        freenas-boot                   ONLINE       0     0     0
          mirror-0                     ONLINE       0     0     0
            gpt/zfs-bootmirror-1       ONLINE       0     0     0
            gpt/zfs-bootmirror-2       ONLINE       0     0     0
        spares
          gpt/zfs-bootmirror-hotspare  AVAIL

errors: No known data errors
root@freenas-202:~ #

проверяем что сервис zfsd запущен

 # service -e | grep zfsd
/etc/rc.d/zfsd

-------

смотрим  dmesg

dmesg это запись всего того что фрибсд вываливает на физический экрна консоли с момента 
загрузки и до конце до ребута.

da3: quirks=0x140<RETRY_BUSY,STRICT_UNMAP>

quirks - это такие особенности которые есть у железок. их индивидульные особенности 
по факту это такие куски софта которые добавляюти в фрибсд чтобы учитывать индивиуальные глюки
железок чтобы в итоге они работали и не падали. индивиуадльные заебы железок. 
и на них добавляют код . кторый компенсирует учитывая что с ними делать нельзя. а что надо делать
но через жопу.

далеко ненавсе квирки можно найти обьяснение что они значат.

прикол в том что драйвер часто пишется недля конкретной железки.
а сразу для широкого класса железа. драйвер который поддерживаетт сразу тонну железок. поому что эти железки
они работают на основе стандарта какогото. но часто конкретная железка несовсем поддерэживает 
стандарт. и надо чтобы драйвер знал что вот с этой конкретнрой эжелезкой вот это делать нельзя.а это 
надо сделать нестандартно. это назыается написать для железки квирк

(http://www.root.org/~nate/freebsd/scsi/quirks.html)
 we have created a quirks mechanism to indicate to the driver that it 
 must avoid certain commands or use them differently with a specific model and/or version of hardware. 


блочные устройства обычно соответсвуют либо RBC либо SBC стандарту

Multimedia devices including CDROMs and DVD-RW are usually MMC-compliant.



--------

gpart show 
показывает невсе диски что подключены к системе.
все диски показывается

# camcontrol devlist

также мжоно в 

# dmesg -a | grep ^da

увидеть.

а gpart show показыает только диски у которых уже есть таблица разбиения.

---

по дефолту фрибсд недаст модифицировать MBR или GPT таблицу разделов
на диске с которого грузится.

так написано в хэндбуке.

более точно оно недаст напрямую записывать в эти сектора руками.

например если загрузочный диск MBR то

 # dd if=/dev/zero of=/dev/da0 bs=512 count=1
dd: /dev/da0: Operation not permitted

и это отлично правильно и хорошо.

за эту защиту отвечает перменная

# sysctl -a | grep kern.geom.debugflags
kern.geom.debugflags: 0

если ее сдедать = 16  то тогда можно будет рушить MBR\GPT рукками записывая в их сектора мусор.

что интересно что на загрузочном диске можно модифицировать MBR\GPT но 
через утилиты. например через gpart

например

вот мы добавили размер  диска для виртуалки.
диск загрузочный. и мы хотим налету расширить его из работающей фрибсд.

# gpart resize -i 1 -s 20G -a 1M da0

и эта команда прокатит.
никакой модификации   kern.geom.debugflags непонадобится.

как я понял расширять можно слайс к которому примыкает свободное пространство.

---
в компе на физ уровне есть несколько чипов которые выдают инфо о времени.

разница в них в том что у них разная разрешающая способность. у одних это 0.5с
а удругих  наносекунды.

RTC - Real Time Clock  (0.5с)
TSC - Time Stamp Counter ( разрешение 64 бит. работает на частоте проца)
PIT - Programmable Interrupt Timer ( разрещение 16 бит)
APIC - Advanced Programmable Interrupt Controller ( разрешение 32 бит, работает на частоте 
зависящим от шины цпу что ли.)
ACPI_PM - ACPI Power Management Timer ( работает на частоте 3.58MHz)
HPET - High Precision Event Timer ( разрешение 64 бит, и в этом чипе до 8 независимых часов сразу)

HPET  - самый навроченный. самый точный.


посмтреть какие источники есть в системе

# cat /sys/devices/system/clocksource/clocksource0/available_clocksource


посмотреть какой из них линукс ипользует для своих нужд.

# cat /sys/devices/system/clocksource/clocksource0/current_clocksource

===
посмотреть какие диски есть в системе и какой у них размер в байтах

# geom disk list

====



root@truenas-0-233[~]# gpart destroy -F ada1
ada1 destroyed

root@truenas-0-233[~]# gpart create -s gpt ada1
ada1 created

root@truenas-0-233[~]# gpart add -b 2048 -t freebsd-zfs -i 1 ada1



root@truenas-0-233[~]# gpart show ada1
=>        40  3907029088  ada1  GPT  (1.8T)
          40        2008        - free -  (1.0M)
        2048  3907027080     1  freebsd-zfs  (1.8T)



root@truenas-0-233[~]# gpart list ada1
Geom name: ada1
modified: false
state: OK
fwheads: 16
fwsectors: 63
last: 3907029127
first: 40
entries: 128
scheme: GPT
Providers:
1. Name: ada1p1
   Mediasize: 2000397864960 (1.8T)
   Sectorsize: 512
   Stripesize: 0
   Stripeoffset: 1048576
   Mode: r0w0e0
   efimedia: HD(1,GPT,a1766594-d147-11f0-8e60-14dae9dc008a,0x800,0xe8e08088)
   rawuuid: a1766594-d147-11f0-8e60-14dae9dc008a
   rawtype: 516e7cba-6ecf-11d6-8ff8-00022d09712b
   label: (null)
   length: 2000397864960
   offset: 1048576
   type: freebsd-zfs
   index: 1
   end: 3907029127
   start: 2048
Consumers:
1. Name: ada1
   Mediasize: 2000398934016 (1.8T)
   Sectorsize: 512
   Mode: r0w0e0



]# ls -1 /dev/gptid/
48ba50a5-d141-11f0-a759-14dae9dc008a%  a1766594-d147-11f0-8e60-14dae9dc008a%


root@truenas-0-233[~]# zpool create -o ashift=12 POOL-01  /dev/gptid/a1766594-d147-11f0-8e60-14dae9dc008a
root@truenas-0-233[~]# 
root@truenas-0-233[~]# zpool status -v POOL-01
  pool: POOL-01
 state: ONLINE
config:

	NAME                                          STATE     READ WRITE CKSUM
	POOL-01                                       ONLINE       0     0     0
	  gptid/a1766594-d147-11f0-8e60-14dae9dc008a  ONLINE       0     0     0

errors: No known data errors
root@truenas-0-233[~]# 




====

