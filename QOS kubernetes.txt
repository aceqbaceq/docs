QOS
kubernetes

QOS это следствие. а так оно опирается на 
requests и limits

оно прописывается для кждого контейнера в поде.

requests это заявленный минимум который контейнер требует себе.
запррашивается CPU и память.

так вот requests 
	влияет на то что шедулер смотрит на какой хост засунуть этот контейнер точнее под с этим контейнером.

requests это минимум который куб обязан гарантировать контенеру.
сотвсвтенно куб пере тем как сунуть под на хост он считает сумму 
все ресурсов всех подов которые там крутятся. и он не будет совать
на тот хост под если это приведет к превыщению мощности компа по сумме запроошенных  requests.

пример. 
	хост имеет 2 cpu = 2000m
	и 2GB  памяти.

на хосте крутится под у которого прорисано 
	 requests
		cpu 1200m
		ram 1Gi
		
соотсвтенно если мы хотим на этот хост засунуть под у которого
		 requests
			cpu 1200m
			ram 1Gi
то куб этого не будет делать потому что 1200+1200 = 2400 > 2000

но из скзаанного выше следует что requests эта штука важна только для шедулера. она влияет только на то что будет под засунут на хост или нет.
на сам под этот параметр никак невлияет. он скажем так никак не меняет свойства пода. он только влияет на то что сможет этот под войти на этот хост или нет.
	шедулер размещает столько подов на хосте чтобы из requests <= мощности компа. 
этой настройкой под завляет что ему нужно обеспечить этот минимум. requests это запрашиваемый со стороны пода минимум. 

то есть со стороны пода resurce означает заявление = " я буду использовать как минимум" + "куб ты мне обязан обеспечить этот минимум".

из того что под будет использовать этот минмум незначит что он небудет использовать больше. ему разрешено использовать больше если есть такая возможность по ресурсам.

у щедулера есть две политики которая на нем активирована (либо одна 
либо другая)
	LeastRequestedPriority 
	MostRequestedPriority
	
вторая  из них это то что шедулер будет стараться как можно плотнее забить вначале один хост а уже потом преейдет ко второму. а первая что он будет срараться как можно равномернее забивать ноды.

итак как уже было сказано request это минимум сколько под заявил что ему нужно ресурса для работы. и он требует у кубе ему гарантировать что он это всегда  получит. 

значит как куб ему это гарантирует.
положим на хосте два пода.
	один заказал 2 цпу
	второй заказал 4 цпу
	а всего цпу 10.

так вот если поды начнуть жрать больше цпу чем они минимально заказали
то куб из того что они будут жрать выше своего заказа будет выделять подам в той пропорции как относятся из изначальные заказы. 
 тоесть если оба пода в сумме на 100% загрузили хост то
	первый под получит 2цпу гарантированоо
	второй под получит 4 цпу гарантированно. 
	остается 4 цпу. и вот этот оставшисяй 4цпу ресурс будет поделен между ними в отношении 2:4 
	2х+4х=4
	первый получит 2+1.33
	второй получит 4+2,67
	при этом видно что каждый получил точно тот минимум который заказывал.
	
таким образом мы увидели что параметер requests 
 влияет с точки зрения пода:
	на то сколько ресурсов 100% этот под получит минимум
 шедулеру этот параметр позвоялет понять на какой хост этот под
можно засунуть чтобы ему эту мощность гарантировать что он ее получит.
 шедулер принимает решение пихать под на этот хост или нет сууммирую
все requests всх подов которые на этом хосте уже крутятся и смотрит
осталось ли чтото в запасе. считает он именно requests а не то сколько 
они там щас по факту потребляют.
 также request влияет на то сколько мощности сверху от заказанной этот под получит сверху.

с точки зрения отожранного цпу видно что можно не бояться что какойто под начнет жрать цпу больше чем у него написано в rqueuests и другому недостанется. нет. прежде всего каждый под 100% получит ту мощност что он заказал. ну а если на компе после этого чтото осталось то она будет разделеа пропорционально соотношению их requests. ну это и логично. каждый под получит в % соотношении одинаковое приращение. 

насколько я понял если под заказал 10% минимум цпу но прям щас столько непотребяет то его как как говортся неисопльзованный кусок абсолютно свободоен в этот момент для других. другое дело что если он ему понадобится то куб мгновенно ему отдаст 10%. 
таким обрахом requests 10% неозначает что теперь это 10% потерянных навсегда для остальной системы. нет. если этот под поребляет щас меньше то оставшееся идет на всеобщее растерзание.
если мы опубликуем под у которго requests 90% но этот под щас потребляет 5% то 85% которые он непотребляет доступны остальным.

 про то какая логика при request для RAM я пока на рассматриваю.

поскольку цпу является типа сжимаемым ресурсом. то есть если что можно процесс поставит на троттлинг и все окей. то память неявляется сжимаемой.
поэтому если для цпу достаточно requests то для памяти нужен еще параметр limits. он ограничивает сверху больше которого мы неразрешаем.
если скажем под выжрет больше памяти чем указано в limits то куб его кильнЁт. 
 если процесс хочет сожрать больше цпу чем ему разрешено в limits то он тогда троттлится. если процесс пытается выжрать больше памяти чем ему разрещшено в limite то  он убивается.

как по цпу нужно выбирать величину request для пода.
нужно себя спросить если на хосте куча подов и все они хотят выжрать весь  цпу то скольо мощности 100% должно быть доступно этому поду. порог ниже которого опускаться нельзя. в том плане что эта величина если она нужна всегда должны быть доступна как бы хост небыл загружен по цпу. под
может потреблять и меньше и остаток будет доступен другим то есть эта величина не является потерянной для других навсегда. тут помогает бейслайн загрузки этого сервиса. скажем 

среднее 8.9%
максимум 9.2%

я выбиру request = 10m 
если под будет потреблять меньше то остаток будет доступен другим.
а если ему захочется пикануть то у него всегда эта возможность будет.

что касается памяти то request означает сколько памяти всегда потенциально должно быть доступно на сервер если он весь переполнен подами по памяти. обыяно по бейслайну видно у сервиса сколько он памяти выжирает. чуть накинуть сверху и столько и выставлять.
а еще сколько то сверху накинуть на лимит. это на случай если у процесса утечки есть. чтобы тогда система его кильнула. и он заново отрастал.

request это сколько всегда должно быть доступно на переполненой системе.
с другой стороны это не оторванный ломоть. если поду щас стколько ненадо 
то остатвки будут доступны остальным.


 
 

также выяснилось что путем указания опрделенных флагов при старте kubelet
мы можем зарезеривать на хосте куба столько то cpu и RAM для кубелета и 
и вроде как я понял системных подов куба (подов которые принадлежат kube-system и крутятся на данном хосте) и сколько то для остальных процессов линукса типа ssh bash итп.  чтобы сами поды в сумме невыжрали все. чтоб можно было зайти на хост и спокойно по нему лазить в компандной строке. 
вот эта тема
	https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/
называется Node allocate




	