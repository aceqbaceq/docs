| vlan
| iptables
| logging
| bond

есть такая тема. я построил вот такую схему


                        |
                        | 
vethN1.2 --- vethN1 ----| ----- vethN2 --- vethN2.2 
                        |
                        |


ввертикальная палка разделяет карты которые
сидят в разных неймспейсах


так вот я когда пингую тот второй интфрейс vethN2.2
то вижу в логах

[RAW OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2 
[NAT-OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2
[FILTER-OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2
[NAT-POSTROUTING icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2

из чего видно что  логи иптейблс покзыают что
якобы в нашем нейсмпейсе трафик течет только 
через карту vethN1.2 тоесть 


                |
                | 
vethN1.2 --- ---| ----- ...
                |
                |


а как же карта vethN1 ?
ведь если запустить тцпдамп то четко видно что
через vethN1 трафик течет и еще как!


так вот теперь про разгадку этой загадки.
как работает логинг в иптейблс. поговорим щас 
для определенности про старый иптейблс. так вот
код иптейблс делит все сетевые карты на две группы
это L3 карты и L2 карты. это такие деибильные термины.
щас об этом поговрим. если порт входит в состав
вирт бриджа то такой порт считвается L2(за исключегием
порта который обозначает сам бридж тоесть порта
с именем br* ибо этот порт хотя и входит в состав
бриджа то явлется L3)
все остальыне порты считаются L3.
названия L2 L3  это просто так дебильно подбобраный 
термины. не стоит мучиатлно искать в них настоящий
смысл. так вот это еще не конец. если у нас в ядро
попал пакет то иптейблс смотрит из какого порта
пакет влетел в ядро. если это L2 порт то пакет 
направляется в таблицу правил ebtables.
если это L3 порт и при этом пакет в себе содержит 
ARP протокол он напрлавляатся на таблицу правил 
arptables. а если это порт L3 и другой проткол то 
напоавляется в таббицу правил iptables.

логинг активируется так что в этих таблицах
пропсиывается правило активируещщее логинг. 

если мы хотим увидеть в логах полный путь пролета
пакета внутри ядра то нужно обязатеьно логинг привиа
активировать во всех таблицах - в arptables, ebtables, iptables. 

если мы актиурем логинг только в части таблиц 
то так как пакет может скакать между L2 и L3 поратми
то мы не зафиксируем полный путь путещсествия пакета
между портами.  в этом первая хитрость от чего
зависит видим ли мы в логах полный сетевой тракт
или толко частичный.

итак если пакет шарится только через L3 карты 
то чтобы нам зафкисировать его путь нужно сунуть
праивила в iptables и artables. про второе можно 
сразу забыть потому что во втором фиксируется на какие
порты прилетает ARP трафик. он нам неинтеерсен. 
поэтому можно совать правила только в iptabes таблицы.

если же мы считаем что пакет также пролетит между 
L2 поратми то нужно создавать правила логинга и в
ебтейблс таблицах.

далее супер важно. возникает мысль что если мы 
все так сделаем то мы увидим в логах полный 
путь между каким портами скакал пакет. И ЭТО ПОЛНАЯ
ХУЙНЯ. ЭТО НЕТАК.


если мы посмотрим на нашу исходную схему



                        |
                        | 
vethN1.2 --- vethN1 ----| ----- vethN2 --- vethN2.2 
                        |
                        |



то здесь пакет когда он летит то он пролетает
чере каждую карту. среди этих портов нет L2 портов
потому что тут ни один порт не входит в состав
бриджа. значит это все L3 порты. значит правила
логинга надо добавиьт только в таблицы iptables.
окй можно престрахтваться и также сунуть правила
и  в ебтейблс. в любом случае в логах при пинге
мы увидим тлоько вот такое

[RAW OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2 
[NAT-OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2
[FILTER-OUTPUT icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2
[NAT-POSTROUTING icmp] IN= OUT=vethN1.2 SRC=172.16.100.1 DST=172.16.100.2


тоесть якобы путь нашего пакета


приложение - vethN1.2 - другой сет неймпейс


тоесть мы не увидели в логах карту vethN1.2
так почему? может она не L3?  может  она L2 
но я добавил приавлв  в ебтейблс и все равно влогах
пусто. так что за херня ведь точно известно через
тцпдамп что поток летит через эту карту.
и я сразу опять говорю что vethN1 это не L2 карта потому что она не входит в состав брижа.

так в чем же прикол. а прикол вот в чем. 
когда у нас пакет влетел в ядро из карты L3 либо 
из сокета приложения то этот пакет обарабвыается
в ядре кодом правил iptables (тоест имеется
ввиду не правилами ebtables , arptables это не всегда
так но это щас неважно), так вот когда ядро прогоняет
пакет по цепочкам iptables то есть один из шагов
называется ROUTING DECISION это кодга код оббращается
к табице мрашрутиацзии и ищет там правило.
когда правила находится то из него в частности 
иптейблс берет имя карты в которую будет засунет 
пакет. и это имя карты и фигурирует в логах иптейблс.
так вот - вот моя таблица мрашутиазации


default via 192.168.136.246 dev wlp2s0 proto dhcp src 192.168.136.1 metric 600 
10.233.65.0/24 via 10.233.65.0 dev veth0 onlink 
172.16.10.0/24 dev br0 proto kernel scope link src 172.16.10.1 metric 426 
172.16.80.0/24 dev bondV2.2 proto kernel scope link src 172.16.80.1 metric 400 
172.16.90.0/24 dev bondV2.3 proto kernel scope link src 172.16.90.1 metric 401 
172.16.100.0/24 dev vethN1.2 proto kernel scope link src 172.16.100.1 
172.17.20.0/24 dev tun0 proto kernel scope link src 172.17.20.1 metric 450 linkdown 
172.17.30.0/24 dev dummy0 proto kernel scope link src 172.17.30.1 metric 550 
192.168.136.0/24 dev wlp2s0 proto kernel scope link src 192.168.136.1 metric 600 

и из нее видно что из интерсующих нас карт
тут есть тольк одно правилоа и одна карта


172.16.100.0/24 dev vethN1.2 proto kernel scope link src 172.16.100.1 


поэтому так как в таблице нет правила с картой vethN1
то эта карта поэтмоу никогда и не будет видна 
в логах иптбейс!!! вот вчем разгадка!!

тоесть полуается что пакет из сокета программы
попадетв ядро в иптбейлс. тот находит правило

172.16.100.0/24 dev vethN1.2 proto kernel scope link src 172.16.100.1 

из таблицы маршрутизации и в итоге сует  пакет
в карту vethN1.2 что и видно влогах.
а далее  интерсный момент в том что далее ядро 
берет пакет и без всяких прогонов по иптблейс 
цепочкам переклаывает этот пакет в карту vethN1
делает это ядро без всякого иптейблс. а раз нет
прогоно чреез иптбйлс то нет и логов от кода 
иптейблс в журнале. птому что по логике должно 
было быть так
я имею ввиду полет пакета внутри ядра:

приложение -- сокет --- ядро -- иптебйлс -- vethN1.2
--- иптейблс ---vethN1 --- другой сет неймспейс

а мы имеем

приложение -- сокет --- ядро -- иптебйлс -- vethN1.2
--- vethN1 --- другой сет неймспейс


тоеть между vethN1.2 и vethN1 нету прогона через 
иптбейлс. поэтому нет и записи про полет пакета
через карту vethN1!

а что было бы если бы такой прогон был. ответ - ничего
хорошего. ипблейс пошел бы в таблице мрашутизации
опять бы нашел тоже самое правило

172.16.100.0/24 dev vethN1.2 proto kernel scope link src 172.16.100.1 


и сунул бы пакет обратно в vethN1.2 , тоесть у нас только  что пакет оттуда прилеетел чтобы лететь 
дальше а мы бы просто тупо его засунули бы на прдыдущ
ий шаг. поэому ядро переклыает пакет из vethN1.2
в vethN1 без прогона через код иптбейлс.
вот в чем секрет. 

еще раз почдекрну что в логах ипблейс никогда 
не будет записей про L3 карты на компе чрезе которые
пакеты реаьно прогонятся если  в тмаблице маршрути
зации нет записей свзяанных с этими картами. 

вот в чем секрет поччему в логах нету записей 
про пролет пакета чреез карту vethN1 - иптбйлс 
на основе таблцы маршрутизации никогда не сможет 
нарпавтить пакет на эту карту. она для иптейлблс
просто невидимая. она видна другому коду ядра. 
и как толко ипбтейблс маршутизацирует пакет 
в vethN1.2 то далее уже другой код ядра перекладыает
пакет в карту vethN1 без участия иптйлс и без 
учасития таблицы маршрутизации ! возожмно этот
процсс монжно было бы назвать свичингом, но свичинг
как я понимаю возможен только между портами прик
репленными к бриджу. у нас порты vethN1  vethN1.2
не входят в состав бриджа так что свичингом этот
процесс назвать нельзя. это какойто другой
менанизм перемещения пакета между картами.
напомню что по класиске в ядре есть два механизма
перехода пакета между портами - это либо роутинг
тоест на освное таблцы маршурутизации тоест на основе
дест ип и имени сет карты которая указана в праивиле
таблицы маршутизации 
либо это свичинг на основе дест мак  и таблицы
мак адресов. в обоих эти случаях мы увидим тогда
этот трек в логах. 
но  переход пакета из карты vethN1
в карту vethN1.2  присхоидит внутри ядра на основе
какогто друого внутриядерного механзма. какого
не знаю но точно не этих двух. 
пожтому мы в логах этот перход и этот порт никогда 
не увиидим. вот в чем прикол. и вот в чем разгадка.

условно говрря мехамнмзм такой  - вот у нас иптебйлс
на основе рутинга встаивил пакет в карту vethN1.2
и далее в ядре есть код который за вилан овтечает
и он видит что пакет влетел в эту крату. и тут 
он ее хватает и сует в карту vethN1 а там сидит
ругой кусок ядра который отвечает за веф. и он 
хвтает пакет и сует его на второй конец этого
вефа. и все это происходит вне участия иптейлс кода
и вне участия свичинг кода вне учаастя таблицы
маршурутизации. и поэтому с точки зрения иптбейлс
у нас она сует пакет в карту vethN1.2 и потмо толкьо 
код иптейблс видит этот пакет уже когда он 
попал в ядро влетев в ядро из карты vethN2.2 причем
уже в другом нейиспейсе.  а все прмежутончные порты
для иптбейс просто не существуюю эти этапы он о них
не вкурсе. вот как. 


покажу еще на картинке какой этап види код иптбейлс
а  в каком этапе он не принимает никакого участия
он просто незнае об этих этапапах


             |~~~~~iptables~~~|   | тут              
приложение - сокет  -- vethN1.2 ------


        иптбйелс нет     |
----- vethN1 -------- vethN2 ----


   |~~~~~~~~~~iptables~~~~~|
--  vethN2.2 --- приложение
                        
                        
там где код иптейлс не вывается о том куске
пути он и незнает и в логах об этом куске
пути не будет инфо


тоесть вот на этих трех участках

    | %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%|
vethN1.2 ------ vethN1 -------- vethN2 --- vethN2.2 


тутза пеерброс с карты на карту иптейблс не 
отвечает его тут не вызывают. вот.



а расммотрим как еще пример. когда у нас бондинг.


|    iptables           |      bond               
приложение  --ядро-- bond0.2 ---- bond0 ---- veth1 -


        |  bridge       |   iptables     |
----- veth2 ----- --- tap14 --- приложение  


на перво уастке вызывается иптейлс поэтмуо мы 
увиим в логах bond0.2
на второ участке нет иптейлс а есть коод бондинга
потому он невидим  влоагах этот участок
третий участок это код бриджинга работает 
значит этот участок будет видне в логах за счет
ebtables . и поседний участок это уже код 
ипбтейблс он тож будет виден в логах.
итоо в логах я не увижу карты: bond0 veth1

тоесть в логах мы увдидим вот такой тракт

bond0.2 ---- veth2 - tap14


еще такй момент замечу что если мы создали вилан
инфтрейс 

            
  приложение ---- em1.2 ---- em1 ---- сеть 


то в сеть летит тегированный эзернет фрейм
а для кода прилоожения это невидимая 
вещь то еть внутрь юзер программы никакой тегированный
эзернет фрейм не влетает. внутрт юзер приложения
вобще невлетает ни эзернет фрейм и не ип пакет
и не тцп пакет а уже пейлоад от тцп пакета


          |пейлоад |     |тегированный   |
                           трафик
приложение -------- em1.2 ------ em1 ---- сеть 

тоесть из em1.2 в сторону сети летит ъзернет 
тегировваный вилан трафик
а из em1.2 в сторону приложения летит никакой ни
вилан трафик а просто пейлоад из тца пакета
тоест приложеню ненужно ничего думать или знать
о каких то там виланах. это все на себя берет
ядро.  приложение пихает в em1.2 пейлоад . а ядро
берет пейлоад заворачивает это все в тегированный
вилан фрейм и это шлет в сеть


                  тегированный вилан
 пейлоад          трафик
 <--------- em1.2 ------------------> 

