
C - programming language
=============================

обьявление переменных
int vasya

это обьявляет переменную vasya типа integer

далее можно присвоить знаение
vasya = 15

можно сразу сделать два дела и обьвявить перееменную и присвоить ей значение
int vasya = 15

int = это целоый тип
float = это с точкой
char = это литеры ascii я так понял





====

// my first program on C
#include <stdio.h>
#include <unistd.h>

int main ()
{

int vasya = 15;
int *pvasya = &vasya;

printf ( "$vasya = %d\n", vasya  );
printf ( "$vasya = %d\n", *pvasya );

vasya = 16;
printf ( "new $vasya = %d\n", vasya );

*pvasya = 17;
printf ( "new $vasya = %d\n", *pvasya );


return 0;
}

===
printf
%x - позволяет распечатать только 32 битное hex число максимум, а
%lx - уже позволяет распечатать 64 битное hex число !

===

тип переменной определяет для компилятора и проги сколько байт надо выделять под нее 
в памяти и в каком формате туда писать и  как интерпретировать  байты при считывании.
условно говоря если переменная целого типа значит при считывании и печати числа и нее
просто печатать число на экране а если переменная типа char то считанное число 
интерпретировать в литеру.  переменная типа поинтер хранит не значение а адрес памяти по которому
лежит значение тоесть в переменной мы храним незначение а ссылку в памяти где лежит значение 
этой переменной. почему то принято считать что поинтер указывать на память где хранится
значение другой переменной. а на самом деле в поинтере хранится значение самой переменного поинтера.
пример

int a = 1;
int *pA = &a;

получсется мы имеем две переменные которые имеют одинаковый бекенд. и как тут сказать 
какая из них на самом деле владее значением.   походу поинтер это как хардлинк на фс на файл.
несколко хардлинков указвают на один бекенд. 

когда программа напарывается на поинтер то она понимает что в этой переменной pA хранится незначение
переменной а ссылка на то где искать это значение. а значит некоторые операции доступные для обычных
переменных недоступны для переменной типа поинтер а ннекоторые новые операции зато доступны
для переменной поинтер которые недоступны для обычных переменных.

==================

printf

коогда мыхотим напечатать переменную то нужно в явном виде сказать принтф 
какой тип у переменной хотя ведь мы при созании перееменной это явно прописываем.

теме неменее это так  увы


#include <stdio.h>

int main () {

   int  var1 = 500;


printf( "var1=%d\n", var1 );
printf( "octal form=%#o\n", var1 );
printf( "hex form=%#x\n", var1 );
printf( "HEX form=%#X\n", var1 );

printf ( "\n"  );


float var2 = 600.5;
printf( "var2=%f\n", var2 );
printf( "var2=%#A\n", var2 );
printf( "var2=%#a\n", var2 );
printf( "var2=%#g\n", var2 );



   return 0;
}



в этом примере обьявляется переменная var1 с типом int
так вот что интересно что принтф позволяет при распечатке ее конвертировать ее вывод
из дефолтового (десятичного)  в другие виды. что существенно и в чем подьебка что конвертация
доступны не во все виды а только в некоторые

вот такой будет вывод на экран

var1=500
octal form=0764
hex form=0x1f4
HEX form=0X1F4

var2=600.500000
var2=0X1.2C4P+9
var2=0x1.2c4p+9
var2=600.5


таким образом int переменную можно при распечатке вывести в восьемричном виде, hex виде и 
на этом и все.  тоесть например нельзя переменную int типа вывести в виде с плавающей точкой
почему непонятно в чем проблема.


тоже самое касается переменной var2 типа float. 
ее можно при печати вывести в hex виде, но попытка выести ее в виде целочисленном
выдаст ошибку. 

если дефолтовая форма как обьяснить принтф какой тип имеет печатаемая переменная это 
%d
%x
%f

итп, то алтернативный вида задается в виде %#x. вобщем я бы сказал бы что просто напросто
 целочисленныую переменную можно ввывести в dec,hex,oct формате тоесть это блять никакое 
 не преобразование как об этом пишут в man это всего навсего меняется система счисления.
 а переменную с точкой можно вывести в dec,hex форматах. вот и все что касается %# в принтф.

 итак при выводе с помощью %# целое остаетс целым а с точкой осается с точкой 
 просто вывод идет по разным система счисления.

 а если мы хотим целое вывести как с точки или с точкой вывести как целое то для этого
 надо  на переменную натраваить функцию которая ее преобразует. пример

float var2 = 600.5;
printf( "var2=%i\n", ( int ) var2 );

вывод на экране
var2=600.500000
var2=600

вообще я непонима смысл этой решетки %# потому что - тип данных имеет скажем целый тип.
тоесть число без точки. от того что мы печаатем его в hex или dec или oct или bin виде 
от этого тип данных неменяется. поэтому на мой взгляд 

%x = %#x
%X = %#X

непойму нахуя вобще этот оператор # .

потому что и без него все рабоатет.

еть у нас var1 с типом int. окей. теперьмы для себя определяемся в какой системе исчисления
мы хотим распечатать переменную. еси в dec виде то 

printf ("%i", var1);

если в hex виде то 

printf ("%x", var1);

если в HEX виде то 

printf ("%X", var1);

нахуя нам тогда этот #  ??????????? он ничего непреобрзует. и никаких новых возможностей недает!


====

\\ 
C += A is equivalent to C = C + A
\\

=============
pointers
printf

еще интерснейщие пример
он про указатели. 
про принтф


#include <stdio.h>

int main () {

   int  var1 = 500;
   printf( "var1 = %i\n", var1  );


   int *pVar1;
   pVar1 = &var1;
   printf( "Address of var1 variable in memory(hex) =  %p bytes\n", pVar1  );
   printf( "Address of var1 variable in memory(dec) =  %li bytes\n", ( long int ) pVar1  );
   printf( "Address of var1 variable in memory(dec) =  %li TB\n",( ( long int ) pVar1 ) /1024 /1024 /1024 /1024);


   printf( "var1 = %i\n", *pVar1 );


   char var2 = 'a';
   printf ( "var2=%c\n", var2 );
   printf ( "var2=%d\n", ( int ) var2 );






   return 0;
}


вывод на экран:
var1 = 500
Address of var1 variable in memory(hex) =  0x7ffe4bbe0c1c bytes
Address of var1 variable in memory(dec) =  140730169166876 bytes
Address of var1 variable in memory(dec) =  127 TB
var1 = 500
var2=a
var2=97



разберем


   int  var1 = 500;
   printf( "var1 = %i\n", var1  );

  наэкране
  var1 = 500

  обьявляет целую переменную и печатает ее обьясняя принтф что мы собираемся печатать 
  перменуую целого типа. все таки непонятно если мы уже указали что перменная целого типа зачем
  еще раз это прописывать в принтф





   int *pVar1;

   обявляем поинтер переменную которая укащывает на ячеку памяти в которой лежит значение
   целого типа, 


   pVar1 = &var1;

   записываем в pVar1  адрес  переменной var1




   printf( "Address of var1 variable in memory(hex) =  %p bytes\n", pVar1  );

   на экране
   Address of var1 variable in memory(hex) =  0x7ffe4bbe0c1c bytes


   печатаем адрес ячейки памяти который хранится в поинтере. получается в принтф переменная
   типа поинтер указывается как %p.
   заметим что pVar1 указывается без всяких *
   таким образом если мы хотим заглянуть в сам поинтер(тоесть узнать адрес) то  указвыаем его имя pVar1 без  звезд. а если хотим узнать неадрес а знаение ячейки куда этот адрес указываемт то используем звезду *pVar1.
     как видно по дефолту значение поинтер переменной тоесть адрес  печается на экране в виде hex.


далее. хотим узнать знаение ячейки куда  адрес(поинтер) указываемт  используем звезду *pVar1.
   printf( "var1 = %i\n", *pVar1 );

   на экране
   var1 = 500

итак поинтер это адрес. звезда поинтер это значение.

   поскольку значение
   в ячейке имеет целоый тип то для принтф указываем %i

еще раз
   pVar1 = 0x7789798798dc   адрес ячейки памяти
   *pVar1 = 500  значение которое лежит по адресу втой ячейке памяти

   соотвестенно для принтф
   %p = указывает что печатаем переменную поинтер типа
   %i = указываем что печаатем переенную целого типа

прикольно то что нет просто переменной понинтер типа. помимо поинтер типа этот тип еще 
дожен иметь целый тип итп. хотя нет можно создать переменную типа поинтер без типа это будет

    void *pVar1 = переменная поинтер типа ведущая на ячейку неопределенного типа

	int * pVar1 = переменная поинтер типа ведущая на ячейку целого типа





   printf( "Address of var1 variable in memory(dec) =  %li bytes\n", ( long int ) pVar1  );
   printf( "Address of var1 variable in memory(dec) =  %li TB\n",( ( long int ) pVar1 ) /1024 /1024 /1024 /1024);

   на экране
	Address of var1 variable in memory(dec) =  140730169166876 bytes
	Address of var1 variable in memory(dec) =  127 TB

 здесь интересно то что я хотел распечатать поинтер на экране не в дефолтовом виде hex 
 а в десятичном виде. если переводить адрес памяти в из hex в dec то он очень большой и влезает 
 только в тип данных long int  поэтому я преобразовал hex в long int для этого я заюзал функцию  ( long int )  которую натрваил на pVar1. в английских книгах преобразование одного типа данных в 
 другой называется type casting  или просто casting. 
 в принтф я тоже указал что мы печатаем на экране тип данных %li.
 во второй строке  я применили арифмтические операции и перевоел байты в терабайты при этом получается число которое влезает в тип данных integer поэтому для принтф я указал %i

получается про принтф. в нем мы укаваем какой тип данных имеет переменная а потом указываем
эту переменную

printf ( "%тип_данных_у_переменной", имя_переменной)

вот так эта хрень работает.


или в более сложном вариенте принтф вместо переменной мы можем указать функцию которая берет пременную ее значение и тип и пребразует
ее значение вдругой тип

printf ( "%тип_данных_у_переменной",  (функция ) имя_переменной)

на выходе функции должны полчаться данные ровно того типа что мы указали в %.

теперь вспомним что написано в man 3 printf. там написано что если мы в принтф юзаем %p
то принтф ожидает увидеть переменну с типом void *. тоеть переменную котора была обьявлена 
вот так 

void * pVasya

тоесть перменная должна быть поинтером да непросто какого то там типа а воид типа.
если же мы посмотрим как унас вверху заюзано

	int *pVar1;
	pVar1 = &var1;

	printf( "Address of var1 variable in memory(hex) =  %p bytes\n", pVar1  );

   	на экране
   	Address of var1 variable in memory(hex) =  0x7ffe4bbe0c1c byte


то мы увидим что в принтф мы подставили перменную pVar1 которая да поинтер 
но она не воид типа а int типа. хм... почему же компилятор незаругался и у нас все сработало?
может имеет место автопреобразование со стороны компилятора?

тоесть моя практика показывает что принтф если указать %p то в качестве переменной он принимает
переменую типа поинтер абсолютно любого типа ему пострать это int * или void * или long * 
абсолютно похер. главное чтобы был тип поинтер неважно какого типа.
ключ %p печаатает адрес который хранится в поинтере. поэтому ему как бы похер на какой 
тип данных этот адрес ссылается.
 
 я считаю вот эта мудота с обозначением поиинтера как int * или void * это полный идиотизм
 вместо этого надо было ввести обозначениее для создания поинтера чтото типа  такого 

 int * var1  ----> pointer_i  var1
 void * var1 ----> pointer_v  var2

 вместо этих дурацкий звезд. а то сиди иломай мозг разгадывая смысл этих звезд.



=================

потихоньку начинает вырсиываотся смысл

ssize_t read(int fd, void *buf, size_t count);

получается функция read резульаттом является данные с типом ssize_t ( об этом потом) там отличие 
ssize_t от size_t  в том что может вернуться -1 

int fd = тип переменной целое, смысл переменной это файловый дескриптор (файл) из которого читаем
void *buf =  тип переменной поинтер, тип у поинтера void. смысла ее это буфер в который пишем что прочитали
size_t count = тип переменной size_t . смысл ее это размер читаемого в байтах


какой смысл у поинтера который указыаем на ячейку в котрой хранятся данные типа void.
воид это значит что тип данных неизвестен. я так поимаю что запись в поинтер который указывет 
на ячейку с неизвестным типмо данных дает нам взможность типа того что писать туда данные в raw формате. 

но void * var1 поинтер будем подрообнее анализивать и обсуждать ниже.

===========


соатновился на задаче как счиатть 1 символ с клавы
а потом выести на экран

вот этот код считыает с клавы 1 символ

#include <stdio.h>
#include <unistd.h>

int main () {

    int klava = 0;

    void * bufer;
    char k[1];
    bufer = &k;

    printf ( "void address = %p\n", bufer );

    size_t count;
    count = 1;

    read( klava, bufer, count);

   return 0;
}

( прикол read это сисколлл а не команда языка C, мы заюзали сисколл!)

что здесь существенно. 
если просто обьявить void поинтер 

void * bufer;

то как показал практика в реале он неиницилизируется и ни на какую ячейку памяти
непоказывает. поэтому нужна вот такя комбианация чтобы bufer начал релаьно укзатьвыа на
ячеку в памяти

void * bufer;
char k[1];
bufer = &k;


ну а эта строчка

printf ( "void address = %p\n", bufer );

это просто проверка что ячейка понинтер кудато реально указывает.

поопутно как я понимаю тип char это 1 байт в памяти под каждый char обьект. по факту 
это число от 0 до 255. целое.
поэтому наша воид поинтер по факту указыает на ячейку 1 байт длинной.



правлная инциализация void - то что он сам по себе никуда незукывает.
его плюс в том что его можно директить на соврешенно разные типы бекенд ячеек

int a = 10;
char b = 'x';

void *p 
p = &a;  
p = &b; 


минус в том что с этой поинтера нельзя напрямую печатать

int main()
{
    int a = 10;
    void *ptr = &a;
    printf("%d", *ptr);
    return 0;
}

если даже на бекенде сидит у нас int то получаетс что по определению void поинтер указывает 
на ячейку памяти в которой сидит занчение перменной у котроой нет типа!!!! а раз нет типа
то ее нельзя распечатать.

поэтому воид поинтер надо конвертить ( и он конвертирится в любой тип без проблем) в тот 
тип данных что мы хоим печатать

int main()
{
    int a = 10;
    void *ptr = &a;
    printf("%d", *(int *)ptr);
    return 0;
}

на счет вот этой хрени  *(int *)ptr


(int *)ptr  = создает поинтер нового типа. адрес в нем такой же а вот тип данных который лежит в
 ячейке по адреу поинтера утверждоаетс что новый тоесть

 int a = 1;
 void * vasya;
 vasya =  &a;

 хотя мы знаем что в ячеке пойинтереа лежит целое но C этого незнает.
 пожтому что мы заявили что по адресу поинтера vasya лежат какието данные но их тип определить
 невозможно.

 поэтому

 int * petya;
 petya = ( int *) vasya;

 тоест мы сконевертировали воид поинтер в int поинтер и подсунули адрес а petya

 теперь petya смотрит тудаже куда и вася но для C уже понятрно что бекенд пети это интеджер.

 поэтому его можно печатать.

 printf ( "%c", *petya  );



так вот я про вотэту команду

*(int *)ptr

она преобразует воид поинтер и вызывает значение по его адресу.

пример

#include <stdio.h>
#include <unistd.h>

int main () {

    void * pVasya;
    char a = 'a';
    pVasya = &a;

    printf ( "pointer pVasya = %p\n", pVasya   );

    char * pa;
    pa = (char *) pVasya;

    printf ( "pointer pa = %p\n", pa);

    printf ( "char = %c\n", *pa  );

   return 0;
}

вывод на экран:
pointer pVasya = 0x7fff5d948237
pointer pa = 0x7fff5d948237
char = a



видно что поинтеры указывают на одну ячейку.

так ну пока я невижу какогот то полезного смысла в воид поинтер
кроме такого что  его указатель можно менять на любые типы препеменных.


int a = 10;
char b = 'x';

void *p;
p = &a;  
p = &b; 

прикольно. но какой в этом болшой смысла на практкие хер его знает


ясно одно кога мы создаем воид поинтер то мы четко заявляен стстеме что тип данных у ячейки остуствует. его нет. мы неможем его определит. данные есть но их тип неопреелим. несущетсвует.
поэтому принтф для воид поинтера неработает. 
для самого адреса %p конечно работает а вот для занчения перменной в ячейке нет.



==========
cast
type cast
type conversion

это все слова о том что можно натравливать на переменную одного типа функцию
которая превратит данные этой переменной в другой тип и эти новыве данные нового типа
можно будет присвоить новой переменной

(type_name) expression

из этого получается что в выражении void * vasya кусок void * является одним целым
и означает тип данных.

тоесть 

int
double 
float
char
int *
void *

это все так обозначаются типы данных. но меня больше всего тут заинтересовало int * и void *

==

#include <stdio.h>


int main () {

    int a;
    printf ("%p\n", &a );

    int * pVasya;
    printf ( "%p\n", pVasya );


    void * pVasya2;
    printf ( "%p\n", pVasya2 );


   return 0;
}

vasya@vasya-Lenovo-IdeaPad-L340-15IWL:~/C$ gcc -o 15 15.c; ./15
0x7fff55d56584
0x5570162325a0
0x7fff55d56680


странно.
переменным неприсовено никакого значения но под них 
уже зарезервированы ячейки в памяти.
===

вот еще пример


#include <stdio.h>


int main () {

    int a;
    printf ("variable \"a\" memory address = %p\n", &a );
    printf ("var a = %i\n", a );


    int * pVasya;
    printf ( "variable pVasya points to memory address = %p\n", pVasya );
    printf ( "*pVasya = %i\n", *pVasya );



    void * pVasya2;
    printf ( "pointer pVasya2 points to memory address = %p\n", pVasya2 );


   return 0;
}


$ gcc -o 15 15.c; ./15
variable "a" memory address = 0x7ffe1165e0c4
var a = 21881
variable pVasya points to memory address = 0x5579416f95a0
*pVasya = -1991643855
pointer pVasya2 points to memory address = 0x7ffe1165e1c0


видно что мы обьявили пермеменные но не присвоили значения
однако значения у них уже есть! это чтото !

=========

пример cast преоббразования одних типпов данных в другие


#include <stdio.h>


int main () {

int a = 10;
int b = 2;

double count;


count = (double ) a / b;

printf ( "%i / %i = %f\n", a, b, count    );


   return 0;
}


vasya@vasya-Lenovo-IdeaPad-L340-15IWL:~/C$ ./15
10 / 2 = 5.000000

======

поговорим про ascii
станадартк кодирования символов. типа есть текст с байтами их надо 
как то транслировать в символы. man ascii
кодирование сосотоит из 128 символов. на него хватвает 7 бит.
часть кодов это несимволы а упправляющие сигналы. кодировка уходит
во времена печаатающих маштнок ( typewriter). и электрических печатных машин ( teletype writer)
так вот хочу про два спец символа сказать

CR - carriage return это когда на печатной машинке мы беремся за железную такую ручку
и тащим налево это приводит к тому что печатная гооловка оказывается опять в левом крайнем
положении. что важно отметить что при этом мы остаемся в тойже строке тоесть бумага при этом
на прокручивается вверх вертикально. ( хотя как я помню из своего опыта печатания на печатной
машинке то при перенеосе головки влево и бумага автоматом прокручивается вверх на одну линию)

LF - line feed. прокрутка листа бумаги на одну линию вверх. при этом с головкой ничего непросиходит
так что печать начнется с тойже позициив строке а не с левой крайней.

поэтому получается что на классическом матричном принтере если закончилась строка то чтобы
начать печатать с новой строки надо подать два сигнала оба тоесть CR + LF либо LF + CR
более того я прочитал что якобы для матричных принтеров нужно было дать несколько таких
сигналов типа CR + CR +CR +LF потому что якобы они неусмевали дотащить головку влево 
за время одного CR что по мне бред ведь они печатают из буфера а не стой скоростью с которой
 в них прилетают сигналы.

 тем не менее теперь понятна разница между CR и LF.
 LF часто называют "new line". а так тепер стало понянто. CR это перметсить печатную голову влево
 а LF это прокруттить рулон бумаги вверх.

 итак вся эта хрень относилась к элетрическим печатным машикам по которым по проводам телеграммы
 летели.  а когда перешли к  теримналам с электронными экранами то ( как я понял ) необходимость
 для переноса строки юзать два символа типа пропала. поэтому в файлах начали изать для этой цели
 обычно один символ либо CR либо LF и  терминалу стало понятно что надо сделать CR + LF.

 поэтому в линуксе в текстовых файлах знаком конца строки и начла новой строки является символ
 LF тоесть байт который в себе несет значение 10 (dec) или 0A (hex)

 тут еще раз важно отметить что символ LF формально должен только пркручиваь бумагу на 1 строку 
 вверх а голвка при этом остается на том же месте. но в линуксе в его терминале это приводит к тому
 что экран прркучиватеся на 1 строку вверх и также при этом и гооловка печаатающая возвращается
 в левое крайнее положение

 вот программа

 $ cat 1.bash 
#!/bin/bash

sleep 1; 

echo -n "v"; 
sleep 1; 

echo -n  "a"; 
sleep 1; 

echo -n "s"; 
sleep 1; 

echo -n "y"; 
sleep 1; 

echo  -n "a"; 
sleep 1;

echo -n -e "\x0D"; 
sleep 2; 



echo -n "*"
sleep 1;

echo -n "*"
sleep 1;

echo -n -e  "\x0A"
sleep 1;


echo -n "!"
sleep 1;

echo -n -e  "\x0A"
sleep 5;

вот ее вывод

**sya
!

теперь разберем.
вначале програ печаате по буквам слово vasya

vasya

печатется оно буквам в одной строке. ключ -n  в echo дает то что при выводе буквы после 
нее непроисходит прокрутки бумаги и возврата головки(курсора) в левое положение ( условно говоря
не вставляется enter)

потом печатная головка (курсор мигающий) возвращаетмя в начало строки (без прокрутки бумаги).
за это отвечает команда echo -n -e "\x0D".  0D это символ CR (возврат головки влево) в hex 
формате. здесь важно отметить еще раз что при возврате каретки бумага непрокручивается. так что 
печать остается в тойже строке.
и далее начинает затираться строка печатая две звездочки. так что мы увидим вот такое

**sya

этим я хотел еще раз подчеркуть что при поступлении в терминал ( котрорый можно сравнить с матричным принтером) символа CR ( 0D hex ) происходит возрат головки вначало строки и не происходит
прокрутка бумаги. так что печать начинает затирать ранее набранные символы.

далее в
 бумага прокручивается вверх  потому что на терминал поступает байт 0A (hex ).
это делается командой echo -n -e  "\x0A"
0A (hex) этот байт это  символ LF - line feed - прокрутка  бумаги наверх. но помимо покрутки бумаги также происходит и возврат головки
 вначало строки. здесь уже 0A ни причем это чисто отсебятина linux терминала.

терминал можно сравнить с матричным принтером. а байты которые в него влетают с управляющими командами. если прилетает байт 76(hex) то принтер печаатает головкой литеру "v"
если прилетает байт 61 (hex) то принтер печатает литеру "a"
а если прилетает байт 0D (hex) то принтер ничего непечаатает он возвращает головку в левое положение
в начало строки.
а если прилетает байт 0A (hex) то принтер пррокручивает бумагу на одну строку вверх. и еще добавляет  от себя возврат головки в начало строки.



так вот когда напечаатся **sya то происходит пркрутка бумаги и  возврат в начало строки 
и печается !

**sya
!

далее происходит опять пркоуркртка бумаги и возврат в начало строки.

ключ -e позволяет через echo передвать байты в hex виде.
ключ -n засталвяет echo невставлять автоматом LF в конце команды. так что мы имеем полный контроль
над выводом в терминал.

такми мккаром мы изучили влияние и работу CR и LF.

также полчается если у нас есть файл и мы запустим его вывод на терминал 

$ cat vasya.txt

то файл содержит байты. так вот терминал (ядро линукса) он как матричный принтер рассматривает каждй байт в файле как 
литеру ascii таблицы и либо печатает сооветвующую литеру или если это нелитера а управляющая команда
такая как CR или LF то прокручивает бумагу (то бишь экран) или возвращает головку (курсор) в начало
строки. таким образом голые байты в файле превращаются  в набор литер на экране. (ну или на бумаге) есл бы это был принтер.

таким образом в файле никакие литеры нехранятся ( как это могло бы интуитивно показаться). 
файл это не бумага. в файле литер нет. там только голые байты.


далее. что инересно.
если мы откроем скажем в mcedit файл в котлром есть байты которые в таблице asccii отвечают 
за упраляющие команды то на экране  в определенных местах будут стремные символы например для 
байта CR на экране в тексте будет что то типа ^M

вообще это интересно. потому что при просто выводе на экран такого ничего нет.
курсор терминала просто делает что ему предписано прокручивает бумагу или возвращает курсор 
в начало строки. так что при просмотре файла никаких стремных символов нет. потому что просмотр файла  это аналогично печати на принтер. где каждый байт это либо литера либо управляющая команда
для головки принтера (курсор)

вобще полчучется файл это поток байтов которй по проводам предавался от одгной электро печатной машинки на другую и использоваолся чтобы набрать текст в автоматическом режиме.


типа это как рецепт изготовления пирога.

принтер является поваром а файл рецептом.

терминал выступает в роли принтера.

когда мы открваем файл на редактирование то получается в определеннымх местах нам надо 
как то показывать что здесь сохранен непросто литера а управляющая команда. 
это как открыть файл ворда. там помимо голого текста еще напихана куча управляющей информации.
таким образом это власть текстового редактора показывать каким либо одразом управляющие символы
ascii или их скрывать.

mcedit например байт CR показывает как ^M

===

ascii

рассмотрим следущий байт

00 (hex)

он означает то что при получении этого байта терминал ничего неделает. ни печатает и с головой
ничего неделает.


пример

$ echo -n -e "\x00v\x00a\x00s\x00y\x00a"

здесь получается слово vasya и между буквами вставлены байты 00 (hex) 
на экране мы увидим просто слово 

vasya

между буквами ничего небудет никаких лишних символов.
возможно в teletype writeer машиных этот символ вставляли для того чтобы у принимащей
машины были паузы при печати незнаю для чего эти паузы. чтобы машины не перегревались.

этот как в процессоре команда nope которая ничего неделает 1 цикл.


что при этом существенно что если мы направим вывод в файл 

echo -n -e "\x00v\x00a\x00s\x00y\x00a" > ./vasya2.txt

то конечно внутри него попимо байтов отвечающих за литеры vasya еще будут байты 00 (hex)

делаем следущий экспримент

$ cat /dev/zero

на экране терминала небудет отображаться ничего. потому что в темринал поступают байты у которых
значение 00 (hex) поэтому драйвер терминала  ( ака виртуальный матричный принтер) интерпретурует
данную команду как ничего непечатать и неделать.

(а совсем не так как казалось бы интуитивно раз поступают байты с нуля то на экране побегут нули. хаха)

в тоже время если направить эту штуку в файл то конечно файл забьется байтами 00 (hex)
и это можно отлично посмотрет в hex редакторе файлов.


итак с 00 (hex) байтом в ascii разоборались
===

ascii

написано что в бинарном виде заглавная буква отличается от маленькой буквы только одним битом.
я проверил это так.

например

dec 87 = 'W'
dec 119 = 'w'

$ echo 'obase=2;87' | bc
1010111

$ echo 'obase=2;119' | bc
1110111

напписано что на мехаических teletypewriter такая схема облегачала 
их програмирование их контсрукции

===
ascii

вначае был морзе. потом бодо(ita1). потом ita2

в морзе буква от буквы при передаче отделяются опреденной паузой размером как три точки.
слово от слова отделяется еще более длинной паузой как семь точек.

морзе можно передавать  через один провод.
кодирование идет ну типа двоичное но на каждый симовол уходит много бит потому что еще идут и стоп биты. условно говоря если точка это 0
а тире это 1 , то буква A = 01, буква B = 1000 что касается букв то максимум 4 бита используется, 
например H = 0000 
но прикол в том что чтобы передать слово из одной буквы уходит слишком много битов еще и на стопы.
передача слова из одной буквы выглядит так:
стоп-(от одного до  четырех бит)-стоп-стоп-стоп

при наборе даже одной буквы между точкаи и тире делается пауза в размере одной точки по длине.
получается берем букву A: A = 01, тогда передача выглядит по времени как

0-пауза-1-пауза-пауза-пауза

вобщем да очень много стоп битов так скажем при передаче чтобы уметь отделять на слух буквы друг от друга и слова от слов.



далее был бодо. его код уже работает только через ПЯТЬ проводов ! зато уже нет этих многочисленных
стоп пауз.

у бодо уже чисто двоичная кодировка символов. как я понял схема работала на практике так.
с нашей стороны аппарат с клавой на 5 кнопок потом в поле уходит пять проводов,
на той стороне принимающий аппарат и принтер. принтер это полоска бумаги.


на нашей стороне мы жмем комбинацию из 5 кнопок. например A = 10000 
этот сигнал по пяти проводам полетел туда. там на ленте пробивается столбик. в котором одна дырка
и четыре места где нет дырок. соотвесвтенно на пяти битах можно запрграмировать 32 символа.

тоесть на той стороне будет лента на которой будет вот такая лента. каждая буква
это отдельный символ

--------
1 1 0 0
0 0 0 0
0 0 1 1
0 0 1 1
0 0 0 0
---------

на этой ленте запрограмировано AABB сообщение.
при этой схеме человек сидит печаатет и сообщение улетает в режиме онлайн.

как я понял бодо изобрел и метод кодировки и сам аппарат по отправке сообщений.
на аппарате небыло как я понимаю клавы с символами  а было просто реально пять кнопок
каждая из которых была привязана к одному проводов которые шли через леса и поля на ту сторону
приемника.

потом мюррей придумал такой аппарат что можно на нашей стороне набрать собщение которое
у нас же отпечаается в форме ленты с дырками. потом взять эту ленту засунуть в другой апарат
и он уже автоматом по этой ленте отправит собщение. так что набор сообщение стал отделен от 
процесса отправки сообщения. также как я понимаю мюррей уже привязал печатную машинку с полноценной
клавой к этой кодировке бодо. тоесть человек нажимал на кнопки на которых были нарисованы уже буквы. что сущесвтеннно улучшает удобство отправки. как на печатной машинке. и также как уже сказал
мюррей сделал асинхронным процесс набора текста и его отправку. 
также как я понимаю что касается приема сообщений все оставалось неудобным тоесть на 
принимающей стороне люди получали ленту с дырками а не печатный текст. ленту получается
надо было еще руками дешифровать. но хотя бы отправка удобная стала.



как я примерно понял кодировка бодо на пяти битах называется также ita1
ita это чтото типа телеграфный стандарт алафита.


потом сделали ita2
он тоже базируется на 5 проводах.но! в нем сделали хитрую штуку. добавили спец символ 11011
и таким макаром получили двойную емкость символов. выглядело так.
есть закодированный набор букв от 00000 до 11111 ( за исчключением некоторых комбиацний  в частности спец символ 11011). и есть закодированный набор уже доп символов всякие там цифры
знак доллара, знак вопроса, знак фунта, кавычки запятые условно говоря всю эту группу назовем
группа цифр. так вот если мы хотим отправить цифру то мы вначале шлем на ту сторону спецсимвол а уже за ним код символа. спец символ 11011 это что типа прообраза кнопки Shift на клаве.
для того чтобы показать что мы обратно вернулись к отправке букв был тоже спецсимвол 11111

тогда отправка выгляди так

11011 - цифра-цифра-цифра-11111-буква-буква-буква-буква

как видно если подряд идет несколько бука или цифр то между ними спецсимвол каждый раз неставиться
он ставиться только вначале группы.

пример 

буква A = 11000
цифра 1 = 11101

тогда передаем AA11 сообщение:


11111(спецсимвол группы букв)-11000-11000-11011(спецсимвол цифр)-11101-11101


и вся эта хрень на той стороне выбиывалась на ленте в форме дырок вот так:


					-------------	
					|o o o o o o
					|o o o o o o
начало ленты=>		|o       o o        <== конец ленты
					|o     o  
					|o     o o o
					|-------------

буквами 'o'  я обозначил дырки на ленте в бумаге.

в этой кодировке также был символ для пробела. символ прокрутки бумаги на одну строку (line feed), символ переноса каретки влево вначало строки.

как бы спрашивается какая хрен каретка. каретка она же у печатной машинки только есть.
тоесть зачем пеересылать на ту сторону знак прокрутки бумаги или знак возврата печати символа 
с левой позиции. я так понимаю что эти симфолы форматирования текста отсылались на ту сторону
в форме дырок на ленте чтобы человек который дешифрует сообщение мог понимать как ему форматировать  текст уже на бумаге на печатной машинке чтобы текст невыглядел как сплошная длинная одна строчка. может так ? и видимо на каком то этапе все таки сделали автоматический аппарат который вместо человека считывал дырки и печатал литеры уже на печатной машинке автоматом с соблю
дением форматирования. тем более что на печатной машинке нужно по любому переносить строку 
потому что лист то имеет конечную ширину (чото я непомню если печатть на печатной машинке  и дошел до конца строки она что делает продолжает долбит в последнюю позицию в строке или что ?)

 с точки зрения печатных машинок непонятно какой смысл имеет CR без функции LF.
 какой смысла на печатной машине вернуть головку вначало строки и начать запечатыывать а именно
 поверх старых символов херачить сверху новые символы. мы же наавоз получим на бумаге.
 это непонятно. по мне CR всегда должен быть с автоматичеким LF. непонятно

 однако имеенно на этом этапе ita2 появились управлящие спец символы CR и LF.

 эти симолв предназанчались для тех усторйств которые декодировали ленты с дырками 
  и печатали текст на печатных машинках на бумаге (типа проорбразы принтеров) чтобы текст получался
  полноценно форматированным. типа такого


  ------------------------------
  |мама мыла                   |
  |раму.                       |
  ------------------------------

тоесть CR и LF нам позволяет начать печатать новое слово с новой строки в любой момент.


таким образом уже видно что CR и LF символы были придуманы для управления принтерами печатными 
устройствами но не электронно-лучевыми мониторами терминалов.

это важно понять откуда зачем почему для чего появились символы CR и LF.
короткий ответ - для автоматического управления принтерами. для форматирования текста при печати.
ровно как это есть при печати на матричном принтере!

единственное мне пока остается непонятным как же они ухитирились создать аппарат котоырй автоматом
умел расшифроввыать дырки на ленте и потом печаать правильные буквы на печатной машине.
как это можно было сделать без компов и микросхем с процессорами.

так вот забегая вперед скажем про ASCII.
ascii хотя я неочень понял это стандарт кодирования символов в телекоммуникациоонном оборудовании
и в компах. походу поскольку телеграфные устройства это тоже телекомуникационное оборудование
то типа того что ascii это апгреженный вариант кодирования бодо. только уже на 7 проводах.
потому что используется 7 бит для этого. так вот получается что управляющие символы в кодировке этой опять же предназначены для того чтобы на принмающей поток стороне  принтеры (телепринтеры так вроде их звали) правильно форматировали текст. тоесть еще раз в ascii кодировке управляющие символы это символы управления форматироваиния печати на принтерах. тоесть эти символы придумывались изначально для принтеров ! а не элт экранов терминалов.


тоесть принимает телепринтер телеграмму и поступают к нему буквы он их печаатет. потом в потоке
поступает символ CR+LF и телепринтер прокручивает бумагу пеерводит печатную головку вначало строки
и дальнейшая печать идет с новой строки. таким образом передаваемый поток содержал нетолько инфо 
что печатать но и как печатать как форматировать.
====

ascii

получсется код бодэ был придуман чтобы по шине 5бит передавать буквы.
где хранилась данная инфо в цифровом виде. ответ нигде.
кроме как в виде дырок на ленте. лента была как файл и жесткий диск одновременно.
данное цифрая инфо только летела по шине (проводам) и все больше нигде не хранилась.

 важный вопрос что такое кодировка? =  получается кодировка бодэ это отправка от источника к приемнику информации о букве  в виде двоичного кода длинной 5 бит.
за что отвечает кодировка на что она влияет? = если у нас есть цифровой канал от источника
к получателю и мы отсылаем символ из предоопределенной таблицы ( букву "a") через этот канал 
то согласно кодировке этот символ будет иметь конкретный вид битовый. 00100. кодировка этот 
метод преобразования литеры в 5битовое слово.  в разных кодировка литера будет иметь другой вид
этого слова. получается если у нас есть поток буквенной информации и мы этот поток шлем по 
цифровому канаду в виде битов то кодировка определяет конкоетный битовый вид для литеры.

поток литер может идти как с клавы так и из файла. в файле поток сразу выглядит в форме потока
битов. если поток идет  с клавы то вначале коды нажатия клавиш надо преобразовать в коды литер
согласно кодировке. а потом отправлять получателю. получаетель должен получить при приеме поток 
битов и байтов составленный согласно кодировке. 

кодировка позволяет набор литер преобразовать в битовый\байтовый массив. в цифровой вид. нули и единицы. эта же кодировка позволяет преобразовать битовый массив в человеческие литеры. 

получается 


 литеры на бумаге  --> кодировка -->  массив байтов 
 литеры на бумаге  <-- кодировка <--  массив байтов


применительно к компьюетеру а не телеграфу = есть файл на диске в виде набора байтов.
нам его надо вывести на монитор или принтер в виде букв литер. для этого надо их преобразовать.
преобразование , поиск какой байт кодирует какую литеру идет через таблицу кодировки.

в случае телеграфа кодировка позовляла задать для буквы на бумаге или кнопки на клаве 
конкретный цифровой сигнал битовый который уже можно отправит по шине. по каналу связи. через
электричество. 

кодировка позволяет имея битовый сигнал узнать что за буквы за ним кроются.
или имея буквы трансформировать их в битовое представление.

получается еще раз что позволяет кодировка

aABjqwdkqwdkd  --> кодировка --> 01010101001010100101
или
0101010101011  --> кодировка --> Abbdbdbdbwdjewbfjwfb


пуолчается кодировка нам позволяет информацию из литерного вида перевести в битовый вид
и наоборот из битового вида в литерный вид.

битовый вид можно передавать по каналам связи. а литерный нет. поэтому то и нужна кодировка
чтобы как преобразовать литерный вид в битовый.

остается вопрос где этот битовый поток информации живет и существует. что является его носителем.
где байты рождаются и где умирают и где хранится что их носитель.
для телеграфа это  канал связи. и походу только в нем и все. ну еще на перфорированной ленте.
человек тыкает кнопку на телетайпе , аппарат создает битовый поток на этой стороне провода. это место рождения этого потока этих бит. потом аппарат его пихает в канал связи. канал связи носитель этого потока бит.поток прилетает на приемник и там как цифровой вид он умирает. остается в форме дырок на бумажной ленте. лента это носитель. но это уже не цифровой вид потока. хотя...наверное цифровой все таки. просто немагнитный носитель а так цифровой.

для компьютера поток хранится во первых в файлах. в файлах записаны биты. биты имеют опреденный порядок как раз на основе кодировки. биты текстовой информации естественно потому что ascii это 
таблица кодировки символов литер букв. где еще.. еслы мы говорим о кодировке значит
должен быть где то в компе поток либо битов которые надо перевести в литеры на бумаге или экране
либо поток чегото еще (например кодов нажатия кнопок на клаве) в поток битов. когда мы говорим
 о кодировке значит сейчас у нас есть поток литер букв которые нужно перевести в поток битов
 либо у нас есть поток битов которые нужно перевести в литеры.  там где кодировка там обязательно 
 должен быть поток либо либо битов либо литер. потому что кодировка это трансляция букв в биты 
 либо в битов в буквы. это процесс. как горение. а как же клава. при чем здесь кодировка.
 мы нажали кнопку и программа обработчик берет код нажатия кнопки  и понимает что это литера 
 "A" и ей нужно преобразовать эту литеру этот код нажатия в биты в битовый вид согласно 
 правилу преобразования на основе кодировки и эти биты куда то потом отправить какому то получаетелю. если говорим о кодировке значит есть отправитель и получаетель.  вцелом получается
 кодировка позволяет взять литеры на одном конце преобразовать их в биты и послать на другой конец.
 или наоборот. взять биты на одном конце полать в другой и там их преобразовать в литеры.

 кодировка это получаеся всегда два процесса преобразование и передача.

а то получается непонятно было . кодировка это про буквы и биты. а где эти буквы где 
эти биты. все висело в воздухе.

для компа в самом простом случае если мы говорим кодировка то вспоминаем файл внутри которого
лежат биты и байты и кодировка нам позволяет получить из битов и байтов литеры буквы текст.
позоволяет полученные нули и единицы преобразовать в понятный текст. на заре интернета часто 
при заходе на страницу надо было выбирать кодировку для страницы. потому что - страница имеет 
вид битов и байтов и типа тогда почемуто браузер непонимал какой кодировкой закодирован текст
внутри этих битов и байтов.  получаетс в одном из случаев если мы получили некий кусок байтов
некий набор байтов то применив на них кодировку мы можем получить набор букв. текст. превратить
набор битов и байтов в текст. 

получается когда слышим слова кодировка то на ум должно прходить сразу два ее спутника : некий поток набор байтов и  набор текста.  кодировка позволяет превратить одно в другое.
если мы хотим бумажный текст на листе засунуть в комп то нужно составить массив байтов согласно 
кодировке и поместить в комп. если у нас на компе есть файл из байтов а мы хотим его прочитать 
то нужно на читать массив байт за байтом искать в таблице кодировки за какую литеру отвечает 
текущий байт и писать на бумажку эту литеру. таким макаром мы из байтов получим текст

в чем прикол кодировки. это как слово горение. оно лишь часть картины. горение это 
процесс. значит если есть горение значит есть дрова и продукты отходов горения и  продукт полезный от горения. и это надо все вместе значть понимать и рассматривать. это как полет.
полет это процесс. есть обьект полета - самолет. есть куда он летит откуда. и другие атрибуты полета они все неотделимы от полета. полет лишь часть картинки. надо всю картинку представлять.

тоже самое про кодировку. есть обьекты кодирровки - это литеры и биты. есть процесс пееревода 
одно в другое. есть носители обьектов - бумага, жесткий диск. так что  одного слова кодировка
мало чтобы оно говорило обо всей картине в целом.  а важна именно картинка  в целом.

если мы скажем полет. то ничего непоняно. что летит. куда летит откуда летит. как быстро летит.
итд итп.  слово полет это лишь часть картины. это процесс. но одного слова полет мало чтобы 
было все понятно.


так и кодировка. что кодиируется . во что кодируется. что является носителем источника
и результата. 

согласно man ascii кодируются литеры  ( а что такое литеры в целом говоря ?) в байтовый вид.
но этого мало.  что является носителем литер. кто делает преобразование. что является носиелем
байтов. 

ясно одно если мы слышим слово кодировка ascii то значит где то там мы будем иметь дело с литерами
и с байтами  и преобразовывать одно в другое.

это как слово костер. значит гдето там мы будем иметь дрова и высокую температуру. 
неотьемилимые свойства костра.

так и с кодировкой. буквы и байты это ее неотьемлимный свойства

=======

OCT, HEX, DEC

вопрос захера нам oct вид в компьютерах. заодно и hex.
где это все полезно на практике?



в файле все записано битам 01010101010101101010101010
но по факту они на диске разбиты на байты

байт байт байт байт байт байт байт байт



распечатаем на экране содержимое файла в виде байтов. причем в трех вариантах.
вначале байт будет представлять в десятичном виде, в шестнадцарритриицном и в восьемирочном.

(dec) 118  97 115 121  97  13  42  42  10 118  97 115 121  97  10
(hex)  76  61  73  79  61  0d  2a  2a  0a  76  61  73  79  61  0a
(oct) 166 141 163 171 141 015 052 052 012 166 141 163 171 141 012


возникает какой из этих видов проше всего позволяет налету глазами конвертировать байт в битовый 
двоичны вид 0101010101 чтоб неприбегать к калькулятору. ответ восьмеричный вид! щас разберем так. поэтому то он и существует!


в восьемричном исчислении знаков восемь 0,1,2,3..7
семерка  в битовом представлении это 7 = 111

получается один символ собой кодирует три бита. 
в самом деле

0 = 000
1 = 001
2 = 010
3 = 011
4 = 100
5 = 101
6 = 110
7 = 111

как видно если у нас есть восьмеричное число на данный момент состоящее из одной цифры
то можно точно сказать что за ней кроется три бита.


поэтому скажем за двухзначным oct числом кроется всегда шесть бит. неболее шести бит

57 = 101 111

проверим (oct) 57 = ( dec (8^1)*5 + (8^0)*7  ) = (dec 47) = 101 111

так вот у oct чисел ест два охуенных свойства.  первое это то что если перевести oct число в битовый вид то число бит будет небольше чем число oct цифр * 3. тоесть

(oct) x = 3 бита
(oct) xу = 6 bit
(oct) xyz = 9 bit итд

пример

(oct) 7 = 111
(oct) 77 =  111 111
(oct) 777 = 111 111 111

7 - это макс число из одной цифры в oct счислении
77 - это макс число из двух цифр в oct счислении
777 - это макс число из трех цифр в oct счислении

поэтому тут я доказал эту щтуку что если у нас есть oct число 3457676 то в битовом виде
оно будет занимать 7цифр * 3бита = 21 бит

и второе суперкрутое свойство это то что для того чтобы перевести oct число в битовый вид
надо взять каждую цифру в числе и представить в битовом виде
тоесть

57 = 5 и 7 
5 это 101
7 это 111

значит 57 = 101 111

и это суперкруто! потому что такое правило совершенно неработает в десятичном представлнии байта.

еще пример

(oct ) 456 
4 это 100
5 это 101
6 это 110

значит (oct) 456 = 100 101 110

это совершенно фантастичкское свойство oct чисел.
ничего подобного у dec чисел абсолютно нет!
чтобы пеервести dec число в битовый вид это нужно поебаться конкретно.

приведу пример
вот битовое представление некоторых dec чисел

dec
 9 								1001
 99 						110 0011
 999 					11 1110 0111
 9999 			   10 0111 0000 1111
 99999 		   1 1000 0110 1001 1111

как видно даже и близко тут неработает правило что битовый вид является суммой
отдельных цифр.

единственное что верно для dec чисел это то что если dec число состоит из n цифр 
то его битовый вид займет не более чем n*4 бит. получается за каждой dec цифрой скрывается 
четыре бита. или до четырех бит точнее. но поскольку инфо на дисках хранися в виде байтов то есть
в виде неменее 8 бит то получается что 

пример есть у нас число 

(dec)  1212338898898234980

оно состоит из 19 цифр. значит оно занимает 19*4 бит = 76 бит
дополняем до полных байтов итого 80 бит или 8 байт.

таким макаром мы умеем представлять сколько бит надо надо на диске в зависимости от того 
сколько цифр в dec числе.  за 1 dec цифрой кроется 4 бита.это хорошо. но как уже сказал dec числа плохи тем что зная цифровой вид dec числа его совершенно непросто переввести в битовый вид.


а вот oct числа переводятся просто прекрасно. за одной oct цифрой кроется 3 бита.
и битовый вид можно получить записав битовый вид отдельных цифр.

как уже говорил вот пример

(oct)  1237701 = 

берем табличку для цифр

0 = 000
1 = 001
2 = 010
3 = 011
4 = 100
5 = 101
6 = 110
7 = 111

получаем
1237701 = 001 010 011 111 111 000 001

проверим на компе 
$ echo "obase=2; ibase=8; 1237701" | bc
1 010 011 111 111 000 001

полное совпадение!

тут сразу скажу про obase и ibase их нужно вставлять в echo именно в порядке что 
obase первый а ibase второй всегда. если наоброт то будет полная хуйня. 
obase это счисление которое хотим получить а ibase исходное.


чтоб было еще лучше видно то что 
цифры в dec числе  никак не вяжутся с ббитами вот картинка



dec
 9 								1001
 99 						110 0011
 999 					11 1110 0111
 9999 			   10 0111 0000 1111
 99999 		   1 1000 0110 1001 1111

в тоже время oct и hex числа отлично переводятся в биты

oct
 7 				111
 77 		111 111
 777 	111 111 111


hex
 F 			 	    1111
 FF			   1111 1111
 FFF 	  1111 1111 1111


это потому что последняя цифра и в oct и в hex выражается через биты у которых 
все единицы


тоесть 7 (oct) = 111
       F (hex) = 1111


hex счисление отличается от oct только тем что hex цифра за собой скрывает четыре бита
а в oct цифра скрывает три бита вот и вся разница.


тоесть если мы видим 

hex ABC4567F 

то мы можем смело понимать что в битах это число занимает n*4 бит = 8 * 4 = 32бита
тоесть каждая цифра в hex отбражает половину байта. таким образом если наше hex число 
можно отбразить в байтовом виде как

(AB)(C4)(56)(7F)

кстати говоря в oct виде байт занимает три цифры.
поскольку байт в dec максимально это 255 посмотрим чему оно равно в oct.
dec 255 = bin 1111 1111 = 11 111 111 = oct 377

правда тут несовем понятно ведь 3 = 011 тоесть 377 = 011 111 111 это 9 бит а не 8 бит
так что неочень понятно в точности как это байт можно в oct представить. мы типа 0 откинули в 
oct 3.

а вот у hex все впорядке одна цифра это 4 бит. так что две цифры это 8 бит или байт.
так что любой байт  в hex это две цифры.

таким образом в целом говоря кода мы смотрим на oct или hex мы сразу понимаем сколько бит
занимает данное цисло и можем достаточно быстро на лету перевести в битовый вид.
ну для hex это сложнее потмоу что надо помнить в битовом виде  16 значений ( для 0, 1, 2,... F)
а вот для oct это существенно проще так как там нужно помнить всего 7 битовых значений
для 0,1, 2, ... 7

причем как уже сказал чтобы перевести из hex,oct в битовый вид надо просто взять 
перевести в биты каждую цифру и просто соединить. эьто очень круто и очень просто дает 
вохможность налету переводить окты и хексы в битовый вид.


возвращаемся к нашему исхоному примеру.
у нас есть файл в котором есть байты. я их 
распечатал в трех разных методах отображения байтов


(dec) 118  97 115 121  97  13  42  42  10 118  97 115 121  97  10
(hex)  76  61  73  79  61  0d  2a  2a  0a  76  61  73  79  61  0a
(oct) 166 141 163 171 141 015 052 052 012 166 141 163 171 141 012

dec вобщн бесполезен для трансформации в 010011 вид
hex сложноват ибо за одним символм кроется аж четыре бита
oct самый простой для визуальной трансформацмии  в 010 вид ибо за одним символом кроется всего три бита.

берем строчку

(oct) 166 141 163 171 141 015 052 052 012 166 141 163 171 141 012

уже находу я могу много ее кусков перевести на лету в битовый вид

(oct) 001хххххх 001ххх001 001хххххх 001111001 001ххх001 000001ххх 000хххххх ...


потмому что в oct виде 1= 001, 7= 111, 0= 000

тоесть даже помня всего две цифры в битовом виде ( один и семь) я уже сразу 
существенно понимаю как в битовом виде выглядят байты в файле. это огонь.

еще раз в чем прикол oct и hex счислений.
инфо на диске ханится в виде байтов.  байт состоит из битов.
в конечно итоге на диске хранятся биты.
0101010100101101010101010101010110101011010101001

тоесть инфн на диске хранися в двоичной системе
отображать инфо в форме битов (двоичная систе) очень громоздко накладно.

далее можно конечно всмопнмить что все таки в прграмму инфо считывается в форме байтов тоесть
в группах по 8 бит. 

далее мы можем отобразить каждый байт в dec системе  тогда соедержимое файла это будуц
цифры то 0 до 255

123 111 000 007  012 017 итп

в чем минус такого отображения что налету из dec числа трудно его преобразить в битовый вид.
а нам порой это хочется. также если у нас есть небайтовый вид а битовый

010101001010101010101010 

то его вобще  в dec отобразить сложно

толидело когда мы юзаем oct

для того чтобы байт отобразить в oct надо просто напросто разбить его на группу по три бита

aabbbccc  правда у нас нехваетает одного бита но вместо него добавляем незначащий 0
тоесть

0aabbccc

а далее мы ищем для каждой группы просто цифру по таблице. пример

11010110 = 11 010 110 = 011 010 110

таблица


0 = 000
1 = 001
2 = 010
3 = 011
4 = 100
5 = 101
6 = 110
7 = 111

получаем

011 010 110 = (oct) 326 

вот так мгновенно и легко мы биты превратили в oct
более того нам похеру сколько у нас бит в потоке. 

берем поток 
0101010110101010110101010110100110

разбиваем его на группы по три. применяем таблицу и получаем это число  в oct виде.

тоже самое для hex счисления. только там группы по 4 бита и таблица на 16 символов.

таким образом бинанрный вид биты можно буквально на лету трансофирировать в oct поток
ну и если чуть более постараться то и в hex поток.


верна и обратная задача . если есть oct число  то его супер легко трансформироваь в битовый вид

пример

(oct) 24577453562 = 010 100 101 111 111 100 101 011 101 110 010

все по тойже таблице
 

таблица


0 = 000
1 = 001
2 = 010
3 = 011
4 = 100
5 = 101
6 = 110
7 = 111

просто берем цифру и ее превращаем в три бита.

это все просто супер. и в тоже время для dec преобразований вида dec -> bin , bin -> dec
ничего подобного неработает. в этом и фишка hex и oct счислений.

в следущей части я разобрал почему 377 (oct) в bin виде имеет четко 8 бит а не 9бит
как это нам казалось.
============
bit, byte
octal 
bin

прежде всего байт это группа битов в размере 8 штук. (как кучка семечек которых 8 штук)
а что такое бит. бит это некая хрень которая может принимать два значения. условно
 говоря либо значение "a" либо значение "b". бит это чисто математическое понятие
 тоесть абстрактное. физическим носителем бита может быть что угодно. например кружка воды.
 она может быть полная или пустая. далее нужна некая система которая будет считывать 
 физический носитель бита и выдаваь нам такое: бит (состояние ) = полный\пустой. 
 или бит(состояние) = жив\мертв
 далее нам же похеру каким физ свойством закодировано состояние бита нам главное 
 понимать суть состояния. поэтому далее некая машина нам преобразует физ свойство в
 мат величину. например. полный = a, пусто = b
 получаем 
 bit = a
 или
 bit = b

 далее вспоминаем что в байте битов у нас 8 
 значит мы имеем группу сущностей вида abbababa
 вместо a и b можно заюзать 0 и 1
 получаем 

 байт это множество вида 0100110
 причем байт это непросто множество битов а оно еще и упорядоченное то есть
 у битов есть порядковые номер тоесть биты нельзя переставлять местами

 ну хорошо у нас куча байтов

 01010101
 01010110
 01001010
 01010101

 тоесть некая система нам генерирует эти байты.

 далее можно этому обьекту сопоставить число. потому что по случайности 
 ровно такой же вид имеют числа в бинарной записи

 таким образом у нас абстрактный мат обьект как бы превратился в число.
 ну или мы можем всяегда для байта найти однозначное сооовествие в форме числа которое 
 имеет такой же вид в бинарной системе счисления.

дален интересно. если у нас есть bin число то мы всегда можем его 
преобразовать по алгоритму в dec число

01001011 =  (2^7)*0+ (2^6)*1+ (2^5)*0+ (2^4)*0+ (2^3)*1+ (2^2)*0+ (2^1)*1+ (2^0)*1= 75 (dec)  

(oct)64*x+8*y+1*z=(dec) 75
x=1

8*y+z=11
y=1

z=3

113 (oct) = (dec) 75
из верхнего мы уже знаем что (dec) 75 = (bin) 01001011

полуаетчся что 113(oct) = (bin) 01001011
далее мы берем цифры 113 и смотрим что
1(oct) = (bin) 001
3(oct) = (bin) 011

и мы замечаем что 113 (oct) = 010 010 011 где каждые три бита представляют собой его же цифры.
010 = 1(oct)
010 = 1(oct)
011 = 3(oct)

берем 255 dec

255(dec) = 11111111 
255(dec) = 64*x+8*y+z
x=3
8*y+z=63
y=7
z=7

значит

255(dec) = 377(oct)

значит 377(oct) = 255(dec) =  11111111
значит
377(oct) = 1111 1111

теперь посмотрим а какой бинарный вид имеют цифры в числе 377(oct)

3(oct) = 3(dec)=(bin) 011
7(oct) = 7(dec) = 111

выпишем рядышком 3(oct)7(oct)7(oct)= 011 111 111 = 0 1111 1111

сравниваем 377(oct) =   1111 1111
и 3(oct)7(oct)7(oct)= 0 1111 1111

видно что из второго числа можно получть первое если отбросить лидирующий ноль.

получаем такое правило: если мы хотим преобразоать oct в bin то прямой способ точный 
это преобразовать oct в dec а уже dec в bin. но есть быстрый способ - берем каждую цифру 
в oct числе. преботазауем ее в bin. потом записываем вместе все биты и отрасываем головной бит "0"

посмотрим а может ли быть такой вариант что головной бит будет "1"
мин число в бинарном было бы вида 100 000 000 = 1 0000 0000 = 1 0000000 . тоесть это число
уже больше чем 1 байт. 
также посмотрим из каких oct цифр 100 000 000 оно бы состояло = 4(oct)0(oct)0(oct)
(oct) 400 > (oct) 377
тоесть если мы говорим о преобразовании oct чисел не превышающих байт то 
вышеописанное правило точно работает.

прикольно что правило oct -> dec -> bin это реальное правило преобразования
а правило (oct) abc -> a(bin)b(bin)c(bin) минус лидирующий бит "0" это некая удачная эмпирическая формула. поэтому то мы ноль и убираем чтобы подогнать эмпирическую формулу под строгий мат результат. поэтому то 377 (oct) и занимает 8 бит а никак не 9 бит. 9бит это чисто погрешность
эмпирической формулы.

еще раз почеркну что полноцеееный способ перевода октал в бин это октал перевести в дек
а дек перевестив бин. а способ кодга мы еберем цифры в окт и каждую раскладываем в три бита
а потом собираем вместе это эмпирическая формула поэтому то она в случае с (oct)377 и дает
девять бит. тоесть эмпирическуб формулу надо использовать с поправкой в итоге. никаких девяти
бит там нет. также стоит заметиь что для бин числа что  11 что 00000000011 это одно и тоже 
поэтому вобщем и целом эмпирическя формула дает верный результат даже без поправки

============
откуда 
скачал intel книжки по cpu 

https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html


============
octal 2 byte

если записать в файл символы "1 " (один  и пробел)

$ echo -n "1 " > ./text1

далее мы читаем этот файл через od в режиме oct и в режиме когда поток байтов в файле
разбивается на биты и далее обьединяется в группы размером 1 байт

$ od -t o1 ./text1 
0000000 061 040

0000000 это просто адрес офсета смещения относительно начала файла.
(oct) 061 отвечает за "1"
(oct) 040 отвечает за " "

пока все нормально все ожидаемо.

далее мы читаем этот же файл в режиме когда считыаемый поток разбивается на биты а потом
эти биты обьединяется в группу по 2 байта.

$ od -t o2 ./text1
0000000 020061


 пеерведем байты в биты

(oct) 061  = 00 110 001 = 00110001  
(oct) 040  = 00 100 000 = 00100000  

(oct) 020061 = 0 010 000 000 110 001 = 00100000 00110001

ожидалось что мы будем иметь 
00110001 00100000 = 0 011 000 100 100 000  ( oct 030440 )


а программа показала нам что на диске
00100000 00110001 = 0 010 000 000 110 001  ( oct 020061 )

тоесть байты поменяны местами.


на самом деле вот в чем дело. на диске биты байтов записаны в порядке
little endian. это значит что первым на диск пишется LSB (least siginificant bit тот который
2^0) а последним пишется MSB (most significant bit тот который 2^7)

берем (oct) 061 = 0011 0001 он будет записан на диске вот в таком виде 
(начало файла) --> 1000 1100

после него (oct) 040  = 0010 0000 будет записан на диске в виде
0000 0100

и таким образом оба байта будут записаны на диске виде битовой последовательности
(начало файла) --> 1000 1100  0000 0100 --> (конец файла)

при этом еще раз бит с 2^0 он находится несправа как мы привыкли а слева в каждом байте

еще раз битовый вид как мы ожидали

00110001 00100000

а вот как по факту 

10001100 00000100

как видно сами байты расположены в томже порядке. но каждй байт зеркально отражен 
относительно своей середины. потому что (еще раз) комп пишет биты байта в файл начиная с младшего
бита а не старшего. потому что intel цпу они хранят байты в оперативке а значит и на диске
согласно "little endian" правила. мы же обычно на бумаге записывем биты в порядке "big endian" 
чего нет на цпу интел. точнее в регистрах цпу интел тоже биты хранятся в режиме big endian но в
оперативке и походу значит на диске биты хранятся в порядке little endian.

еще раз покажу где находится 2^0 бит в файле как мы полагали 

    (начало файла)-->  (2^7)00110001(2^0)    (2^7)00100000(2^0)

а вот как по факту они записаны в файле

    (начало файла)--> (2^0)10001100(2^7)     (2^0)00000100(2^7)



собственно далее как происходит расшифровка битов в случае файла с big endian.

есть поток битов
01010101 10101010 1011010 1010101...

мы говорим что мы хотим его расммотреть в разрезе скажем по три байта. выбираем первые 
три байта
01010101 10101010 10110101

если кернел знает что биты записаны как big-endian то комп их расшифроваывает вот так:
(2^23)--> 01010101 10101010 10110101 <--(2^0)

если же кернел знает  что биты записаны как little endian то он эти же биты расшифроывает как
(2^0)--> 01010101 10101010 10110101 <--(2^23)


покажу на примере как выглядит разбивка потока битов в файле скажем когда мы хотим 
посмотреть разбивку по 2 байта

(2^0)01010101 01010101(2^15) (2^0)010101010 00101010(2^15) (2^0)10101010 10101010(2^15) (2^0)10101010 10101010(2^15) (2^0)10101010 10101010(2^15) (2^0)10101.. 


получаетс чтобы правильно понимать как записаны биты байтов в файл надо знать какой endian
юзатеся на компе. тоже самое для обратной задачи. если мы читаем биты с файла то чтобы их 
интерпретровать в байты надо знать как endian юзается на компе потмоу что одна и таже последова
тельность битов можно интерптретировать двояко


(2^0)01010101 01010101(2^15)

либо

(2^15)01010101 01010101(2^0)

 биты одни и теже. а числа будут разныве в итоге.




еще раз возьмем исходный пример

(oct) 061  = 00 110 001 = 00110001  
(oct) 040  = 00 100 000 = 00100000

пишем 061 на диск. пишем как bigendian. первым пишем старший бит в байте.
00110001

далее пишем 040 получаем 

00110001 00100000

далее читаем биты и  интеретируем помня что это bigendian

(2^15)00110001 00100000(2^0) = 0 011 000 100 100 000 = (oct) 030440


теперь пишем на диск тот же 061 и 040 но используем little endian тоесть первым на диск
идет младщий бит байта

10001100 00000100

читаем эти биты помня что это litle endian.

(2^0)10001100 00000100(2^15)

переписываем эти биты в стандарной бинарной нотации

00100000 00110001 =  0 010 000 000 110 001 = (oct) 020061


теперь понятно почему мы получили 020061

$ od -t o2 ./text1
0000000 020061



далее. запишем в файл "1 1"
$ echo -n "1 1" > ./text1

посмотрим побайтно
$ od -t o1 ./text1 
0000000 061 040 061

попробуем предсказать как будеь выглядеть ответ если мы посмотрим потрехбайтно.


(oct) 061  = 00 110 001 = 00110001  
(oct) 040  = 00 100 000 = 00100000

на диске "1 1" в битовом виде с учетом того что комп их туда пихает в виде little endian
будет вылядеть как

10001100 00000100 10001100

далее мы вспоминаем каков порядок битов в little endian

(2^0)10001100 00000100 10001100(2^23)

перепишем биты в стандартной нотации бинарной

00110001 00100000  00110001 = 001 100 010 010 000 000 110 001 = (oct) 14220061

проверяем на компе

$ od -t o3 ./text1
od: invalid type string ‘o3’;
this system doesn't provide a 3-byte integral type

хахаха! od неподдерживает трехбайтовый вид.

прикольно что и hex трехбайтовый неподдерживается утилитой od
$ od -t x3 ./text1 
od: invalid type string ‘x3’;
this system doesn't provide a 3-byte integral type




endiness зависит от модели цпу.




пока что я понял вот что. кернел для процесса в памяти создает page table в которой записан 
маппинг между вирт адресации памяти ( с которой оперирует программа в юзер спейсе) и физ памятью.
между цпу и шиной памяти стоит mmu железка. цпу всегда оперирует внутри себя тоесть знает
только вирт адресное пространство. как он он физ адресацию незнает невидит не вкурсе.
цпу обращается к вирт адресу. запрос от цпу приходит на mmu. как я понял в регистр CR3 цпу кернел
записывает адрес в физ памяти с которого начинается page table для текущего процесса. так что mmu читая тот регистр знает где ей в физ памяти искать page table. таким образом mmu для вирт адреса
в оперативке в page tabe находит физ адрес. этот адрес mmu и выставляет на шину адреса памяти
для запроса. 

таким образом работа кернела в том чтобы в памяти для процесса создать page table
заполнить ее а в цпу в CR3 регистр пихнуть адрес page table. после этого работа ядра по настройке
mmu закончена. а mmu имеет все для того чттбы сделать свою работу -> преборазовать вирт адрес
в физ адрес.

context switch. это коогда мы из цпу выдавливаем все инфо от одного процесса
и загружаем в него инфо от друого процесса. как я понял это на данный момент истории происходит
так - шедулер ядра копирует значения регистров цпу в память в область ядра. в ту структуру 
в памяти которая описывает процесс. далее шедулер загружает в цпу в регистры значения регистров
того процесса который будет следущим запущен на цпу. когда все регистры загружены то 
шедулер копирует как я помнимаю в спец регистр адрес начала кода нового процесса на который
мы будем пеереклчаться. и далее как я понимаю происходит (неким образом)возможно чеерз int 
возврат цпу из режим ринг 0 в ринг 3. и процессор получетя имеет все регистры с данными от процесса
и также начинает иполнять ту команду ссылка на которую у него хранится тоже в спец регистре.
так что вуаля - новый процесс начнет выполняться в тайм слайсе. фишка главная в том что context
switch это не какая то там особая секретаня загадочная процедура а просто тупо баналоьно упрощенно
говоря шедулер(кусок кода ядра) копирует регистры от процесса в память в таблицу информации
 о процессе или наоборот из памяти в цпу.  руками как говорится. есть еще и процесс
 когда сохраннеиео инфо о регистрах можно делать неруками и типа одной командой цпу (тоесть hardware context switch) но типа он якобы менее гибкий ибо сохраняет все регистры а это может 
 быть и ненадо и типа и медленней. ведь каждый регистр сохранить это обращение к памяти поэтому 
 ручное сохранение происходит  типа в кончено итоге быстрее.


=========
bios 

окаывается что это просто программа. просто кусок кода.
который хранится условно говоря на флэшке внутри компа.

цпу так устроен что он когда стартует то лезет читать данные по определенному адресу
в RAM. и так устроено что содержимое биоса маппится или копируется (незнаю) по этому адресу
таким образом цпу начинает исполнять программу кода биоса.

=====
640k mem

на счет цпу вначале истории линейки от интела.
было 4004 и 8008 и 8080 и потом был 8086.

так вот все текущие процессоры по крайней мере которые 32 битные (тоесть не 64 битные) 
они все в режиме real mode если им подсунуть один и тот же exe (бинарный) файл
то они все его выполнят без проблем. что 8086 что условно говоря pentium 4.
тоесть коды команд в бинарном виде ( оп коды) кодируют на всех этих цпу одни и теже
команды. тоесть у всех цпу начиная от 8086 и выше бинарная совместимость. не говоря уже
про source code совместимость. естственно она совместимость обратная тоесть коод от 8086
прокати на p4 но не наоборот.

так вот все цпу начиная с 8086 тоесть >= 8086 они совместимы в том смысле в котором уже
описал. а вот скажем 8080 и 8086 уже несовместимы ни на уровне source code ( команда асемблера которые еще нужно откомпилировать) ни на бинарном уровне ( готовые exe elf файлы).
если вы брали откоипилированный файл для 8080 то он неработает на 8086.
если взять txt файл с асемблером от 8080 то его неоткомпилует комплиятор для 8086.
итак эти цпу несовместимы. единственное что была программа которая шла к 8086 которая преобразо
вывала текстовый файл с асемблером от 8080 в текстовый файл с асемблером для 8086.
но это несовместимость это преобразование одного асемблера в другой. а потом уже компиляция комилятором для 8086. итак эра 8086 началась с процесссора 8086. об более древних можно забыть.


возврашаепся к исходному вопросу : изучаем откуда взялся этот лимит памяти 640k

для этого берем цпу:

intel 8088

сразу скажу что 8088 это ровно такой же 8086 но у него обрезана шина данных с 16 бит ( как у 8086)
до 8 бит. вот и вся разница. это позволило присобачивать этот цпу на мат платы которые (как я понял
из книжки морзе который автор цпу) были предназначены ранее под 8080. в любом случае так как 
шина данных имела не 16 а 8 бит это экономило стоимость мат платы компа. да из того что я понял
8 битная шина данных почемуто делала его совместимым с кучей перифериных микросхем которые
до этого употреблялись для мат плат с 8080 который был 8 бит и хотя как я уже сказал 8080
и 8086\8088 были несовместимы на уровне бинарном(откомпилированных файлов) и уровне source code
(на уровне тектовых файлов с асемблером которые нужно компилировать еще) но на уровне микросхем 
которые крепились на мат платы 8 шина данных от 8088 делала его совместимым с периферийными 
микросхемами и это было круто чтобы чип сразу пошел в рынок под него ненужно было изготаливать
перифериыные микросхемы. 

что еще супер примечательно - именно 8088 цпу выбрал ibm для своего первого ibm pc. того
самого с которого началась эра ibm pc персоанльных компьютеров.


прикольно то что в фирменных документах от интел он назван как 8-битный.
а на самом деле щас его относят к 16 битным.
разберемся:

это 16 битный процессор. 
что значит что процессор столько то битный. например 16 битный. это значит нето что он обязан иметь возможность адресовать память размером 16 бит (шина адреса  16 бит). нет.
это всего навсего значит что  в цпу регистры общего назначения (да есть такие там регистры) имеют 16 бит. и все! опять же это незначит что ширина шины данных 16 бит. нет! у процессора могут быть
регистры по 16 бит а шина данных 8 бит. 
воюбще это забавно. текущие 64 битные процессоры имеют внутри себя 64 битные регистры
а в памяти то байты по прежнему имеют размер 8 бит.  

что дает то что у цпу регистр имеет столько то бит. например 16 бит. это значит
что цпу может взять такой регистр выполнить сложение  с другим таким же регистром.
это будет математическая операция. в чем разница если бы в цпу были 8 битные регистры в чем
улучшение. в том что на регистрах в 8 бит мы можем выполнять математику на числах по 255



разница его с 8080 8086. (уже описал выше) 


термины:
byte = 8bit
word = 16bit

8088 его способ доступа к памяти. способ адресации ячейки памяти. способ указания
адреса ячейки досутп 1 048 575.

данный цпу имел шину адреса шириной 20 бит.
в двочной системе на двадцати битах можно закодировать числа от нуля до 1 048 575.
1 048 575 это 1 Mбайт в двоичной системе.
1 048 575(dec) = 11 1111111 111111 (bin)

таким образом через 20 битную шину адреса можно адресовать миллион ячеек памяти. 

1MB (dec) обозначается в hex счислении как FFFFF

1MB = FFFFFh

таким образом мы узнали какой обьем RAM памяти способен был адресовать данный процессор.

Далее прикол в том что внутри процессора небыло 20 битного регистра в который бы можно было 
совать значения чтобы напрямую адресовать ячейки из памяти. типа выставил биты в 20 битном регистре
и таким образом обозначил в какую ячейку памяти ты хочешь иметь доступ. такого там небыло чудо 
регистра.

внутри цпу были только 16 битные регистры. так что чтобы получить доступ к ячейке памяти 
надо помудить.

значит адрес по которому хранится следующая команда на исполнение вычислялся так:
берется два регистра: CS регистр 16  битный + IP регистр 16 битный.

далее цпу делал так, он брал CS и добавлял к нему 4 бита нулевых справа

был CS(FFFFh): 1111 1111 1111 1111 
стало(FFFF0h):         1111 1111 1111 1111 0000

далее цпу брал регистр IP и складывал с тем что стало

IP(0001h): 0000 0000 0000 0001


сложение(FFFF0h+0001h):

	1111 1111 1111 1111 0000
+	     0000 0000 0000 0001
   ------------------------
    1111 1111 1111 1111 0001 (FFFF1h) 

 получаем что цпу хочет обратится к ячейке с адресом FFFF1h = 1 048 561  байт
вспоминаем а сколько байт в  1МБ (1 048 575).

далее вопрос а если вот такую компбинацию зададим

	1111 1111 1111 1111 0000   (FFFF0h)
+	0000 1111 1111 1111 1111   (FFFFh)
   ------------------------
  1 0000 1111 1111 1110 1111   (10FFEFh) 

10FFEFh = 1 114 095 > 1MB (1 048 575) 
непонятно что происходит с цпу когда он указывает на адрес в памяти больше чем 1МБ
скорей всего так как ответ превышает 20бит то какой нибудь флаг срабатывает о переполнении
и цпу посылает нахуй такой адрес потому что физически на линии адерса всего 20 линий так что
двадцать первая линия там никак неможет повятся. как я понимаю если резудьтат сложение CS+IP
дает резудльтат больше чем FFFFFh то срабыватет флаг об ошибке.


далее комбинации:
CS:IP -- code segment:instruction pointer points to the physical address of the next instruction in memory to execute.
SS:SP -- stack segment:stack pointer points to the stack in memory, a temporary storage place for data.
DS:DI -- data segment:destination index points to the physical address in memory where data is to be stored using a pointer.
DS:SI -- data segment:source index points to the physical address in memory where data is to be retrieved using a pointer.

пока все равно непонтно откуда появляется ограничение на 640К по памяти ? (забегая вперед
я вроде нашел откуда ограничение 640к. в компах от IBM использовался memory map io. это 
значит что между цпу и памятью стоят memory arbiter. запросы от цпу по шинне адреса шли на мемори
арбитр и все запросы по адресу выше 640к он переадресовывал на периферийные устроуства. для цпу
это выглядело как запросы к паяти выше 640к а на самом деле шел доступ к регистрам перифеиных
устройств. вот и весь секрет как был сделано ограничение на 640k памяти со стороны ibm)



=====
8086\88

на счет мульттаскинга

в книге указано что  адрес памяти задается через комбинацию двух регистров.
например CS+IP получаетс в форме segment+offset.

в книжке написано что типа это дает следущее удобство - что операционная система сможет 
контролировать регистр сегмента а пользовательская программа будет иметь свободный доступ
к регистру смещения. значит  можено будет удобно иметь несколько программ в оперативке 
которые непересекаются в памяти.

при этом я непонял каким образом ОС будет захватывать контроль над сегментым регистром
как я понял у 8086\88 нет такого мехагизма потому что у него нет колец. поэтмоу каждая прога
имеет полный доступ к цпу со всеми его функциями. 


также по поводу мультииаскинга. как это на практике в этом цпу можно настроить.
прочел что только кооператиный мультитаскинг . что это. это значит что программа пользоваетьская
должна быть написана так чтобы она САМА периодичеки возращвала упралвение операционной системе.

все таки непонятно. как я понимаю ограничение в 640к это не желеное ограничение не хардварное
а софтварное со стороны самой DOS. так если программа запускаемая в дос получала полный доступ
к цпу то ей по идеебыло глубоко похер на то что думает дос. и она могла лазить по любым адресам.
непонятно. абсолютно непонятно. у прцоессеесаора небыло протектед режима так что любая программа
лазила напрямую в память и плюс имела полный доступ ко всем функциям цпу потому что также
небыло никаких колец. програме ничегонемешало лазить по адресам выше 640К. непонятно.
возможно тут фича в том что программа в досе которая запускалась она непросто сама посебе
на асемблере все функции работы в себе имел а опиралась на api который предоставлял дос.
таким образом вожмно если программа скажем хранила свои данные за пределом 640к то возможно
если дос нужно было туда слазить то дос писало что мол программа корявая нарушает договоренности.
может как то так ?

пока про это все

=====
8086

состоит из двух частей
каждля из которых работает асинхронно от второй

блок EU он выполняет команды
блок BUI он качает данные из памяти и в память.

как   я понял то что два блока рабоиают асинхронно называется pipelining в цпу

в BUI находятся сегментые регистры и IP регистр
в EU находятся регистры общего назначения
=====
8086

регистры

наскько я понял адрес стека задается через SS:SP
непонятно что делает BP регистр. как я понял в ряде случаев вместо SP юзается BP 
но когда и зачем непонятоно
====
8086

как я понял если шина простаивала то цпу его bui блок автономмно подкачивал команды
в размере 6 штук и клал их в спец регистры (без имени) это типа как предикитианый механизм
чтобы некачать команды а уже их иметь . типа кэш команд. как я понял команды он брал
начина я с адерса CS:IP
====
8086

пра работу с памятью. как мы помним 8086 имеет 16 битную шину данных. тоесть он качает 
всегда 2 байта за раз. 

так вот на шине адреса как я понял всегда выставляется только четный адрес в независимости
что мы прописали в команде.

а именно если мы напишем

mov BX, [00520]

то так как он четный то гнашине адреса будет выставлен 00520h
и за один проход будут скачаны ячейки 00520h и 00521h и засунуты в BX

а если мы наппишем

mov BX, [00521]

то тут начнется хитрое. получается посольку у нас регистр BX двухбаыйтный то получается мы 
хотим скачать два байта и указали первый. получается мы хотим скачать байты 00521+00522
тогда цпу выставит на шине адреса адрес 00520 и скачает 00520+00521 за раз. отбросит значение из 00520
и засунет 00521 в BL. далее еще раз выставить на шине адреса адрес 00522 скачает 00522+00523
отбросит 00523 и засунет 00521  в BH.

таким образом если мы задаем четный адрес то он слово скачиывается за 1 такт.
а если мы задаем нечетный адрес то слово скачивается за 2 такта.

интреано!
 
====
8086

сегмент это количество байтов у которых оффсет лежит в диапазоне  
от 00000000 00000000 до 11111111 11111111 

поскольку  
 11111111 11111111 это 65535 то плюс еще нулевой адрес и мы получаем 65536 штук байтов.

далее мы вспоминаем что в 1KB = 1024 байт. тогда делим получаем

65536 : 1024 = 64KB

в сегменте 64 килобайта 
===
8086

interrupt

какие регистры цпу сам самостоятельно автоматически сохраняет прежде чем переключиться на ISR(Interrupt Service Routine):
    When an interrupt occurs, the CPU does the following:

    Push the current address (contents of the Instruction Pointer) onto the stack; also, push the processor flags (but not all the other processor registers)
    Jump to the address of the ISR (Interrupt Service Routine), which is specified in the Interrupt Descriptor Table.

если цпу 32 битный значит сохранение IPE(32bit)+Flags register(32bits) = 16 байт укладывается в стек. если цпу 64битный то 32байта укладывается в стек. А в какой стек юзерский или ядерный? ответ - вот в каком режиме (ring0 или ring3 работал цпу ) цпу работал в тот стек он и уложит.

теперь про ISR:
    The ISR should do the following:

    Push any registers which it intends to alter (or, push all registers)
    Handle the interrupt
    Reenable interrupts
    Pop any registers which it pushed
    Use the IRET instructions, which pops the CPU flags and Instruction Pointer value from the stack (and thus returns to whatever was executing when the interrupt occured).

у этого цпу есть ножка которая сигнаизирует цпу об прерывании от железок

также я так понял что прерываение можно инициировать и софтеверно

я не очень понял как одна ножка это же один бит по факту так вот как одна ножка
позволяет цпу различать номер прерывания.

первые 1024 байт 0000-03FFh в RAM зазерезированы под таблицу interrupt vectors
содержит адреса кода в RAM обработчика события интерапта

одна запись это 4 байта. потому что адрес обрабочика хрнаится в виде Segment:Offset
поскольку каждый по 16 бит то в итоге 4 байта на один вектор. 
значит 1024\4 = 256 штук векторов под 256 разных прерываний.

также последние 16 байт в памяти FFFF0h - FFFFFh зазервериврованы я так понимаю под маппинг кода биоса или его куска или чтото типа того. потому что после сигнала RESET 8086\88 бросается
исполнять код исключительно по адресу FFFF0h

NMI и INTR это hardware interuts
INT n это software interrupts


maskable interrut это такой который может быть проигноиррван или отменен
uunmaskable который несможет цпу ни проигнорироваь ни отменить


интерапт можно активировать програмно но щас интересует больше хардварный метод.
итак на ногу цпу прилетает сигнал что есть интерапт.
он кладет флаги в стек, дизейблит дальнешее получение сигнала о следущем интерапте, и 
считывает по дата bus один байт в котором находится типа номер интерапта. (тут интересный 
момент в том что цпу получает байт по шине данных при этом невыставляя ничего не шине адреса как я понял)
далее он этот номер интерапта умножает на 4 и читает из памяти по адресу "номер интерапта*4" где
же находится процедура обработки этого интерапта.

например NMI немаскируемое пррываение имеет номер интерапта 2. поэтому цпу обращается к
памяти по адресу 2*4=8 тоесть адрес= байт номер 8 и оттуда он считывает адрес процедуры
которая обрабаыавет немаскируемый интерапт.

ну теперт хоть сталоп онятно как цпу различает интерапты между собой. я так примерно понимаю
что номер интерапта который летит в цпу по дата басу его туда засоывает контроллер интераптов. 

спасибо индусу = https://nptel.ac.in/content/storage2/courses/106108100/pdf/Teacher_Slides/mod1/M1L3.pdf

далее индус пишет что софтвейр интерапт имеет номер 3. хм... так что получается что софт интер
апт всегда будет иметь запись в вектор таблице по адресу 3*4 ? а как же тогда номер интерапта
который укаызвается в команде INT <номер интерапта> ?

вобще я так и непонял что получает цпу по дата шине толи номер интерапта толи его приоритет.а!
походу это одно и тоже! номер интерапта он же его приоритет! он же его тип. так тоже бывает 
называют.

NMI интерапт. на серверах есть кнопка тыкая которую мы активируем на цпу nmi интерапт. 
что обычно вызывает немедленное прекрашение выполннения кода и старт выполнения хэндлера nmi интерапата. спрашивается захера эта кнопка нужна. 
как я понял типа ее назначение такое - у нас завис сервер и мы хотим снять дамп памяти чтобы разобраться что с ним было. если тыкнем ресет то ничего неузнаем а если тыкнем nmi то во первых
как бы ни завис сервер цпу 100% прекратит выполгнять то что оно выполняло и кинется выполнять
хэндлер nmi интерапта. и как я понял в том хэндлере можно прописать чтобы был снять дамп всей 
памяти.

при поступлении интерапта цпу помещает в стек регистры с флагами CS:IP регистры, также 
устаналиватс в ноль флаги TF и IF. TF если равен 1 то цпу будет выполнять одну команду а затем
цпу сам будет генерировать прерываение номер 1 и будет выполгнять вектор для этого прерывания.
так как мы уже заняты обработкой прерывания то комады которые мы будеи выполнять по адресу вектора
прерывания нам нужно выполгнить без всяких остановок так что TF надо поставть точно в 0.
когда потом вернемся из векторп прерыания и вытащим регистрс флагами то если там был установлен
Tf=1 то он будет восстановлен. IF=1 дает то что если он устаролвен то цпу может принимать 
сигнал об интераптамх и исполнять их. а если мы поствим IF=0 то прилетающие сигналы об интераптах
будут игнорирваться . это имеет смысл ибо мы уже заняты обоработкой интерапта.



итак еще что происходит когда цпу обрабатывает интерапт.
если от внешнего устройства через ногу на цпу приетает сигнал - то цпу понимат что 
надо запустить интерапт. интерапт через ногу - это внешний хардвейр интерапт.

также интерапт можно инциировать из порограммы через команду int n это софтвейр интерапт

также цпу сам может инциировать интерапт например когда он поделил на ноль. 

значит  при интерапте цпу надо узнат какой номер у интерапта. еслт это хардвейр интерапт 
через ногу то тогда контроллер интерапта (как я понял)  по шине данных посылает на цпу 
один байт в котором указаон номер интерапта.

если это програмный интерапт то int n указывает номер интерапта.

если это сам цпу гененирует интерапт типа при делении на ноль то цпу уже знает какой интерапт
он генениририует.


итак имеем номер интерапта.

цпу кладет CS:IP в стек.также обнуляет флаги TF и IF

далее он умножает на 4 номер интерапта. получаает адрес в памяти откуда он счиывает
два байта.  младщий байт он кладет в IP старший кладет в CS . далее юзая CS:IP он 
качает команду из памяти. и начинает ее выполнять. таим образом в RAM по адресу CS:IP
должна леджать процедура обработки интерапта. выход из процедуры пооисходит по команде IRET.


тут важно отметить что часть интеравтов уже заранее заняты предопределены.
напрмиер


номера интераптов:

0) деление на ноль
int 0  = автоматом генерируется саимим цпу при делении на ноль.

так как номер = 0 , то 4*0 = 0

значит цпу лезет по адресу 0000h и 0001h и качает этт два байта в IP
далее он лезет в 0002h + 0003h и качает эти два байта в CS

итак считыватся байта 0000h,0001h,0002h,0003h

и потом он лезет по адреу cs:ip и ищет там обаботчик деления на ноль.

важно отметить что это анмаскабл интерапт. то есть цпу в него 100% впадет если мы поделим
на ноль. так что от него нескроешься

1) single step interrupt

если мы установим флаг TF.

то цпу после выполенения каждой команды будет сам автомтом вызывать интерапт 1.
эта хрень юзается при отладке программ.

это наверное тоже анмаскабл хотя я незнаю

из таблицы векторов считываются байты

0004h, 0005h, 0006h,0007h


2) NMI

это точно анмаскабл.

происходит от нажатия на кнопку на корпусе компа ( на серверах она таакая есть).

из таблицы векторов считыватся байты c 8-го по 11-ый


3) one byte interrpt

это софтвейр интерапт.
он вызвыается чрез 

int3

исполщуется для дебагинга как точка остановки. еси мы посмтеим в программе 
комаду int 3 то будет сделан интерпапт и цпу выполнит  обрабочткик интерпатпта по 
адресу 3*4 = 12 (dec) = 000Сh адресу

если у нас линукс и мы в нем запустим откомпилированную программу на асемблере
в которой будет команда int3 то в ответ на эту команду ядро линукса убьет процесс создаст 
на диске dump памяти процесса. в терминале появится надпись "Trace/breakpoint trap (core dumped)".
если запускать программу в связке с strace то он покажет что был получен сигнал SIGTRAP.
что значит процесс получил сигнал. это значит что в ядро прилетел сигнал и ядро этот сигнал 
записывает в таблице свойств процесса. когда в очередной раз шедулер собирается пихать процесс
на цпу то он проверяет нет ли какого сигнала который процесс должен обрабоать. если есть
то (как я понимаю) шедулер вместо того чтобы пихать на цпу процесс он запустит обработчик 
этого сигнала при условии что программа когда запускалась то она зарегистрировала в ядре 
обработчик. если прога этого несделала то шедулер запускает для этого сигнала дефолтовый обработ
чик на стороне ядра. дефолтовое действие на сигнал SIGTRAP это убить процесс и записать 
на диск его дамп. что ядро и сделало. в целом я полагаю что цепочка работает вот так: 
на цпу оказывается команда int3 это заставляет цпу запихать регистры в стек. далее цпу запускает
обработчик прерывания считав адрес обработчика из 3*4=12 байта в памяти. 
ну и видимо тот обработчик прерывания запускает кусок кода ядра который генерирует сигнал SIGTRAP
для нашего процесса. генерирует это значит что как уже сказал что в таблицу информации процесса
записвается доп поле что этот процесс получил свойство SIGTRAP. потому что да что значит процесс
получил сигнал. это по факту значит что структура данных в ядре которая описывает свойства 
процесса получила новое свойство. вот и все. сам процесс при этом вобще ничего нечуствует
и незнает тоесть навход всяких там файловых дескрипторов которые открыты у процесса ничего не
прилетает. тоесть область оперативной памяти самого процесса вобще не вкурсе ни о каких сигналах.
появляется запись в области ядра а не вобласти памяти процесса. поэтому в целом эта фраза 
что процесс получает сигнал это херня. получает сигнал ядро. это как сказать что младенец получил
пособие по рождению. его получает немладенец а его родичи. так и здесь. процесс никакой сигнал в форме входящего потока информации на свои открытые файловые дескрипторы неполучает. получает 
ядро - одик кусок ядра сообщает другому куску ядра что вот этот процесс получил новое свойство.
это изовется тем что "процесс получил сигнал". этот сигнал он недля кода процесса он для 
шедулера для куска кода ядра. сигнал о том что для данного процесса нужно вызывать обработчик
данного сигнала. если сравнить процесс с дельфинами то фраза "дельфины получили сигнал" по факту 
значит что сигнал о делфинах получили их дрессировщики что их надо кормить. и обработкой сигнала
занимает ядро а не код процесса. единственное что ( как я понял ) для ряда сигналов процесс при запуске может в ядре зарегистрировать действительно свой обработчик. тогда при "поступлении сигнала" шедулер запустит код обработчика который зарегистрировал  процесс при старте.  

интересно что меняется когда мы запускам программу (дальше для ясности назову ее 2.exe) под дебагером. ведь в этом случае 
по команде int3 терминации 2.exe непроисходит. во первых как работает gdb. 
он запускает 2.exe как свой child процесс. я попробовал притаачится к 2.exe через strace
но нетутто было. толи потому что может к нему gdb уже приаттачен либо потому что 2.exe
находится в состоянии T как процесс (тоесть остановлен). но  я смог приаттачится к gdb
через strace и там видно что у него проскакивает инофрмация что типа его child получил
сигнал SIGTRAP. причем gdb тоже обо этом напишет на экране: 

	Program received signal SIGTRAP, Trace/breakpoint trap.
	0x0000555555554601 in main ()

каким макаром gdb недает ядру затерминейтить процесс я пока без понятия.  
про SIGTRAP немного можно посмотреть тут  $ man 7 signal



4) Interrupt on Overflow 

если у нас при арифметике срабывает переполнение. например.
мы скадывали  11111111 + 1111111  то очевидно что в 8 бит результат не помещается
тоесть происходит переполнение. тогда цпу выставляет флаг OF =1 чтобы нам об этом скзаать.

так вот если на это важно. то мы можем при событии когда цпу высталвяет флаг OF то мы можем
запускат прерыаение. для этго надо после кода арифтиеческих опреаций вставить команду INTO

она и будет озанчать что если OF =1 то запусти  как цпу четвертый интерапт обработку.

советсвенно вектор обработчи будет искаться по адресу 4*4 = с 16-го байта (dec) = 00010h
по 19-ый байт. 

далее.
интерапты с 5 по 31 были зарезерировны на будущее.
так что для софтовых целей остатся доступными для програмирования интерапты с 32 по 256


===

8086

asm

 яп ходу понял почпму почти все операции идут с регсистраом A 
 потому что у нас каждоая операция имеет свой опкод. скажем OB

 и если бы скажем у нас можно было делать 

 mov любой регистр, любой регистр

 то для этой команды нужно скажем три байта к примеру. первый байт чтобы закодировать команду
 mov вторйо для операнда и третий для перанада.

 если же у нас команда mov уже привязана толькок к регистру A то мы одним байтом кодирует
 и команду и первый операнда
 тоесть OB = mov A,

 это большая экономия на коичество опкодов внутри цпу

====

freedos

установка небез подьебок.

скачиваем iso = https://www.ibiblio.org/pub/micro/pc-stuff/freedos/files/distributions/1.2/FD12CD.iso

далее создаем виртуабокс ВМ. в свойствах высталяем 32MB RAM,
чипесет выставляем PIIX3

грузимся с CD.

выбираем установку на harddisk

далее подьебка полетят ошибки "invalid opcode" и установка обломится. 
решение. когда видим картинку "install from harddisk" тыкаем "tab" и дописываем в конце raw

тыкаем enter. вот теперь установка пройодет успешн8о.

перегуржаеся (обяиазтельно надо перзагурится!)
грузимися с диска

запускаем программу FDIMPLES
она позволит потавить разные полезные пакеты с CD. ставим NASM ассемблер комплияторы.

он поставится в папку c:\devel\nasm\nasm.exe
путь к нему небудет прописан в PATH:
идем в autoexec.bat и там добавляем его в path

также ставим из пакетов (через fdimples) ассемблер дебагер insight
и добавляем в path в autoexec.bat путь к нему c:\insight\


далее через msedit состалвяем asm файл.
а собираем егов опкоды через 
> nasm -0 19.com 19.asm

теперь его можно загрузить в дебагер 

> insight

F1 - кнопка справки в insight 


код. пример

19.asm

bits 16
MOV AH, 0 
MOV AL, 6 
ADD AL, 5 
AAA


> nasm -f bin -o 19.com 19.asm

это создать com файл внутри которые только опкоды который может раотать под дос.

директива bit16 говорит nasm чтобы он делал опкоды от 16-bit асемблера

почемуто запуск в дос 19.com приводит к зависагию а раньше все было окей.
тем немнее можно запутстиь код 19,com  вдебагере insight
и там тыкая на F8 смотреть выоплнение шаг за шагом

nasm manual = https://www.nasm.us/xdoc/2.09.10/html/nasmdoc0.html

из тго что я понял nasm генрруиет obj файл. в котором голые опкоды. такой код можно
запускать только в дос. в линуксе запуск такого файла ничего недаст. а скажем в линуксе после nasm нужно по файлу еще проходится линкером
только линкер превратит файл в готовый к исполненмию файл. детали пока туманны.

если мы сидим в линукс и имеем  файл который хотим дизассемблиоровать то:
$ objdump -b elf64-x86-64  -M "intel" -d 27.exe

-b = тип формата файла. он может быть elf64-x86-64, а может быть binary.

обычно узнать формат файла можно через подсказку самого objdump 

$ objdump -f 27.exe
27.exe:     file format elf64-x86-64

-M "intel" = это настройка чтобы асемблерный текст был в красивом формате intel а не уродском AT&T

-d = означает чтобы дизасемблить только ту часть файла где исполняемый код. есть
еще ключ -D это дизасемблить весь файл целиком со всеми секциями.

также objdump умеет сам автоматом распознавать типы файла так что можно 
его вобщем то сразу запускать вот так:
$  objdump -d ./51.exe -M intel

также удобно откомпилировать программу чтобы  в нее были включены debug символы (текст программмы
на C) и потом objdump покажет микс из ассемблера и программы на C:

$  gcc -g -m64 -o 51.exe 51.c
$  objdump -S -d ./51.exe -M intel

пример программы:
$ cat 51.c
#include<stdlib.h>
#include<stdio.h>
#include<sys/wait.h>

int main(){


// обьявляем переменные

char d = 1;

while(1){
};


return(0);
};


пример что покажет objdump в микс режиме:
$  gcc -g -m64 -o 51.exe 51.c
$  objdump -S -d ./51.exe -M intel


00000000000005fa <main>:
#include<stdlib.h>
#include<stdio.h>
#include<sys/wait.h>

int main(){
 5fa:   55                      push   rbp
 5fb:   48 89 e5                mov    rbp,rsp


// обьявляем переменные

char d = 1;
 5fe:   c6 45 ff 01             mov    BYTE PTR [rbp-0x1],0x1

while(1){
 602:   eb fe                   jmp    602 <main+0x8>
 604:   66 2e 0f 1f 84 00 00    nop    WORD PTR cs:[rax+rax*1+0x0]
 60b:   00 00 00 
 60e:   66 90                   xchg   ax,ax


важно еще раз заметить что objdump может дизасемблить и object файлы *.o и готовые бинарники типа elf64

возвращаемся конкретно кнашему примеру. у нас бинарный файл.

$ objdump -D -b binary -mi386 имя_файла

Disassembly of section .data:

00000000 <.data>:
   0:	b8 41 00 83 c0       	mov    $0xc0830041,%eax
   5:	30 ba f8 03 ee 66    	xor    %bh,0x66ee03f8(%edx)
   b:	b8 00 c0 00 00       	mov    $0xc000,%eax
  10:	66 ff e0             	jmpw   *%ax

как видно по дефолту заюзан формат вывода "at&t" мне же удобнее когда асемблер выглядит 
в виде "intel"

$ objdump -D -b binary -m "i386" -M "intel" 22.bin

Disassembly of section .data:

00000000 <.data>:
   0:	8b ec                	mov    ebp,esp


вот это уже то что надо.



также можно как альтернативу можно заюзать дизасемблер от самого nasm

 $ ndisasm -b16 20.com


еще раз напомн как через nasm откопилировать асемблер текст в 16-bit опкоды  (он же object файл)

$ nasm -f bin -o 19.com 19.asm


а вот как откомпилировать 64-bit код в elf файл 

$  nasm -f elf64 2.asm
$  ld -s -o 2.exe 2.o


ключ -s в ld = Omit all symbol information from the output file.
можно запускать ./2.exe



или вот еще пример компиляции в 64-bit
(взято с https://gist.github.com/yellowbyte/d91da3c3b0bc3ee6d1d1ac5327b1b4b2)


$ nasm -f elf64 -o hello.o hello.asm
$ ld -o hello.exe hello.o

а вот пример как откомпилировать с debug символами (чтобы потом в gdb смотреть)
$ nasm -g -f elf64 -l hello.lst -o hello.o hello.asm
$ ld -o hello.exe hello.o

-g = включить дебаг символы 
-l = в явном файле показать что там за дебаг символы будут вставлены



=====

8086

онлайн эмулятор. где сразу можно програировать на асмеблере

https://yjdoc2.github.io/8086-emulator-web/compile

===
8086

opcodes.

приступил к разбору как асемлер переводить руками в машинные коды.
на примере команды mov.

описать вариант старый который  у людей с бумажки.
и вариант  с книжки интел.

расмотрим  примеры

1. mov bp,sp
первый вариант машинного кода: код 89  для "Move r16 to r/m16" , когда двигаем 
из регистра в регистр либо память. где r16 это операнд откуда двигаем  то есть 
из sp. смотрим таблицу 2-1. в горизонтальной линии выбираем операнд sp. опускаемся вниз 
и ищем строчку с вторым параемтром bp получаем E5. 
Итого машин код = 89 E5

подставляем проверяем
$ echo -n -e "\x89\xE5" > 22.bin
$ ndisasm -b16 22.bin
00000000  89E5              mov bp,sp

все правилььно.

второй вариант машинного кода: код 8B для "MOV r16,r/m16 RM" когда двигаем из регистра или памяти 
в регистр. тут важно отметить что в этом случае наш операнд это первый параметр после слова mov 
(а в предыдущем примере это был первый параметр после mov). в данном случае этот параметр=bp
(а впрошлом случае параметр был равено sp). берем параметр bp и постдавляем в таблицу 2-1 
в строку с r16/r опускаемся по столбцу вниз ищем строку с SP. получаем на пересечении код EC
Итого машин код = 8B EC

подсталяем проверяем
$ echo -n -e "\x8B\xEC" > 22.bin
$ ndisasm -b16 22.bin
00000000  8BEC              mov bp,sp

все совпало все правильно!

тоесть для одной команы на асемблере есть несколько команд в машинных кодах !

еще примеры:
2. mov ax, 0x1020
3. mov dx, 0x1020

=====
8086
640k

по моему я наконец понял откуда взялся этот блядский 640к ограничение по размеру памяти доступному 
для программ если работать на intel 8086\88.

вообще хуй найешт явный ответ как же сука они это сделали ведь цпу может адресовать 1MB памяти. так как? как суки как?

так вот гна стековерфлоу я нашел уопминание в коментариии что остальрые 340к были замаплены периферийными устройствами через 
memory map io.   вот оно бляь !!!!!! наконец то ответ!!!!!

и это сделало ibm как я понимаю через ихние ibm материнские платы. цпу был от интел а мат платы были от ibm.

так вот как работает memory map io. 

цпу подключен к шине ( шина это набор трех шин - шина адреса, шина данных, шина управления. шина у простом смысле это проводки.) шина покдлючена к микросхеме на мат плате под названием memory arbiter , также к шине подключены 
все перифериные устройства. так вот когда цпу выставляет на шине адреса адрес а на шину управления сигнал что он хочет сделать (прочитать или записать инфо) то этот запрос приходит на мемори арбитр и он делает вот что. он смотри по какому адресу идет запрос. если это адрес в диапазоне
таком то то арбитр через линии управления высылает сигнал на все периферийные устройства и на все модули памяти кроме одной о том чтобы они все
заткнулись и не трогали шину данных. а на один конкнетный модуль памяти арбитр памяти пукскает через
шину контроля сигнал на чтение запись порции данных. так вот когда цпу выставить определенный 
адрес на шину адреса то арбитр вырубает все модули памяти точнее посылает им сигнал чтоб неприксались
к шине данных и активирует через шину контроля ПЕРИФЕРИЙНОЕ УСТРОУСТВО! таким макаром с тчоки зрения
цпу это выглядит как запрос к RAM а по факту он начинает работать с перифериным устроством.
это и есть memory map io. когда цпу обращаясь к памяти по факту попадает на периферинйо устройство.
область адресов при которых мы попадае на то или иное периферийное устройство зависит как я понял от
арбитра памяти. то есть от железки от мат платы. так вот так как мат плату делали в ibm то они на ней
на арбитре памяти запрогармировали что если цпу обращается к памяти выше 640к то он уже в память 
непопадает. он попадает на то или иное периферийное устровство!!!! вот она разгадка 
как это так на параткие сделали что цпу может обращаться к 1МБ а по факту он 
для программы доступно только 640к!. при обращении по адресу выше чем 640к цпу попадаел не в память
а в периферийное устроуство. вроде бы так. ну конечно если мы  при обращении к адресу выше чем 640к
попадаем в перифериноу устройство то конечно ячейки памяти на RAM с адресами выше 640к на модулях
памяти никогда небудут достинуты процессором. тоесть эат память она пропадает выпадает из 
использования процессором!
пока у меня такое видение загадки 640к!








====
8086

дебаг 

gdb

nasm

debug

я нащупал как можно дебагить в линуксе асемблер

берем файл

$ cat 2.asm

section .data
    msg db      "hello, world!"

section .text
    global main
main:
    int3
    int3
    int3
    int3
    int3
    int3
    int3
    int3
    int3
    int3
    int3


компилиуруем его с символами дебаг внутри (это важная фишка которую надо уметь делать иначе позже 
gdb выдаст ошибку "gdb No symbol table is loaded" )
важно также чтобы была секция main чтоб успешно gcc отработал.

 $  nasm -g -f elf64 -l 2.lst  2.asm
 $  gcc -m64 -o 2.exe  2.o

или еще вариант без gcc потому что он в код вставляет кучу доп команд. если мы хотим более голый
оригинальный вариант получить то компилируем:

$ nasm -g -f elf64 -l 2.lst -o 2.o 2.asm
$ ld -o 2.exe 2.o


запускаем gdb

 $  gdb 2.exe

если с дебаг символами все окей то gdb напишет
Reading symbols from 2.exe...done

а вот тут инструкция по быстрому старту с gdb

https://www.csee.umbc.edu/portal/help/nasm/nasm_64.shtml

тоесть как запустили gbd используем команды:

> break main
(устанавливает брейкопоинт на секции main пограммы)

>run
...
Program received signal SIGTRAP, Trace/breakpoint trap.
0x0000555555554601 in main ()

устанавливаем чтобы ассемблер имел вид intel а не at&t
>set disassembly-flavor intel

>disassemble main
Dump of assembler code for function main:
   0x0000555555554600 <+0>:	int3   
=> 0x0000555555554601 <+1>:	int3   
   0x0000555555554602 <+2>:	int3   
   0x0000555555554603 <+3>:	int3   
   0x0000555555554604 <+4>:	int3   
   0x0000555555554605 <+5>:	int3   
   0x0000555555554606 <+6>:	int3   
   0x0000555555554607 <+7>:	int3   
   0x0000555555554608 <+8>:	int3   
   0x0000555555554609 <+9>:	int3   
   0x000055555555460a <+10>:	int3   
   0x000055555555460b <+11>:	nop    DWORD PTR [rax+rax*1+0x0]
End of assembler dump.



> x/12bx main
0x555555554600 <main>:	0xcc	0xcc	0xcc	0xcc	0xcc	0xcc	0xcc	0xcc
0x555555554608 <main+8>:	0xcc	0xcc	0xcc	0x0f
 

>info registers
rax            0x555555554600	93824992232960
rbx            0x0	0
rcx            0x555555554610	93824992232976


>print /x $rsp
$7 = 0x555555554610

>nexti
>stepi
>next

>info float


>info stack
>q
>y


хочу прокоментироваь команды gdb
	>x /12bx main
эта команда позволяет посмотреть содержимое оперативки
вначале начну с более простой формы этой команды
	> x 0x0000555555554600
	0x555555554600 <main>:	0xcccc

сама команда это "x".  
0x0000555555554600 это адрес в памяти который мы хотим посмотреть содержимое.
можно адрес задать и по другому , например main - это таким образом задан адрес. поскольку у нас есть секция main то gdb сам знает с какого адреса она начинается. 
видно что по дефолту команда считала 2 байта. и вывела содержимое в hex виде.
это можно поменять. можно вывести значение в десятичном виде например

	>x /u 0x0000555555554600
	0x555555554600 <main>:	52428

/u означает decimal unsigned формат.

далее. память то у нас состоит из байтов. а вывели мы значение двухбайтное. 
это тоже можно менять. вот так выводится значение одного байта

	>x /bu 0x0000555555554600
	0x555555554600 <main>:	204

/b означает что мы просим считать только один байт.


	>x /hx 0x0000555555554600
	0x555555554600 <main>:	0xcccc

/h означает что мы хотим считать двухбайтовое выражение издеь важно заметить что когда мы 
считали два байта то мы их интерпретируем не как два отдельных байта а как единое 16 битное 
выражение.


 	>x /wx 0x0000555555554600
	0x555555554600 <main>:	0xcccccccc

/w этот ключ говорит что мы хотим считать 4 байта и инерпретировать 32бита как единое число



окей. до настоящего момента мы считывали только одну порцию памяти. не втом плане что один байт
а втом плане что назначли размер куска ( байт. два байта, четыре байта) и читали один этот кусок.
далее мы хотим считывать несколько таких кусков. окей.

	>x /5wx 0x0000555555554600
	0x555555554600 <main>:	0xcccccccc	0xcccccccc	0x0fcccccc	0x0000441f
	0x555555554610 <__libc_csu_init>:	0x56415741

/5 означает что мы хотим считать пять кусков с памяти, размер одного куска 4 байта.
вот мы и получили пять четырехбайтовых кусков: 0xcccccccc	0xcccccccc	0x0fcccccc	0x0000441f 0x56415741.
напомню что /x означает что мы хотим видеть интерпретацию битов в hex виде.
здес также важно отметит что число кусков почемуто всегда задается в dec виде. тоесть /5 это
пять в десятичном счислении. тоесть если мы захотим считат 100 кусков то надо будет 
писать /100

вернемся к исходному примеру
	>x /12bx main
значит адрес первого байта заан через переменную main
/12 это число кусков которые мы хотим считать
/b размер куска равен один байт
/x содрежимое памяти отобоажать в hex виде
итого получим
	x555555554600 <main>:		0xcc	0xcc	0xcc	0xcc	0xcc	0xcc	0xcc	0xcc
	0x555555554608 <main+8>:	0xcc	0xcc	0xcc	0x0f

кстати вот еще прикольная тема. когда мы хотим посмотреть память в бинарном виде это ключ /t
пример
 	> x /3bt 0x0000555555554600
	0x555555554600 <main>:	11001100	11001100	11001100
/3 счиатть три куска
/b размер куска один байт
/t вывести содержимое куска в бинарном виде


итак с командой "x" разобрались
кстати можно посмотреть справку по команде x через
	> help x

прикольно что память разбита на блоки как жесткий диск на блоки.  а файл может занимать несколько
блоков на диске так и наша переменная записанная в память может занимать от 1 до 8 байт 
а при желании и больше. тот же самый регистр имеет размер 8 байт.
грубо говоря размерность памяти внутри цпу (регистры) несовпдатает с размерностью в оперативной
памяти

еще есть команда print сокрашенно p
если x в качестве аргурмента берет значения и памяти тоесть лазиит в ячейки памяти и достает 
то что там есть то команд print работает не с памятью как источником а с переменными тоесть еще раз
у команды x аргуменотом является некий адрес в памяти  а у команды p аргументом является имя переменной. большая разница. но также у команды p аргументом может быть сразу голове число
примеры

(gdb) p /t 8
$1 = 1000
(gdb) p /t 255
$2 = 11111111
(gdb) p /2t 255
Item count other than 1 is meaningless in "print" command.
(gdb) p /t 255
$3 = 11111111
(gdb) p /t 255.1
$4 = 11111111
(gdb) p f
No symbol "f" in current context.
(gdb) p /t 128
$5 = 10000000
(gdb) p /t 255.1
$6 = 11111111
(gdb) p /du 11111111
$7 = 11111111
(gdb) p /d 11111111
$8 = 11111111
(gdb) p /du 11111111
$9 = 11111111
(gdb) p /du 8
$10 = 8
(gdb) p /du -8
$11 = 4294967288
(gdb) 

ключи форматов ( /t /d /du ) такие же как у команды x ( help x)
и тут важно тметить что для комнды print если мы указали выходной формат бинарный /t а
аргументом является число c точкой то число с точкой будет округлено до целого а потом уже 
переведено в бинарный вид 
пример

(gdb) p /t 255.1
$6 = 11111111

вивдно что мы ввели 255.1 а на выходе получили 255

прикольно что есть ieee754 который описывает как через бинарный вид можно кодировать числа с точкой.

(gdb) p /f 0x4a9f060f
$20 = 5210887.5
(gdb) p /u 0x4a9f060f
$21 = 1251935759
(gdb) 

получается в зависимости от нашей интерпретации один и тотже бинарное число можно интерпетировать
и как целое и как число с плааавающей точкой

как уже сказал в команде print если мы будем пытаться перевести число с плаюващей точкой
в бинарный вид то система небудет переводить его в бинаный вид на основе ieee754 , она окгругит
число до целого и переведт именно целое в бинарный вид

также в чем прикол! - man gdb говоит что он предназначен для дебагинга програм на C а про 
асемблер нислова! так вот формат чисел gdb испольует такой же как как  в C. поэтому hex числа задаются в виде 0x1212121 а бинарные числа задаются как 0b101010101010101
таким образом еслимы хотим перевести двочное число в десятичное надо

	> p /u 0b01001010100111110000011000001111
	$35 = 1251935759

а вот перевод бинарного в плавающую точку
	>p /f 0b01001010100111110000011000001111
	$36 = 5210887.5

так что двоичное число задается через 0b.....
тажке видно что в зависиомсти от интерпретации одно и тоже бинарное число может быть 
интерпетировано и как целое и как с плавающей точкой

с командой print надо быть осторожным. как я уже сказал это команда при 
переводе из float в bin вначале округляет число до целого а потом уже переводит его 
в bin. второй момент связан с регистрами.

и в продолжение темы. вот мы имеем в C программе переменную скажем с именем f.
и мы хотим посмотреть ее значение. так вот лучше cмотреть через x а не через p

	>x/tw &f
	0xbffff3f4: 01001010100111110000011000001111


далее
	>info registers - это смотрит показания что внути регистров. 
		rax            0x555555554600	93824992232960
		rbx            0x0	0
		rcx            0x555555554610	93824992232976

тут особеннрость такая что gdb показывает значение регистра и в hex и в dex виде. поэтому 
на один регистр сразу два значения
у современных интел цпу в 32 битном режиме 8 регистров общего назначения (всего лишь)
а в 64 битном режиме 16 регистров общего назначения (всего лишь)

далее
	>print /x $rsp
		$7 = 0x55555555461
эта команда показывает содержимое отдельного регистра. ключ /x говорит чтобы на экране 
вывод был в hex формате. ключ $7 незначит ничего в выводе чисто временная служебная хрень.
в этом можно убедиться если запустить команду повторно тогда увидим что уже будет $8
	>print /x $rsp
		$8 = 0x55555555461


далее
	>nexti

	>stepi

сравним эти две команды сразу. истинный +1 шаг выполняется командой stepi. будет 
выполнена точно +1 инструкция асемблера и небольше. nexti делает побольше будет выполнена
+1 инструкция а если встретится вызов subroutine то этот субротин будет выполнен целиком.
есть также инструкции step и next. в чем разница их с nexti и stepi.
дело в том что gdb он умеет дебажиь нетолько асемблрные программы но и С программы поэтому
next и step предназначены для прохода по тексту C программы. а именно step выполняет машинный код
который соотвествует одной строке программы на C. втоже время как stepi выполняет ровно одну машинную команду. в этом и разница  - выполнить машинный код который соотвествует одной строке
на C или ровно одну команду машиинного кода. при этом если step попадет на вызов какото то субфункции то он выполнит только первую команду на C внутри этой субфункции. втоже время как next за один проход выполнит все что внутри этой субфункции.

далее
	>info float
показывает состояние регистров математического сопроцессора ( FPU )
	R7: Empty   0x4002b1c5dc0ab47e8f94
  	R6: Empty   0x00000000000000000000
  	R5: Empty   0x00000000000000000000
  	R4: Empty   0x00000000000000000000
  	R3: Empty   0x00000000000000000000
  	R2: Empty   0x00000000000000000000
  	R1: Empty   0x00000000000000000000
	=>R0: Empty   0x00000000000000000000

по идее вроде как они должны называться st0,st1 итд у меня же они назвыаются почемуто R0-R7
это реально регистры сопроцессора потому что они длинной 80-bit ( а не 64бит как у обычных )
эти регистры используются если мы хотим делать мат операции над числами с плавающей точкой. 
для этого юзаются эти спец регистры и спец команды. тоесть эти регистры предназначены только 
для этого. что интересно данные в них можно закачать только из оперативки а из обычных регистров
почмуто туда данные нельзя совать. результат тоже можно записать из этиъ регистров только в 
память а в обычные регистры нельзя. при записи в память результат из 80-бит округляется до 64-бит
естественно. 

хотя когда я ввел команду
	> info all-registers
то оно показало уже верные имена регистров st0-st7
	st0            123.450000000000002842	(raw 0x4005f6e6666666666800)
	st1            0	(raw 0x00000000000000000000)
	st2            0	(raw 0x00000000000000000000)
	st3            0	(raw 0x00000000000000000000)
	st4            0	(raw 0x00000000000000000000)
	st5            0	(raw 0x00000000000000000000)
	st6            0	(raw 0x00000000000000000000)
	st7            0	(raw 0x00000000000000000000)

тут мы вспоминаем что комада print может печатать значения регистров а нетолько переменных.
с целочисленными регистрами она работает коректно и хорошо. а вот с st-st7 она работает 
как то плохо. попроуем посмотреть st0 в hex формате через print
	> print /x $st0
		$10 = 0x7b
в то время как info all-registers нам показыавает что st0=0x4005f6e6666666666800
так что команда print ненадежная. то при выводе в /t она переводит float в integer и толко 
потом в bin. то теперь значение float регистра отображает неверно. поэтому то что печатает 
команда print как то доверять нельзя. хотя для целочисленных регистов она работает верно. и 
только с помощью нее можно посмотреть на содержимое регистра в бинарном виде.

 	>print /t $eax
		$11 = 10000000000010010100000
	>print /t $rsp
		$12 = 11111111111111111111111111111111101110000101000

однако возвращаемся к FPU регистрам.

пример программы которая юзает эти регистры
\\\
global main

section .data
    val: dq 123.45   ; define quadword (double precision)

section .bss
    res: resq 1      ; reserve 1 quadword for result

section .text

main:
    ; load value into st(0)
    fld qword [val]  ; treat val as an address to a qword
    ; compute square root of st(0) and store the result in st(0)
    fsqrt
    ; store st(0) at res, and pop it off the x87 stack
    fstp qword [res]
    ; the FPU stack is now empty again

    ; end of program
\\\

компилируем ее вот так а то вылезет ошибка ( relocation R_X86_64_32 against `.data' can not be used when making a PIE object; recompile with -fPIE )
$ nasm -g -f elf64 -l 3.lst  3.asm
$ gcc -m64 -o 3.exe  3.o -no-pie

запускаем gdb и смотрим

	$ gdb ./3.exe
	> break main
	> run
	> nexti
	>info float
		=>R7: Valid   0x4005f6e6666666666800 +123.4500000000000028

так как программа сует в регистр константу из памяти. посмотрим проверим 
а что там в памяти лежит откуда она берет

	>disassemble main
		Dump of assembler code for function main:
		0x00000000004004a0 <+0>:	fldl   0x601028
		=> 0x00000000004004a7 <+7>:	fsqrt  
   		0x00000000004004a9 <+9>:	fstpl  0x601034
		End of assembler dump.

видим что переменная была считана из адреса 0x601028. 
читаем из него руками

	>x /1gx 0x601028
		0x601028 <val>:	0x405edccccccccccd

смотрим еще раз чему равно значение этой же переменной уже в fpu регистре
	>info float
		=>R7: Valid   0x4005f6e6666666666800 +123.4500000000000028

получается в hex виде отличается 0x405edccccccccccd <> 0x4005f6e6666666666800. 
сравним в float виде

	>x /1gf 0x601028
		0x601028 <val>:	123.45

123.45 ~ 123.4500000000000028

ну чтож так лучше. (хотя непонятно откуда на конце 28 появилось.)

итак мы убедились что число из памяти было закачано в FPU registr R7 (st0)

двигаем дальше по программе
 	>nexti
	>disassemble main
		Dump of assembler code for function main:
   		0x00000000004004a0 <+0>:	fldl   0x601028
   		0x00000000004004a7 <+7>:	fsqrt  
		=> 0x00000000004004a9 <+9>:	fstpl  0x601034
		End of assembler dump.

	>info float
		=>R7: Valid   0x4002b1c5dc0ab47e8f94 +11.11080555135405125 

итак получили 11.11...

двигаем дальше
	>nexti
проверяем какое число было в итоге записано из FPU в память
	>x /1gf  0x601034
		0x601034 <res>:	11.110805551354051

сравниваем его с тем что было в FPU (RAM)11.110805551354051 ~ (FPU)11.11080555135405125
как видим одно и тоже число. просто оно стало покороче ибо его нужно было округлить из 80битного
прдеставления в 64битное.


моменты:
 - проблема компиляции программы


гоча!
===
disassemble
gdb
objdump
nasm


еще пример дизассемблирования


имеем
текст на asm

$ cat 27.asm
; 27.asm
section .text
    global _start
_start:
BITS 64
    mov       rax,0xff11ff11ff11ff11
    push      rax
    pop       rax
    push      0x7a
    pop       rax
    push      0x8a
    pop       rax


; call exit(0)
    mov    rax, 0x3c
    mov    rdi, 0x0
    syscall



компилируем (причем с дебаг символами чтобы gdb мог успешно работать):
$ nasm -g -f elf64 -l 27.lst -o 27.o 27.asm
$ ld -o 27.exe 27.o


диаззассемблируем(objdump):
$ objdump -b elf64-x86-64  -M "intel" -d 27.exe
27.exe:     file format elf64-x86-64
Disassembly of section .text:

0000000000400080 <_start>:
  400080:   48 b8 11 ff 11 ff 11    movabs rax,0xff11ff11ff11ff11
  400087:   ff 11 ff 
  40008a:   50                      push   rax
  40008b:   58                      pop    rax
  40008c:   6a 7a                   push   0x7a
  40008e:   58                      pop    rax
  40008f:   68 8a 00 00 00          push   0x8a
  400094:   58                      pop    rax
  400095:   b8 3c 00 00 00          mov    eax,0x3c
  40009a:   bf 00 00 00 00          mov    edi,0x0
  40009f:   0f 05                   syscall 

вобщем то видим что имеем поочти то то что в исходном файле.

диаззассемблируем(ndisasm): лучше неиспользовать иногда как то он хуево работает 
и выдает совсем нетот код который там есть внутри.

дизассемблирвем (через gdb):
$ gdb hello.exe
> break _start
>run
> set disassembly-flavor intel
> disassemble _start

=> 0x0000000000400080 <+0>: movabs rax,0xff11ff11ff11ff11
   0x000000000040008a <+10>:    push   rax
   0x000000000040008b <+11>:    pop    rax
   0x000000000040008c <+12>:    push   0x7a
   0x000000000040008e <+14>:    pop    rax
   0x000000000040008f <+15>:    push   0x8a
   0x0000000000400094 <+20>:    pop    rax
   0x0000000000400095 <+21>:    mov    eax,0x3c
   0x000000000040009a <+26>:    mov    edi,0x0
   0x000000000040009f <+31>:    syscall 
End of assembler dump.


получили тоже самое. 
отлично

кстаи в gdb чтобы дизассемблировать необязательно устанавливать breakpoint и запускаить программу.
тоесть команды
> break _start
>run
они лишние если мы хотим только дизассемблировать


таким образом умеем компиилровать из кода. плюс в файле будет дебаг символы.
потом дизасемблим через objdump и через gdb

===
8086
asm

наконецто! раскрылась правда про чтото непонятное.
а именно.

вот берем создаем минимальный asm файл

$ cat 28.asm
; 28.asm
  GLOBAL _start
  SECTION .text
  _start:
      hlt

во первых куча мусора будет после gcc
во вторых причем здесь секции ведь будет исполняться машинный код там нет никаких секций
там только mov,jmp итд. там нет никаких .text

что значит _start  в чем отличие если написать _main 
если копилировать через gcc или через nasm+ld

почему gcc сует туда кучу мусора

программа стартует с точки _start

теперь сталоп онятно зачем нужны ipC итп. потому что процессы сидят в своем виртпростанстве
и никак не могут обменяться инфой с другими процессами. кроме как через дескрипторы файлов
которые доступны сразу  обоим процессам// нужна дверь обмена

поехали.
вначаале elf файла идет HEADER. рассмотрим конкретно elf64 файл.
хидер начинается с офсета 0 и занимает 64 байта.

структура HEADER имеет формат\структуру:

{
  unsigned char	e_ident[EI_NIDENT];	/* Magic number and other info    (16 bytes) */
  Elf64_Half	e_type;			/* Object file type    (2 bytes) */
  Elf64_Half	e_machine;		/* Architecture        (2 bytes) */
  Elf64_Word	e_version;		/* Object file version (4 byte)  */
  Elf64_Addr	e_entry;		/* Entry point virtual address    (8 bytes) */
  Elf64_Off	e_phoff;		/* Program header table file offset   (8 bytes) */
  Elf64_Off	e_shoff;		/* Section header table file offset   (8 bytes) */
  Elf64_Word	e_flags;		/* Processor-specific flags  (4 bytes) */
  Elf64_Half	e_ehsize;		/* ELF header size in bytes  (2 bytes) */
  Elf64_Half	e_phentsize;		/* Program header table entry size (2 bytes)  */
  Elf64_Half	e_phnum;		/* Program header table entry count    (2 bytes)  */
  Elf64_Half	e_shentsize;		/* Section header table entry size  (2 bytes) */
  Elf64_Half	e_shnum;		/* Section header table entry count     (2 bytes) */
  Elf64_Half	e_shstrndx;		/* Section header string table index    (2 bytes)  */
} Elf64_Ehdr;

итого 64 байта.

это структура хидера для elf64 типа файла.

ну чтож легко запомнить elf64 его HEADER занимает 64 байта.

EI_NIDENT= 16(dec)
поэтому unsigned char e_ident[EI_NIDENT]  это массив из 16 символов то есть 16 байт в итоге.

итак вначале хидера идет e_ident 16 байт размером, разберем что там в этих байтах:
и сразу разберем на примере:
$ hexdump -C -n 16 a.out
00000000  7f 45 4c 46 02 01 01 00     00 00 00 00 00 00 00 00  |.ELF............|

0x7f - константа
0x45 - символ 'E' в ASCII
0x4c - символ 'L' в ASCII
0x46 - символ 'F' в ASCII

0x02 - это поле это какой машинный код внутри 32\64бит. для 64 бит поле = 0х02
0x01 - порядок битов в байте littlen или big endian. для little endian(для цпу intel) поле = 0x01 
0х01 - File version byte index. что это такое непонятно. но на данный момент это поле всегда = 0x01


чтоб понять дальше то надо понять что такое api. все как попугаи твердят что api это некая хрень которая позволяет одной программе 
обмениваться данными с другой программой. 
разницу между 'rest vs http'. судя по интернету rest это некий набор правил  которым должна подчинятся
программа а http это такой 

>>>>>> отсановился на том что такое 'os abi' vs 'abi'. для этого надо понять что такое api. для этого надо понять http vs api.
для этого надо понять rest vs http , POSIX ?<<<<<

канонические адреса вирт памяти в 64битном режиме.
11111111 11111111 100000000000000000000000000000000000000000000000
...
00000000 00000000 011111111111111111111111111111111111111111111111

00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 

разбираем его поля. 

$ hexdump -C -n 64 a.out
00000000  7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  |.ELF............|
00000010  02 00 3e 00 01 00 00 00  80 00 40 00 00 00 00 00  |..>.......@.....|
00000020  40 00 00 00 00 00 00 00  98 00 00 00 00 00 00 00  |@...............|
00000030  00 00 00 00 40 00 38 00  01 00 40 00 03 00 02 00  |....@.8...@.....|
00000040

его поля описаны в /usr/include/elf.h
7f - константа
45 - символ 'E' в ASCII
4c - символ 'L' в ASCII
46 - символ 'F' в ASCII




===
8086

ELF, a.out , linker





The smallest unit of an object file is a section. A section is a block of code or data that occupies contiguous space in the memory map. Each section of an object file is separate and distinct.


In Binutils, how sections are put into segments by ld is determined by a text file called a linker script
You can get the default one with ld --verbose, and set a custom one with -T.
For example, my default Ubuntu 17.04 linker script contains:

  .text           :                                                                                                                                                             
  {                                                                                                                                                                             
    *(.text.unlikely .text.*_unlikely .text.unlikely.*)                                                                                                                         
    *(.text.exit .text.exit.*)                                                                                                                                                  
    *(.text.startup .text.startup.*)                                                                                                                                            
    *(.text.hot .text.hot.*)                                                                                                                                                    
    *(.text .stub .text.* .gnu.linkonce.t.*)                                                                                                                                                                                                                                                  breadbox@muppetlabs.com                                             
  } 
which tells the linker to put sections named .text.unlikely, .text.*_unlikely, .text.exit, etc. in the .text segment.


===
???&&&&&&&&&&&???????????????????????????????????
??????????????????????????????????????????????????
??????????????????????????????????????????????????
как устроен a.out, elf формат, что такое object file vs executable file 
закончил на том что коментирую команды gdb (закончил на том что читаю какие регистры
испольщуюстя при работе с плавающей точкой арифметикой)
описать AAA команду , посмотрет его опкоды
asm debugger for ubuntu 
numa vs miltichannel memory controller без нума vs memory interleaving. причем у  cpu fsb 64bit всего. также \
как выглядит распределение физ адресов в таких случаях для линукса ?
память ранки?(читать мою доку)
если у нас есть цпу. у него есть мемори контроллер. у него есть два канала к памяти. одна планка воткнута
	в первый канал вторая во второй. вопрос как распредеелена нумерация физ памяти межу первой планкой и второй.
	идет ли нумерация так что 1-я планка от 1 до 1000 000 потом вторая планка от 1000 001 до 2000 000.
	или нумерация идет так что первый байт на 1-ой планке вторйо байт на второй планке. третий байт
	на первой планке четвертный байт на второй планке ?


???&&&&&&&&&&&???????????????????????????????????
??????????????????????????????????????????????????
??????????????????????????????????????????????????
===
8086
asm

теперь стало понятно 16-bit код, 32-bit код, 64-bit код. вот скажем у нас есть
64 битный цпу и он может выпонять 32-бит программы и 64-бит программы. что это значит на уровне
кода. 
дело в том что машиный код (команды в двоичном виде) имеет разные опкоды условно говоря
для одних и техе же команд. я имею ввиду те команды у которых нет регистров как параметры.
и также 32-бит код отличается от 64-бит код тем что регистры имеют другие имена.

===
assembly


как выглядит обьявление констант в асемблере 
в разных системах счисления:

 	mov     ax,200          ; decimal 
    mov     ax,0200         ; still decimal 
    mov     ax,0200d        ; explicitly decimal 
    mov     ax,0d200        ; also decimal 
    mov     ax,0c8h         ; hex 
    mov     ax,$0c8         ; hex again: the 0 is required 
    mov     ax,0xc8         ; hex yet again 
    mov     ax,0hc8         ; still hex 
    mov     ax,310q         ; octal 
    mov     ax,310o         ; octal again 
    mov     ax,0o310        ; octal yet again 
    mov     ax,0q310        ; octal yet again 
    mov     ax,11001000b    ; binary 
    mov     ax,1100_1000b   ; same binary constant 
    mov     ax,1100_1000y   ; same binary constant once more 
    mov     ax,0b1100_1000  ; same binary constant yet again 
    mov     ax,0y1100_1000  ; same binary constant yet again

 =======

===
linux 
signals

сигналы



Что интересно signal определяют в книжке по libc как software interrupt доставленный со стороны
ОС процессу. тоесть они проводят аналогию между cpu interrupt и сигналами. в случае cpu interrupt 
обьектом назначения является цпу. к нему поступает интеррапт. получается что в случае сигналов
по аналогии целью назначения является процесс. тоесть процесс выступает в той же роли что и цпу 
если аналогии проводить.  еще раз:

(hardware interrupt ) цель = cpu
(signal) цель = process

в случае cpu interrupt он(цпу) сразу все бросает тоесть останавливается и бросается обслуживать
интеррапт.

в случае  process interrupt (так я дальше буду порой называть signal) : во первых сам код процесса
мало на что влияет. схема такая что один кусок ядра порписывает в таблице процессов в его свойствах в поле сегналов наш сигнал. тогда шедулер в следущий таймслайс когда он собирается помещать процесс на цпу вместо этого запускает обработчик сигнала. тоесть вобще то реагирующим 
субьектом на сигнал является некод процесса а шедулер. тоесть похорошему целью интеррапта является шедулер. процесс в отличие от цпу и так постоянно прерывается шедулером без всяких сигналов вот
в чем прикол.  так вот когда наступает очередной шедулер тайм слайс в котором проецесс должен исполняться на цпу то шедулер вместо размешения кода процесса на цпу направляет цпу на обработчик сигнала. да в этом смысле выполение процесса прерыается на выаолнение обработчика. 

в случае цпу интеррапта сигнал к нему прилетает от контроллера интерраптов а к контроллеру сигнал 
летит от железки (  и нетолько но неважно). в случае сигнала он летит к процессу ( а точнее к шедулеру) от ядра. единственное что к ядру он запрос ( не сигнал а запрос на формирование сигнала) поступает от : яддра, самого процесса, другого процесса, кнопки с клавы. 

ну а так да. сигнал это в какомто смысле прерыватель нормальной работы процесса из внешнего мира.
другое дело что и без сигналов работу процесса постоянно прерывавет тот же самый шедулер.

цпу интерапты называют синхронными 

есть станартные сигналы которые можно послать процессу. каждый сигнал имеет номер.
нафиг они нужны. ну например  послать сигнал это способ закончить программу досрочно.
в целом это способ сообщить чтото из внешнего мира процессу. как то повлиять на него.
причем мы хотми повлиять таким способом который независит от открытых файлов этим процессом.
дело в том что обычно процесс общается с внешним миром путем того что он открывает несколько
файлов из которых пишет или читает. сколко он откроет файлов и в каком формате процесс ждет посту
пающей инфо это все завиисит от прихотей процесса. а нам нужен способ донести какуто информацию
какой то приказ внезависимости от возможностей которые предоставляет сам процесс. если сравнить
процесс с человеком который сидит в квартире за закрытой дверью и это дело самого человека
кому открыть кому неоткрыть а нам нужен способ сообщать чтот человеку внезависимости от 
его открытой закрытой двери скажем этот способ это громкая связь.

далее тонкий момент в том что сигнал может быть обработан как кодом самого процесса так и 
кодом ядра без участи кода процесса вообще.
как я понял обычно работае так. запускается процесс и он регистрирует в ядре процедуры своего 
кода которые могут обработать тот или иной конкретный сигнал ( с конкретным номером. потому что сигнал идентифицируется номером). далее если мы шлем процессу сигнал то что при этом происхдит -
ядро присваивает некое свойство таблице данных которая содержит описательное инфо о процессе.
это как в личном деле человека появляется новая заметка. далее когда шедулер собирается 
пихнуть процесс на цпу он проверяет таблицу записей этого процесса нет ли там заметки о том что
к процесс имеет свойство о том что ему послали сигнал. более точно  я считаю было бы говориить что 
сигнал непослали процессу а назначили присвоили процессу. как орден присвоили. так вот шедулер 
смотрит неприсвоен ли процессу сигнал. если да то шедулер код процесса непихает на цпу . нет.
далее шедулер смотрит зарегистрировал ли процесс какойто свой обработчик для данного сигнала. если
да то шедулер запускает этот обработчик. тоесть в этом случае можно сказать что процесс получил
сигнал. ибо код процесса стал его обрабатывать. а если процесс при своем старте незарегистриовал
обработчик этого сигнала то тогда шедулер запускает дефолтовый обработчик сигнала через кусок 
предопредленного кода ядра. в этом случае формально получется что процесс ничего неполучал.
сигнал обрабатывается исключительно ядром.
поэтому я бы сказал что более верно было бы говориить что сигнал посылается непроцессу а ядру о том
чтобы присвоить сигнал процессу.  это как послать письмо матери школьника о школьнике. а далее
может быть это письмо и будет выдано школьнику для обработки а может быть и нет и останется на 
оббработке матери.

так вот так называемые стандартные сигналы. а есть real time сигналы.

вначале про стандартные сигналы.
все сигналы имеют дефолтовый обработчик в ядре. это значит что если процесс неимеет своего 
обработчика то сигнал все равно будет обработан но уже ядром.
для части сигналов можно запрограмирвать в процессе что он эти сигналы примет но ничего не будет
делать в ответ. тоесть он "как бы" эти сигналы может игнорировать. 
а часть сигналов процесс неможет игнорировать на наних точно нужно выполнить действие.
но на самом деле плохая терминалогия. для таких "неигноруемых " сигналов на самом деле до кода 
процесса они просто недойдут их обработкой займется само ядро и обычно смысл этих сигналов том
чтобы либо остановить временно процесс тоесть пока его больше не помещать на цпу и недвигаться
под коду процесса или втом чтобы уничтожит процесс. так что неигнорируемые сигналы процесс просто
необрабатывает они до негоо просто недоходят до его кода. это скорее четкий приказ ядру.

итак для части сигналов можно настроить процесс что он при желании может иметь свой обработчик
для этих сигналов, может неиметь этого обработчика и тогда будет запускаться обработчик в коде
ядра. можно настроить обработчик в коде процесса который будет принимать сигнал но ничегонеделать
в ответ (так называемое игнорирование сигнала).  в любом случае если у процесса нет своего 
оработчика то для каждого сигнала у ядра всегда есть обработчик так что в любом случае сигнал
будет обработан либо обработчиком самого процесса либо ядром. другое дело как я сказал 
что для ряда синалов обработчик процесса в ответ может позволить ничего неделать.


а для другой части сигналов ответеное действие обязательно, причем обработка кодом процесса
даже недопускается а обработчка сразу идет через обработчик ядра. обычно требуется такие действия
как приостановить процесс  или уничтожить.

станадартные сигналы имеют предопреледенные исторические значения.
это значит что ядро генерирует конкретные сигналы в ответ на возникновения конкретных событий.
и приложение в целом может быть уверено что если прилетел сигнал номер X то это значит что 
до этого произошло определенное событие Y.


рил тайм сигналы это как я понимаю типа доп множество сигналов. ( условно говоря если 
сигнал когда мы его шлем определяется его номером то рил тайм сигналы их номера от 32 по 64). 

значение рил тайм сигналов неопределено. это значит что если приложение получило сигнал номер
34 то  в целом приложению неизвестно какое событие послужило причиной этого сигнала и получается
что на этот сигнал в ответ от процесса хотят.
если у процесса нет своего обработчика этого сигнала то по дефолту ядерный обработчик 
как ответное действие просто уничтожает процесс.

сигнал это как домашнее задание для процесса. если сам процесс неделает домашнее задание то за него
егоделает ядро. а делает так - просто уничтожает процесс.

как я понимаю рил тайм сигналы ( я бы их назвал просто доп сигналы с неопрееленным значением 
чтобы мозги незаебыываь некоректными терминами) в целом могут использованым для написания 
программ у которых несколько компонентов тоесть несколько процессов. и тогда один процесс может посылать другому процессу вот эти вот доп сигналы чтобы сообщать о своих каких то кастомных событиях.  

есть еще три свойства для рил тайм сигналов которых нетакие как у стандартных сигналов.

1 если послать несколько станадртных сигналов процессу то в каком порядке эти сигналы будут применены
для процесса является неизвестным. чисто будет работать рандомная статистика.
если же послать процессу нескоько рил тайм сигналов то они будут приходит к процессу на обработку
ровно в том порядке в каком они были изначально посланы по времени. тоесть как FIFO.

2 если послать несколько стадартых сигналов одинаковых то в иттге процесс получит только 
один такой сигнал. а если послать несоклько рил тайм сигналов одинаковых то будут доставлены
на обрабтку все

3 при отправке рил тайм сигнала ему также можно дополнительно вложить некие дополниельные 
переменные которые прибудут к процессу вместе с этим сигналом. тоесть вместе с сигналом можно 
передавать значения. а процесс сможет их получить и обрабатывать. 
стандартные сигналы непозволяют передавать процессу никакие значения. процесс только получает
инфо о самом сигнале и больше ничего. 
стандартный сигнал можно сравнить с тем что процесс получает инфо в форме тольк одной цифры. тоесть
процесс получает инфо такого вида : к вам поступил сигнал номер 1. на этом все.
а с рил тайм сигналом процесс получает инфо такого вида: к вам поступил сигнал номер 34 и вместе с ним еще шло число 45.

signal handler (код обработки прилетевшего сигнала) может быть прерван другим сигналом если 
особо неустановлено (незнаю где наверно в свойствах хендлера) что его нельзя прерыывать пока
он отрабатывает.  в связи с этим непонятно что происхдоит дальше. будет ли возврат обратно.
вроде как блокировку нового сигнала можно задать через некую спец маску для процесса  неуверен
что ее коректно изменять из хэндлера. а вот вроде нашел - To avoid this, you can use the sa_mask member of the action structure passed to sigaction to explicitly specify which signals should be blocked while the signal handler runs. тоесть когда в коде описываем кастомный хэндлер
то в его свйоствах можно указать маску которая говорит ядру что когда будет запущен хендеор то его
нельзя прерывать такими то сигналами. и далее - When the handler returns, the set of blocked signals is restored to the value it had before the handler ran. So using sigprocmask inside the handler only affects what signals can arrive during the execution of the handler itself, not what signals can arrive once the handler returns. вот еще нашел что если хендлер уже стартанул то 
если прилетит такойже сигнал то он прерывает наш хендлер - When a handler function is invoked on a signal, that signal is automatically blocked (https://www.gnu.org/software/libc/manual/html_node/Blocking-for-Handler.html) 

есть и другой прикол. вроде. если прилетел сигнал и запустился хендлер этого сигнала
и если прилетел ТАКОЙЖЕ еще сигнал то вроде как прерываение данного хендлера непроисходит
правда вопрос что будет с тем сигналом когда хендлер закончит он будет обработан или он будет
потерян?

кстати я походу я понял по поводу деления на ноль на цпу. такой операции просто непроисходит.
как только цпу собирается это сделать срабаывает встроенная защита о том что эта операция запрещена. вот ивсе. срабатывает interrupt , интеррапт вызывает то что цпу начнет выполнять 
обработчик интеррапта который ОС поставляет. обработчик интеррапта(который ядерный код) сгенерирует сигнал который будет послан процессу. интересно если ядерный код поделит на ноль
то что будет. ведь процесса при выполнении ядерного кода нет.


в C libc функция которая позволяет установить кастомный сигнал хендлер это signal()
которая по факту обращается к кернел сисколу sigaction()

пример программы
$ cat 39-kids.c
#include<unistd.h>
#include<sys/wait.h>
#include<stdio.h>
#include<signal.h>

// five-children.c
static const size_t kNumChildren = 10;
static size_t NumChildrenExit = 0;


static void reapChild(int sig) {
  waitpid(-1, NULL, 0);
  NumChildrenExit++;
}

int main(int argc, char *argv[]) {
  printf("The program is started.\n");

  signal(SIGCHLD, reapChild); // install signal handler



  // lets create kNumChildren children via fork()
  for (size_t kid = 1; kid <= kNumChildren; kid++) {
    pid_t pid_c = fork();
    if (pid_c > 0){
       printf("Create #%zu child\n", kid);
    };
    if (pid_c == 0) {
      sleep(30 * kid); // sleep emulates "play" time
      printf("Child #%zu is finished the work... -->exit.\n", kid);
      return 0;
    }
  }



  // main loop in parent process
  while (  1  ) {
    sleep(5); // custom fn to sleep uninterrupted
    if (NumChildrenExit == kNumChildren){
       printf("To exit press Ctrl+C.\n");
    };
  }
  return 0;
}


вывод на экран:
$ ./39-kids.exe 
The program is started.
Create #1 child
Create #2 child
Create #3 child
Create #4 child
Create #5 child
Create #6 child
Create #7 child
Create #8 child
Create #9 child
Create #10 child
Child #1 is finished the work... -->exit.
Child #2 is finished the work... -->exit.
Child #3 is finished the work... -->exit.
Child #4 is finished the work... -->exit.
Child #5 is finished the work... -->exit.
Child #6 is finished the work... -->exit.
Child #7 is finished the work... -->exit.
Child #8 is finished the work... -->exit.
Child #9 is finished the work... -->exit.
Child #10 is finished the work... -->exit.
To exit press Ctrl+C.
To exit press Ctrl+C.


что она делает. она устанавливает обработчик сигнала SIGCHLD,
создает 10 чилдренов. чилдрены спят какоето время потом они выходят,
в парент поступает SIGCHLD он его отрабатывает забирает код возврата от чайлда,
после этого ядро наконце убивает процесс чайлда полностью.  итак пока все чидрены
не закончат.
 на этом конец программы.
что интересно вот создал парент 10 чилдренов. если после этого грохнуть через kill -15 
парента то чидрены конечно же продолжат жить (потому что в паренте нет кастомного обработчика сигнала -15 который бы убивал чилдренов а по дефолту убиение парент процесса неприводит к автоматическому убиению чидренов). при этом чилдрены сменят парента (на процесс "systemd --user"
а не на pid=1). и поскольку сообщение "Child #7 is finished the work... -->exit." сидит в теле
чилдрена то прикольно как на экране будут появляться собщения эти. тоесть парента уже нет
а чилдрены работают и выводят на экран. в целом чуда нет но прикольно. чуда нет потому что  
если один процесс грохнуть то почему другие должны автоматом быть грохнуты. недолжны. 
а так как все они имеют станадртный вывод на один терминал то на экране будут вылезать эти мессаги.

далее прикол втом что если мы заменим строчку 

sleep(30 * kid);

на 

sleep(1);

это будет значит что все чилдрены одновременно (более менее) закончать свою работу.
тогда получится то что (надо обьяснить почему) часть чайлдов окажется необработанной 
сигнал хендлером и они останутся висеть как Z. 
чтобы этого небыло наизменить хэендлер вот с такого

static void reapChild(int sig) {
  waitpid(-1, NULL, 0);
  NumChildrenExit++;
}

на такой (обьяснить почему это даст эффект)

static void reapChild(int sig) {
    while (1) {
       pid_t pid = waitpid(-1, NULL, 0);
       if (pid < 0) break;
       NumChildrenExit++;
    }
}


(обьяснить почему это даст эффект)



===
8086

cs регистр якобы неможет быть измненен напрямую.. кхм странно
ss и ds можно изменить нарямую через инстркуию POP

как я понял SP указывает офсет начала вершины стека а BP это уже произвольный офсет 
который юзается чтобы иметь доступ к данным где то в глубине от вершины стека

===
8086

в регистрах биты расположены в режиме big endian
тоесть левый это MSB а правый это LSB

а память наоборот. младший бит и байт пишутся первыйми а старщий байт и старший бит пишутся
последними



===
8086\88

dma

в цпу есть две ножки про dma
если устройство внешгнее хочет занять шину то оно в цпу послыает запрос по одной ножке
а цпу подрверждает что он освободит шину (на следущем цикле) по второй ножке
===
PAE

после пентиума (тот который P5) у которого ширина шины адреса была 32 бита и позволяла адресовать
4ГБ RAM был выпущен pentium pro (который P6) у которого ширина шины адреса была 36 бит и это ему
позволяло адресовать уже 64ГБ памяти. это был первый цпу у интел с шириной шины адреса больше чем 32 бита.
тоесть в теории в комп с цпу pentium pro можно было
вставить до 64ГБ RAM. но внутри него регистры 32 бит значит напрямую это неполучится сделать.
ровно также как это было с 80888 у котрого регистры 16 бит а ширина шины адреса 20 бит.тоесть
нужно изголяться. но все равно сам факт что пентиум про это был первый от интел 32 битный процессор который позволял работать с памятью больше чем 4ГБ (знаменитый предел 4ГБ для 32 битных процессоров).  
?????????????????????????????

=====
640k mem

segmentaion in real mode типа нетоже самое что segmatation в protected mode = ?


ext4 - имена файлов хранятся в directory entry. что я непонял эти directory entry тоже хранятся
в inodes или вчемто другом ?

bios memory map addr по какому адресу мапится биос код ?


cpu mode: real vs protrcted vs 8086virtual
адресация памяти : segment vs page




процесс когда хочет писать в память он переклчается в режим ядра  а если нет как же 
утвержлоение что доступ к железу от процесса идет тлоько через ядро?

paging - разееление памяти на 4к.  а как тогда обратится к байту отедьнуму?

paging vs segmantaion ?

кто пишет данные в tlb ? сам цпу или кернел участвует

как цпу знает где лежит page table


mmu и os. как os управляет mmu











===========
утилита od

предыдущая тема теерь здорово поможет при расммотрении утилиты od
она позволяет выводит на экран содержимое файла в виде байтов . причем 
моэно выбирать в каком счислении эти байты будут отображены. ведь байт это просто число.
вопрос только в том   в какой системе счисения мы это число выводим. dec, hex, oct

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


=============
???????????????????????
понять как поменят кнопку и литеру в которую она резолвится. key remapping.
приколльно есть scan коды клавы, есть ascii, есть escape коды терминала
====
linux locale. связь с ascii

====
ascii
escape симолв и терминал escape коды и ASCII взаимосвязь ?

=======
kill process
terminate process

kill -9  $pid
kill -15 $pid


еще раз обсудим как происходит убиение процесса в системе.
дело в том что процесс это целая структура разных штук которые обеспечивают каркас процессу.
процесс неможет просто сам взят и както там испариться. если мы хотим удалить процесс то 
мало просто взят не помещать его код на цпу. в памяти остаесят куча разных стркутур которые 
давали каркас сущности процесс.

вначале дам список как это можно сделать:
один вариант - сам процесс делает вызов к сисколлу 60 exit().
второй вариант - процесс уничтожается по инициативе ядра.
третий вариант - процесс уничтжается по просьбе от другого процесса.
четвертый вариант - по кнопке от пользователя. 


рассмотрим подробно:

один вариант - сам процесс делает вызов к сисколлу 60 exit().
что дальше происходит. 

$ cat 31.asm
section .data
section .text
    global _start
_start:

    mov    rax, 60
    mov    rdi, 0
    syscall

$ nasm -g -f elf64 -l 31.lst  31.asm
$ ld -o 31.exe 31.o


проверим сразу ради интереса получим ли мы в программе ровно тот код который заказали
или там будет насовано куча доп кода

$ objdump -d ./31.exe -M intel

./31.exe:     file format elf64-x86-64


Disassembly of section .text:

0000000000400080 <_start>:
  400080:   b8 3c 00 00 00          mov    eax,0x3c
  400085:   bf 00 00 00 00          mov    edi,0x0
  40008a:   0f 05                   syscall 

видно что получили ровно тот код который заказали. это хорошо. ( а если бы мы вместо ld заюзали gcc то он бы напихал в шапку нашей программы еще кучу своего кода).

окей но щас речь не об этом. 
запускаем strace и наблюдаем какие сисколлы и сигналы происходят
с процессом при вызове exit() 

$ strace ./31.exe
execve("./31.exe", ["./31.exe"], 0x7ffcb39fd0e0 /* 74 vars */) = 0
exit(0)                                 = ?
+++ exited with 0 +++

значит видно что процесс делает сисколл exit() и после этого конец наступает процессу.
вроде бы логично. но здесь важно что - поскольку код сисколла exit неизвестен то интересно было узнать посылает ли ядро к процессу сигналы -15 или -9 после вызова exit или ядро грохает процесс сразу. так вот видно что убивается сразу без 
посылания сигнала процессу. если бы сигнал прилетал то strace бы это 
отобразил. значит получается что когда процесс просит ос прикончить его и вызывает сисколл exit() то кернел убивает процесс уже сразу без каких то дополнительных механизмов например без посылок сигналов -9 и -15 процессу.
опять же тут важно понять что сам процесс если он выполнил все что хочет и хочет прекратить свое существование то он неможет сам себя убить. потому что убить процесс в системе это значит то что 
нужно убит вычистить все структуры вспомогательные которые образуют каркас процесса. что это за структуры - структуры которые задают виртуальную память  , структуры 
которые в ядре описывают все настройки сущности процесса. вот это все сам процесс убить неможет
это все может убить только ядро. поэтому сам процесс может только попросить об этом ядро через 
сисколл exit(). важные слова неможет и попросить. а вычисткой уже занимается исключительно ядро.
и кстати как уже помним что ядро по факту в ответ на эту просьбу откликается и удаляет почти все структуры которые обеспечивают обвязку процесса но хвостик остается и пока парент процесс несчитает код возврата от чайлда через wait() ядро неудалит этот хвостик этот остаток от процесса.
и все таки еще раз очень существенно понять что процессы сами себя ни создать немогут и уничтожить себя из системы немогут. все это делает исключительно ядро (по своей инициативе, по просьбе 
самого процесса, по просьбе другого процесса.)

второй вариант - процесс уничтожается по инициативе ядра.
вот пример программы:
$ cat 38.c
#define _GNU_SOURCE
#include<stdlib.h>
#include<unistd.h>
#include<stdio.h>
#include<sched.h> 


int variable, fd;

int do_something() {
   variable = 42;
   printf("The parent: the variable = %d\n", variable);
   _exit(0);
}

int main(int argc, char *argv[]) {
   void **child_stack;
   char tempch;

   variable = 9;
   child_stack = (void **) malloc(16384);
   printf("The parent: the variable = %d\n", variable);

   clone(do_something, child_stack, CLONE_VM|CLONE_FILES, NULL);
   sleep(60);

   printf("The parent: the variable is =  %d\n", variable);
   return 0;
}


смотрим что покажет strace:
$ strace ./38.exe
clone(child_stack=0x56047fea9250, flags=CLONE_VM|CLONE_FILES) = 17642
nanosleep({tv_sec=60, tv_nsec=0},  <ptrace(SYSCALL):No such process>
<... nanosleep resumed> <unfinished ...>) = ?
+++ killed by SIGSEGV +++
Segmentation fault (core dumped)

тут видно что ядру чтото непонравилось и оно уничтожило процесс. а как оно это 
сделало через какой механизм? а через сигнал SIGSEGV, ядро послало этот сигнал процессу. а далее
так как мой процесс неимел хэндлера по обработке этого сигнала то вступил в силу дефолтовый обработчик этого сигнала от ядра а он процесс уничтожает в ответ на такой сигнал. ( а еще возможно (я непроверял) сигнал SIGSEGV неигнорируемый тоесть процесс неможет его заблокировать . единственное что я незнаю неигнорируемый сигнал может ли у него быть обработчик в программе или сразу начинает действоват ядерый хендлер сигнала). итак в случае когда само ядро инициирует унитожение процесса то оно это делает через посылку сигнала процессу.


третий вариант - процесс уничтжается по просьбе от другого процесса.
самый простой вариант. самый привычный.

в первом окне запускаем bash под strace
(окно1)$ bash strace

во втором окне определяем pid запущенного баша.
(окно2)$  ps aux | grep strace
vasya    18194  0.5  0.0  20800  3244 pts/155  S    00:25   0:00 strace bash

наши pid strace, щас найдем его чайлда который нам и нужен:

$ pstree  -A  -s  -p  18194
systemd(1)---systemd(1718)---gnome-terminal-(3866)---bash(18175)---bash(18184)---strace(18194)---bash(18196)

итак нашли pid баша = 18196

просим ОС завершить тот процесс:
(окно2)$ kill -15 18196

что увидим в первом окне
(окно1)$ --- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=18213, si_uid=1000} ---
rt_sigreturn({mask=[]})                 = -1 EINTR (Interrupted system call)

таким образом мы видим то что когда другой процесс (через сисколл конечно) ос завершить
другой процесс, то ядро завершает тот другой процесс через отсылку тому другому процессу 
сигнала. причем что интересно вот из этой строки 

--- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=18213, si_uid=1000} ---

видно что

si_code=SI_USER, si_pid=18213, si_uid=1000

тоесть в прилетевшем сигнале
указано кто был его инициатором, что инициатором посылки сигнала был юзерский процесс,
и даже указан его pid и под каким юзером он работал.


четвертый вариант - по кнопке от пользователя. 
$ strace bash

далее тыкаем на кнопках Ctrl+C
и что мы видим

--- SIGINT {si_signo=SIGINT, si_code=SI_KERNEL} ---

тоесть нажатие кнопки породило что ядро направило в процесс сигнал. 
причем в сигнале видно что заказчиком является как бы само ядро si_code=SI_KERNEL.
хотя ядро всего лишь исполнитель заказчиком является юзер за терминалом.

В целом что хочется сказать напоследок. видно что во всех случая процесс убивается 
через отсылку ему сигнала. а уже хендлер сигнала убивает этот процесс. за исключением случая
когда уничтожение процесса происходит по просьбе самого процесса через сисколл exit().
тогда убиение процесса происходит както сразу ядром напряму без отыслки сигнала процессу.или 
я как то пока несмоге его отловить.



=======
multitasking 
как это работает.


у нас есть таймер на компе. он периодически через ножку на цпу передает на цпу интеррапт сигнал.
когда это происходит то цпу прерывает то что он делает и лезет в хендлер этого интеррапта ( а хэндлер интеррапта записан в память операционной системой загодя таким образом хэндлер интеррапта 
то тоже код ядра) , насколько я понимаю этот хендлео он перенаправляет выполнение на шедулер.
а шедулер уже смотрит на очередь процессов и принимает решение какой процесс следущим пихать
на цпу. так работает мудьтиитаскинг. что непонятно кто отвественен за сохранение и восстановление
регистров в оперативке в случае интеррапта. это сам цпу автоматом делает когда сигнал интеррапта
на его ножку прилетает или это делает хэндлер или на какой стадии кто сохраняет состояние 
регистров которое было до наступление интеррапта.  4


из того я нашел во время происходит все вот как. 
прилетает сигнал на ножку цпу которая про интеррапт. потом по шине данных от контроллера
преррываений прилетает номер прерываения. окей цпу знает номер прерываения.

далее цпу сам автоматом сохраняет EIP (регистр который указывает на адрес в памяти следующей 
команды которую надо выполнить. хотя тут пока неясно ведь EIP это не единственный регистр который 
нужен чтобы определить адрес команды в памяти) в память. сохраняет как я понял через команду
push тоесть в стек. но стек это все равно память. вопрос но ведь ссылку на стек тоже нужно где то сохранять.  но вроде как EIP это единственный регистр который цпу сохраняет сам. далее цпу передает
управление на хэндлер. и уже отвественность хэндлера за то чтобы сохранить все остальные регистры
чтобы можно было удачно вернуться.тут тоже интересный момент если перед моментом запуска хендлера
цпу сохраняет всего один регистр а далее передает на хэндлер прерывания то возникает вопрос 
может ли хендлер интеррапта быть прерван другим интерраптом ведь если да то легко может получится
что текущий хендлер еще неуспел сохранить все регистры а уже его код прерывал другой хендлер другого интеррапта.  Interrapt handler зовется еще по другому ISR - Interrupt Service Routine.

 я нашел что да один интеррапт может прерываться другим интерраптом. положим что первый интеррапт
 только начал сохранять регистры и сохранил два регистра из тридцати и тут случился более важный
 интеррапт. как я понимаю тут логика такая - каждый интеррапт хендлер прежде чем начать чтото делать сохраняет все регистры или по крайней мере те регистры которые собирается менять таким 
 образом вызов ISR внутри другого ISR неломает систему данных в регистрах. но при такой системе
 все упирается в акуратносить прогарммирования в то что ISR прежде чем чтот делать должен прежде
 всего сохранить все регистры и только потом начинать чтото делать.

 тутже я напоролся на такой термин как reentrant. в программировании он значит что если у нас
 ест какойто код (функция) то оназывается reentrant если если мы можем прервать ее выполнение
 в любом месте запустить заново (на этом или другом цпу) и при этом мы сможем получить резуль
 тат коректрный который ничего не поломает при условии что предыдущий вызов функции еще
 неотработал.  пример такой . вот у нас функция и она входе своего выолпнения блокирует
 некий ресурс  и тут бах срабатывает например интеррапт хендлер и и он тоже иползует этот ресурс
 и получается хендлер неможет отработать потому что ресурс уже заблокирован исходной
 функцией а она стоит у нас. 

я пока еще непонял на счет момента относительно когда у нас выполняется ISR (interrapt service routeint) тоесть хэндлер интеррапта как там насчет заблокировано ли прерываение этого хендлера 
или нет. пока я понял что что код хендлера вначале своего исполнения может заблокировать прием со стороны цпу новых интерраптов пока выполняется наш хэндлер. однако есть как я понимаю и вариант
что хендлер неблокирует прием новых интерраптов со стороны цпу и тогда наш хендлер может быть
прерван другим интерраптом. что также известно что сам цпу неимеет никакого никакой очереди 
в которой бы накапливались интеррапты. он может либо принять интеррапт либо непринять.
работу по интерраптам на себя берет контроллер интерраптов. что делает контрроллер прерыаений: если у нас несколько интерраптов приключаилось то у них есть приоритетность так вот контроллер
инерраптов выбирает тот который самый приориеттный и только его пихает на цпу. также контроллер
как я понял может подержать в очереди один или два прерывания. однако если цпу все таки будет 
медленно обрабатывать прерывания и скажем в очереди будет три прерывания то как я понял часть прерываений начнет скажем так "теряться" что это значит на практике я незнаю пока.

на счет вообще зачем нужны интерапты затем что устройство хочет чтобы цпу обработал порцию байтов
от устройства чтобы в итоге байты от устройства перекочевали в некую область оперативной памяти
а поскольку устройство незнает куда в память качать данные и как это сдлеать то нужен цпу а цпу чтобы это знать надо запусить хендлер который знает куда в память качать байты от устройства.
да устройства может качат данные в память без участия цпу через DMA контроллер. но там все равно
хоть и отчасти нужен цпу. итак инфо которая поступает в устройства их нужно пееркачать в память 
без цпу условно говоря это несделать. что дает именно мехаизм интерраптов это то что вместо 
того чтобы ждать когда от железки поступит сигнал цпу делает другие дела  а когда в жеелезку поступает сигнал то интеррапт дергает цпу за руку.

по поводу статуса процесс как S (interruptible sleep)  вэтом состоянии процесс (его код контекст)
шедулером несуется на цпу потому что процессу нечего делать. как я понимаю там регистрируется в ядре что мы ждем некое событие. и пока оно непроизойдет ядро шедулер небудет совать процесс на цпу.
а вот когда заказанное событие произойдет тогда цпу и "разбудит " процесс другими словами сунет 
код процесса обратно на цпу ибо у него пояивилось что делать снова. на счет того что он интерраптибл как я понимаю это значит что процесс процессу можно послать сигнал. например kill -9 или kill -15 и либо кастомный хендлер либо деолфтотвый от ядра отрадотает на этом процессе.
но главное что я хотел подчеркнуть что если процесс в состоянии S то его код несуется на цпу. это ключевой момент. есть еще статус процесса D (uninterrptuble sleep) такой процесс тоже его код
несуется шедулером на ядро но этот процесс небудет отвечать на сигналы потому что он ждет 
ответа от ядра обычно это работа с диском например тоесть если процесс грохнуть то как я понимаю
можно получить на диске какой то мусор. тоесть corrupt данных. поэтому надо ждать пока
ядро ответит процессу. 


про семафоры. что это такое.
есть две функции P и V. они отвечают за доступ к некоему критичному ресурсу к которому одновременно
можно чтобы имело доступ скажем один процесс или несколько скажем три. как это работает.
процесс лезет в функцию P и проверяет чтобы она была >0 если это так то процесс получает
доступ к ресурсу. и одновременно значение функции P уменьшается на 1. а если при доступе
процесса ( а скорее всего все таки треда) к P показыает что значение функции 0 или меньше нуля
(правда неочень понятно как оно может быть меньше нуля) то процесс (или тред пока неясно) ждет пока P станет больше нуля чтобы получить доступ к ресурсу. (как он ждет тоже непонятно он регулярно обращается или там есть какойто механизм уведомления).  если у нас изначально P=1 
значит только один процесс может иметь доступ  к ресурсу такой вид семафора называется mutex (mutual exclusion). а если P>1 изначално скажем P=2 то к ресурсу может иметь одноверменно 
доступ два процесса это уже семафор . мьютекс тоже семафор но конкретный частный случай.

тут еще пришла мысль а нафига нам нужно было придумывать такую штуку как stack то есть в цпу есть команды push\pop  есть регистры которые укзываются на стек. стек это кусок в памяти в которую 
можно пихать данные туда и обратно в цпу не через mov команды а через push и pop вот и возникает 
вопрос нахера вобще стек если можно было бы mov использовать? пока ответа ненашел.
зато: кажоый процесс имеет два стека. один используется когда цпу работает в ring3 с кодом
процесса (юзерский код) а второй стек используется когда через сисколл цпу переключается на ring0
и на ядерный код. тогда другой стек используется.



про context switch(синонимы process switch\task switch). есть понятие cpu context switching а есть linux process context switching
 а есть software context switching а есть cpu hardware context swithing.
поехали.во первых линукс неиспользует intel tss. потому что это очень медленно. гораздо быстрее
это делать вручную тоесть руками а не с помощью железных возможностей цпу. это делает код 
более переносимым якобы и это выполняется быстрее потому что зачастую ненужно сохранять 
все хрени и этого хватит для переключения процессов а выполнится быстрее.
набор регистров которые нужны чтобы процесс мог успешно продолжть свою работу называется 
hardware context. в линуксе часть hardware context сохраняется в кернел стеке а часть в процесс
дескрипторе.(о как!) , тоесть часть регистров пихается в стек а часть в процесс дескриптор.

что такое intel tss - одно уже известно сразу. в 64битном варианте нет никакого режима TSS.





================


syscall


где можно найти список всех сисколлов.
один способ это 

man 2 syscalls
хотят тут несовсем сиколлы а libs обертки которые уже обращаются к ядерным сисколлам
прикол в том что порой они имеют одинаковые имена а порой и нет. тамже ( man 2 syscalls) указано
в каких манах искать тот или иной "сисколл". но в этих манах нет порядкового номера сисколла


второй способ это 
в файле /usr/src/linux-headers-5.4.0-91-generic/arch/x86/include/generated/uapi/asm/unistd_64.h
можно посмотреть какие сисколлы есть в линуксе. они там все указаны и там также указан порядковый
номер сисколла. (порядковый номер нам нужен если мы собираемся вызываь сисколл через ассемблер)

выглядит это так:

#ifndef _ASM_X86_UNISTD_64_H
#define _ASM_X86_UNISTD_64_H 1

#define __NR_read 0
#define __NR_write 1
#define __NR_open 2
#define __NR_close 3
...

это и есть те самые fork() итд.

каждый сисколл имеет имеет свой номер

write = 1
fork = 57

signal - c этим интересно. согласно man 2 signal - By default, in glibc 2 and later, the signal() wrapper function does not invoke the kernel system call.  Instead, it calls sigaction(2).
и все верно. в unistd_64.h мы ненайдем сисколла signal. его просто нет. а вот sigaction есть.
таким образом signal это не сисколл. это wrapper функция libc вызывающая настоящий сисколл sigaction. sigaction имеет номер 13
 
waitpid - c ним тоже самое. это не сисколл. это libc обертка по вызову сисколла wait4. 
в unistd_64.h мы ненайдем сисколла по имени waitpid. а вот wait4 тут есть. с номером 61.
о том что waitpid это не сисколл а обертка написано в man 2 waitpid - On some architectures, there is no waitpid() system call; instead, this interface is implemented via a C library wrapper function that calls wait4(2)

mmap =9

кстати спросите а зачем нам номер этого сисколла. дело в том что когда мы в C программе вызываем
тот или иной сисколл по имени то компилятор вызывает на асемблере сисколл именно по номеру.
в опрееленный регистр цпу на асемблере кладется именно номер сисколла. а далее вызывается асмеблерная команда syscall. и когда цпу переключаился в привлигированный режим то он смотрит в
определный регистр и ищет там номер чтоб понять к какойму сисколлу юзер программа хочет обратиться.
сисколл с точки зрения кода ядра его некоторая функция.

пример вызыва сисколла с номер 1 тоесть тот который сисколл write.

$ cat 1.asm
section .data
    msg db      "hello, world!"
    msg1 db     10
section .text
    global _start
_start:
    mov     rax, 1
    mov     rdi, 1
    mov     rsi, msg
    mov     rdx, 13
    syscall

    mov     rax, 1
    mov     rdi, 1
    mov     rsi, msg1
    mov     rdx, 1
    syscall

    mov    rax, 60
    mov    rdi, 0
    syscall


компилим
$ nasm -g -f elf64 -l 1.lst  1.asm
$ ld -o 1.exe 1.o

запускаем
 $./1.exe
hello, world!

в этой программа вызывается три сискола.
первый сискол это сисколл 1 тоесть write

есть такой станарт ABI он определяет в какие регистры и что надо положить
чтобы при вызыве ассемблерной команды syscall цпу\ос (или кто там я незнаю) поняли какой сисколл
просит запустить юзерская программа у ядра и в каких регистрах искать праметры с которыми
запускать этот сисколл.(ибо сисколллы требуеют параметры). сисколл еще раз это с одной стороны
команда цпу (тоесть свойство железки )  с другой стороны это функция в пространстве кода ядра.

иатк про регистры что куда надо класть перед запуском цпу команды syscall

RAX — This register contains the system call number. сюда надо записать номер сисколла который 
мы хотим вызвать. в нашем соучае мы туда пишем 1 единицу

mov     rax, 1

номера сисколллоа надо искать в unistd_64.h (тот который выше указан)

RDI — this register contains the value of the first argument to be passed to the system call
в случае нашего сисколла write первый параметр это номер файлового десктриптора куда 
мы хотим чтото писать. в нашем случае это станадртный вывод. тоесть дестриктор =1 поэтому

mov     rdi, 1


RSI — this register contains the value of the second argument
втторой аргемент для write это то что мы хотим записать. точне туда кладется ссылка на ячейку
памяти в которой лежит то что мы хотим записать

mov     rsi, msg

RDX — 3rd argument
третий аргумент сколько байт наше сообщение занимает. внашем случае 13 байт.


mov     rdx, 13

все . все перменные для вызова сисколла write подгтовлены можно его вызывать

syscall

на экане будетт напечаатано 


hello, world!

проблема в том что небует знака переноса строка. я незнаю как его красиво
вставить в  msg db      "hello, world!"  поэтому для печати символа переноса строки 
это ascii сивол с dec номером 10 ( man ascii)  я исползую следущий второй сискол write

        msg1 db     10

        mov     rax, 1
    mov     rdi, 1
    mov     rsi, msg1
    mov     rdx, 1
    syscall


третий сисколл это сисколл которйы просит ядро завершит процесс. убить его. это сисколл с номером 60
который называется exit


        mov    rax, 60
    mov    rdi, 0
    syscall


в rax мы калдем номер сиколла 60
в rdi мы кладем номер кода возврата 0 ( все успешно)
тоесть всего два регистра нам надо запрограммировать

и мы вызываем сисколл через команду цпу

syscaall

победа!

важно понять что наш вывзов сисколла когда цпу переключится в привилигорваннй режим обрабатывает
код ядра операционной сситемы. если бы когда цпу перклювился в привлигированнй режим там бы небыло операционной системы то небыло бы никакого эффекта. нужен код ядра по ту стороны от непривилигированного режима. тоесть мы юзаем асемблер только для того чтобы передать переменные
на ту стороны из непривлигорванного режима в режим привлигоровынный чтобы тамошний код по ту сторону
смог получить переменные.  если бы небыло ос по ту сторону то запустив голвый асемблер код мы бы ничего неполучили в иттоге  цпу переключился бы а там нихера нет никакого кода который бы мог 
принять наши переменные.

что интересно - для того чтобы создать процесс мы в нашей программе недолжны использовать никакой
сисколл. это как на автоматате происходит а вот завршение работы программы неможет быть 
выполнено на автомате. мы должны сами в коде в явном виде попросить сообщиь ядру о том что 
наша программа хочет завершить свою жизнь через сисколл 60 exit.

интересно что даже через голый асемблер из юзерспейса мы неможем получить доступ к голому железу
наппрямую. на примере сисколла write - мы только можем сунуть данные в некую асбтракцию файловый 
дескрпитор который является некой асбтракцией представленной ядром. и только то.

поскольку сисколл это детище ОС ее функции то получается в коде ос надо искать спецификацию
какие переменные нужны для вызовра сисколла. в каком виде итд если мы хотим запускать сисколлы
через асемблер. например для сисколла write = man 2 write 

NAME
       write - write to a file descriptor

SYNOPSIS
       #include <unistd.h>

       ssize_t write(int fd, const void *buf, size_t count)

и там написано что 

write() writes up to COUNT bytes from the buffer starting at BUF to the file referred to by the file descriptor FD.

тоесть видим что три переменные. и что они значат. ровно их мы и юзали (четвертая переменная rax 
использовалась чтбы сообщить ядру номер сисколла кооторый хотим юзать)

        mov     rax, 1

    mov     rdi, 1
    mov     rsi, msg1
    mov     rdx, 1


так. ну тут еще надо при этом понять что как я понимаю что через man если искать то мы 
на самом деле ищем формат не кернел сисколла а libc оболочки которая вызывает сисколл.
но все же man имя_сисколл это хороший источник посмотреть спецификацию сисколла чтобы его 
верно вызывать через асемблер.


по поводу каков механизм сисколла. как это все происходит. еще раз.
юзер программа кладет в в eax\rax регистр номер сисколла который мы хотим вызвать а в
регистры rdi,rsi, и другие кладет аргументы для сисколла (параметры). далее юзер программа
использует цпу команду syscall ассемблерную
что делает цпу выполняя команду syscall ассемблерную - цпу пеерклчаеся в привилигированный
режим. и в цпу есть спец регистры называются MSR их целая кучка. они служат разным особым целям и 
вот там среди них есть спец регистры которые служат исключительно целям обеспечения работы 
ассемблер команды syscall\sysret. эти регистры программируются ядром линукса заранее.

первый регистр: STAR
 STAR регистр переводится как SYSCALL/SYSRET Target Address Register (STAR) и содержит в себе
the target EIP address used by the SYSCALL instruction and the 16-bit code and stack segment selector bases used by the SYSCALL and SYSRET instructions.
а что за смысл eip ? ответ - EIP is a register in x86 architectures (32bit). It holds the "Extended Instruction Pointer" for the stack. In other words, it tells the computer where to go next to execute the next command and controls the flow of a program. вот еще про смысл eip - eip, or the instruction pointer, is a special-purpose register which stores a pointer to the address of the instruction that is currently executing. хмм. тоесть написано что внем содержится адрес в памяти команды которая щас выполняется. хотя чуть дальше там же пишут что - After each instruction, a value equal to the size of the instruction is added to eip, which means that eip points at the machine code for the next instruction. тоесть все таки это регистр содержит 
адрес в памяти команды которая должна будет быть выполнена следующей. тоесть указан адрес где искать команду которую надо будет выполнить следующей. ну уже понятней.
правда eip у нас 32 бит. а какже обстоит делов случае x64. ну ладно это уже сложные детали.

значит еще раз  у этого регистра который 64 бита длинной биты содержат такие штуки:

биты 0-31 содержат = TARGET EIP address (тоесть адрес в памяти где лежит следущая команда которую надо будет выполнить)  я так понимаю там лежит адрес ядерного хендлера или как там эта хрень называется короче та самая функция обработки всех сисколлов. обработчик сисколлов верхнего уровня.(кусок кода уровня ядра).


биты 32-47 содержат = syscall cs selector и ss selector base

отсановился на том что надо понять смысл cs и ss регистров в разрезе 64бит памяти по сути
надо понять linux 64 bit memory model через какие регистры происходит адресация в памяти.
я понял что когда унас real mode режим памяти тогда адрес в памяти определется через сумму
CS:IP, оба регистра 16бит. это 64KB. адрес в памяти вычисляется по формуле 

memory address = CS*0x10+IP

в таком режиме можно адресовать 1МБ памяти. тоесть

FFFF*10+FFFF " | bc
10FFEF

а 10FFEF байт это 1МБ.


Некоторое отступление от темы но тоже очень важное = вот у нас работает процесс в режиме ring3
юзерский режим. вот мы вызываем syscall и цпу переключился на ring0 и запустил код ядра. вопрос
какой статус будет иметь процесс в top либо ps. и тут прикол вот в чем. насколько я понимаю 
код ядра будет выполняться с точки зрения шедулера в том же самом таймслайсе что был выделен
исходному процессу. пока немогу прям точно все расписать и аргументировать но для шедулера
все остается типа по прежнему тот же самый процесс работает без изменений. Это значит что 
далее статус процесса зависит от кода самого сисколла. например если коду сисколла мало что 
надо и скажем только достаточно цпу то статус процесса будет 'R'.
я провел важный эксперимент:
запустил команду
$strace dd if=/dev/urandom of=/dev/null bs=30M count=1000

она показывает на экране постоянно вот такую картину
read(0, ",g\32155\320,\16\16\261\22\240\27b\303\34\311\276\240M0\33)\331"..., 31457280) = 31457280
write(1, ",g\321\366\20332\2261\22\240\27b\303\34\311\276\240M0\33)\331"..., 31457280) = 31457280
read(0, "\20W\340M;j\233\3247\361\317\252fiD\374"..., 31457280) = 31457280
write(1, "\20W\340M;j\233\31316\247\361\317\252fiD\374"..., 31457280) = 31457280

то есть процесс по факту все время делает только сисколлы и больше нихера.
логично предположить что процесс буквально все время сидит в кернел моде.

далее смотрим в top либо ps и там видно что статус процесса все время 'R'
ну уже как бы верится что этот R он неможет быть из за того что цпу пашет в юзерском режиме
ибо в юзеском режиме там просто нихера нет кода никакого. но хотим еще убедитсяь надежнее
запускаем 
$nmon

и видим что цпу на 100% занят только кернел моде нагрузкой.
но нам и этого мало. может быть ненаш процесс работает в режиме кернела а какойто другой
компонент системы. мы тогда лезем в procfs и там постоянно считываем две цифры 
из статуса процесса


$ awk '{print $14, $15}' /proc/18774/stat
0 3915

первая цифра это = Amount of time that this process has been scheduled in user mode, measured in clock ticks
вторая цифра это = Amount of time that this process has been scheduled in kernel mode, measured in clock ticks

и мы будем видеть что первая нихера нерастет а вторая постояно растет.
так что мы получили 100% подтверждение что наш процесс имеет 'R' и эта R связана именно с тем
что выполняется код ядра "от имени нашего процесса" с точки зрения шедулера.
детали надеюсь смооу обьяснить позже.
вопрос родился потому что навсидку реально мало понятно что происходит с процессом после того 
как он вызывал сисколл с точки зрения шедулера как меряется статус процесса. может быть он 
условно говоря сразу в спячку (состояние S впадает или в состяние D к примеру.). более того 
я нашел на стэковерфлоу неверный ответ там утвержали что процесс автоматом впадает в состояние D.
что намой взгляд верно но только в части случаев но отнюдь невсегда. а зависит именно от самого
кода сисколлаа и всякого другого. если бы скажем я писал данные не на/dev/null а на шпиндельный
диск который медленный тогда получается что наш сисколл вынужджен был бы ждать ответ 
от диска  и тогда бы да был бы статус D но не из за сисколла как такоовоо а из за последубщего
компонента - медленного диска. пока вопрос остаетя в некотором роде открытым.
Насколько я понимаю на данный момент когда мы запускаем команду syscall\int 80 то мы



далее надо разобратсья так как же через какие регистры происходит адресация в 64 битном режиме
в протектед моде  в режиме ядра

...
=====================
gcc

как компилировать чтобы он сохранял код ассемблера чтобы можно 
было посмотреть без дизассмблирования. причем чтобы он писал код ассемблера
в intel формате


$ gcc -S -masm=intel 51.c 
$ cat 51.s



=====================
leave

очень часто вначале main идут команды

    push   rbp
    mov    rbp,rsp

так вот есть команда которая делает все наоборот это LEAVE она делает:

    mov  rsp,rbp
    pop  rbp

кстати первые две команды эквиваленты команде ENTER. но она гораздо дольше работает 
чем две отдельные. в этом плане LEAVE вроде как работает достаточно быстро по сравнению с 
ее двумя командами эквивалентами поэтому leave все таким применяют сейчас а enter нет.

а в чем разница leave с ret?

=====================
push
pop

значит я проверил что реально когда мы суем push в стек
то он сдвигается на 8 байт ( 64bit код) и 4 байта (32bit код)

пример программы:
64bit:

$ cat 32.asm
section .data
section .text
    global _start
_start:

    mov    rax, 0xffaaaa
    push   rax
    pop    rax

    ; exit(0)
    mov    rax, 60
    mov    rdi, 0
    syscall



32bit:

$ cat 32.asm
section .data
section .text
    global _start
_start:

    mov    eax, 0xffaaaa
    push   eax
    pop    eax

    ; exit(0)
    mov    eax, 60
    mov    edi, 0
    int 80

(замечу что в 32битном виде у цпу нет команды syscall а вместо нее только int 80)

компилируем в 64bit код

а вот пример как откомпилировать с debug символами (чтобы потом в gdb смотреть)
$ nasm -g -f elf64 -l 32.lst -o 32.o 32.asm
$ ld -o 32.exe 32.o

компилируем в 32bit код

а вот еще как откомпилировать с debug символами в 32bit файл
$ nasm -g -f elf32 -l 32.lst -o 32.o 32.asm
$ ld  -m elf_i386   -o 32.exe 32.o


$ gdb ./32.exe
> b _start
(gdb) set disassembly-flavor intel
(gdb) disassemble
(gdb) run
(gdb) info registers
(gdb) nexti


в случае 64бит код после команды push esp изменяется 
с
0x7fffffffdc60
до
0x7fffffffdc58

разница 8 байт , верхушка стека движется вверх.



в случае 32бит код после команды push esp изменяется 
с
0xffffce40
до
0xffffce3c

разница 4 байт , верхушка стека движется вверх.
===================
ia32
x86-32
32bit  mode

вобщем открыл для себя что 
вот у нас есть 32битный код машинный. и в нем мы хотим вызывать сисколл.

во первых номера сисколлов для 32 битного режима и для 64 битного они разные.
пример для сисколла exit

$ cat /usr/src/linux-headers-5.4.0-91-generic/arch/x86/include/generated/uapi/asm/unistd_64.h | grep exit
#define __NR_exit 60

$ cat /usr/src/linux-headers-5.4.0-91-generic/arch/x86/include/generated/uapi/asm/unistd_32.h | grep exit
#define __NR_exit 1

тоесть в 64битном режиме это 60-ый номер а в 32-битном режиме это номер 1.



далее. если в в 64 битном режиме мы кладем:
номер сисколла в RAX
первый параметр сисколла в RDI

то в 32 битном режиме мы кладем:
номер сисколла в EAX
первый параметр сисколла в EBX



далее. в 32битном режиме мы неможем использовать асемблерную команду syscall для вызова
сисколла она просто там неработает. ее там нет.  и попытка ее вызова вызовет то что 
ядро пришлет процессу сигнал SIGILL.

(я правда непонимаю 
почему компилятор позволяет ее использовать в 32 битном коде почему не посылает с ошибкой).
пример , вызываем сисколл exit()  в 32 битном режиме

$ cat 34.asm
section .data
section .text
    global _start
_start:

    mov    eax, 1    ; номер сискола exit()
    mov    ebx, 0    ; код возврата
    syscall

$  nasm -f elf32 -o 34.o 34.asm
$  ld  -m elf_i386   -o 34.exe 34.o

$  strace ./34.exe
execve("./34.exe", ["./34.exe"], 0x7ffd56c744b0 /* 74 vars */) = 0
--- SIGILL {si_signo=SIGILL, si_code=ILL_ILLOPN, si_addr=0x804806a} ---
+++ killed by SIGILL (core dumped) +++
Illegal instruction (core dumped)


вызов сисколла через int 0x80 в 32 битном режиме работает без проблем:
$ cat 34.asm 
section .data
section .text
    global _start
_start:

    mov    eax, 1
    mov    ebx, 0
    int 0x80


$ strace ./34.exe 
execve("./34.exe", ["./34.exe"], 0x7ffc5dad7880 /* 74 vars */) = 0
strace: [ Process PID=12424 runs in 32 bit mode. ]
exit(0)                                 = ?
+++ exited with 0 +++


а вот вызов сисколла в 32битном режиме через sysenter имеет реальные приколы.
если мы заменим int 0x80 на sysenter то мы получим ошибку SEGFAULT.
а в чем же дело? ответ нашел вот здесь - https://reverseengineering.stackexchange.com/questions/2869/how-to-use-sysenter-under-linux :

the sysenter instruction expect to have the stack forged in that way:
0x______0c  saved_eip   (ret)
0x______08  saved_%ecx  (pop %ecx)
0x______04  saved_%edx  (pop %edx)
0x______00  saved_%ebp  (pop %ebp)

хотя по факту судя по коду из ответа и я проверил на практике надо сделат и еще кое что.
итого перед вызовом sysenter надо кое чего сделать дополнительно :

в самом начале функции надо добавить команды

        push ebp
        mov  ebp, esp

а перед вызовом sysenter надо вставить

        push   $_start
        push   ecx
        push   edx
        push   ebp
        sysenter 

итого скажем для вызова сисколла exit(0) в 32битном режиме через systenter надо

$ cat 34.asm
section .data
section .text
    global _start
_start:
    push ebp
    mov  ebp, esp

    mov    eax, 1
    mov    ebx, 0

    push   $_start
    push   ecx
    push   edx
    push   ebp
    sysenter


для сравнению приведу тот же самый сисколл через int 0x80
чтобы была видна разница сколько всего нужно добавить чтобы тотже сисколл успешно
прошел через sysenter

$ cat 37.asm
section .data
section .text
    global _start
_start:

    mov    eax, 1
    mov    ebx, 0

    int 0x80


как говорится почуствуй разницу.
а если вот эту обвязку вокруг sysenter несделать то програма будет вылетать с ошибкой SIGFAULT.

естественно сама инструкция sysenter на цпу невиновата (тоесть цпу ни причем) а виноват
хендлер ядра линукск который обрабатывает по разному переход в сисколл в зависимости от команды
цпу ( я так понял).

общий вывод такой по сисколлам :
для 64 битного машиноого кода - юзай syscall
для 32 битного машинного кода - юзай int 0x80

и никакой ебалы тогда небудет.

sysenter якобы работает быстрее но вот с ним дополниельные заморочки нужно делать.


также видно что в тексет асемблера используется необычная инстркция

push   $_start

она приводит к тому что будет в файле подставлен адрес начала функции _start.
тоесть это делается средставами компилятора. как получить в программе адрес старта текущей
функции я пока незнаю.

вот как выглядит дизасембл код: 

08048060 <_start>:
 8048060:   55                      push   ebp
 8048061:   89 e5                   mov    ebp,esp
 8048063:   b8 01 00 00 00          mov    eax,0x1
 8048068:   bb 00 00 00 00          mov    ebx,0x0
 804806d:   68 60 80 04 08          push   0x8048060
 8048072:   51                      push   ecx
 8048073:   52                      push   edx
 8048074:   55                      push   ebp
 8048075:   0f 34                   sysenter


соотвтсвенно  push   0x8048060, 
где  0x8048060 это адрес старта функции <_start>:


========
AT&T 
as
gas

если у нас программа в AT&T синтаксисе то его nasm непонимает.

$ cat 36.asm
.data
msg:
    .ascii "Hello World!\n"
    len = . - msg

.text
.globl _start
_start:
;    pushl  %ebp
;    movl   %esp, %ebp

    movl   $0, %ebx
    movl   $1, %eax
# Setting the stack for the systenter
    pushl  $_start
    pushl  %ecx
    pushl  %edx
    pushl  %ebp
;    movl   %esp,%ebp
    sysenter



и его можно откомплировать тогда через as

для 32битного кода это выглядит так



$ as 36.asm -o 36.o --32
$ ld  -m elf_i386   -o 36.exe 36.o

=====================
что такое и зачем stack alignment? и связанный  с ним вопрос - а что такое assmbly function? как это с abi связано?

$ cat 27.asm
; 27.asm
section .text
    global _start
_start:
BITS 64
    mov       rax,0xff11ff11ff11ff11
    push      rax
    pop       rax
    push      0x7a
    pop       rax
    push      0x8a
    pop       rax


; call exit(0)
    mov    rax, 0x3c
    mov    rdi, 0x0
    syscall


компилируем
$ nasm -f elf64 27.asm
$ ld -s -o 27.exe 27.o

а вот пример как откомпилировать с debug символами (чтобы потом в gdb смотреть)
$ nasm -g -f elf64 -l hello.lst -o hello.o hello.asm
$ ld -o hello.exe hello.o

а вот еще как откомпилировать с debug символами в 32bit файл
$ nasm -g -f elf32 -l 32.lst -o 32.o 32.asm
$ ld  -m elf_i386   -o 32.exe 32.o



заходим в gdb

=> 0x0000000000400080 <+0>: movabs rax,0xff11ff11ff11ff11
   0x000000000040008a <+10>:    push   rax
   0x000000000040008b <+11>:    pop    rax
   0x000000000040008c <+12>:    push   0x7a
   0x000000000040008e <+14>:    pop    rax
   0x000000000040008f <+15>:    push   0x8a
   0x0000000000400094 <+20>:    pop    rax
   0x0000000000400095 <+21>:    mov    eax,0x3c
   0x000000000040009a <+26>:    mov    edi,0x0
   0x000000000040009f <+31>:    syscall 

первое . проверим а вот сам текст с командами он тоже выровненный лежит в памяти или нет.
выровненный значит то что сущности (перменная или команда) размещаются в опертивке только
по адресам которые как минимум четные.вобще кода мы гооворим об выровненнности надо уточнять
по какому размеру выравниваем. если выравниваем по размеру 16бит (2 байта) то значит что 
сущности размещаются в памяти только по четным адресам получается оставляя дырки в памяти.
гнапример у нас первая переменная равна 1 байт. а вторая  2 байта. тогда в памяти они буудт помещены согласно правилу выровенности по двум байтам вот так:

0000 переменная-1
0001 пусто
0002 переменная-2
0003 переменная-2

видно что байт с адресом 0001(нечетный)  оставлен пустым. зачем так делается - например процессор
8086 или 8088 (точно непомню) имел ширину шины данных 2 байта плюс память так устроена что 
в ней данные читаются строками а неоотдельными байтами в итоге это приводит к тому что 
на том цпу за один такт можно было считать байты 0000 и 0001, либо 0002 и 0003. а вот если 
нам нам над было считать байты 0001 и 0002 то это занимало бы два такта. потому что вначале
цпу читает 0000 и 0001 отбрасывает ненужное осталяет 0001 и потом читает за второй такт
0002 и 0003 отбрасывает ненужное и осталвяет 0002. итак в этом виновата щирина шины данных на цпу
и то что из памяти на самом деле байты нельзя считать произвольные. можно только читать некоторой
кучкой. поэтому вся эта чехарда с размещением в памяти данных только по определенным адерсам
из за того чтобы потом когда кэтим данным обращаться чтобы небыло доступа за несколько тактов.
чтобы доступ был быстро за минимальное число тактов. вот ради чего все это.

так вот смоирим на gdb на то как текст программы размеене в памяти и проверяем выровнены ли 
они компилятором.

   0x0000000000400080 = 4194432 
   0x000000000040008a = 4194442
   0x000000000040008b = 4194443
   0x000000000040008c = 
   0x000000000040008e = 
   0x000000000040008f = 
   0x0000000000400094 = 
   0x0000000000400095 = 
   0x000000000040009a = 
   0x000000000040009f = 

таким образом видно что команды в памяти располагаются без выравнивания. окей поняли это.


регистр RIP = в нем рамзмещен адрес по которому лежит следующая команда. (в рамках тогоже сегмента).

для нашей программы внаале ее выполнения это выглядит:
rip =           0x400080

и смотрим по какому адресу лежит стек вначале выполенения программы:
rsp =           0x7fffffffdc60

вот как это посмотреть:
> info registers
rsp            0x7fffffffdc60   0x7fffffffdc60
rip            0x400080 0x400080 <_start>

далее выполняем команду из программы

push rax

смотрим как меняется адрес вершины стека:
было 0x7fffffffdc60  стало 0x7fffffffdc58.
разница = 8байт.
и это правильно потому что мы же пихаем в стек значение регистра rax который 64бита длинной.
все совпало.

далее замечаем что как положено вершина стека после того как в него чтото вложили
смещается наверх в сторону уменьшения адреса.

проверим адрес вершины стека выровнен ли относительно 64бит(8байт)
$ echo "obase=10;ibase=16;7FFFFFFFDC60" | bc
140737488346208

$ echo "obase=10;ibase=10;140737488346208/8" | bc
17592186043276

адрес поделился на 8 нацело. значит адрес вершины стека выровнен относиельно 8 байт.
значит чтение и запись в стек будет идти по времени на минимальном числе цпу тактов.
я так понимаю полагается что ширина шины данных у 64битного процессора тоже 64бит.

итак получается что величина на котору сдвигается вершина стека при операциях с ним
должна двигаться ровно на то число байт сколько по размеру регистры в цпу.
тоесть: 

mod|предыдущее значение вершины стека - текущее значение вершины стека| = mod | размер регистра цпу|

почему mod потому что мы можем как соватьв стек таки ивытаскивать с него. поэтому знак неизвестен.

тоесть мы щас обсудили дельтту сдвига вершины стека.
а вот сам адрес должен быть выровнен ... относииельно чего? причем мало выровнять изначально.
ведь кажый положенный регистр в стек может поломать выровненность...

положим размер регистра 8 байт а ширина шины 16 байт.
положим стек набит и вершина стека лежит по адреу 0.
rsp=0

вытаскиваем первый элемент из стека( байты 0-7). 
0
1
2
3
4
5
6
7

вершина сдвигается в 
rsp=8 байт.

чтобы счиатать по шине 0-7 байт мы сделаем это за 1 такт цпу (условно ) потомучто
цпу считает за раз 16 байт (0-15). все окей.

далее вытаскиваем еще один элемент из стека. (байты7-15). они тоже будут считаны за 1 такт.
потому что цпу считает 

????????????????????????????????????