ext4 data=jornal

значит при монтированиии ext4 раздела есть опции по режимам работы 
жунала на разделе

mount -t ext4  data=writeback\ordered\journal

посмотреть  с каким параметрами сейчас примонтированы разделы

$ mount | grep ext4
/dev/mapper/ubuntu--uefi--vg-root on / type ext4 (rw,relatime,errors=remount-ro,data=ordered)
/dev/mapper/vg01-lvol0 on /mnt/lvol0 type ext4 (rw,relatime,nodelalloc,errors=remount-ro,data=journal)


режим data=writeback 
	это облегченный режим ordered поэтому writeback даже нерассмаиваем

режим data=ordered 
	как я примерно понял при записи файла на диск вначале льются блоки 
	данных сразу на ФС а потом после этого вначале в спец место на диске назыаемое журнал льюбтся метаданные о файле. и только потом эти метаданные льются на саму ФС. таким образом типа если отнять питание на стадии записи этого файла то в худшем случае данные внутри файла 
	будет попорчены тоесть самое тело файла но метаданные будут непопорчены по этому на уровне структуры файлов\папок фс будет непопорчена.
	
режим data=journal
	в этом режиме в журнал льютс и данные и метаданные. поэтому как я понимаю если приложение получило от кернела сообщение что некоторая часть файла записана на диск то она туда 100% записана. таким образом эта опция позволяет быть уверенным что то что было сообщено от ОС к приложению было записано оно записано. таким образом мы защиезщны от неконстисентности при обрыве питания. понято что при этом скорость записи на диск падает в 2 раза. как выход держать журнал на отдельном разделе на другом физ диске. в целом по процессу 
	вот мы пишем какойто кусок файла на диск и ОС нашему приложению сообщила что этот кусок типа записан. при этой опции мы типа знаем что кусок файла был типа записан в журнал а потом на ФС и потом ОС нам сообщает что кусок файла записан на ФС. возникает вопрос но можем ли мы быть уверены что он куда то реально записан. ведь у диска есть буфер кэш память. может оно только туда записано. это момент непонятен. по крайней мере запись в два места дает больше гарантии что хоть в одно место оно реально было записано. если мы юзаем рейд контроллер с батарейкой то рейд контролллер отключает буферы на дисках а данные пихает в память рейд контроллера потеря питания на которой защизщена батарейкой. поэтому в случае рейд контроллера с батарейкой типа можно быть уверенным что данные действетльно будут непотеряны в случае обрыва питания. но опять же совпременные ssd диски они сверхмежденно работают на запись если на ниъ отключать буфер. поэтому надо покупать ssd диски у которых есть встроенная батарейка защищющая их буфер. еще есть такая штука как если мы работаем на виртуалке типа под esxi поэтому с этой сети посредников еще сидит гипервизор. но в случае если мы пишем на локальный диск или на nfs диск то гипервизор типа гарантирует что те данные которые он получил он небудет обратно сообщать что они записаны пока они небудут реально записаны.(какието там он принудитедльные команды юзает чтоб бекенд сторадж опорожнил свои буферы). в случае iscsi хранилища как я помню сфера недает гарантии и нужно на самом iscsi бекенд хранилище ставить опции что запись шла вроде как называется в синхронном режиме.
	

еще раз опция в каком режиме работает журнал относится не к ФС в целом а к режиме как она примонтирована на данный момент.


есть такая еще штука как barriers на ext4. по умолчанию она включена
так что ее настраивать руками ненужно.	
	

вывод data=journal очень хорошая опция для сохранности данных но надо понимать в целом какие посредники сидят между приложением и конечным диском чтоб быть уверненным про сохранность данных.

я провел опыт.схема такая виртуалка на esxi которая сидит на iscsi 
хранилище на котором принудительно включена синхронная запись

у меня был раздел смонтрованный как data=ordered

я вот этим скриптом писал маленькие файлы на этот раздел

$ cat ./script.sh
#! /bin/bash
for n in {1..1000}; do
    dd if=/dev/urandom of=/mnt/lvol0/fio/file$( printf %03d "$n" ).bin bs=1 count=$(( RANDOM + 1024 ))
done

и во время этого ресети виртуалку. после перезагрузки раздел показывал 
в свойствах что у него состояние clean

$ sudo dumpe2fs /dev/mapper/vg01-lvol0  | grep -i "state"
Filesystem state:         clean

файлы в каталоге были но все они были пусты.

я  неоднокартно повторил этот эксперимент.

до ресета виртуалки файлы были заполенены.


потом я смонтировал раздел с опцией data=journal
и повторил. после ресета и состоняие фс было clean
и файлы были непусты.

общий вывод - монтировать ext4 разделы с data=journal

как улучшение если есть возможность выносить журнал на другой физ диск.
==

	