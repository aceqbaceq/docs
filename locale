locale

интернализация(i18n) vs локализаця(l10n)

i18n - это когда мы пишем прогу которая может работать 
с отдельным локалями. тоесть идея в том что прога должна уметь принимать в себя
и переваривать локали.

локализация - это когда мы пишем конкреретный модуль локали.


пример по аналогии. мы делаем ноутубук у которого будет порт usb. 
это интернационализация. 
далее мы делаем флэшку которая работает по usb это локализация.
далее мы понаделали сто разных устройств которые работают по usb это локализация.
теперь благодаря интерналиционализациив наш ноутбук можно воткнуть любое usb устройство.

еще пример мы делаем робота у которого вместо рукми модуль с дыркой. это интернационализация
а потом мы делаем сто разных рук которые подключаются через такую дырку . это локализация.
теперь благодаря интернационализации в нашего робота можно вставить и поменять любую приставную
руку. и при этом ненужно кадый раз ему одну отпиливать а другую приклеивать.

итак интерналицаонлизация нам позовеляет к программе подключать локали как флэшки к ноуибукуу
а локализация и это работа по написанию подготовке конкретной локали.

еще пример. мы на машине создали разьем под колеса . теперь к машине можно прикручитвать колеса.
это была интернационализация. далее мы изготовили колеса трех разных диаметров. это локализация.  благодаря интернацлионалиации к машине можно подключать колеса. 
благодаря локализации у нас есть три разных типа колеса. 
без интернационализации к программе неприсобачиить локали. без локализации к приложению нечего
присоединять.


локале обычно определяется тремя факторам = язык (English) + терриория (Англия) + кодриовка (UTF8)

пример локалей
$ locale -a

C.UTF-8
en_AG
en_AG.utf8
en_AU.utf8
en_BW.utf8
en_CA.utf8
en_DK.utf8
en_GB.utf8
en_HK.utf8
en_IE.utf8
en_IL
en_IL.utf8
en_IN
en_IN.utf8
en_NG
en_NG.utf8
en_NZ.utf8
en_PH.utf8
en_SG.utf8
en_US.utf8
en_ZA.utf8
en_ZM
en_ZM.utf8
en_ZW.utf8
POSIX
ru_RU.utf8


термины:
(от отсюда https://www.debian.org/doc/manuals/intro-i18n/ch-coding.en.html
это не юникод документ поэтому он уже старый)

character - символ.это как буква. тоеть самостоятельная хрень из которой лепятся слова
glyph - это часть символа из которых рисутеся charcter
encoding - по ихнему это правило перевода символа в байтовую форму. также они говорят что charset (character set ) и encoding это одно и тоже.

по юникодовской же темринологии charset это набор символов в их абстрактном описании и соотвествующих им целых чисел. например

a -1
б -2

encoding же это правило преобразования целого числа из charset в байтовый вид для компа.

в этом же документе все по другому. у них character set это просто набор символов без 
приязвки их к каким либо числам. поэтому они еще зовут character set как non-coded character set.

поэтому далее они вводят уже Coded Character Set (CCS). 
это уже как раз набор символов которым ставится в соотвествие число.

далеее они определяют Character Encoding Scheme (CES).
по мне это как encoding.  для него CCS является входным потоком а выходдным является поток байтов.

далее
codeset=encoding

далее они пишут что в документе они будут юзать слово charset в смысле CCS.
что помне абсолдютно правильно.

далее я попал обратно на документ юникода.
в нем определяются следущие штуки

ACR - abstract character repertoire. это набор символов в самом классическом смысле тоесть
без привязки  к каким либо числам и цифрам. какой вид имеют символы неважно в формео 
описательнымх слов или в форме картинок на листочке. это ровно та исходная хрень с которой
мы начинаем работать.

CCS - Coded character set. маппинг абстрактных символов (в любой форме) в набор натуральных чисел. все теперь мы получили множество чисел.

CEF - Character Encoding Form(символ в encoding форме). это когда берем натуральное число из CCS и превращаем его в набор code units. вотэтот набор code units и является представлением символ в encoding виде тоесть в виде CEF. code unit насколько я понял имеет вид тоже целых чисел. данная форме еще непозволяет напрямую ее впихнуть в комп.

CES - character encoding scheme. переводит числа из CEF в поток байтов. и вот уже этот поток
байтов можно напрямую совать в комп.

CM - character map. это обьединение всех четырх шагов предыдущих в один. тоесть
маппинг символов  в абстрактной форме в поток байтов. CM=ACR+CCS+CEF+CES

Unicode ACR имеет номера версии. с каждой новой версией добавляются новые символы. начиная с версии 2.0 новые символы только добаляются и ниодин неудаляется.это гарантировано.

дальше юникод говорит про glyphs. он говорит что глиф это уже конкретное начертание графическое изображение символа или части какого-то символа на конечном носителе (бумага, экран). glyph определяется шрифтом. причем могут быть такие подставы что у нас например мы преедли шрифту два символа "f" и "i" а на экране будет нарисован один глиф так называемый "fi"
таким образом два смивола могут поступившие в шрифт могут быть им отображены на экране\бумаге одним глифом. символы ( в форме байтового потока ) отвечают не графическое представление на конечном носителе бумаге или принтере а за байтовый набор на носителе информации и также этот поток является входным для шрифта. а глифы это выходной поток из шрифта и именно глифы отвечают за графическое представление символов на конечно носителе. тоесть глазамы мы всегда видим глифы. а символы это внутрикомпьютерное представление на носителе информации и входной поток для шрифта. символы мы на экране никогда невидим. также получается что в зависимости
от конкретного набора символоа на входе на шрифт условно гооворя какие буквы естьв слове это может повлиять на выбор глифов. как уже сказал два символа на входе могут дать один глиф.
Выбор глифов (в зависиомтси от входного потока символов ) это уже проблема шрифта  ане энкодинга (как я понимаю). там далее написано что на конечный поток глифов влияет нетоллко 
поток символов но и другие факторы. 

Code point - число в hex формате в виде U-HHHHH

UTF-8/16//32 = encoding form

BMP - basic multiligual plane. вклчюаем в себя 65,536 code points. и таким макаром включает в себя все самые часто используемые characters.

Any given Unicode code point always represents the same character.

юникод не опреееделяет Glyphs. тоесть он не определяет визуальный вид символов на экране\бумаге.

Encoded character = code point

диапазон code points =  0 - 0x10FFFF

Text elements correspond to what users
perceive as single characters are called grapheme clusters

где хранятся code points - code points  reside only in a memory representation, as
strings in memory, on disk, or in data transmission. The Unicode Standard deals only with
character codes

Glyphs represent the shapes that characters can have when they are rendered or displayed.
In contrast to characters, glyphs appear on the screen or paper as particular representations of one or more characters. таким макаром сказано что я говорил. глифы это графическое отображение на экране или бумаге. это то что мы видим глазами то что мы называем интуитивно символы. 

A repertoire of glyphs makes up a font

далее следует кусок о том какая связь между characters и glyphs. 
понятно что одному character(code point) может соотвестовать куча глифов. это понятно ибо 
буква "А" ее начертание на экране в форме глифа может быть какое угодно разное в  зависимости от шрифта. далее один глиф может быть результатом нескольких символов.( пока я знаю только 
один пример. символ "f" + "i" а на экране будет один глиф так называемый "fi"). еще раз подчеркну это не такой случай что у нас есть один code point и он имеет глиф %глиф% и второй code point имеет тот же самый глиф. нет! это когда у нас два разных code point в суммме отображаются в форме одного глифа. пример символ "f" + символ "i" на экране могут быть выражены в форме единого глифа "fi" (точный глиф ненашел.)
прикольно то что из за разных шрифтов символ может иметь разный вид в виде глифа. пример
буква "A" в форме жирной A или в форме курсивной A. это понятно. но вот в арабском
там буква\символ имеет разное начертание в зависимости от ее положения внутри слова!
в любом случае это уже проблема шрифта понять какой глиф нужно юзать для символа в зависимости
от всех там факторов ее положения в слове итп, с точки зрения юникода и его code point он остается один и тотже безизменения для символа!
	- alphabet vs script ?
script переводится система письменности. 
алфавит это частный случай системы письменности.
когда алфавит то буква обозначает звук. такая система пиьмсменности подразделяется как алфавит.
в других системах письменности там буква означает другое.
есть системы письменности где символ означает слог. у японцев так. такая система письменности
относится к типу syllable. это не алфавит. есть система письменности где символ означает слово
целиком как у китайцев. вроде как этот scipt относится к logographic. виды скрипов смотри на вики = https://en.wikipedia.org/wiki/List_of_writing_systems.
также вот такое предложение встретил -  For non-alphabetic scripts such as East Asian scripts... тоесть здесь хорошо видно что азиатские системы написания они неалфавитные.

насколько я понял одно дело character в смысле юникода. тоесть есть некоторй символ и юникод
ему в соотвествие ставит число code point.  но если мы говорим про экран или бумагу там где
мы глазами уже видим символы то тут есть разница или фишка в том что если мы возьмем на экране
кусок картинки которая в нашем понимании является отдельным символом и захотим узнать как эта картинка выглядит в виде code point то в одном случае у данной картинки будет один code point а в другом случае у данной картинки ее будет кодировать несколько code point. потому что символ на экране может состоять из нескольких глифов наложенных друг на друга и каждый глиф может кодиоваться отдедльным code point.

font - на входе у него поток code points а на выходе поток глифов. на экране\бумаге.





	- independenet glyph vs ligature glyph
	- #10, “Unicode Collation Algorithm,”
	- пока непонятно юникод стандарт он както про глифы 
чтото прописывает или он заканчивается на байтовом уровне?



